<html lang="en-US"><head>
      <meta name="citation_pii" content="S0031320317302327">
<meta name="citation_issn" content="0031-3203">
<meta name="citation_volume" content="71">
<meta name="citation_lastpage" content="143">
<meta name="citation_publisher" content="Pergamon">
<meta name="citation_firstpage" content="132">
<meta name="citation_journal_title" content="Pattern Recognition">
<meta name="citation_type" content="JOUR">
<meta name="citation_doi" content="10.1016/j.patcog.2017.06.009">
<meta name="dc.identifier" content="10.1016/j.patcog.2017.06.009">
<meta name="citation_article_type" content="Full-length article">
<meta property="og:description" content="Head pose estimation is an old problem that is recently receiving new attention because of possible applications in human-robot interaction, augmented…">
<meta property="og:image" content="https://ars.els-cdn.com/content/image/1-s2.0-S0031320317X00071-cov150h.gif">
<meta name="citation_title" content="Head pose estimation in the wild using Convolutional Neural Networks and adaptive gradient methods">
<meta property="og:title" content="Head pose estimation in the wild using Convolutional Neural Networks and adaptive gradient methods">
<meta name="citation_publication_date" content="2017/11/01">
<meta name="citation_online_date" content="2017/06/03">
<meta name="robots" content="INDEX,FOLLOW,NOARCHIVE,NOCACHE,NOODP,NOYDIR">
      <title>Head pose estimation in the wild using Convolutional Neural Networks and adaptive gradient methods - ScienceDirect</title>
      <link rel="canonical" href="https://www.sciencedirect.com/science/article/pii/S0031320317302327">
      <meta property="og:type" content="article">
      <meta name="viewport" content="initial-scale=1">
      <meta name="SDTech" content="Proudly brought to you by the SD Technology team">
      <script async="" src="https://cdn.pendo.io/agent/static/d6c1d995-bc7e-4e53-77f1-2ea4ecbb9565/pendo.js"></script><script type="text/javascript">(function newRelicBrowserProSPA() {
  ;
  window.NREUM || (NREUM = {});
  NREUM.init = {
    privacy: {
      cookies_enabled: true
    },
    ajax: {
      deny_list: ["bam-cell.nr-data.net"]
    }
  };
  ;
  NREUM.loader_config = {
    accountID: "2128461",
    trustKey: "2038175",
    agentID: "1118783207",
    licenseKey: "7ac4127487",
    applicationID: "814813181"
  };
  ;
  NREUM.info = {
    beacon: "bam.nr-data.net",
    errorBeacon: "bam.nr-data.net",
    licenseKey: "7ac4127487",
    applicationID: "814813181",
    sa: 1
  };
  ; /*! For license information please see nr-loader-spa-1.238.0.min.js.LICENSE.txt */
  (() => {
    "use strict";

    var e,
      t,
      r = {
        5763: (e, t, r) => {
          r.d(t, {
            P_: () => f,
            Mt: () => p,
            C5: () => s,
            DL: () => v,
            OP: () => T,
            lF: () => D,
            Yu: () => y,
            Dg: () => h,
            CX: () => c,
            GE: () => b,
            sU: () => _
          });
          var n = r(8632),
            i = r(9567);
          const o = {
              beacon: n.ce.beacon,
              errorBeacon: n.ce.errorBeacon,
              licenseKey: void 0,
              applicationID: void 0,
              sa: void 0,
              queueTime: void 0,
              applicationTime: void 0,
              ttGuid: void 0,
              user: void 0,
              account: void 0,
              product: void 0,
              extra: void 0,
              jsAttributes: {},
              userAttributes: void 0,
              atts: void 0,
              transactionName: void 0,
              tNamePlain: void 0
            },
            a = {};
          function s(e) {
            if (!e) throw new Error("All info objects require an agent identifier!");
            if (!a[e]) throw new Error("Info for ".concat(e, " was never set"));
            return a[e];
          }
          function c(e, t) {
            if (!e) throw new Error("All info objects require an agent identifier!");
            a[e] = (0, i.D)(t, o), (0, n.Qy)(e, a[e], "info");
          }
          var u = r(7056);
          const d = () => {
              const e = {
                blockSelector: "[data-nr-block]",
                maskInputOptions: {
                  password: !0
                }
              };
              return {
                allow_bfcache: !0,
                privacy: {
                  cookies_enabled: !0
                },
                ajax: {
                  deny_list: void 0,
                  block_internal: !0,
                  enabled: !0,
                  harvestTimeSeconds: 10
                },
                distributed_tracing: {
                  enabled: void 0,
                  exclude_newrelic_header: void 0,
                  cors_use_newrelic_header: void 0,
                  cors_use_tracecontext_headers: void 0,
                  allowed_origins: void 0
                },
                session: {
                  domain: void 0,
                  expiresMs: u.oD,
                  inactiveMs: u.Hb
                },
                ssl: void 0,
                obfuscate: void 0,
                jserrors: {
                  enabled: !0,
                  harvestTimeSeconds: 10
                },
                metrics: {
                  enabled: !0
                },
                page_action: {
                  enabled: !0,
                  harvestTimeSeconds: 30
                },
                page_view_event: {
                  enabled: !0
                },
                page_view_timing: {
                  enabled: !0,
                  harvestTimeSeconds: 30,
                  long_task: !1
                },
                session_trace: {
                  enabled: !0,
                  harvestTimeSeconds: 10
                },
                harvest: {
                  tooManyRequestsDelay: 60
                },
                session_replay: {
                  enabled: !1,
                  harvestTimeSeconds: 60,
                  sampleRate: .1,
                  errorSampleRate: .1,
                  maskTextSelector: "*",
                  maskAllInputs: !0,
                  get blockClass() {
                    return "nr-block";
                  },
                  get ignoreClass() {
                    return "nr-ignore";
                  },
                  get maskTextClass() {
                    return "nr-mask";
                  },
                  get blockSelector() {
                    return e.blockSelector;
                  },
                  set blockSelector(t) {
                    e.blockSelector += ",".concat(t);
                  },
                  get maskInputOptions() {
                    return e.maskInputOptions;
                  },
                  set maskInputOptions(t) {
                    e.maskInputOptions = {
                      ...t,
                      password: !0
                    };
                  }
                },
                spa: {
                  enabled: !0,
                  harvestTimeSeconds: 10
                }
              };
            },
            l = {};
          function f(e) {
            if (!e) throw new Error("All configuration objects require an agent identifier!");
            if (!l[e]) throw new Error("Configuration for ".concat(e, " was never set"));
            return l[e];
          }
          function h(e, t) {
            if (!e) throw new Error("All configuration objects require an agent identifier!");
            l[e] = (0, i.D)(t, d()), (0, n.Qy)(e, l[e], "config");
          }
          function p(e, t) {
            if (!e) throw new Error("All configuration objects require an agent identifier!");
            var r = f(e);
            if (r) {
              for (var n = t.split("."), i = 0; i < n.length - 1; i++) if ("object" != typeof (r = r[n[i]])) return;
              r = r[n[n.length - 1]];
            }
            return r;
          }
          const g = {
              accountID: void 0,
              trustKey: void 0,
              agentID: void 0,
              licenseKey: void 0,
              applicationID: void 0,
              xpid: void 0
            },
            m = {};
          function v(e) {
            if (!e) throw new Error("All loader-config objects require an agent identifier!");
            if (!m[e]) throw new Error("LoaderConfig for ".concat(e, " was never set"));
            return m[e];
          }
          function b(e, t) {
            if (!e) throw new Error("All loader-config objects require an agent identifier!");
            m[e] = (0, i.D)(t, g), (0, n.Qy)(e, m[e], "loader_config");
          }
          const y = (0, n.mF)().o;
          var w = r(385),
            A = r(6818);
          const x = {
              buildEnv: A.Re,
              bytesSent: {},
              queryBytesSent: {},
              customTransaction: void 0,
              disabled: !1,
              distMethod: A.gF,
              isolatedBacklog: !1,
              loaderType: void 0,
              maxBytes: 3e4,
              offset: Math.floor(w._A?.performance?.timeOrigin || w._A?.performance?.timing?.navigationStart || Date.now()),
              onerror: void 0,
              origin: "" + w._A.location,
              ptid: void 0,
              releaseIds: {},
              session: void 0,
              xhrWrappable: "function" == typeof w._A.XMLHttpRequest?.prototype?.addEventListener,
              version: A.q4,
              denyList: void 0
            },
            E = {};
          function T(e) {
            if (!e) throw new Error("All runtime objects require an agent identifier!");
            if (!E[e]) throw new Error("Runtime for ".concat(e, " was never set"));
            return E[e];
          }
          function _(e, t) {
            if (!e) throw new Error("All runtime objects require an agent identifier!");
            E[e] = (0, i.D)(t, x), (0, n.Qy)(e, E[e], "runtime");
          }
          function D(e) {
            return function (e) {
              try {
                const t = s(e);
                return !!t.licenseKey && !!t.errorBeacon && !!t.applicationID;
              } catch (e) {
                return !1;
              }
            }(e);
          }
        },
        9567: (e, t, r) => {
          r.d(t, {
            D: () => i
          });
          var n = r(50);
          function i(e, t) {
            try {
              if (!e || "object" != typeof e) return (0, n.Z)("Setting a Configurable requires an object as input");
              if (!t || "object" != typeof t) return (0, n.Z)("Setting a Configurable requires a model to set its initial properties");
              const r = Object.create(Object.getPrototypeOf(t), Object.getOwnPropertyDescriptors(t)),
                o = 0 === Object.keys(r).length ? e : r;
              for (let a in o) if (void 0 !== e[a]) try {
                "object" == typeof e[a] && "object" == typeof t[a] ? r[a] = i(e[a], t[a]) : r[a] = e[a];
              } catch (e) {
                (0, n.Z)("An error occurred while setting a property of a Configurable", e);
              }
              return r;
            } catch (e) {
              (0, n.Z)("An error occured while setting a Configurable", e);
            }
          }
        },
        6818: (e, t, r) => {
          r.d(t, {
            Re: () => i,
            gF: () => o,
            q4: () => n
          });
          const n = "1.238.0",
            i = "PROD",
            o = "CDN";
        },
        385: (e, t, r) => {
          r.d(t, {
            FN: () => a,
            IF: () => u,
            Nk: () => l,
            Tt: () => s,
            _A: () => o,
            il: () => n,
            pL: () => c,
            v6: () => i,
            w1: () => d
          });
          const n = "undefined" != typeof window && !!window.document,
            i = "undefined" != typeof WorkerGlobalScope && ("undefined" != typeof self && self instanceof WorkerGlobalScope && self.navigator instanceof WorkerNavigator || "undefined" != typeof globalThis && globalThis instanceof WorkerGlobalScope && globalThis.navigator instanceof WorkerNavigator),
            o = n ? window : "undefined" != typeof WorkerGlobalScope && ("undefined" != typeof self && self instanceof WorkerGlobalScope && self || "undefined" != typeof globalThis && globalThis instanceof WorkerGlobalScope && globalThis),
            a = "" + o?.location,
            s = /iPad|iPhone|iPod/.test(navigator.userAgent),
            c = s && "undefined" == typeof SharedWorker,
            u = (() => {
              const e = navigator.userAgent.match(/Firefox[/\s](\d+\.\d+)/);
              return Array.isArray(e) && e.length >= 2 ? +e[1] : 0;
            })(),
            d = Boolean(n && window.document.documentMode),
            l = !!navigator.sendBeacon;
        },
        1117: (e, t, r) => {
          r.d(t, {
            w: () => o
          });
          var n = r(50);
          const i = {
            agentIdentifier: "",
            ee: void 0
          };
          class o {
            constructor(e) {
              try {
                if ("object" != typeof e) return (0, n.Z)("shared context requires an object as input");
                this.sharedContext = {}, Object.assign(this.sharedContext, i), Object.entries(e).forEach(e => {
                  let [t, r] = e;
                  Object.keys(i).includes(t) && (this.sharedContext[t] = r);
                });
              } catch (e) {
                (0, n.Z)("An error occured while setting SharedContext", e);
              }
            }
          }
        },
        8e3: (e, t, r) => {
          r.d(t, {
            L: () => d,
            R: () => c
          });
          var n = r(8325),
            i = r(1284),
            o = r(4322),
            a = r(3325);
          const s = {};
          function c(e, t) {
            const r = {
              staged: !1,
              priority: a.p[t] || 0
            };
            u(e), s[e].get(t) || s[e].set(t, r);
          }
          function u(e) {
            e && (s[e] || (s[e] = new Map()));
          }
          function d() {
            let e = arguments.length > 0 && void 0 !== arguments[0] ? arguments[0] : "",
              t = arguments.length > 1 && void 0 !== arguments[1] ? arguments[1] : "feature";
            if (u(e), !e || !s[e].get(t)) return a(t);
            s[e].get(t).staged = !0;
            const r = [...s[e]];
            function a(t) {
              const r = e ? n.ee.get(e) : n.ee,
                a = o.X.handlers;
              if (r.backlog && a) {
                var s = r.backlog[t],
                  c = a[t];
                if (c) {
                  for (var u = 0; s && u < s.length; ++u) l(s[u], c);
                  (0, i.D)(c, function (e, t) {
                    (0, i.D)(t, function (t, r) {
                      r[0].on(e, r[1]);
                    });
                  });
                }
                delete a[t], r.backlog[t] = null, r.emit("drain-" + t, []);
              }
            }
            r.every(e => {
              let [t, r] = e;
              return r.staged;
            }) && (r.sort((e, t) => e[1].priority - t[1].priority), r.forEach(e => {
              let [t] = e;
              a(t);
            }));
          }
          function l(e, t) {
            var r = e[1];
            (0, i.D)(t[r], function (t, r) {
              var n = e[0];
              if (r[0] === n) {
                var i = r[1],
                  o = e[3],
                  a = e[2];
                i.apply(o, a);
              }
            });
          }
        },
        8325: (e, t, r) => {
          r.d(t, {
            A: () => c,
            ee: () => u
          });
          var n = r(8632),
            i = r(2210),
            o = r(5763);
          class a {
            constructor(e) {
              this.contextId = e;
            }
          }
          var s = r(3117);
          const c = "nr@context:".concat(s.a),
            u = function e(t, r) {
              var n = {},
                s = {},
                d = {},
                f = !1;
              try {
                f = 16 === r.length && (0, o.OP)(r).isolatedBacklog;
              } catch (e) {}
              var h = {
                on: g,
                addEventListener: g,
                removeEventListener: function (e, t) {
                  var r = n[e];
                  if (!r) return;
                  for (var i = 0; i < r.length; i++) r[i] === t && r.splice(i, 1);
                },
                emit: function (e, r, n, i, o) {
                  !1 !== o && (o = !0);
                  if (u.aborted && !i) return;
                  t && o && t.emit(e, r, n);
                  for (var a = p(n), c = m(e), d = c.length, l = 0; l < d; l++) c[l].apply(a, r);
                  var f = b()[s[e]];
                  f && f.push([h, e, r, a]);
                  return a;
                },
                get: v,
                listeners: m,
                context: p,
                buffer: function (e, t) {
                  const r = b();
                  if (t = t || "feature", h.aborted) return;
                  Object.entries(e || {}).forEach(e => {
                    let [n, i] = e;
                    s[i] = t, t in r || (r[t] = []);
                  });
                },
                abort: l,
                aborted: !1,
                isBuffering: function (e) {
                  return !!b()[s[e]];
                },
                debugId: r,
                backlog: f ? {} : t && "object" == typeof t.backlog ? t.backlog : {}
              };
              return h;
              function p(e) {
                return e && e instanceof a ? e : e ? (0, i.X)(e, c, () => new a(c)) : new a(c);
              }
              function g(e, t) {
                n[e] = m(e).concat(t);
              }
              function m(e) {
                return n[e] || [];
              }
              function v(t) {
                return d[t] = d[t] || e(h, t);
              }
              function b() {
                return h.backlog;
              }
            }(void 0, "globalEE"),
            d = (0, n.fP)();
          function l() {
            u.aborted = !0, u.backlog = {};
          }
          d.ee || (d.ee = u);
        },
        5546: (e, t, r) => {
          r.d(t, {
            E: () => n,
            p: () => i
          });
          var n = r(8325).ee.get("handle");
          function i(e, t, r, i, o) {
            o ? (o.buffer([e], i), o.emit(e, t, r)) : (n.buffer([e], i), n.emit(e, t, r));
          }
        },
        4322: (e, t, r) => {
          r.d(t, {
            X: () => o
          });
          var n = r(5546);
          o.on = a;
          var i = o.handlers = {};
          function o(e, t, r, o) {
            a(o || n.E, i, e, t, r);
          }
          function a(e, t, r, i, o) {
            o || (o = "feature"), e || (e = n.E);
            var a = t[o] = t[o] || {};
            (a[r] = a[r] || []).push([e, i]);
          }
        },
        3239: (e, t, r) => {
          r.d(t, {
            bP: () => s,
            iz: () => c,
            m$: () => a
          });
          var n = r(385);
          let i = !1,
            o = !1;
          try {
            const e = {
              get passive() {
                return i = !0, !1;
              },
              get signal() {
                return o = !0, !1;
              }
            };
            n._A.addEventListener("test", null, e), n._A.removeEventListener("test", null, e);
          } catch (e) {}
          function a(e, t) {
            return i || o ? {
              capture: !!e,
              passive: i,
              signal: t
            } : !!e;
          }
          function s(e, t) {
            let r = arguments.length > 2 && void 0 !== arguments[2] && arguments[2],
              n = arguments.length > 3 ? arguments[3] : void 0;
            window.addEventListener(e, t, a(r, n));
          }
          function c(e, t) {
            let r = arguments.length > 2 && void 0 !== arguments[2] && arguments[2],
              n = arguments.length > 3 ? arguments[3] : void 0;
            document.addEventListener(e, t, a(r, n));
          }
        },
        3117: (e, t, r) => {
          r.d(t, {
            a: () => n
          });
          const n = (0, r(4402).Rl)();
        },
        4402: (e, t, r) => {
          r.d(t, {
            Ht: () => u,
            M: () => c,
            Rl: () => a,
            ky: () => s
          });
          var n = r(385);
          const i = "xxxxxxxx-xxxx-4xxx-yxxx-xxxxxxxxxxxx";
          function o(e, t) {
            return e ? 15 & e[t] : 16 * Math.random() | 0;
          }
          function a() {
            const e = n._A?.crypto || n._A?.msCrypto;
            let t,
              r = 0;
            return e && e.getRandomValues && (t = e.getRandomValues(new Uint8Array(31))), i.split("").map(e => "x" === e ? o(t, ++r).toString(16) : "y" === e ? (3 & o() | 8).toString(16) : e).join("");
          }
          function s(e) {
            const t = n._A?.crypto || n._A?.msCrypto;
            let r,
              i = 0;
            t && t.getRandomValues && (r = t.getRandomValues(new Uint8Array(31)));
            const a = [];
            for (var s = 0; s < e; s++) a.push(o(r, ++i).toString(16));
            return a.join("");
          }
          function c() {
            return s(16);
          }
          function u() {
            return s(32);
          }
        },
        7056: (e, t, r) => {
          r.d(t, {
            Bq: () => n,
            Hb: () => o,
            oD: () => i
          });
          const n = "NRBA",
            i = 144e5,
            o = 18e5;
        },
        7894: (e, t, r) => {
          function n() {
            return Math.round(performance.now());
          }
          r.d(t, {
            z: () => n
          });
        },
        7243: (e, t, r) => {
          r.d(t, {
            e: () => o
          });
          var n = r(385),
            i = {};
          function o(e) {
            if (e in i) return i[e];
            if (0 === (e || "").indexOf("data:")) return {
              protocol: "data"
            };
            let t;
            var r = n._A?.location,
              o = {};
            if (n.il) t = document.createElement("a"), t.href = e;else try {
              t = new URL(e, r.href);
            } catch (e) {
              return o;
            }
            o.port = t.port;
            var a = t.href.split("://");
            !o.port && a[1] && (o.port = a[1].split("/")[0].split("@").pop().split(":")[1]), o.port && "0" !== o.port || (o.port = "https" === a[0] ? "443" : "80"), o.hostname = t.hostname || r.hostname, o.pathname = t.pathname, o.protocol = a[0], "/" !== o.pathname.charAt(0) && (o.pathname = "/" + o.pathname);
            var s = !t.protocol || ":" === t.protocol || t.protocol === r.protocol,
              c = t.hostname === r.hostname && t.port === r.port;
            return o.sameOrigin = s && (!t.hostname || c), "/" === o.pathname && (i[e] = o), o;
          }
        },
        50: (e, t, r) => {
          function n(e, t) {
            "function" == typeof console.warn && (console.warn("New Relic: ".concat(e)), t && console.warn(t));
          }
          r.d(t, {
            Z: () => n
          });
        },
        2587: (e, t, r) => {
          r.d(t, {
            N: () => c,
            T: () => u
          });
          var n = r(8325),
            i = r(5546),
            o = r(8e3),
            a = r(3325);
          const s = {
            stn: [a.D.sessionTrace],
            err: [a.D.jserrors, a.D.metrics],
            ins: [a.D.pageAction],
            spa: [a.D.spa],
            sr: [a.D.sessionReplay, a.D.sessionTrace]
          };
          function c(e, t) {
            const r = n.ee.get(t);
            e && "object" == typeof e && (Object.entries(e).forEach(e => {
              let [t, n] = e;
              void 0 === u[t] && (s[t] ? s[t].forEach(e => {
                n ? (0, i.p)("feat-" + t, [], void 0, e, r) : (0, i.p)("block-" + t, [], void 0, e, r), (0, i.p)("rumresp-" + t, [Boolean(n)], void 0, e, r);
              }) : n && (0, i.p)("feat-" + t, [], void 0, void 0, r), u[t] = Boolean(n));
            }), Object.keys(s).forEach(e => {
              void 0 === u[e] && (s[e]?.forEach(t => (0, i.p)("rumresp-" + e, [!1], void 0, t, r)), u[e] = !1);
            }), (0, o.L)(t, a.D.pageViewEvent));
          }
          const u = {};
        },
        2210: (e, t, r) => {
          r.d(t, {
            X: () => i
          });
          var n = Object.prototype.hasOwnProperty;
          function i(e, t, r) {
            if (n.call(e, t)) return e[t];
            var i = r();
            if (Object.defineProperty && Object.keys) try {
              return Object.defineProperty(e, t, {
                value: i,
                writable: !0,
                enumerable: !1
              }), i;
            } catch (e) {}
            return e[t] = i, i;
          }
        },
        1284: (e, t, r) => {
          r.d(t, {
            D: () => n
          });
          const n = (e, t) => Object.entries(e || {}).map(e => {
            let [r, n] = e;
            return t(r, n);
          });
        },
        4351: (e, t, r) => {
          r.d(t, {
            P: () => o
          });
          var n = r(8325);
          const i = () => {
            const e = new WeakSet();
            return (t, r) => {
              if ("object" == typeof r && null !== r) {
                if (e.has(r)) return;
                e.add(r);
              }
              return r;
            };
          };
          function o(e) {
            try {
              return JSON.stringify(e, i());
            } catch (e) {
              try {
                n.ee.emit("internal-error", [e]);
              } catch (e) {}
            }
          }
        },
        3960: (e, t, r) => {
          r.d(t, {
            K: () => a,
            b: () => o
          });
          var n = r(3239);
          function i() {
            return "undefined" == typeof document || "complete" === document.readyState;
          }
          function o(e, t) {
            if (i()) return e();
            (0, n.bP)("load", e, t);
          }
          function a(e) {
            if (i()) return e();
            (0, n.iz)("DOMContentLoaded", e);
          }
        },
        8632: (e, t, r) => {
          r.d(t, {
            EZ: () => u,
            Qy: () => c,
            ce: () => o,
            fP: () => a,
            gG: () => d,
            mF: () => s
          });
          var n = r(7894),
            i = r(385);
          const o = {
            beacon: "bam.nr-data.net",
            errorBeacon: "bam.nr-data.net"
          };
          function a() {
            return i._A.NREUM || (i._A.NREUM = {}), void 0 === i._A.newrelic && (i._A.newrelic = i._A.NREUM), i._A.NREUM;
          }
          function s() {
            let e = a();
            return e.o || (e.o = {
              ST: i._A.setTimeout,
              SI: i._A.setImmediate,
              CT: i._A.clearTimeout,
              XHR: i._A.XMLHttpRequest,
              REQ: i._A.Request,
              EV: i._A.Event,
              PR: i._A.Promise,
              MO: i._A.MutationObserver,
              FETCH: i._A.fetch
            }), e;
          }
          function c(e, t, r) {
            let i = a();
            const o = i.initializedAgents || {},
              s = o[e] || {};
            return Object.keys(s).length || (s.initializedAt = {
              ms: (0, n.z)(),
              date: new Date()
            }), i.initializedAgents = {
              ...o,
              [e]: {
                ...s,
                [r]: t
              }
            }, i;
          }
          function u(e, t) {
            a()[e] = t;
          }
          function d() {
            return function () {
              let e = a();
              const t = e.info || {};
              e.info = {
                beacon: o.beacon,
                errorBeacon: o.errorBeacon,
                ...t
              };
            }(), function () {
              let e = a();
              const t = e.init || {};
              e.init = {
                ...t
              };
            }(), s(), function () {
              let e = a();
              const t = e.loader_config || {};
              e.loader_config = {
                ...t
              };
            }(), a();
          }
        },
        7956: (e, t, r) => {
          r.d(t, {
            N: () => i
          });
          var n = r(3239);
          function i(e) {
            let t = arguments.length > 1 && void 0 !== arguments[1] && arguments[1],
              r = arguments.length > 2 ? arguments[2] : void 0,
              i = arguments.length > 3 ? arguments[3] : void 0;
            return void (0, n.iz)("visibilitychange", function () {
              if (t) return void ("hidden" == document.visibilityState && e());
              e(document.visibilityState);
            }, r, i);
          }
        },
        1214: (e, t, r) => {
          r.d(t, {
            em: () => b,
            u5: () => j,
            QU: () => O,
            _L: () => I,
            Gm: () => H,
            Lg: () => L,
            BV: () => G,
            Kf: () => K
          });
          var n = r(8325),
            i = r(3117);
          const o = "nr@original:".concat(i.a);
          var a = Object.prototype.hasOwnProperty,
            s = !1;
          function c(e, t) {
            return e || (e = n.ee), r.inPlace = function (e, t, n, i, o) {
              n || (n = "");
              const a = "-" === n.charAt(0);
              for (let s = 0; s < t.length; s++) {
                const c = t[s],
                  u = e[c];
                d(u) || (e[c] = r(u, a ? c + n : n, i, c, o));
              }
            }, r.flag = o, r;
            function r(t, r, n, s, c) {
              return d(t) ? t : (r || (r = ""), nrWrapper[o] = t, function (e, t, r) {
                if (Object.defineProperty && Object.keys) try {
                  return Object.keys(e).forEach(function (r) {
                    Object.defineProperty(t, r, {
                      get: function () {
                        return e[r];
                      },
                      set: function (t) {
                        return e[r] = t, t;
                      }
                    });
                  }), t;
                } catch (e) {
                  u([e], r);
                }
                for (var n in e) a.call(e, n) && (t[n] = e[n]);
              }(t, nrWrapper, e), nrWrapper);
              function nrWrapper() {
                var o, a, d, l;
                try {
                  a = this, o = [...arguments], d = "function" == typeof n ? n(o, a) : n || {};
                } catch (t) {
                  u([t, "", [o, a, s], d], e);
                }
                i(r + "start", [o, a, s], d, c);
                try {
                  return l = t.apply(a, o);
                } catch (e) {
                  throw i(r + "err", [o, a, e], d, c), e;
                } finally {
                  i(r + "end", [o, a, l], d, c);
                }
              }
            }
            function i(r, n, i, o) {
              if (!s || t) {
                var a = s;
                s = !0;
                try {
                  e.emit(r, n, i, t, o);
                } catch (t) {
                  u([t, r, n, i], e);
                }
                s = a;
              }
            }
          }
          function u(e, t) {
            t || (t = n.ee);
            try {
              t.emit("internal-error", e);
            } catch (e) {}
          }
          function d(e) {
            return !(e && e instanceof Function && e.apply && !e[o]);
          }
          var l = r(2210),
            f = r(385);
          const h = {},
            p = f._A.XMLHttpRequest,
            g = "addEventListener",
            m = "removeEventListener",
            v = "nr@wrapped:".concat(n.A);
          function b(e) {
            var t = function (e) {
              return (e || n.ee).get("events");
            }(e);
            if (h[t.debugId]++) return t;
            h[t.debugId] = 1;
            var r = c(t, !0);
            function i(e) {
              r.inPlace(e, [g, m], "-", o);
            }
            function o(e, t) {
              return e[1];
            }
            return "getPrototypeOf" in Object && (f.il && y(document, i), y(f._A, i), y(p.prototype, i)), t.on(g + "-start", function (e, t) {
              var n = e[1];
              if (null !== n && ("function" == typeof n || "object" == typeof n)) {
                var i = (0, l.X)(n, v, function () {
                  var e = {
                    object: function () {
                      if ("function" != typeof n.handleEvent) return;
                      return n.handleEvent.apply(n, arguments);
                    },
                    function: n
                  }[typeof n];
                  return e ? r(e, "fn-", null, e.name || "anonymous") : n;
                });
                this.wrapped = e[1] = i;
              }
            }), t.on(m + "-start", function (e) {
              e[1] = this.wrapped || e[1];
            }), t;
          }
          function y(e, t) {
            let r = e;
            for (; "object" == typeof r && !Object.prototype.hasOwnProperty.call(r, g);) r = Object.getPrototypeOf(r);
            for (var n = arguments.length, i = new Array(n > 2 ? n - 2 : 0), o = 2; o < n; o++) i[o - 2] = arguments[o];
            r && t(r, ...i);
          }
          var w = "fetch-",
            A = w + "body-",
            x = ["arrayBuffer", "blob", "json", "text", "formData"],
            E = f._A.Request,
            T = f._A.Response,
            _ = "prototype";
          const D = {};
          function j(e) {
            const t = function (e) {
              return (e || n.ee).get("fetch");
            }(e);
            if (!(E && T && f._A.fetch)) return t;
            if (D[t.debugId]++) return t;
            function r(e, r, i) {
              var o = e[r];
              "function" == typeof o && (e[r] = function () {
                var e,
                  r = [...arguments],
                  a = {};
                t.emit(i + "before-start", [r], a), a[n.A] && a[n.A].dt && (e = a[n.A].dt);
                var s = o.apply(this, r);
                return t.emit(i + "start", [r, e], s), s.then(function (e) {
                  return t.emit(i + "end", [null, e], s), e;
                }, function (e) {
                  throw t.emit(i + "end", [e], s), e;
                });
              });
            }
            return D[t.debugId] = 1, x.forEach(e => {
              r(E[_], e, A), r(T[_], e, A);
            }), r(f._A, "fetch", w), t.on(w + "end", function (e, r) {
              var n = this;
              if (r) {
                var i = r.headers.get("content-length");
                null !== i && (n.rxSize = i), t.emit(w + "done", [null, r], n);
              } else t.emit(w + "done", [e], n);
            }), t;
          }
          const C = {},
            N = ["pushState", "replaceState"];
          function O(e) {
            const t = function (e) {
              return (e || n.ee).get("history");
            }(e);
            return !f.il || C[t.debugId]++ || (C[t.debugId] = 1, c(t).inPlace(window.history, N, "-")), t;
          }
          var S = r(3239);
          const P = {},
            R = ["appendChild", "insertBefore", "replaceChild"];
          function I(e) {
            const t = function (e) {
              return (e || n.ee).get("jsonp");
            }(e);
            if (!f.il || P[t.debugId]) return t;
            P[t.debugId] = !0;
            var r = c(t),
              i = /[?&](?:callback|cb)=([^&#]+)/,
              o = /(.*)\.([^.]+)/,
              a = /^(\w+)(\.|$)(.*)$/;
            function s(e, t) {
              if (!e) return t;
              const r = e.match(a),
                n = r[1];
              return s(r[3], t[n]);
            }
            return r.inPlace(Node.prototype, R, "dom-"), t.on("dom-start", function (e) {
              !function (e) {
                if (!e || "string" != typeof e.nodeName || "script" !== e.nodeName.toLowerCase()) return;
                if ("function" != typeof e.addEventListener) return;
                var n = (a = e.src, c = a.match(i), c ? c[1] : null);
                var a, c;
                if (!n) return;
                var u = function (e) {
                  var t = e.match(o);
                  if (t && t.length >= 3) return {
                    key: t[2],
                    parent: s(t[1], window)
                  };
                  return {
                    key: e,
                    parent: window
                  };
                }(n);
                if ("function" != typeof u.parent[u.key]) return;
                var d = {};
                function l() {
                  t.emit("jsonp-end", [], d), e.removeEventListener("load", l, (0, S.m$)(!1)), e.removeEventListener("error", f, (0, S.m$)(!1));
                }
                function f() {
                  t.emit("jsonp-error", [], d), t.emit("jsonp-end", [], d), e.removeEventListener("load", l, (0, S.m$)(!1)), e.removeEventListener("error", f, (0, S.m$)(!1));
                }
                r.inPlace(u.parent, [u.key], "cb-", d), e.addEventListener("load", l, (0, S.m$)(!1)), e.addEventListener("error", f, (0, S.m$)(!1)), t.emit("new-jsonp", [e.src], d);
              }(e[0]);
            }), t;
          }
          const k = {};
          function H(e) {
            const t = function (e) {
              return (e || n.ee).get("mutation");
            }(e);
            if (!f.il || k[t.debugId]) return t;
            k[t.debugId] = !0;
            var r = c(t),
              i = f._A.MutationObserver;
            return i && (window.MutationObserver = function (e) {
              return this instanceof i ? new i(r(e, "fn-")) : i.apply(this, arguments);
            }, MutationObserver.prototype = i.prototype), t;
          }
          const z = {};
          function L(e) {
            const t = function (e) {
              return (e || n.ee).get("promise");
            }(e);
            if (z[t.debugId]) return t;
            z[t.debugId] = !0;
            var r = t.context,
              i = c(t),
              a = f._A.Promise;
            return a && function () {
              function e(r) {
                var n = t.context(),
                  o = i(r, "executor-", n, null, !1);
                const s = Reflect.construct(a, [o], e);
                return t.context(s).getCtx = function () {
                  return n;
                }, s;
              }
              f._A.Promise = e, Object.defineProperty(e, "name", {
                value: "Promise"
              }), e.toString = function () {
                return a.toString();
              }, Object.setPrototypeOf(e, a), ["all", "race"].forEach(function (r) {
                const n = a[r];
                e[r] = function (e) {
                  let i = !1;
                  [...(e || [])].forEach(e => {
                    this.resolve(e).then(a("all" === r), a(!1));
                  });
                  const o = n.apply(this, arguments);
                  return o;
                  function a(e) {
                    return function () {
                      t.emit("propagate", [null, !i], o, !1, !1), i = i || !e;
                    };
                  }
                };
              }), ["resolve", "reject"].forEach(function (r) {
                const n = a[r];
                e[r] = function (e) {
                  const r = n.apply(this, arguments);
                  return e !== r && t.emit("propagate", [e, !0], r, !1, !1), r;
                };
              }), e.prototype = a.prototype;
              const n = a.prototype.then;
              a.prototype.then = function () {
                var e = this,
                  o = r(e);
                o.promise = e;
                for (var a = arguments.length, s = new Array(a), c = 0; c < a; c++) s[c] = arguments[c];
                s[0] = i(s[0], "cb-", o, null, !1), s[1] = i(s[1], "cb-", o, null, !1);
                const u = n.apply(this, s);
                return o.nextPromise = u, t.emit("propagate", [e, !0], u, !1, !1), u;
              }, a.prototype.then[o] = n, t.on("executor-start", function (e) {
                e[0] = i(e[0], "resolve-", this, null, !1), e[1] = i(e[1], "resolve-", this, null, !1);
              }), t.on("executor-err", function (e, t, r) {
                e[1](r);
              }), t.on("cb-end", function (e, r, n) {
                t.emit("propagate", [n, !0], this.nextPromise, !1, !1);
              }), t.on("propagate", function (e, r, n) {
                this.getCtx && !r || (this.getCtx = function () {
                  if (e instanceof Promise) var r = t.context(e);
                  return r && r.getCtx ? r.getCtx() : this;
                });
              });
            }(), t;
          }
          const M = {},
            B = "setTimeout",
            F = "setInterval",
            U = "clearTimeout",
            q = "-start",
            Z = "-",
            V = [B, "setImmediate", F, U, "clearImmediate"];
          function G(e) {
            const t = function (e) {
              return (e || n.ee).get("timer");
            }(e);
            if (M[t.debugId]++) return t;
            M[t.debugId] = 1;
            var r = c(t);
            return r.inPlace(f._A, V.slice(0, 2), B + Z), r.inPlace(f._A, V.slice(2, 3), F + Z), r.inPlace(f._A, V.slice(3), U + Z), t.on(F + q, function (e, t, n) {
              e[0] = r(e[0], "fn-", null, n);
            }), t.on(B + q, function (e, t, n) {
              this.method = n, this.timerDuration = isNaN(e[1]) ? 0 : +e[1], e[0] = r(e[0], "fn-", this, n);
            }), t;
          }
          var W = r(50);
          const X = {},
            Q = ["open", "send"];
          function K(e) {
            var t = e || n.ee;
            const r = function (e) {
              return (e || n.ee).get("xhr");
            }(t);
            if (X[r.debugId]++) return r;
            X[r.debugId] = 1, b(t);
            var i = c(r),
              o = f._A.XMLHttpRequest,
              a = f._A.MutationObserver,
              s = f._A.Promise,
              u = f._A.setInterval,
              d = "readystatechange",
              l = ["onload", "onerror", "onabort", "onloadstart", "onloadend", "onprogress", "ontimeout"],
              h = [],
              p = f._A.XMLHttpRequest = function (e) {
                const t = new o(e),
                  n = r.context(t);
                try {
                  r.emit("new-xhr", [t], n), t.addEventListener(d, (a = n, function () {
                    var e = this;
                    e.readyState > 3 && !a.resolved && (a.resolved = !0, r.emit("xhr-resolved", [], e)), i.inPlace(e, l, "fn-", A);
                  }), (0, S.m$)(!1));
                } catch (e) {
                  (0, W.Z)("An error occurred while intercepting XHR", e);
                  try {
                    r.emit("internal-error", [e]);
                  } catch (e) {}
                }
                var a;
                return t;
              };
            function g(e, t) {
              i.inPlace(t, ["onreadystatechange"], "fn-", A);
            }
            if (function (e, t) {
              for (var r in e) t[r] = e[r];
            }(o, p), p.prototype = o.prototype, i.inPlace(p.prototype, Q, "-xhr-", A), r.on("send-xhr-start", function (e, t) {
              g(e, t), function (e) {
                h.push(e), a && (m ? m.then(w) : u ? u(w) : (v = -v, y.data = v));
              }(t);
            }), r.on("open-xhr-start", g), a) {
              var m = s && s.resolve();
              if (!u && !s) {
                var v = 1,
                  y = document.createTextNode(v);
                new a(w).observe(y, {
                  characterData: !0
                });
              }
            } else t.on("fn-end", function (e) {
              e[0] && e[0].type === d || w();
            });
            function w() {
              for (var e = 0; e < h.length; e++) g(0, h[e]);
              h.length && (h = []);
            }
            function A(e, t) {
              return t;
            }
            return r;
          }
        },
        7825: (e, t, r) => {
          r.d(t, {
            t: () => n
          });
          const n = r(3325).D.ajax;
        },
        6660: (e, t, r) => {
          r.d(t, {
            t: () => n
          });
          const n = r(3325).D.jserrors;
        },
        3081: (e, t, r) => {
          r.d(t, {
            gF: () => o,
            mY: () => i,
            t9: () => n,
            vz: () => s,
            xS: () => a
          });
          const n = r(3325).D.metrics,
            i = "sm",
            o = "cm",
            a = "storeSupportabilityMetrics",
            s = "storeEventMetrics";
        },
        4649: (e, t, r) => {
          r.d(t, {
            t: () => n
          });
          const n = r(3325).D.pageAction;
        },
        7633: (e, t, r) => {
          r.d(t, {
            Dz: () => i,
            OJ: () => a,
            qw: () => o,
            t9: () => n
          });
          const n = r(3325).D.pageViewEvent,
            i = "firstbyte",
            o = "domcontent",
            a = "windowload";
        },
        9251: (e, t, r) => {
          r.d(t, {
            t: () => n
          });
          const n = r(3325).D.pageViewTiming;
        },
        3614: (e, t, r) => {
          r.d(t, {
            BST_RESOURCE: () => i,
            END: () => s,
            FEATURE_NAME: () => n,
            FN_END: () => u,
            FN_START: () => c,
            PUSH_STATE: () => d,
            RESOURCE: () => o,
            START: () => a
          });
          const n = r(3325).D.sessionTrace,
            i = "bstResource",
            o = "resource",
            a = "-start",
            s = "-end",
            c = "fn" + a,
            u = "fn" + s,
            d = "pushState";
        },
        7836: (e, t, r) => {
          r.d(t, {
            BODY: () => x,
            CB_END: () => E,
            CB_START: () => u,
            END: () => A,
            FEATURE_NAME: () => i,
            FETCH: () => _,
            FETCH_BODY: () => v,
            FETCH_DONE: () => m,
            FETCH_START: () => g,
            FN_END: () => c,
            FN_START: () => s,
            INTERACTION: () => f,
            INTERACTION_API: () => d,
            INTERACTION_EVENTS: () => o,
            JSONP_END: () => b,
            JSONP_NODE: () => p,
            JS_TIME: () => T,
            MAX_TIMER_BUDGET: () => a,
            REMAINING: () => l,
            SPA_NODE: () => h,
            START: () => w,
            originalSetTimeout: () => y
          });
          var n = r(5763);
          const i = r(3325).D.spa,
            o = ["click", "submit", "keypress", "keydown", "keyup", "change"],
            a = 999,
            s = "fn-start",
            c = "fn-end",
            u = "cb-start",
            d = "api-ixn-",
            l = "remaining",
            f = "interaction",
            h = "spaNode",
            p = "jsonpNode",
            g = "fetch-start",
            m = "fetch-done",
            v = "fetch-body-",
            b = "jsonp-end",
            y = n.Yu.ST,
            w = "-start",
            A = "-end",
            x = "-body",
            E = "cb" + A,
            T = "jsTime",
            _ = "fetch";
        },
        5938: (e, t, r) => {
          r.d(t, {
            W: () => o
          });
          var n = r(5763),
            i = r(8325);
          class o {
            constructor(e, t, r) {
              this.agentIdentifier = e, this.aggregator = t, this.ee = i.ee.get(e, (0, n.OP)(this.agentIdentifier).isolatedBacklog), this.featureName = r, this.blocked = !1;
            }
          }
        },
        9144: (e, t, r) => {
          r.d(t, {
            j: () => m
          });
          var n = r(3325),
            i = r(5763),
            o = r(5546),
            a = r(8325),
            s = r(7894),
            c = r(8e3),
            u = r(3960),
            d = r(385),
            l = r(50),
            f = r(3081),
            h = r(8632);
          function p() {
            const e = (0, h.gG)();
            ["setErrorHandler", "finished", "addToTrace", "inlineHit", "addRelease", "addPageAction", "setCurrentRouteName", "setPageViewName", "setCustomAttribute", "interaction", "noticeError", "setUserId", "setApplicationVersion"].forEach(t => {
              e[t] = function () {
                for (var r = arguments.length, n = new Array(r), i = 0; i < r; i++) n[i] = arguments[i];
                return function (t) {
                  for (var r = arguments.length, n = new Array(r > 1 ? r - 1 : 0), i = 1; i < r; i++) n[i - 1] = arguments[i];
                  let o = [];
                  return Object.values(e.initializedAgents).forEach(e => {
                    e.exposed && e.api[t] && o.push(e.api[t](...n));
                  }), o.length > 1 ? o : o[0];
                }(t, ...n);
              };
            });
          }
          var g = r(2587);
          function m(e) {
            let t = arguments.length > 1 && void 0 !== arguments[1] ? arguments[1] : {},
              m = arguments.length > 2 ? arguments[2] : void 0,
              v = arguments.length > 3 ? arguments[3] : void 0,
              {
                init: b,
                info: y,
                loader_config: w,
                runtime: A = {
                  loaderType: m
                },
                exposed: x = !0
              } = t;
            const E = (0, h.gG)();
            y || (b = E.init, y = E.info, w = E.loader_config), (0, i.Dg)(e, b || {}), (0, i.GE)(e, w || {}), y.jsAttributes ??= {}, d.v6 && (y.jsAttributes.isWorker = !0), (0, i.CX)(e, y);
            const T = (0, i.P_)(e);
            A.denyList = [...(T.ajax?.deny_list || []), ...(T.ajax?.block_internal ? [y.beacon, y.errorBeacon] : [])], (0, i.sU)(e, A), p();
            const _ = function (e, t) {
              t || (0, c.R)(e, "api");
              const h = {};
              var p = a.ee.get(e),
                g = p.get("tracer"),
                m = "api-",
                v = m + "ixn-";
              function b(t, r, n, o) {
                const a = (0, i.C5)(e);
                return null === r ? delete a.jsAttributes[t] : (0, i.CX)(e, {
                  ...a,
                  jsAttributes: {
                    ...a.jsAttributes,
                    [t]: r
                  }
                }), A(m, n, !0, o || null === r ? "session" : void 0)(t, r);
              }
              function y() {}
              ["setErrorHandler", "finished", "addToTrace", "inlineHit", "addRelease"].forEach(e => h[e] = A(m, e, !0, "api")), h.addPageAction = A(m, "addPageAction", !0, n.D.pageAction), h.setCurrentRouteName = A(m, "routeName", !0, n.D.spa), h.setPageViewName = function (t, r) {
                if ("string" == typeof t) return "/" !== t.charAt(0) && (t = "/" + t), (0, i.OP)(e).customTransaction = (r || "http://custom.transaction") + t, A(m, "setPageViewName", !0)();
              }, h.setCustomAttribute = function (e, t) {
                let r = arguments.length > 2 && void 0 !== arguments[2] && arguments[2];
                if ("string" == typeof e) {
                  if (["string", "number"].includes(typeof t) || null === t) return b(e, t, "setCustomAttribute", r);
                  (0, l.Z)("Failed to execute setCustomAttribute.\nNon-null value must be a string or number type, but a type of <".concat(typeof t, "> was provided."));
                } else (0, l.Z)("Failed to execute setCustomAttribute.\nName must be a string type, but a type of <".concat(typeof e, "> was provided."));
              }, h.setUserId = function (e) {
                if ("string" == typeof e || null === e) return b("enduser.id", e, "setUserId", !0);
                (0, l.Z)("Failed to execute setUserId.\nNon-null value must be a string type, but a type of <".concat(typeof e, "> was provided."));
              }, h.setApplicationVersion = function (e) {
                if ("string" == typeof e || null === e) return b("application.version", e, "setApplicationVersion", !1);
                (0, l.Z)("Failed to execute setApplicationVersion. Expected <String | null>, but got <".concat(typeof e, ">."));
              }, h.interaction = function () {
                return new y().get();
              };
              var w = y.prototype = {
                createTracer: function (e, t) {
                  var r = {},
                    i = this,
                    a = "function" == typeof t;
                  return (0, o.p)(v + "tracer", [(0, s.z)(), e, r], i, n.D.spa, p), function () {
                    if (g.emit((a ? "" : "no-") + "fn-start", [(0, s.z)(), i, a], r), a) try {
                      return t.apply(this, arguments);
                    } catch (e) {
                      throw g.emit("fn-err", [arguments, this, e], r), e;
                    } finally {
                      g.emit("fn-end", [(0, s.z)()], r);
                    }
                  };
                }
              };
              function A(e, t, r, i) {
                return function () {
                  return (0, o.p)(f.xS, ["API/" + t + "/called"], void 0, n.D.metrics, p), i && (0, o.p)(e + t, [(0, s.z)(), ...arguments], r ? null : this, i, p), r ? void 0 : this;
                };
              }
              function x() {
                r.e(111).then(r.bind(r, 7438)).then(t => {
                  let {
                    setAPI: r
                  } = t;
                  r(e), (0, c.L)(e, "api");
                }).catch(() => (0, l.Z)("Downloading runtime APIs failed..."));
              }
              return ["actionText", "setName", "setAttribute", "save", "ignore", "onEnd", "getContext", "end", "get"].forEach(e => {
                w[e] = A(v, e, void 0, n.D.spa);
              }), h.noticeError = function (e, t) {
                "string" == typeof e && (e = new Error(e)), (0, o.p)(f.xS, ["API/noticeError/called"], void 0, n.D.metrics, p), (0, o.p)("err", [e, (0, s.z)(), !1, t], void 0, n.D.jserrors, p);
              }, d.il ? (0, u.b)(() => x(), !0) : x(), h;
            }(e, v);
            return (0, h.Qy)(e, _, "api"), (0, h.Qy)(e, x, "exposed"), (0, h.EZ)("activatedFeatures", g.T), _;
          }
        },
        3325: (e, t, r) => {
          r.d(t, {
            D: () => n,
            p: () => i
          });
          const n = {
              ajax: "ajax",
              jserrors: "jserrors",
              metrics: "metrics",
              pageAction: "page_action",
              pageViewEvent: "page_view_event",
              pageViewTiming: "page_view_timing",
              sessionReplay: "session_replay",
              sessionTrace: "session_trace",
              spa: "spa"
            },
            i = {
              [n.pageViewEvent]: 1,
              [n.pageViewTiming]: 2,
              [n.metrics]: 3,
              [n.jserrors]: 4,
              [n.ajax]: 5,
              [n.sessionTrace]: 6,
              [n.pageAction]: 7,
              [n.spa]: 8,
              [n.sessionReplay]: 9
            };
        }
      },
      n = {};
    function i(e) {
      var t = n[e];
      if (void 0 !== t) return t.exports;
      var o = n[e] = {
        exports: {}
      };
      return r[e](o, o.exports, i), o.exports;
    }
    i.m = r, i.d = (e, t) => {
      for (var r in t) i.o(t, r) && !i.o(e, r) && Object.defineProperty(e, r, {
        enumerable: !0,
        get: t[r]
      });
    }, i.f = {}, i.e = e => Promise.all(Object.keys(i.f).reduce((t, r) => (i.f[r](e, t), t), [])), i.u = e => "nr-spa.1097a448-1.238.0.min.js", i.o = (e, t) => Object.prototype.hasOwnProperty.call(e, t), e = {}, t = "NRBA-1.238.0.PROD:", i.l = (r, n, o, a) => {
      if (e[r]) e[r].push(n);else {
        var s, c;
        if (void 0 !== o) for (var u = document.getElementsByTagName("script"), d = 0; d < u.length; d++) {
          var l = u[d];
          if (l.getAttribute("src") == r || l.getAttribute("data-webpack") == t + o) {
            s = l;
            break;
          }
        }
        s || (c = !0, (s = document.createElement("script")).charset = "utf-8", s.timeout = 120, i.nc && s.setAttribute("nonce", i.nc), s.setAttribute("data-webpack", t + o), s.src = r), e[r] = [n];
        var f = (t, n) => {
            s.onerror = s.onload = null, clearTimeout(h);
            var i = e[r];
            if (delete e[r], s.parentNode && s.parentNode.removeChild(s), i && i.forEach(e => e(n)), t) return t(n);
          },
          h = setTimeout(f.bind(null, void 0, {
            type: "timeout",
            target: s
          }), 12e4);
        s.onerror = f.bind(null, s.onerror), s.onload = f.bind(null, s.onload), c && document.head.appendChild(s);
      }
    }, i.r = e => {
      "undefined" != typeof Symbol && Symbol.toStringTag && Object.defineProperty(e, Symbol.toStringTag, {
        value: "Module"
      }), Object.defineProperty(e, "__esModule", {
        value: !0
      });
    }, i.p = "https://js-agent.newrelic.com/", (() => {
      var e = {
        801: 0,
        92: 0
      };
      i.f.j = (t, r) => {
        var n = i.o(e, t) ? e[t] : void 0;
        if (0 !== n) if (n) r.push(n[2]);else {
          var o = new Promise((r, i) => n = e[t] = [r, i]);
          r.push(n[2] = o);
          var a = i.p + i.u(t),
            s = new Error();
          i.l(a, r => {
            if (i.o(e, t) && (0 !== (n = e[t]) && (e[t] = void 0), n)) {
              var o = r && ("load" === r.type ? "missing" : r.type),
                a = r && r.target && r.target.src;
              s.message = "Loading chunk " + t + " failed.\n(" + o + ": " + a + ")", s.name = "ChunkLoadError", s.type = o, s.request = a, n[1](s);
            }
          }, "chunk-" + t, t);
        }
      };
      var t = (t, r) => {
          var n,
            o,
            [a, s, c] = r,
            u = 0;
          if (a.some(t => 0 !== e[t])) {
            for (n in s) i.o(s, n) && (i.m[n] = s[n]);
            if (c) c(i);
          }
          for (t && t(r); u < a.length; u++) o = a[u], i.o(e, o) && e[o] && e[o][0](), e[o] = 0;
        },
        r = self["webpackChunk:NRBA-1.238.0.PROD"] = self["webpackChunk:NRBA-1.238.0.PROD"] || [];
      r.forEach(t.bind(null, 0)), r.push = t.bind(null, r.push.bind(r));
    })(), (() => {
      var e = i(50);
      class t {
        addPageAction(t, r) {
          (0, e.Z)("Call to agent api addPageAction failed. The session trace feature is not currently initialized.");
        }
        setPageViewName(t, r) {
          (0, e.Z)("Call to agent api setPageViewName failed. The page view feature is not currently initialized.");
        }
        setCustomAttribute(t, r, n) {
          (0, e.Z)("Call to agent api setCustomAttribute failed. The js errors feature is not currently initialized.");
        }
        noticeError(t, r) {
          (0, e.Z)("Call to agent api noticeError failed. The js errors feature is not currently initialized.");
        }
        setUserId(t) {
          (0, e.Z)("Call to agent api setUserId failed. The js errors feature is not currently initialized.");
        }
        setApplicationVersion(t) {
          (0, e.Z)("Call to agent api setApplicationVersion failed. The agent is not currently initialized.");
        }
        setErrorHandler(t) {
          (0, e.Z)("Call to agent api setErrorHandler failed. The js errors feature is not currently initialized.");
        }
        finished(t) {
          (0, e.Z)("Call to agent api finished failed. The page action feature is not currently initialized.");
        }
        addRelease(t, r) {
          (0, e.Z)("Call to agent api addRelease failed. The agent is not currently initialized.");
        }
      }
      var r = i(3325),
        n = i(5763);
      const o = Object.values(r.D);
      function a(e) {
        const t = {};
        return o.forEach(r => {
          t[r] = function (e, t) {
            return !1 !== (0, n.Mt)(t, "".concat(e, ".enabled"));
          }(r, e);
        }), t;
      }
      var s = i(9144);
      var c = i(5546),
        u = i(385),
        d = i(8e3),
        l = i(5938),
        f = i(3960);
      class h extends l.W {
        constructor(e, t, r) {
          let n = !(arguments.length > 3 && void 0 !== arguments[3]) || arguments[3];
          super(e, t, r), this.auto = n, this.abortHandler, this.featAggregate, this.onAggregateImported, n && (0, d.R)(e, r);
        }
        importAggregator() {
          let t = arguments.length > 0 && void 0 !== arguments[0] ? arguments[0] : {};
          if (this.featAggregate || !this.auto) return;
          const r = u.il && !0 === (0, n.Mt)(this.agentIdentifier, "privacy.cookies_enabled");
          let o;
          this.onAggregateImported = new Promise(e => {
            o = e;
          });
          const a = async () => {
            let n;
            try {
              if (r) {
                const {
                  setupAgentSession: e
                } = await i.e(111).then(i.bind(i, 3228));
                n = e(this.agentIdentifier);
              }
            } catch (t) {
              (0, e.Z)("A problem occurred when starting up session manager. This page will not start or extend any session.", t);
            }
            try {
              if (!this.shouldImportAgg(this.featureName, n)) return (0, d.L)(this.agentIdentifier, this.featureName), void o(!1);
              const {
                  lazyFeatureLoader: e
                } = await i.e(111).then(i.bind(i, 8582)),
                {
                  Aggregate: r
                } = await e(this.featureName, "aggregate");
              this.featAggregate = new r(this.agentIdentifier, this.aggregator, t), o(!0);
            } catch (t) {
              (0, e.Z)("Downloading and initializing ".concat(this.featureName, " failed..."), t), this.abortHandler?.(), o(!1);
            }
          };
          u.il ? (0, f.b)(() => a(), !0) : a();
        }
        shouldImportAgg(e, t) {
          return e !== r.D.sessionReplay || !!n.Yu.MO && !1 !== (0, n.Mt)(this.agentIdentifier, "session_trace.enabled") && (!!t?.isNew || !!t?.state.sessionReplay);
        }
      }
      var p = i(7633),
        g = i(7894);
      class m extends h {
        static featureName = p.t9;
        constructor(e, t) {
          let i = !(arguments.length > 2 && void 0 !== arguments[2]) || arguments[2];
          if (super(e, t, p.t9, i), ("undefined" == typeof PerformanceNavigationTiming || u.Tt) && "undefined" != typeof PerformanceTiming) {
            const t = (0, n.OP)(e);
            t[p.Dz] = Math.max(Date.now() - t.offset, 0), (0, f.K)(() => t[p.qw] = Math.max((0, g.z)() - t[p.Dz], 0)), (0, f.b)(() => {
              const e = (0, g.z)();
              t[p.OJ] = Math.max(e - t[p.Dz], 0), (0, c.p)("timing", ["load", e], void 0, r.D.pageViewTiming, this.ee);
            });
          }
          this.importAggregator();
        }
      }
      var v = i(1117),
        b = i(1284);
      class y extends v.w {
        constructor(e) {
          super(e), this.aggregatedData = {};
        }
        store(e, t, r, n, i) {
          var o = this.getBucket(e, t, r, i);
          return o.metrics = function (e, t) {
            t || (t = {
              count: 0
            });
            return t.count += 1, (0, b.D)(e, function (e, r) {
              t[e] = w(r, t[e]);
            }), t;
          }(n, o.metrics), o;
        }
        merge(e, t, r, n, i) {
          var o = this.getBucket(e, t, n, i);
          if (o.metrics) {
            var a = o.metrics;
            a.count += r.count, (0, b.D)(r, function (e, t) {
              if ("count" !== e) {
                var n = a[e],
                  i = r[e];
                i && !i.c ? a[e] = w(i.t, n) : a[e] = function (e, t) {
                  if (!t) return e;
                  t.c || (t = A(t.t));
                  return t.min = Math.min(e.min, t.min), t.max = Math.max(e.max, t.max), t.t += e.t, t.sos += e.sos, t.c += e.c, t;
                }(i, a[e]);
              }
            });
          } else o.metrics = r;
        }
        storeMetric(e, t, r, n) {
          var i = this.getBucket(e, t, r);
          return i.stats = w(n, i.stats), i;
        }
        getBucket(e, t, r, n) {
          this.aggregatedData[e] || (this.aggregatedData[e] = {});
          var i = this.aggregatedData[e][t];
          return i || (i = this.aggregatedData[e][t] = {
            params: r || {}
          }, n && (i.custom = n)), i;
        }
        get(e, t) {
          return t ? this.aggregatedData[e] && this.aggregatedData[e][t] : this.aggregatedData[e];
        }
        take(e) {
          for (var t = {}, r = "", n = !1, i = 0; i < e.length; i++) t[r = e[i]] = x(this.aggregatedData[r]), t[r].length && (n = !0), delete this.aggregatedData[r];
          return n ? t : null;
        }
      }
      function w(e, t) {
        return null == e ? function (e) {
          e ? e.c++ : e = {
            c: 1
          };
          return e;
        }(t) : t ? (t.c || (t = A(t.t)), t.c += 1, t.t += e, t.sos += e * e, e > t.max && (t.max = e), e < t.min && (t.min = e), t) : {
          t: e
        };
      }
      function A(e) {
        return {
          t: e,
          min: e,
          max: e,
          sos: e * e,
          c: 1
        };
      }
      function x(e) {
        return "object" != typeof e ? [] : (0, b.D)(e, E);
      }
      function E(e, t) {
        return t;
      }
      var T = i(8632),
        _ = i(4402),
        D = i(4351);
      var j = i(7956),
        C = i(3239),
        N = i(9251);
      class O extends h {
        static featureName = N.t;
        constructor(e, t) {
          let r = !(arguments.length > 2 && void 0 !== arguments[2]) || arguments[2];
          super(e, t, N.t, r), u.il && ((0, n.OP)(e).initHidden = Boolean("hidden" === document.visibilityState), (0, j.N)(() => (0, c.p)("docHidden", [(0, g.z)()], void 0, N.t, this.ee), !0), (0, C.bP)("pagehide", () => (0, c.p)("winPagehide", [(0, g.z)()], void 0, N.t, this.ee)), this.importAggregator());
        }
      }
      var S = i(3081);
      class P extends h {
        static featureName = S.t9;
        constructor(e, t) {
          let r = !(arguments.length > 2 && void 0 !== arguments[2]) || arguments[2];
          super(e, t, S.t9, r), this.importAggregator();
        }
      }
      var R = i(6660);
      class I {
        constructor(e, t, r, n) {
          this.name = "UncaughtError", this.message = e, this.sourceURL = t, this.line = r, this.column = n;
        }
      }
      class k extends h {
        static featureName = R.t;
        #e = new Set();
        constructor(e, t) {
          let n = !(arguments.length > 2 && void 0 !== arguments[2]) || arguments[2];
          super(e, t, R.t, n);
          try {
            this.removeOnAbort = new AbortController();
          } catch (e) {}
          this.ee.on("fn-err", (e, t, n) => {
            this.abortHandler && !this.#e.has(n) && (this.#e.add(n), (0, c.p)("err", [this.#t(n), (0, g.z)()], void 0, r.D.jserrors, this.ee));
          }), this.ee.on("internal-error", e => {
            this.abortHandler && (0, c.p)("ierr", [this.#t(e), (0, g.z)(), !0], void 0, r.D.jserrors, this.ee);
          }), u._A.addEventListener("unhandledrejection", e => {
            this.abortHandler && (0, c.p)("err", [this.#r(e), (0, g.z)(), !1, {
              unhandledPromiseRejection: 1
            }], void 0, r.D.jserrors, this.ee);
          }, (0, C.m$)(!1, this.removeOnAbort?.signal)), u._A.addEventListener("error", e => {
            this.abortHandler && (this.#e.has(e.error) ? this.#e.delete(e.error) : (0, c.p)("err", [this.#n(e), (0, g.z)()], void 0, r.D.jserrors, this.ee));
          }, (0, C.m$)(!1, this.removeOnAbort?.signal)), this.abortHandler = this.#i, this.importAggregator();
        }
        #i() {
          this.removeOnAbort?.abort(), this.#e.clear(), this.abortHandler = void 0;
        }
        #t(e) {
          return e instanceof Error ? e : void 0 !== e?.message ? new I(e.message, e.filename || e.sourceURL, e.lineno || e.line, e.colno || e.col) : new I("string" == typeof e ? e : (0, D.P)(e));
        }
        #r(e) {
          let t = "Unhandled Promise Rejection: ";
          if (e?.reason instanceof Error) try {
            return e.reason.message = t + e.reason.message, e.reason;
          } catch (t) {
            return e.reason;
          }
          if (void 0 === e.reason) return new I(t);
          const r = this.#t(e.reason);
          return r.message = t + r.message, r;
        }
        #n(e) {
          return e.error instanceof Error ? e.error : new I(e.message, e.filename, e.lineno, e.colno);
        }
      }
      var H = i(2210);
      let z = 1;
      const L = "nr@id";
      function M(e) {
        const t = typeof e;
        return !e || "object" !== t && "function" !== t ? -1 : e === u._A ? 0 : (0, H.X)(e, L, function () {
          return z++;
        });
      }
      function B(e) {
        if ("string" == typeof e && e.length) return e.length;
        if ("object" == typeof e) {
          if ("undefined" != typeof ArrayBuffer && e instanceof ArrayBuffer && e.byteLength) return e.byteLength;
          if ("undefined" != typeof Blob && e instanceof Blob && e.size) return e.size;
          if (!("undefined" != typeof FormData && e instanceof FormData)) try {
            return (0, D.P)(e).length;
          } catch (e) {
            return;
          }
        }
      }
      var F = i(1214),
        U = i(7243);
      class q {
        constructor(e) {
          this.agentIdentifier = e;
        }
        generateTracePayload(e) {
          if (!this.shouldGenerateTrace(e)) return null;
          var t = (0, n.DL)(this.agentIdentifier);
          if (!t) return null;
          var r = (t.accountID || "").toString() || null,
            i = (t.agentID || "").toString() || null,
            o = (t.trustKey || "").toString() || null;
          if (!r || !i) return null;
          var a = (0, _.M)(),
            s = (0, _.Ht)(),
            c = Date.now(),
            u = {
              spanId: a,
              traceId: s,
              timestamp: c
            };
          return (e.sameOrigin || this.isAllowedOrigin(e) && this.useTraceContextHeadersForCors()) && (u.traceContextParentHeader = this.generateTraceContextParentHeader(a, s), u.traceContextStateHeader = this.generateTraceContextStateHeader(a, c, r, i, o)), (e.sameOrigin && !this.excludeNewrelicHeader() || !e.sameOrigin && this.isAllowedOrigin(e) && this.useNewrelicHeaderForCors()) && (u.newrelicHeader = this.generateTraceHeader(a, s, c, r, i, o)), u;
        }
        generateTraceContextParentHeader(e, t) {
          return "00-" + t + "-" + e + "-01";
        }
        generateTraceContextStateHeader(e, t, r, n, i) {
          return i + "@nr=0-1-" + r + "-" + n + "-" + e + "----" + t;
        }
        generateTraceHeader(e, t, r, n, i, o) {
          if (!("function" == typeof u._A?.btoa)) return null;
          var a = {
            v: [0, 1],
            d: {
              ty: "Browser",
              ac: n,
              ap: i,
              id: e,
              tr: t,
              ti: r
            }
          };
          return o && n !== o && (a.d.tk = o), btoa((0, D.P)(a));
        }
        shouldGenerateTrace(e) {
          return this.isDtEnabled() && this.isAllowedOrigin(e);
        }
        isAllowedOrigin(e) {
          var t = !1,
            r = {};
          if ((0, n.Mt)(this.agentIdentifier, "distributed_tracing") && (r = (0, n.P_)(this.agentIdentifier).distributed_tracing), e.sameOrigin) t = !0;else if (r.allowed_origins instanceof Array) for (var i = 0; i < r.allowed_origins.length; i++) {
            var o = (0, U.e)(r.allowed_origins[i]);
            if (e.hostname === o.hostname && e.protocol === o.protocol && e.port === o.port) {
              t = !0;
              break;
            }
          }
          return t;
        }
        isDtEnabled() {
          var e = (0, n.Mt)(this.agentIdentifier, "distributed_tracing");
          return !!e && !!e.enabled;
        }
        excludeNewrelicHeader() {
          var e = (0, n.Mt)(this.agentIdentifier, "distributed_tracing");
          return !!e && !!e.exclude_newrelic_header;
        }
        useNewrelicHeaderForCors() {
          var e = (0, n.Mt)(this.agentIdentifier, "distributed_tracing");
          return !!e && !1 !== e.cors_use_newrelic_header;
        }
        useTraceContextHeadersForCors() {
          var e = (0, n.Mt)(this.agentIdentifier, "distributed_tracing");
          return !!e && !!e.cors_use_tracecontext_headers;
        }
      }
      var Z = i(7825),
        V = ["load", "error", "abort", "timeout"],
        G = V.length,
        W = n.Yu.REQ,
        X = n.Yu.XHR;
      class Q extends h {
        static featureName = Z.t;
        constructor(e, t) {
          let i = !(arguments.length > 2 && void 0 !== arguments[2]) || arguments[2];
          super(e, t, Z.t, i), (0, n.OP)(e).xhrWrappable && (this.dt = new q(e), this.handler = (e, t, r, n) => (0, c.p)(e, t, r, n, this.ee), (0, F.u5)(this.ee), (0, F.Kf)(this.ee), function (e, t, i, o) {
            function a(e) {
              var t = this;
              t.totalCbs = 0, t.called = 0, t.cbTime = 0, t.end = E, t.ended = !1, t.xhrGuids = {}, t.lastSize = null, t.loadCaptureCalled = !1, t.params = this.params || {}, t.metrics = this.metrics || {}, e.addEventListener("load", function (r) {
                _(t, e);
              }, (0, C.m$)(!1)), u.IF || e.addEventListener("progress", function (e) {
                t.lastSize = e.loaded;
              }, (0, C.m$)(!1));
            }
            function s(e) {
              this.params = {
                method: e[0]
              }, T(this, e[1]), this.metrics = {};
            }
            function c(t, r) {
              var i = (0, n.DL)(e);
              i.xpid && this.sameOrigin && r.setRequestHeader("X-NewRelic-ID", i.xpid);
              var a = o.generateTracePayload(this.parsedOrigin);
              if (a) {
                var s = !1;
                a.newrelicHeader && (r.setRequestHeader("newrelic", a.newrelicHeader), s = !0), a.traceContextParentHeader && (r.setRequestHeader("traceparent", a.traceContextParentHeader), a.traceContextStateHeader && r.setRequestHeader("tracestate", a.traceContextStateHeader), s = !0), s && (this.dt = a);
              }
            }
            function d(e, r) {
              var n = this.metrics,
                i = e[0],
                o = this;
              if (n && i) {
                var a = B(i);
                a && (n.txSize = a);
              }
              this.startTime = (0, g.z)(), this.listener = function (e) {
                try {
                  "abort" !== e.type || o.loadCaptureCalled || (o.params.aborted = !0), ("load" !== e.type || o.called === o.totalCbs && (o.onloadCalled || "function" != typeof r.onload) && "function" == typeof o.end) && o.end(r);
                } catch (e) {
                  try {
                    t.emit("internal-error", [e]);
                  } catch (e) {}
                }
              };
              for (var s = 0; s < G; s++) r.addEventListener(V[s], this.listener, (0, C.m$)(!1));
            }
            function l(e, t, r) {
              this.cbTime += e, t ? this.onloadCalled = !0 : this.called += 1, this.called !== this.totalCbs || !this.onloadCalled && "function" == typeof r.onload || "function" != typeof this.end || this.end(r);
            }
            function f(e, t) {
              var r = "" + M(e) + !!t;
              this.xhrGuids && !this.xhrGuids[r] && (this.xhrGuids[r] = !0, this.totalCbs += 1);
            }
            function h(e, t) {
              var r = "" + M(e) + !!t;
              this.xhrGuids && this.xhrGuids[r] && (delete this.xhrGuids[r], this.totalCbs -= 1);
            }
            function p() {
              this.endTime = (0, g.z)();
            }
            function m(e, r) {
              r instanceof X && "load" === e[0] && t.emit("xhr-load-added", [e[1], e[2]], r);
            }
            function v(e, r) {
              r instanceof X && "load" === e[0] && t.emit("xhr-load-removed", [e[1], e[2]], r);
            }
            function b(e, t, r) {
              t instanceof X && ("onload" === r && (this.onload = !0), ("load" === (e[0] && e[0].type) || this.onload) && (this.xhrCbStart = (0, g.z)()));
            }
            function y(e, r) {
              this.xhrCbStart && t.emit("xhr-cb-time", [(0, g.z)() - this.xhrCbStart, this.onload, r], r);
            }
            function w(e) {
              var t,
                r = e[1] || {};
              if ("string" == typeof e[0] ? 0 === (t = e[0]).length && u.il && (t = "" + u._A.location.href) : e[0] && e[0].url ? t = e[0].url : u._A?.URL && e[0] && e[0] instanceof URL ? t = e[0].href : "function" == typeof e[0].toString && (t = e[0].toString()), "string" == typeof t && 0 !== t.length) {
                t && (this.parsedOrigin = (0, U.e)(t), this.sameOrigin = this.parsedOrigin.sameOrigin);
                var n = o.generateTracePayload(this.parsedOrigin);
                if (n && (n.newrelicHeader || n.traceContextParentHeader)) if (e[0] && e[0].headers) s(e[0].headers, n) && (this.dt = n);else {
                  var i = {};
                  for (var a in r) i[a] = r[a];
                  i.headers = new Headers(r.headers || {}), s(i.headers, n) && (this.dt = n), e.length > 1 ? e[1] = i : e.push(i);
                }
              }
              function s(e, t) {
                var r = !1;
                return t.newrelicHeader && (e.set("newrelic", t.newrelicHeader), r = !0), t.traceContextParentHeader && (e.set("traceparent", t.traceContextParentHeader), t.traceContextStateHeader && e.set("tracestate", t.traceContextStateHeader), r = !0), r;
              }
            }
            function A(e, t) {
              this.params = {}, this.metrics = {}, this.startTime = (0, g.z)(), this.dt = t, e.length >= 1 && (this.target = e[0]), e.length >= 2 && (this.opts = e[1]);
              var r,
                n = this.opts || {},
                i = this.target;
              "string" == typeof i ? r = i : "object" == typeof i && i instanceof W ? r = i.url : u._A?.URL && "object" == typeof i && i instanceof URL && (r = i.href), T(this, r);
              var o = ("" + (i && i instanceof W && i.method || n.method || "GET")).toUpperCase();
              this.params.method = o, this.txSize = B(n.body) || 0;
            }
            function x(e, t) {
              var n;
              this.endTime = (0, g.z)(), this.params || (this.params = {}), this.params.status = t ? t.status : 0, "string" == typeof this.rxSize && this.rxSize.length > 0 && (n = +this.rxSize);
              var o = {
                txSize: this.txSize,
                rxSize: n,
                duration: (0, g.z)() - this.startTime
              };
              i("xhr", [this.params, o, this.startTime, this.endTime, "fetch"], this, r.D.ajax);
            }
            function E(e) {
              var t = this.params,
                n = this.metrics;
              if (!this.ended) {
                this.ended = !0;
                for (var o = 0; o < G; o++) e.removeEventListener(V[o], this.listener, !1);
                t.aborted || (n.duration = (0, g.z)() - this.startTime, this.loadCaptureCalled || 4 !== e.readyState ? null == t.status && (t.status = 0) : _(this, e), n.cbTime = this.cbTime, i("xhr", [t, n, this.startTime, this.endTime, "xhr"], this, r.D.ajax));
              }
            }
            function T(e, t) {
              var r = (0, U.e)(t),
                n = e.params;
              n.hostname = r.hostname, n.port = r.port, n.protocol = r.protocol, n.host = r.hostname + ":" + r.port, n.pathname = r.pathname, e.parsedOrigin = r, e.sameOrigin = r.sameOrigin;
            }
            function _(e, t) {
              e.params.status = t.status;
              var r = function (e, t) {
                var r = e.responseType;
                return "json" === r && null !== t ? t : "arraybuffer" === r || "blob" === r || "json" === r ? B(e.response) : "text" === r || "" === r || void 0 === r ? B(e.responseText) : void 0;
              }(t, e.lastSize);
              if (r && (e.metrics.rxSize = r), e.sameOrigin) {
                var n = t.getResponseHeader("X-NewRelic-App-Data");
                n && (e.params.cat = n.split(", ").pop());
              }
              e.loadCaptureCalled = !0;
            }
            t.on("new-xhr", a), t.on("open-xhr-start", s), t.on("open-xhr-end", c), t.on("send-xhr-start", d), t.on("xhr-cb-time", l), t.on("xhr-load-added", f), t.on("xhr-load-removed", h), t.on("xhr-resolved", p), t.on("addEventListener-end", m), t.on("removeEventListener-end", v), t.on("fn-end", y), t.on("fetch-before-start", w), t.on("fetch-start", A), t.on("fn-start", b), t.on("fetch-done", x);
          }(e, this.ee, this.handler, this.dt), this.importAggregator());
        }
      }
      var K = i(3614);
      const {
        BST_RESOURCE: Y,
        RESOURCE: J,
        START: ee,
        END: te,
        FEATURE_NAME: re,
        FN_END: ne,
        FN_START: ie,
        PUSH_STATE: oe
      } = K;
      var ae = i(7836);
      const {
        FEATURE_NAME: se,
        START: ce,
        END: ue,
        BODY: de,
        CB_END: le,
        JS_TIME: fe,
        FETCH: he,
        FN_START: pe,
        CB_START: ge,
        FN_END: me
      } = ae;
      var ve = i(4649);
      class be extends h {
        static featureName = ve.t;
        constructor(e, t) {
          let r = !(arguments.length > 2 && void 0 !== arguments[2]) || arguments[2];
          super(e, t, ve.t, r), this.importAggregator();
        }
      }
      new class extends t {
        constructor(t) {
          let r = arguments.length > 1 && void 0 !== arguments[1] ? arguments[1] : (0, _.ky)(16);
          super(), u._A ? (this.agentIdentifier = r, this.sharedAggregator = new y({
            agentIdentifier: this.agentIdentifier
          }), this.features = {}, this.desiredFeatures = new Set(t.features || []), this.desiredFeatures.add(m), Object.assign(this, (0, s.j)(this.agentIdentifier, t, t.loaderType || "agent")), this.start()) : (0, e.Z)("Failed to initial the agent. Could not determine the runtime environment.");
        }
        get config() {
          return {
            info: (0, n.C5)(this.agentIdentifier),
            init: (0, n.P_)(this.agentIdentifier),
            loader_config: (0, n.DL)(this.agentIdentifier),
            runtime: (0, n.OP)(this.agentIdentifier)
          };
        }
        start() {
          const t = "features";
          try {
            const n = a(this.agentIdentifier),
              i = [...this.desiredFeatures];
            i.sort((e, t) => r.p[e.featureName] - r.p[t.featureName]), i.forEach(t => {
              if (n[t.featureName] || t.featureName === r.D.pageViewEvent) {
                const i = function (e) {
                  switch (e) {
                    case r.D.ajax:
                      return [r.D.jserrors];
                    case r.D.sessionTrace:
                      return [r.D.ajax, r.D.pageViewEvent];
                    case r.D.sessionReplay:
                      return [r.D.sessionTrace];
                    case r.D.pageViewTiming:
                      return [r.D.pageViewEvent];
                    default:
                      return [];
                  }
                }(t.featureName);
                i.every(e => n[e]) || (0, e.Z)("".concat(t.featureName, " is enabled but one or more dependent features has been disabled (").concat((0, D.P)(i), "). This may cause unintended consequences or missing data...")), this.features[t.featureName] = new t(this.agentIdentifier, this.sharedAggregator);
              }
            }), (0, T.Qy)(this.agentIdentifier, this.features, t);
          } catch (r) {
            (0, e.Z)("Failed to initialize all enabled instrument classes (agent aborted) -", r);
            for (const e in this.features) this.features[e].abortHandler?.();
            const n = (0, T.fP)();
            return delete n.initializedAgents[this.agentIdentifier]?.api, delete n.initializedAgents[this.agentIdentifier]?.[t], delete this.sharedAggregator, n.ee?.abort(), delete n.ee?.get(this.agentIdentifier), !1;
          }
        }
        addToTrace(t) {
          (0, e.Z)("Call to agent api addToTrace failed. The page action feature is not currently initialized.");
        }
        setCurrentRouteName(t) {
          (0, e.Z)("Call to agent api setCurrentRouteName failed. The spa feature is not currently initialized.");
        }
        interaction() {
          (0, e.Z)("Call to agent api interaction failed. The spa feature is not currently initialized.");
        }
      }({
        features: [Q, m, O, class extends h {
          static featureName = re;
          constructor(e, t) {
            if (super(e, t, re, !(arguments.length > 2 && void 0 !== arguments[2]) || arguments[2]), !u.il) return;
            const n = this.ee;
            let i;
            (0, F.QU)(n), this.eventsEE = (0, F.em)(n), this.eventsEE.on(ie, function (e, t) {
              this.bstStart = (0, g.z)();
            }), this.eventsEE.on(ne, function (e, t) {
              (0, c.p)("bst", [e[0], t, this.bstStart, (0, g.z)()], void 0, r.D.sessionTrace, n);
            }), n.on(oe + ee, function (e) {
              this.time = (0, g.z)(), this.startPath = location.pathname + location.hash;
            }), n.on(oe + te, function (e) {
              (0, c.p)("bstHist", [location.pathname + location.hash, this.startPath, this.time], void 0, r.D.sessionTrace, n);
            });
            try {
              i = new PerformanceObserver(e => {
                const t = e.getEntries();
                (0, c.p)(Y, [t], void 0, r.D.sessionTrace, n);
              }), i.observe({
                type: J,
                buffered: !0
              });
            } catch (e) {}
            this.importAggregator({
              resourceObserver: i
            });
          }
        }, P, be, k, class extends h {
          static featureName = se;
          constructor(e, t) {
            if (super(e, t, se, !(arguments.length > 2 && void 0 !== arguments[2]) || arguments[2]), !u.il) return;
            if (!(0, n.OP)(e).xhrWrappable) return;
            try {
              this.removeOnAbort = new AbortController();
            } catch (e) {}
            let r,
              i = 0;
            const o = this.ee.get("tracer"),
              a = (0, F._L)(this.ee),
              s = (0, F.Lg)(this.ee),
              c = (0, F.BV)(this.ee),
              d = (0, F.Kf)(this.ee),
              l = this.ee.get("events"),
              f = (0, F.u5)(this.ee),
              h = (0, F.QU)(this.ee),
              p = (0, F.Gm)(this.ee);
            function m(e, t) {
              h.emit("newURL", ["" + window.location, t]);
            }
            function v() {
              i++, r = window.location.hash, this[pe] = (0, g.z)();
            }
            function b() {
              i--, window.location.hash !== r && m(0, !0);
              var e = (0, g.z)();
              this[fe] = ~~this[fe] + e - this[pe], this[me] = e;
            }
            function y(e, t) {
              e.on(t, function () {
                this[t] = (0, g.z)();
              });
            }
            this.ee.on(pe, v), s.on(ge, v), a.on(ge, v), this.ee.on(me, b), s.on(le, b), a.on(le, b), this.ee.buffer([pe, me, "xhr-resolved"], this.featureName), l.buffer([pe], this.featureName), c.buffer(["setTimeout" + ue, "clearTimeout" + ce, pe], this.featureName), d.buffer([pe, "new-xhr", "send-xhr" + ce], this.featureName), f.buffer([he + ce, he + "-done", he + de + ce, he + de + ue], this.featureName), h.buffer(["newURL"], this.featureName), p.buffer([pe], this.featureName), s.buffer(["propagate", ge, le, "executor-err", "resolve" + ce], this.featureName), o.buffer([pe, "no-" + pe], this.featureName), a.buffer(["new-jsonp", "cb-start", "jsonp-error", "jsonp-end"], this.featureName), y(f, he + ce), y(f, he + "-done"), y(a, "new-jsonp"), y(a, "jsonp-end"), y(a, "cb-start"), h.on("pushState-end", m), h.on("replaceState-end", m), window.addEventListener("hashchange", m, (0, C.m$)(!0, this.removeOnAbort?.signal)), window.addEventListener("load", m, (0, C.m$)(!0, this.removeOnAbort?.signal)), window.addEventListener("popstate", function () {
              m(0, i > 1);
            }, (0, C.m$)(!0, this.removeOnAbort?.signal)), this.abortHandler = this.#i, this.importAggregator();
          }
          #i() {
            this.removeOnAbort?.abort(), this.abortHandler = void 0;
          }
        }],
        loaderType: "spa"
      });
    })();
  })();
})()</script>
      <link rel="shortcut icon" href="https://sdfestaticassets-eu-west-1.sciencedirectassets.com/shared-assets/103/images/favSD.ico" type="image/x-icon">
      <link rel="icon" href="https://sdfestaticassets-eu-west-1.sciencedirectassets.com/shared-assets/103/images/favSD.ico" type="image/x-icon">
      <link rel="stylesheet" href="https://sdfestaticassets-eu-west-1.sciencedirectassets.com/prod/562c52f0a29e84041e12a6c3286c1d8a5b89ba0b/arp.css">
      <link href="//cdn.pendo.io" rel="dns-prefetch">
      <link href="https://cdn.pendo.io" rel="preconnect" crossorigin="anonymous">
      <link rel="dns-prefetch" href="https://smetrics.elsevier.com">
      <script async="" id="reading-assistant-script-tag" src="/feature/assets/ai-components/S0031320317302327?componentVersion=V11&amp;jwt=eyJ0eXAiOiJKV1QiLCJhbGciOiJIUzI1NiJ9.eyJhdWQiOiJnZW5BaUFwcHMiLCJzdWIiOiI1MDQwMSIsInBpaSI6IlMwMDMxMzIwMzE3MzAyMzI3IiwiaXNzIjoiYXJwIiwic2Vzc2lvbklkIjoiNWUwYThhMzI3ZjI3YTA0OGE4NWIyM2E2YTM3MTU2NmQ2OThkZ3hycWEiLCJleHAiOjE3MzAyMDU3MDYsImlhdCI6MTczMDIwMzkwNiwidmVyc2lvbiI6MSwianRpIjoiMDJhNjU5YzEtZDdmMi00NGE3LThkODAtMTBiNTEzY2IzM2RmIn0.NyIY6s0VMFQv9ut4ThRsHKp1WUdR56Ei8NUwBwV5i-k" type="text/javascript"></script>
      <script type="text/javascript">
        var targetServerState = JSON.stringify({"4D6368F454EC41940A4C98A6@AdobeOrg":{"sdid":{"supplementalDataIDCurrent":"1756F5AA597B493C-1E2AF208361D902E","supplementalDataIDCurrentConsumed":{"payload:target-global-mbox":true},"supplementalDataIDLastConsumed":{}}}});
        window.appData = window.appData || [];
        window.pageTargeting = {"region":"eu-west-1","platform":"sdtech","entitled":true,"crawler":"","journal":"Pattern Recognition","auth":"AE"};
        window.arp = {
          config: {"adobeSuite":"elsevier-sd-prod","arsUrl":"https://ars.els-cdn.com","recommendationsFeedback":{"enabled":true,"url":"https://feedback.recs.d.elsevier.com/raw/events","timeout":60000},"googleMapsApiKey":"AIzaSyCBYU6I6lrbEU6wQXUEIte3NwGtm3jwHQc","mediaBaseUrl":"https://ars.els-cdn.com/content/image/","strictMode":false,"seamlessAccess":{"enableSeamlessAccess":true,"scriptUrl":"https://unpkg.com/@theidentityselector/thiss-ds@1.0.13/dist/thiss-ds.js","persistenceUrl":"https://service.seamlessaccess.org/ps/","persistenceContext":"seamlessaccess.org","scienceDirectUrl":"https://www.sciencedirect.com","shibAuthUrl":"https://auth.elsevier.com/ShibAuth/institutionLogin"},"reaxys":{"apiUrl":"https://reaxys-sdlc.reaxys.com","origin":"sciencedirect","queryBuilderHostPath":"https://www.reaxys.com/reaxys/secured/hopinto.do","url":"https://www.reaxys.com"},"oneTrustCookie":{"enabled":true},"ssrn":{"url":"https://papers.ssrn.com","path":"/sol3/papers.cfm"},"assetRoute":"https://sdfestaticassets-eu-west-1.sciencedirectassets.com/prod/562c52f0a29e84041e12a6c3286c1d8a5b89ba0b"},
          subscriptions: [],
          subscribe: function(cb) {
            var self = this;
            var i = this.subscriptions.push(cb) - 1;
            return function unsubscribe() {
              self.subscriptions.splice(i, 1);
            }
          },
        };
        window.addEventListener('beforeprint', () => pendo.onGuideDismissed());
      </script>
    <script data-cfasync="false" src="https://cdn.cookielaw.org/scripttemplates/otSDKStub.js" data-document-language="true" data-domain-script="865ea198-88cc-4e41-8952-1df75d554d02"></script><script src="https://assets.adobedtm.com/extensions/EP8757b503532a44a68eee17773f6f10a0/AppMeasurement.min.js" async=""></script><script src="https://assets.adobedtm.com/extensions/EP8757b503532a44a68eee17773f6f10a0/AppMeasurement_Module_ActivityMap.min.js" async=""></script><script src="https://assets.adobedtm.com/4a848ae9611a/032db4f73473/6a62c1bc1779/RCa16d232f95a944c0aabdea6621a2ef94-source.min.js" async=""></script><script src="https://cdn.cookielaw.org/scripttemplates/202402.1.0/otBannerSdk.js" async="" type="text/javascript"></script><meta http-equiv="origin-trial" content="AlK2UR5SkAlj8jjdEc9p3F3xuFYlF6LYjAML3EOqw1g26eCwWPjdmecULvBH5MVPoqKYrOfPhYVL71xAXI1IBQoAAAB8eyJvcmlnaW4iOiJodHRwczovL2RvdWJsZWNsaWNrLm5ldDo0NDMiLCJmZWF0dXJlIjoiV2ViVmlld1hSZXF1ZXN0ZWRXaXRoRGVwcmVjYXRpb24iLCJleHBpcnkiOjE3NTgwNjcxOTksImlzU3ViZG9tYWluIjp0cnVlfQ=="><meta http-equiv="origin-trial" content="Amm8/NmvvQfhwCib6I7ZsmUxiSCfOxWxHayJwyU1r3gRIItzr7bNQid6O8ZYaE1GSQTa69WwhPC9flq/oYkRBwsAAACCeyJvcmlnaW4iOiJodHRwczovL2dvb2dsZXN5bmRpY2F0aW9uLmNvbTo0NDMiLCJmZWF0dXJlIjoiV2ViVmlld1hSZXF1ZXN0ZWRXaXRoRGVwcmVjYXRpb24iLCJleHBpcnkiOjE3NTgwNjcxOTksImlzU3ViZG9tYWluIjp0cnVlfQ=="><meta http-equiv="origin-trial" content="A9wSqI5i0iwGdf6L1CERNdmsTPgVu44ewj8QxTBYgsv1LCPUVF7YmWOvTappqB1139jAymxUW/RO8zmMqo4zlAAAAACNeyJvcmlnaW4iOiJodHRwczovL2RvdWJsZWNsaWNrLm5ldDo0NDMiLCJmZWF0dXJlIjoiRmxlZGdlQmlkZGluZ0FuZEF1Y3Rpb25TZXJ2ZXIiLCJleHBpcnkiOjE3MzY4MTI4MDAsImlzU3ViZG9tYWluIjp0cnVlLCJpc1RoaXJkUGFydHkiOnRydWV9"><meta http-equiv="origin-trial" content="A+d7vJfYtay4OUbdtRPZA3y7bKQLsxaMEPmxgfhBGqKXNrdkCQeJlUwqa6EBbSfjwFtJWTrWIioXeMW+y8bWAgQAAACTeyJvcmlnaW4iOiJodHRwczovL2dvb2dsZXN5bmRpY2F0aW9uLmNvbTo0NDMiLCJmZWF0dXJlIjoiRmxlZGdlQmlkZGluZ0FuZEF1Y3Rpb25TZXJ2ZXIiLCJleHBpcnkiOjE3MzY4MTI4MDAsImlzU3ViZG9tYWluIjp0cnVlLCJpc1RoaXJkUGFydHkiOnRydWV9"><script src="https://securepubads.g.doubleclick.net/pagead/managed/js/gpt/m202410240101/pubads_impl.js?cb=31088506" async=""></script><style type="text/css">.MathJax_Hover_Frame {border-radius: .25em; -webkit-border-radius: .25em; -moz-border-radius: .25em; -khtml-border-radius: .25em; box-shadow: 0px 0px 15px #83A; -webkit-box-shadow: 0px 0px 15px #83A; -moz-box-shadow: 0px 0px 15px #83A; -khtml-box-shadow: 0px 0px 15px #83A; border: 1px solid #A6D ! important; display: inline-block; position: absolute}
.MathJax_Menu_Button .MathJax_Hover_Arrow {position: absolute; cursor: pointer; display: inline-block; border: 2px solid #AAA; border-radius: 4px; -webkit-border-radius: 4px; -moz-border-radius: 4px; -khtml-border-radius: 4px; font-family: 'Courier New',Courier; font-size: 9px; color: #F0F0F0}
.MathJax_Menu_Button .MathJax_Hover_Arrow span {display: block; background-color: #AAA; border: 1px solid; border-radius: 3px; line-height: 0; padding: 4px}
.MathJax_Hover_Arrow:hover {color: white!important; border: 2px solid #CCC!important}
.MathJax_Hover_Arrow:hover span {background-color: #CCC!important}
</style><style type="text/css">#MathJax_About {position: fixed; left: 50%; width: auto; text-align: center; border: 3px outset; padding: 1em 2em; background-color: #DDDDDD; color: black; cursor: default; font-family: message-box; font-size: 120%; font-style: normal; text-indent: 0; text-transform: none; line-height: normal; letter-spacing: normal; word-spacing: normal; word-wrap: normal; white-space: nowrap; float: none; z-index: 201; border-radius: 15px; -webkit-border-radius: 15px; -moz-border-radius: 15px; -khtml-border-radius: 15px; box-shadow: 0px 10px 20px #808080; -webkit-box-shadow: 0px 10px 20px #808080; -moz-box-shadow: 0px 10px 20px #808080; -khtml-box-shadow: 0px 10px 20px #808080; filter: progid:DXImageTransform.Microsoft.dropshadow(OffX=2, OffY=2, Color='gray', Positive='true')}
#MathJax_About.MathJax_MousePost {outline: none}
.MathJax_Menu {position: absolute; background-color: white; color: black; width: auto; padding: 2px; border: 1px solid #CCCCCC; margin: 0; cursor: default; font: menu; text-align: left; text-indent: 0; text-transform: none; line-height: normal; letter-spacing: normal; word-spacing: normal; word-wrap: normal; white-space: nowrap; float: none; z-index: 201; box-shadow: 0px 10px 20px #808080; -webkit-box-shadow: 0px 10px 20px #808080; -moz-box-shadow: 0px 10px 20px #808080; -khtml-box-shadow: 0px 10px 20px #808080; filter: progid:DXImageTransform.Microsoft.dropshadow(OffX=2, OffY=2, Color='gray', Positive='true')}
.MathJax_MenuItem {padding: 2px 2em; background: transparent}
.MathJax_MenuArrow {position: absolute; right: .5em; padding-top: .25em; color: #666666; font-size: .75em}
.MathJax_MenuActive .MathJax_MenuArrow {color: white}
.MathJax_MenuArrow.RTL {left: .5em; right: auto}
.MathJax_MenuCheck {position: absolute; left: .7em}
.MathJax_MenuCheck.RTL {right: .7em; left: auto}
.MathJax_MenuRadioCheck {position: absolute; left: 1em}
.MathJax_MenuRadioCheck.RTL {right: 1em; left: auto}
.MathJax_MenuLabel {padding: 2px 2em 4px 1.33em; font-style: italic}
.MathJax_MenuRule {border-top: 1px solid #CCCCCC; margin: 4px 1px 0px}
.MathJax_MenuDisabled {color: GrayText}
.MathJax_MenuActive {background-color: Highlight; color: HighlightText}
.MathJax_MenuDisabled:focus, .MathJax_MenuLabel:focus {background-color: #E8E8E8}
.MathJax_ContextMenu:focus {outline: none}
.MathJax_ContextMenu .MathJax_MenuItem:focus {outline: none}
#MathJax_AboutClose {top: .2em; right: .2em}
.MathJax_Menu .MathJax_MenuClose {top: -10px; left: -10px}
.MathJax_MenuClose {position: absolute; cursor: pointer; display: inline-block; border: 2px solid #AAA; border-radius: 18px; -webkit-border-radius: 18px; -moz-border-radius: 18px; -khtml-border-radius: 18px; font-family: 'Courier New',Courier; font-size: 24px; color: #F0F0F0}
.MathJax_MenuClose span {display: block; background-color: #AAA; border: 1.5px solid; border-radius: 18px; -webkit-border-radius: 18px; -moz-border-radius: 18px; -khtml-border-radius: 18px; line-height: 0; padding: 8px 0 6px}
.MathJax_MenuClose:hover {color: white!important; border: 2px solid #CCC!important}
.MathJax_MenuClose:hover span {background-color: #CCC!important}
.MathJax_MenuClose:hover:focus {outline: none}
</style><style type="text/css">.MJX_Assistive_MathML {position: absolute!important; top: 0; left: 0; clip: rect(1px, 1px, 1px, 1px); padding: 1px 0 0 0!important; border: 0!important; height: 1px!important; width: 1px!important; overflow: hidden!important; display: block!important; -webkit-touch-callout: none; -webkit-user-select: none; -khtml-user-select: none; -moz-user-select: none; -ms-user-select: none; user-select: none}
.MJX_Assistive_MathML.MJX_Assistive_MathML_Block {width: 100%!important}
</style><style type="text/css">#MathJax_Zoom {position: absolute; background-color: #F0F0F0; overflow: auto; display: block; z-index: 301; padding: .5em; border: 1px solid black; margin: 0; font-weight: normal; font-style: normal; text-align: left; text-indent: 0; text-transform: none; line-height: normal; letter-spacing: normal; word-spacing: normal; word-wrap: normal; white-space: nowrap; float: none; -webkit-box-sizing: content-box; -moz-box-sizing: content-box; box-sizing: content-box; box-shadow: 5px 5px 15px #AAAAAA; -webkit-box-shadow: 5px 5px 15px #AAAAAA; -moz-box-shadow: 5px 5px 15px #AAAAAA; -khtml-box-shadow: 5px 5px 15px #AAAAAA; filter: progid:DXImageTransform.Microsoft.dropshadow(OffX=2, OffY=2, Color='gray', Positive='true')}
#MathJax_ZoomOverlay {position: absolute; left: 0; top: 0; z-index: 300; display: inline-block; width: 100%; height: 100%; border: 0; padding: 0; margin: 0; background-color: white; opacity: 0; filter: alpha(opacity=0)}
#MathJax_ZoomFrame {position: relative; display: inline-block; height: 0; width: 0}
#MathJax_ZoomEventTrap {position: absolute; left: 0; top: 0; z-index: 302; display: inline-block; border: 0; padding: 0; margin: 0; background-color: white; opacity: 0; filter: alpha(opacity=0)}
</style><style type="text/css">.MathJax_Preview {color: #888}
#MathJax_Message {position: fixed; left: 1em; bottom: 1.5em; background-color: #E6E6E6; border: 1px solid #959595; margin: 0px; padding: 2px 8px; z-index: 102; color: black; font-size: 80%; width: auto; white-space: nowrap}
#MathJax_MSIE_Frame {position: absolute; top: 0; left: 0; width: 0px; z-index: 101; border: 0px; margin: 0px; padding: 0px}
.MathJax_Error {color: #CC0000; font-style: italic}
</style><link id="plx-css-summary" type="text/css" rel="stylesheet" href="//cdn.plu.mx/summary.css"><script type="text/javascript" src="//ajax.googleapis.com/ajax/libs/jquery/1.10.2/jquery.min.js"></script><script type="text/javascript" src="//cdn.plu.mx/extjs/xss.js"></script><style type="text/css">.MJXp-script {font-size: .8em}
.MJXp-right {-webkit-transform-origin: right; -moz-transform-origin: right; -ms-transform-origin: right; -o-transform-origin: right; transform-origin: right}
.MJXp-bold {font-weight: bold}
.MJXp-italic {font-style: italic}
.MJXp-scr {font-family: MathJax_Script,'Times New Roman',Times,STIXGeneral,serif}
.MJXp-frak {font-family: MathJax_Fraktur,'Times New Roman',Times,STIXGeneral,serif}
.MJXp-sf {font-family: MathJax_SansSerif,'Times New Roman',Times,STIXGeneral,serif}
.MJXp-cal {font-family: MathJax_Caligraphic,'Times New Roman',Times,STIXGeneral,serif}
.MJXp-mono {font-family: MathJax_Typewriter,'Times New Roman',Times,STIXGeneral,serif}
.MJXp-largeop {font-size: 150%}
.MJXp-largeop.MJXp-int {vertical-align: -.2em}
.MJXp-math {display: inline-block; line-height: 1.2; text-indent: 0; font-family: 'Times New Roman',Times,STIXGeneral,serif; white-space: nowrap; border-collapse: collapse}
.MJXp-display {display: block; text-align: center; margin: 1em 0}
.MJXp-math span {display: inline-block}
.MJXp-box {display: block!important; text-align: center}
.MJXp-box:after {content: " "}
.MJXp-rule {display: block!important; margin-top: .1em}
.MJXp-char {display: block!important}
.MJXp-mo {margin: 0 .15em}
.MJXp-mfrac {margin: 0 .125em; vertical-align: .25em}
.MJXp-denom {display: inline-table!important; width: 100%}
.MJXp-denom > * {display: table-row!important}
.MJXp-surd {vertical-align: top}
.MJXp-surd > * {display: block!important}
.MJXp-script-box > *  {display: table!important; height: 50%}
.MJXp-script-box > * > * {display: table-cell!important; vertical-align: top}
.MJXp-script-box > *:last-child > * {vertical-align: bottom}
.MJXp-script-box > * > * > * {display: block!important}
.MJXp-mphantom {visibility: hidden}
.MJXp-munderover, .MJXp-munder {display: inline-table!important}
.MJXp-over {display: inline-block!important; text-align: center}
.MJXp-over > * {display: block!important}
.MJXp-munderover > *, .MJXp-munder > * {display: table-row!important}
.MJXp-mtable {vertical-align: .25em; margin: 0 .125em}
.MJXp-mtable > * {display: inline-table!important; vertical-align: middle}
.MJXp-mtr {display: table-row!important}
.MJXp-mtd {display: table-cell!important; text-align: center; padding: .5em 0 0 .5em}
.MJXp-mtr > .MJXp-mtd:first-child {padding-left: 0}
.MJXp-mtr:first-child > .MJXp-mtd {padding-top: 0}
.MJXp-mlabeledtr {display: table-row!important}
.MJXp-mlabeledtr > .MJXp-mtd:first-child {padding-left: 0}
.MJXp-mlabeledtr:first-child > .MJXp-mtd {padding-top: 0}
.MJXp-merror {background-color: #FFFF88; color: #CC0000; border: 1px solid #CC0000; padding: 1px 3px; font-style: normal; font-size: 90%}
.MJXp-scale0 {-webkit-transform: scaleX(.0); -moz-transform: scaleX(.0); -ms-transform: scaleX(.0); -o-transform: scaleX(.0); transform: scaleX(.0)}
.MJXp-scale1 {-webkit-transform: scaleX(.1); -moz-transform: scaleX(.1); -ms-transform: scaleX(.1); -o-transform: scaleX(.1); transform: scaleX(.1)}
.MJXp-scale2 {-webkit-transform: scaleX(.2); -moz-transform: scaleX(.2); -ms-transform: scaleX(.2); -o-transform: scaleX(.2); transform: scaleX(.2)}
.MJXp-scale3 {-webkit-transform: scaleX(.3); -moz-transform: scaleX(.3); -ms-transform: scaleX(.3); -o-transform: scaleX(.3); transform: scaleX(.3)}
.MJXp-scale4 {-webkit-transform: scaleX(.4); -moz-transform: scaleX(.4); -ms-transform: scaleX(.4); -o-transform: scaleX(.4); transform: scaleX(.4)}
.MJXp-scale5 {-webkit-transform: scaleX(.5); -moz-transform: scaleX(.5); -ms-transform: scaleX(.5); -o-transform: scaleX(.5); transform: scaleX(.5)}
.MJXp-scale6 {-webkit-transform: scaleX(.6); -moz-transform: scaleX(.6); -ms-transform: scaleX(.6); -o-transform: scaleX(.6); transform: scaleX(.6)}
.MJXp-scale7 {-webkit-transform: scaleX(.7); -moz-transform: scaleX(.7); -ms-transform: scaleX(.7); -o-transform: scaleX(.7); transform: scaleX(.7)}
.MJXp-scale8 {-webkit-transform: scaleX(.8); -moz-transform: scaleX(.8); -ms-transform: scaleX(.8); -o-transform: scaleX(.8); transform: scaleX(.8)}
.MJXp-scale9 {-webkit-transform: scaleX(.9); -moz-transform: scaleX(.9); -ms-transform: scaleX(.9); -o-transform: scaleX(.9); transform: scaleX(.9)}
</style><style id="onetrust-style">#onetrust-banner-sdk{-ms-text-size-adjust:100%;-webkit-text-size-adjust:100%}#onetrust-banner-sdk .onetrust-vendors-list-handler{cursor:pointer;color:#1f96db;font-size:inherit;font-weight:700;text-decoration:none;margin-left:5px}#onetrust-banner-sdk .onetrust-vendors-list-handler:hover{color:#1f96db}#onetrust-banner-sdk:focus{outline:2px solid #000;outline-offset:-2px}#onetrust-banner-sdk a:focus{outline:2px solid #000}#onetrust-banner-sdk #onetrust-accept-btn-handler,#onetrust-banner-sdk #onetrust-reject-all-handler,#onetrust-banner-sdk #onetrust-pc-btn-handler{outline-offset:1px}#onetrust-banner-sdk.ot-bnr-w-logo .ot-bnr-logo{height:64px;width:64px}#onetrust-banner-sdk .ot-tcf2-vendor-count.ot-text-bold{font-weight:700}#onetrust-banner-sdk .ot-close-icon,#onetrust-pc-sdk .ot-close-icon,#ot-sync-ntfy .ot-close-icon{background-size:contain;background-repeat:no-repeat;background-position:center;height:12px;width:12px}#onetrust-banner-sdk .powered-by-logo,#onetrust-banner-sdk .ot-pc-footer-logo a,#onetrust-pc-sdk .powered-by-logo,#onetrust-pc-sdk .ot-pc-footer-logo a,#ot-sync-ntfy .powered-by-logo,#ot-sync-ntfy .ot-pc-footer-logo a{background-size:contain;background-repeat:no-repeat;background-position:center;height:25px;width:152px;display:block;text-decoration:none;font-size:.75em}#onetrust-banner-sdk .powered-by-logo:hover,#onetrust-banner-sdk .ot-pc-footer-logo a:hover,#onetrust-pc-sdk .powered-by-logo:hover,#onetrust-pc-sdk .ot-pc-footer-logo a:hover,#ot-sync-ntfy .powered-by-logo:hover,#ot-sync-ntfy .ot-pc-footer-logo a:hover{color:#565656}#onetrust-banner-sdk h3 *,#onetrust-banner-sdk h4 *,#onetrust-banner-sdk h6 *,#onetrust-banner-sdk button *,#onetrust-banner-sdk a[data-parent-id] *,#onetrust-pc-sdk h3 *,#onetrust-pc-sdk h4 *,#onetrust-pc-sdk h6 *,#onetrust-pc-sdk button *,#onetrust-pc-sdk a[data-parent-id] *,#ot-sync-ntfy h3 *,#ot-sync-ntfy h4 *,#ot-sync-ntfy h6 *,#ot-sync-ntfy button *,#ot-sync-ntfy a[data-parent-id] *{font-size:inherit;font-weight:inherit;color:inherit}#onetrust-banner-sdk .ot-hide,#onetrust-pc-sdk .ot-hide,#ot-sync-ntfy .ot-hide{display:none!important}#onetrust-banner-sdk button.ot-link-btn:hover,#onetrust-pc-sdk button.ot-link-btn:hover,#ot-sync-ntfy button.ot-link-btn:hover{text-decoration:underline;opacity:1}#onetrust-pc-sdk .ot-sdk-row .ot-sdk-column{padding:0}#onetrust-pc-sdk .ot-sdk-container{padding-right:0}#onetrust-pc-sdk .ot-sdk-row{flex-direction:initial;width:100%}#onetrust-pc-sdk [type=checkbox]:checked,#onetrust-pc-sdk [type=checkbox]:not(:checked){pointer-events:initial}#onetrust-pc-sdk [type=checkbox]:disabled+label::before,#onetrust-pc-sdk [type=checkbox]:disabled+label:after,#onetrust-pc-sdk [type=checkbox]:disabled+label{pointer-events:none;opacity:.7}#onetrust-pc-sdk #vendor-list-content{transform:translate3d(0,0,0)}#onetrust-pc-sdk li input[type=checkbox]{z-index:1}#onetrust-pc-sdk li .ot-checkbox label{z-index:2}#onetrust-pc-sdk li .ot-checkbox input[type=checkbox]{height:auto;width:auto}#onetrust-pc-sdk li .host-title a,#onetrust-pc-sdk li .ot-host-name a,#onetrust-pc-sdk li .accordion-text,#onetrust-pc-sdk li .ot-acc-txt{z-index:2;position:relative}#onetrust-pc-sdk input{margin:3px .1ex}#onetrust-pc-sdk .pc-logo,#onetrust-pc-sdk .ot-pc-logo{height:60px;width:180px;background-position:center;background-size:contain;background-repeat:no-repeat;display:inline-flex;justify-content:center;align-items:center}#onetrust-pc-sdk .pc-logo img,#onetrust-pc-sdk .ot-pc-logo img{max-height:100%;max-width:100%}#onetrust-pc-sdk .screen-reader-only,#onetrust-pc-sdk .ot-scrn-rdr,.ot-sdk-cookie-policy .screen-reader-only,.ot-sdk-cookie-policy .ot-scrn-rdr{border:0;clip:rect(0 0 0 0);height:1px;margin:-1px;overflow:hidden;padding:0;position:absolute;width:1px}#onetrust-pc-sdk.ot-fade-in,.onetrust-pc-dark-filter.ot-fade-in,#onetrust-banner-sdk.ot-fade-in{animation-name:onetrust-fade-in;animation-duration:400ms;animation-timing-function:ease-in-out}#onetrust-pc-sdk.ot-hide{display:none!important}.onetrust-pc-dark-filter.ot-hide{display:none!important}#ot-sdk-btn.ot-sdk-show-settings,#ot-sdk-btn.optanon-show-settings{color:#68b631;border:1px solid #68b631;height:auto;white-space:normal;word-wrap:break-word;padding:.8em 2em;font-size:.8em;line-height:1.2;cursor:pointer;-moz-transition:.1s ease;-o-transition:.1s ease;-webkit-transition:1s ease;transition:.1s ease}#ot-sdk-btn.ot-sdk-show-settings:hover,#ot-sdk-btn.optanon-show-settings:hover{color:#fff;background-color:#68b631}.onetrust-pc-dark-filter{background:rgba(0,0,0,.5);z-index:2147483646;width:100%;height:100%;overflow:hidden;position:fixed;top:0;bottom:0;left:0}@keyframes onetrust-fade-in{0%{opacity:0}100%{opacity:1}}.ot-cookie-label{text-decoration:underline}@media only screen and (min-width:426px)and (max-width:896px)and (orientation:landscape){#onetrust-pc-sdk p{font-size:.75em}}#onetrust-banner-sdk .banner-option-input:focus+label{outline:1px solid #000;outline-style:auto}.category-vendors-list-handler+a:focus,.category-vendors-list-handler+a:focus-visible{outline:2px solid #000}#onetrust-pc-sdk .ot-userid-title{margin-top:10px}#onetrust-pc-sdk .ot-userid-title>span,#onetrust-pc-sdk .ot-userid-timestamp>span{font-weight:700}#onetrust-pc-sdk .ot-userid-desc{font-style:italic}#onetrust-pc-sdk .ot-host-desc a{pointer-events:initial}#onetrust-pc-sdk .ot-ven-hdr>p a{position:relative;z-index:2;pointer-events:initial}#onetrust-pc-sdk .ot-vnd-serv .ot-vnd-item .ot-vnd-info a,#onetrust-pc-sdk .ot-vs-list .ot-vnd-item .ot-vnd-info a{margin-right:auto}#onetrust-pc-sdk .ot-pc-footer-logo img{width:136px;height:16px}#onetrust-pc-sdk .ot-pur-vdr-count{font-weight:400;font-size:.7rem;padding-top:3px;display:block}#onetrust-banner-sdk .ot-optout-signal,#onetrust-pc-sdk .ot-optout-signal{border:1px solid #32ae88;border-radius:3px;padding:5px;margin-bottom:10px;background-color:#f9fffa;font-size:.85rem;line-height:2}#onetrust-banner-sdk .ot-optout-signal .ot-optout-icon,#onetrust-pc-sdk .ot-optout-signal .ot-optout-icon{display:inline;margin-right:5px}#onetrust-banner-sdk .ot-optout-signal svg,#onetrust-pc-sdk .ot-optout-signal svg{height:20px;width:30px;transform:scale(.5)}#onetrust-banner-sdk .ot-optout-signal svg path,#onetrust-pc-sdk .ot-optout-signal svg path{fill:#32ae88}#onetrust-banner-sdk,#onetrust-pc-sdk,#ot-sdk-cookie-policy,#ot-sync-ntfy{font-size:16px}#onetrust-banner-sdk *,#onetrust-banner-sdk ::after,#onetrust-banner-sdk ::before,#onetrust-pc-sdk *,#onetrust-pc-sdk ::after,#onetrust-pc-sdk ::before,#ot-sdk-cookie-policy *,#ot-sdk-cookie-policy ::after,#ot-sdk-cookie-policy ::before,#ot-sync-ntfy *,#ot-sync-ntfy ::after,#ot-sync-ntfy ::before{-webkit-box-sizing:content-box;-moz-box-sizing:content-box;box-sizing:content-box}#onetrust-banner-sdk div,#onetrust-banner-sdk span,#onetrust-banner-sdk h1,#onetrust-banner-sdk h2,#onetrust-banner-sdk h3,#onetrust-banner-sdk h4,#onetrust-banner-sdk h5,#onetrust-banner-sdk h6,#onetrust-banner-sdk p,#onetrust-banner-sdk img,#onetrust-banner-sdk svg,#onetrust-banner-sdk button,#onetrust-banner-sdk section,#onetrust-banner-sdk a,#onetrust-banner-sdk label,#onetrust-banner-sdk input,#onetrust-banner-sdk ul,#onetrust-banner-sdk li,#onetrust-banner-sdk nav,#onetrust-banner-sdk table,#onetrust-banner-sdk thead,#onetrust-banner-sdk tr,#onetrust-banner-sdk td,#onetrust-banner-sdk tbody,#onetrust-banner-sdk .ot-main-content,#onetrust-banner-sdk .ot-toggle,#onetrust-banner-sdk #ot-content,#onetrust-banner-sdk #ot-pc-content,#onetrust-banner-sdk .checkbox,#onetrust-pc-sdk div,#onetrust-pc-sdk span,#onetrust-pc-sdk h1,#onetrust-pc-sdk h2,#onetrust-pc-sdk h3,#onetrust-pc-sdk h4,#onetrust-pc-sdk h5,#onetrust-pc-sdk h6,#onetrust-pc-sdk p,#onetrust-pc-sdk img,#onetrust-pc-sdk svg,#onetrust-pc-sdk button,#onetrust-pc-sdk section,#onetrust-pc-sdk a,#onetrust-pc-sdk label,#onetrust-pc-sdk input,#onetrust-pc-sdk ul,#onetrust-pc-sdk li,#onetrust-pc-sdk nav,#onetrust-pc-sdk table,#onetrust-pc-sdk thead,#onetrust-pc-sdk tr,#onetrust-pc-sdk td,#onetrust-pc-sdk tbody,#onetrust-pc-sdk .ot-main-content,#onetrust-pc-sdk .ot-toggle,#onetrust-pc-sdk #ot-content,#onetrust-pc-sdk #ot-pc-content,#onetrust-pc-sdk .checkbox,#ot-sdk-cookie-policy div,#ot-sdk-cookie-policy span,#ot-sdk-cookie-policy h1,#ot-sdk-cookie-policy h2,#ot-sdk-cookie-policy h3,#ot-sdk-cookie-policy h4,#ot-sdk-cookie-policy h5,#ot-sdk-cookie-policy h6,#ot-sdk-cookie-policy p,#ot-sdk-cookie-policy img,#ot-sdk-cookie-policy svg,#ot-sdk-cookie-policy button,#ot-sdk-cookie-policy section,#ot-sdk-cookie-policy a,#ot-sdk-cookie-policy label,#ot-sdk-cookie-policy input,#ot-sdk-cookie-policy ul,#ot-sdk-cookie-policy li,#ot-sdk-cookie-policy nav,#ot-sdk-cookie-policy table,#ot-sdk-cookie-policy thead,#ot-sdk-cookie-policy tr,#ot-sdk-cookie-policy td,#ot-sdk-cookie-policy tbody,#ot-sdk-cookie-policy .ot-main-content,#ot-sdk-cookie-policy .ot-toggle,#ot-sdk-cookie-policy #ot-content,#ot-sdk-cookie-policy #ot-pc-content,#ot-sdk-cookie-policy .checkbox,#ot-sync-ntfy div,#ot-sync-ntfy span,#ot-sync-ntfy h1,#ot-sync-ntfy h2,#ot-sync-ntfy h3,#ot-sync-ntfy h4,#ot-sync-ntfy h5,#ot-sync-ntfy h6,#ot-sync-ntfy p,#ot-sync-ntfy img,#ot-sync-ntfy svg,#ot-sync-ntfy button,#ot-sync-ntfy section,#ot-sync-ntfy a,#ot-sync-ntfy label,#ot-sync-ntfy input,#ot-sync-ntfy ul,#ot-sync-ntfy li,#ot-sync-ntfy nav,#ot-sync-ntfy table,#ot-sync-ntfy thead,#ot-sync-ntfy tr,#ot-sync-ntfy td,#ot-sync-ntfy tbody,#ot-sync-ntfy .ot-main-content,#ot-sync-ntfy .ot-toggle,#ot-sync-ntfy #ot-content,#ot-sync-ntfy #ot-pc-content,#ot-sync-ntfy .checkbox{font-family:inherit;font-weight:400;-webkit-font-smoothing:auto;letter-spacing:normal;line-height:normal;padding:0;margin:0;height:auto;min-height:0;max-height:none;width:auto;min-width:0;max-width:none;border-radius:0;border:none;clear:none;float:none;position:static;bottom:auto;left:auto;right:auto;top:auto;text-align:left;text-decoration:none;text-indent:0;text-shadow:none;text-transform:none;white-space:normal;background:0 0;overflow:visible;vertical-align:baseline;visibility:visible;z-index:auto;box-shadow:none}#onetrust-banner-sdk label:before,#onetrust-banner-sdk label:after,#onetrust-banner-sdk .checkbox:after,#onetrust-banner-sdk .checkbox:before,#onetrust-pc-sdk label:before,#onetrust-pc-sdk label:after,#onetrust-pc-sdk .checkbox:after,#onetrust-pc-sdk .checkbox:before,#ot-sdk-cookie-policy label:before,#ot-sdk-cookie-policy label:after,#ot-sdk-cookie-policy .checkbox:after,#ot-sdk-cookie-policy .checkbox:before,#ot-sync-ntfy label:before,#ot-sync-ntfy label:after,#ot-sync-ntfy .checkbox:after,#ot-sync-ntfy .checkbox:before{content:"";content:none}#onetrust-banner-sdk .ot-sdk-container,#onetrust-pc-sdk .ot-sdk-container,#ot-sdk-cookie-policy .ot-sdk-container{position:relative;width:100%;max-width:100%;margin:0 auto;padding:0 20px;box-sizing:border-box}#onetrust-banner-sdk .ot-sdk-column,#onetrust-banner-sdk .ot-sdk-columns,#onetrust-pc-sdk .ot-sdk-column,#onetrust-pc-sdk .ot-sdk-columns,#ot-sdk-cookie-policy .ot-sdk-column,#ot-sdk-cookie-policy .ot-sdk-columns{width:100%;float:left;box-sizing:border-box;padding:0;display:initial}@media(min-width:400px){#onetrust-banner-sdk .ot-sdk-container,#onetrust-pc-sdk .ot-sdk-container,#ot-sdk-cookie-policy .ot-sdk-container{width:90%;padding:0}}@media(min-width:550px){#onetrust-banner-sdk .ot-sdk-container,#onetrust-pc-sdk .ot-sdk-container,#ot-sdk-cookie-policy .ot-sdk-container{width:100%}#onetrust-banner-sdk .ot-sdk-column,#onetrust-banner-sdk .ot-sdk-columns,#onetrust-pc-sdk .ot-sdk-column,#onetrust-pc-sdk .ot-sdk-columns,#ot-sdk-cookie-policy .ot-sdk-column,#ot-sdk-cookie-policy .ot-sdk-columns{margin-left:4%}#onetrust-banner-sdk .ot-sdk-column:first-child,#onetrust-banner-sdk .ot-sdk-columns:first-child,#onetrust-pc-sdk .ot-sdk-column:first-child,#onetrust-pc-sdk .ot-sdk-columns:first-child,#ot-sdk-cookie-policy .ot-sdk-column:first-child,#ot-sdk-cookie-policy .ot-sdk-columns:first-child{margin-left:0}#onetrust-banner-sdk .ot-sdk-two.ot-sdk-columns,#onetrust-pc-sdk .ot-sdk-two.ot-sdk-columns,#ot-sdk-cookie-policy .ot-sdk-two.ot-sdk-columns{width:13.3333333333%}#onetrust-banner-sdk .ot-sdk-three.ot-sdk-columns,#onetrust-pc-sdk .ot-sdk-three.ot-sdk-columns,#ot-sdk-cookie-policy .ot-sdk-three.ot-sdk-columns{width:22%}#onetrust-banner-sdk .ot-sdk-four.ot-sdk-columns,#onetrust-pc-sdk .ot-sdk-four.ot-sdk-columns,#ot-sdk-cookie-policy .ot-sdk-four.ot-sdk-columns{width:30.6666666667%}#onetrust-banner-sdk .ot-sdk-eight.ot-sdk-columns,#onetrust-pc-sdk .ot-sdk-eight.ot-sdk-columns,#ot-sdk-cookie-policy .ot-sdk-eight.ot-sdk-columns{width:65.3333333333%}#onetrust-banner-sdk .ot-sdk-nine.ot-sdk-columns,#onetrust-pc-sdk .ot-sdk-nine.ot-sdk-columns,#ot-sdk-cookie-policy .ot-sdk-nine.ot-sdk-columns{width:74%}#onetrust-banner-sdk .ot-sdk-ten.ot-sdk-columns,#onetrust-pc-sdk .ot-sdk-ten.ot-sdk-columns,#ot-sdk-cookie-policy .ot-sdk-ten.ot-sdk-columns{width:82.6666666667%}#onetrust-banner-sdk .ot-sdk-eleven.ot-sdk-columns,#onetrust-pc-sdk .ot-sdk-eleven.ot-sdk-columns,#ot-sdk-cookie-policy .ot-sdk-eleven.ot-sdk-columns{width:91.3333333333%}#onetrust-banner-sdk .ot-sdk-twelve.ot-sdk-columns,#onetrust-pc-sdk .ot-sdk-twelve.ot-sdk-columns,#ot-sdk-cookie-policy .ot-sdk-twelve.ot-sdk-columns{width:100%;margin-left:0}}#onetrust-banner-sdk h1,#onetrust-banner-sdk h2,#onetrust-banner-sdk h3,#onetrust-banner-sdk h4,#onetrust-banner-sdk h5,#onetrust-banner-sdk h6,#onetrust-pc-sdk h1,#onetrust-pc-sdk h2,#onetrust-pc-sdk h3,#onetrust-pc-sdk h4,#onetrust-pc-sdk h5,#onetrust-pc-sdk h6,#ot-sdk-cookie-policy h1,#ot-sdk-cookie-policy h2,#ot-sdk-cookie-policy h3,#ot-sdk-cookie-policy h4,#ot-sdk-cookie-policy h5,#ot-sdk-cookie-policy h6{margin-top:0;font-weight:600;font-family:inherit}#onetrust-banner-sdk h1,#onetrust-pc-sdk h1,#ot-sdk-cookie-policy h1{font-size:1.5rem;line-height:1.2}#onetrust-banner-sdk h2,#onetrust-pc-sdk h2,#ot-sdk-cookie-policy h2{font-size:1.5rem;line-height:1.25}#onetrust-banner-sdk h3,#onetrust-pc-sdk h3,#ot-sdk-cookie-policy h3{font-size:1.5rem;line-height:1.3}#onetrust-banner-sdk h4,#onetrust-pc-sdk h4,#ot-sdk-cookie-policy h4{font-size:1.5rem;line-height:1.35}#onetrust-banner-sdk h5,#onetrust-pc-sdk h5,#ot-sdk-cookie-policy h5{font-size:1.5rem;line-height:1.5}#onetrust-banner-sdk h6,#onetrust-pc-sdk h6,#ot-sdk-cookie-policy h6{font-size:1.5rem;line-height:1.6}@media(min-width:550px){#onetrust-banner-sdk h1,#onetrust-pc-sdk h1,#ot-sdk-cookie-policy h1{font-size:1.5rem}#onetrust-banner-sdk h2,#onetrust-pc-sdk h2,#ot-sdk-cookie-policy h2{font-size:1.5rem}#onetrust-banner-sdk h3,#onetrust-pc-sdk h3,#ot-sdk-cookie-policy h3{font-size:1.5rem}#onetrust-banner-sdk h4,#onetrust-pc-sdk h4,#ot-sdk-cookie-policy h4{font-size:1.5rem}#onetrust-banner-sdk h5,#onetrust-pc-sdk h5,#ot-sdk-cookie-policy h5{font-size:1.5rem}#onetrust-banner-sdk h6,#onetrust-pc-sdk h6,#ot-sdk-cookie-policy h6{font-size:1.5rem}}#onetrust-banner-sdk p,#onetrust-pc-sdk p,#ot-sdk-cookie-policy p{margin:0 0 1em;font-family:inherit;line-height:normal}#onetrust-banner-sdk a,#onetrust-pc-sdk a,#ot-sdk-cookie-policy a{color:#565656;text-decoration:underline}#onetrust-banner-sdk a:hover,#onetrust-pc-sdk a:hover,#ot-sdk-cookie-policy a:hover{color:#565656;text-decoration:none}#onetrust-banner-sdk .ot-sdk-button,#onetrust-banner-sdk button,#onetrust-pc-sdk .ot-sdk-button,#onetrust-pc-sdk button,#ot-sdk-cookie-policy .ot-sdk-button,#ot-sdk-cookie-policy button{margin-bottom:1rem;font-family:inherit}#onetrust-banner-sdk .ot-sdk-button,#onetrust-banner-sdk button,#onetrust-pc-sdk .ot-sdk-button,#onetrust-pc-sdk button,#ot-sdk-cookie-policy .ot-sdk-button,#ot-sdk-cookie-policy button{display:inline-block;height:38px;padding:0 30px;color:#555;text-align:center;font-size:.9em;font-weight:400;line-height:38px;letter-spacing:.01em;text-decoration:none;white-space:nowrap;background-color:transparent;border-radius:2px;border:1px solid #bbb;cursor:pointer;box-sizing:border-box}#onetrust-banner-sdk .ot-sdk-button:hover,#onetrust-banner-sdk :not(.ot-leg-btn-container)>button:not(.ot-link-btn):hover,#onetrust-banner-sdk :not(.ot-leg-btn-container)>button:not(.ot-link-btn):focus,#onetrust-pc-sdk .ot-sdk-button:hover,#onetrust-pc-sdk :not(.ot-leg-btn-container)>button:not(.ot-link-btn):hover,#onetrust-pc-sdk :not(.ot-leg-btn-container)>button:not(.ot-link-btn):focus,#ot-sdk-cookie-policy .ot-sdk-button:hover,#ot-sdk-cookie-policy :not(.ot-leg-btn-container)>button:not(.ot-link-btn):hover,#ot-sdk-cookie-policy :not(.ot-leg-btn-container)>button:not(.ot-link-btn):focus{color:#333;border-color:#888;opacity:.7}#onetrust-banner-sdk .ot-sdk-button:focus,#onetrust-banner-sdk :not(.ot-leg-btn-container)>button:focus,#onetrust-pc-sdk .ot-sdk-button:focus,#onetrust-pc-sdk :not(.ot-leg-btn-container)>button:focus,#ot-sdk-cookie-policy .ot-sdk-button:focus,#ot-sdk-cookie-policy :not(.ot-leg-btn-container)>button:focus{outline:2px solid #000}#onetrust-banner-sdk .ot-sdk-button.ot-sdk-button-primary,#onetrust-banner-sdk button.ot-sdk-button-primary,#onetrust-banner-sdk input[type=submit].ot-sdk-button-primary,#onetrust-banner-sdk input[type=reset].ot-sdk-button-primary,#onetrust-banner-sdk input[type=button].ot-sdk-button-primary,#onetrust-pc-sdk .ot-sdk-button.ot-sdk-button-primary,#onetrust-pc-sdk button.ot-sdk-button-primary,#onetrust-pc-sdk input[type=submit].ot-sdk-button-primary,#onetrust-pc-sdk input[type=reset].ot-sdk-button-primary,#onetrust-pc-sdk input[type=button].ot-sdk-button-primary,#ot-sdk-cookie-policy .ot-sdk-button.ot-sdk-button-primary,#ot-sdk-cookie-policy button.ot-sdk-button-primary,#ot-sdk-cookie-policy input[type=submit].ot-sdk-button-primary,#ot-sdk-cookie-policy input[type=reset].ot-sdk-button-primary,#ot-sdk-cookie-policy input[type=button].ot-sdk-button-primary{color:#fff;background-color:#33c3f0;border-color:#33c3f0}#onetrust-banner-sdk .ot-sdk-button.ot-sdk-button-primary:hover,#onetrust-banner-sdk button.ot-sdk-button-primary:hover,#onetrust-banner-sdk input[type=submit].ot-sdk-button-primary:hover,#onetrust-banner-sdk input[type=reset].ot-sdk-button-primary:hover,#onetrust-banner-sdk input[type=button].ot-sdk-button-primary:hover,#onetrust-banner-sdk .ot-sdk-button.ot-sdk-button-primary:focus,#onetrust-banner-sdk button.ot-sdk-button-primary:focus,#onetrust-banner-sdk input[type=submit].ot-sdk-button-primary:focus,#onetrust-banner-sdk input[type=reset].ot-sdk-button-primary:focus,#onetrust-banner-sdk input[type=button].ot-sdk-button-primary:focus,#onetrust-pc-sdk .ot-sdk-button.ot-sdk-button-primary:hover,#onetrust-pc-sdk button.ot-sdk-button-primary:hover,#onetrust-pc-sdk input[type=submit].ot-sdk-button-primary:hover,#onetrust-pc-sdk input[type=reset].ot-sdk-button-primary:hover,#onetrust-pc-sdk input[type=button].ot-sdk-button-primary:hover,#onetrust-pc-sdk .ot-sdk-button.ot-sdk-button-primary:focus,#onetrust-pc-sdk button.ot-sdk-button-primary:focus,#onetrust-pc-sdk input[type=submit].ot-sdk-button-primary:focus,#onetrust-pc-sdk input[type=reset].ot-sdk-button-primary:focus,#onetrust-pc-sdk input[type=button].ot-sdk-button-primary:focus,#ot-sdk-cookie-policy .ot-sdk-button.ot-sdk-button-primary:hover,#ot-sdk-cookie-policy button.ot-sdk-button-primary:hover,#ot-sdk-cookie-policy input[type=submit].ot-sdk-button-primary:hover,#ot-sdk-cookie-policy input[type=reset].ot-sdk-button-primary:hover,#ot-sdk-cookie-policy input[type=button].ot-sdk-button-primary:hover,#ot-sdk-cookie-policy .ot-sdk-button.ot-sdk-button-primary:focus,#ot-sdk-cookie-policy button.ot-sdk-button-primary:focus,#ot-sdk-cookie-policy input[type=submit].ot-sdk-button-primary:focus,#ot-sdk-cookie-policy input[type=reset].ot-sdk-button-primary:focus,#ot-sdk-cookie-policy input[type=button].ot-sdk-button-primary:focus{color:#fff;background-color:#1eaedb;border-color:#1eaedb}#onetrust-banner-sdk input[type=text],#onetrust-pc-sdk input[type=text],#ot-sdk-cookie-policy input[type=text]{height:38px;padding:6px 10px;background-color:#fff;border:1px solid #d1d1d1;border-radius:4px;box-shadow:none;box-sizing:border-box}#onetrust-banner-sdk input[type=text],#onetrust-pc-sdk input[type=text],#ot-sdk-cookie-policy input[type=text]{-webkit-appearance:none;-moz-appearance:none;appearance:none}#onetrust-banner-sdk input[type=text]:focus,#onetrust-pc-sdk input[type=text]:focus,#ot-sdk-cookie-policy input[type=text]:focus{border:1px solid #000;outline:0}#onetrust-banner-sdk label,#onetrust-pc-sdk label,#ot-sdk-cookie-policy label{display:block;margin-bottom:.5rem;font-weight:600}#onetrust-banner-sdk input[type=checkbox],#onetrust-pc-sdk input[type=checkbox],#ot-sdk-cookie-policy input[type=checkbox]{display:inline}#onetrust-banner-sdk ul,#onetrust-pc-sdk ul,#ot-sdk-cookie-policy ul{list-style:circle inside}#onetrust-banner-sdk ul,#onetrust-pc-sdk ul,#ot-sdk-cookie-policy ul{padding-left:0;margin-top:0}#onetrust-banner-sdk ul ul,#onetrust-pc-sdk ul ul,#ot-sdk-cookie-policy ul ul{margin:1.5rem 0 1.5rem 3rem;font-size:90%}#onetrust-banner-sdk li,#onetrust-pc-sdk li,#ot-sdk-cookie-policy li{margin-bottom:1rem}#onetrust-banner-sdk th,#onetrust-banner-sdk td,#onetrust-pc-sdk th,#onetrust-pc-sdk td,#ot-sdk-cookie-policy th,#ot-sdk-cookie-policy td{padding:12px 15px;text-align:left;border-bottom:1px solid #e1e1e1}#onetrust-banner-sdk button,#onetrust-pc-sdk button,#ot-sdk-cookie-policy button{margin-bottom:1rem;font-family:inherit}#onetrust-banner-sdk .ot-sdk-container:after,#onetrust-banner-sdk .ot-sdk-row:after,#onetrust-pc-sdk .ot-sdk-container:after,#onetrust-pc-sdk .ot-sdk-row:after,#ot-sdk-cookie-policy .ot-sdk-container:after,#ot-sdk-cookie-policy .ot-sdk-row:after{content:"";display:table;clear:both}#onetrust-banner-sdk .ot-sdk-row,#onetrust-pc-sdk .ot-sdk-row,#ot-sdk-cookie-policy .ot-sdk-row{margin:0;max-width:none;display:block}#onetrust-banner-sdk{box-shadow:0 0 18px rgba(0,0,0,.2)}#onetrust-banner-sdk.otFlat{position:fixed;z-index:2147483645;bottom:0;right:0;left:0;background-color:#fff;max-height:90%;overflow-x:hidden;overflow-y:auto}#onetrust-banner-sdk.otFlat.top{top:0px;bottom:auto}#onetrust-banner-sdk.otRelFont{font-size:1rem}#onetrust-banner-sdk>.ot-sdk-container{overflow:hidden}#onetrust-banner-sdk::-webkit-scrollbar{width:11px}#onetrust-banner-sdk::-webkit-scrollbar-thumb{border-radius:10px;background:#c1c1c1}#onetrust-banner-sdk{scrollbar-arrow-color:#c1c1c1;scrollbar-darkshadow-color:#c1c1c1;scrollbar-face-color:#c1c1c1;scrollbar-shadow-color:#c1c1c1}#onetrust-banner-sdk #onetrust-policy{margin:1.25em 0 .625em 2em;overflow:hidden}#onetrust-banner-sdk #onetrust-policy .ot-gv-list-handler{float:left;font-size:.82em;padding:0;margin-bottom:0;border:0;line-height:normal;height:auto;width:auto}#onetrust-banner-sdk #onetrust-policy-title{font-size:1.2em;line-height:1.3;margin-bottom:10px}#onetrust-banner-sdk #onetrust-policy-text{clear:both;text-align:left;font-size:.88em;line-height:1.4}#onetrust-banner-sdk #onetrust-policy-text *{font-size:inherit;line-height:inherit}#onetrust-banner-sdk #onetrust-policy-text a{font-weight:bold;margin-left:5px}#onetrust-banner-sdk #onetrust-policy-title,#onetrust-banner-sdk #onetrust-policy-text{color:dimgray;float:left}#onetrust-banner-sdk #onetrust-button-group-parent{min-height:1px;text-align:center}#onetrust-banner-sdk #onetrust-button-group{display:inline-block}#onetrust-banner-sdk #onetrust-accept-btn-handler,#onetrust-banner-sdk #onetrust-reject-all-handler,#onetrust-banner-sdk #onetrust-pc-btn-handler{background-color:#68b631;color:#fff;border-color:#68b631;margin-right:1em;min-width:125px;height:auto;white-space:normal;word-break:break-word;word-wrap:break-word;padding:12px 10px;line-height:1.2;font-size:.813em;font-weight:600}#onetrust-banner-sdk #onetrust-pc-btn-handler.cookie-setting-link{background-color:#fff;border:none;color:#68b631;text-decoration:underline;padding-left:0;padding-right:0}#onetrust-banner-sdk .onetrust-close-btn-ui{width:44px;height:44px;background-size:12px;border:none;position:relative;margin:auto;padding:0}#onetrust-banner-sdk .banner_logo{display:none}#onetrust-banner-sdk.ot-bnr-w-logo .ot-bnr-logo{position:absolute;top:50%;transform:translateY(-50%);left:0px}#onetrust-banner-sdk.ot-bnr-w-logo #onetrust-policy{margin-left:65px}#onetrust-banner-sdk .ot-b-addl-desc{clear:both;float:left;display:block}#onetrust-banner-sdk #banner-options{float:left;display:table;margin-right:0;margin-left:1em;width:calc(100% - 1em)}#onetrust-banner-sdk .banner-option-input{cursor:pointer;width:auto;height:auto;border:none;padding:0;padding-right:3px;margin:0 0 10px;font-size:.82em;line-height:1.4}#onetrust-banner-sdk .banner-option-input *{pointer-events:none;font-size:inherit;line-height:inherit}#onetrust-banner-sdk .banner-option-input[aria-expanded=true]~.banner-option-details{display:block;height:auto}#onetrust-banner-sdk .banner-option-input[aria-expanded=true] .ot-arrow-container{transform:rotate(90deg)}#onetrust-banner-sdk .banner-option{margin-bottom:12px;margin-left:0;border:none;float:left;padding:0}#onetrust-banner-sdk .banner-option:first-child{padding-left:2px}#onetrust-banner-sdk .banner-option:not(:first-child){padding:0;border:none}#onetrust-banner-sdk .banner-option-header{cursor:pointer;display:inline-block}#onetrust-banner-sdk .banner-option-header :first-child{color:dimgray;font-weight:bold;float:left}#onetrust-banner-sdk .banner-option-header .ot-arrow-container{display:inline-block;border-top:6px solid rgba(0,0,0,0);border-bottom:6px solid rgba(0,0,0,0);border-left:6px solid dimgray;margin-left:10px;vertical-align:middle}#onetrust-banner-sdk .banner-option-details{display:none;font-size:.83em;line-height:1.5;padding:10px 0px 5px 10px;margin-right:10px;height:0px}#onetrust-banner-sdk .banner-option-details *{font-size:inherit;line-height:inherit;color:dimgray}#onetrust-banner-sdk .ot-arrow-container,#onetrust-banner-sdk .banner-option-details{transition:all 300ms ease-in 0s;-webkit-transition:all 300ms ease-in 0s;-moz-transition:all 300ms ease-in 0s;-o-transition:all 300ms ease-in 0s}#onetrust-banner-sdk .ot-dpd-container{float:left}#onetrust-banner-sdk .ot-dpd-title{margin-bottom:10px}#onetrust-banner-sdk .ot-dpd-title,#onetrust-banner-sdk .ot-dpd-desc{font-size:.88em;line-height:1.4;color:dimgray}#onetrust-banner-sdk .ot-dpd-title *,#onetrust-banner-sdk .ot-dpd-desc *{font-size:inherit;line-height:inherit}#onetrust-banner-sdk.ot-iab-2 #onetrust-policy-text *{margin-bottom:0}#onetrust-banner-sdk.ot-iab-2 .onetrust-vendors-list-handler{display:block;margin-left:0;margin-top:5px;clear:both;margin-bottom:0;padding:0;border:0;height:auto;width:auto}#onetrust-banner-sdk.ot-iab-2 #onetrust-button-group button{display:block}#onetrust-banner-sdk.ot-close-btn-link{padding-top:25px}#onetrust-banner-sdk.ot-close-btn-link #onetrust-close-btn-container{top:15px;transform:none;right:15px}#onetrust-banner-sdk.ot-close-btn-link #onetrust-close-btn-container button{padding:0;white-space:pre-wrap;border:none;height:auto;line-height:1.5;text-decoration:underline;font-size:.69em}#onetrust-banner-sdk #onetrust-policy-text,#onetrust-banner-sdk .ot-dpd-desc,#onetrust-banner-sdk .ot-b-addl-desc{font-size:.813em;line-height:1.5}#onetrust-banner-sdk .ot-dpd-desc{margin-bottom:10px}#onetrust-banner-sdk .ot-dpd-desc>.ot-b-addl-desc{margin-top:10px;margin-bottom:10px;font-size:1em}@media only screen and (max-width: 425px){#onetrust-banner-sdk #onetrust-close-btn-container{position:absolute;top:6px;right:2px}#onetrust-banner-sdk #onetrust-policy{margin-left:0;margin-top:3em}#onetrust-banner-sdk #onetrust-button-group{display:block}#onetrust-banner-sdk #onetrust-accept-btn-handler,#onetrust-banner-sdk #onetrust-reject-all-handler,#onetrust-banner-sdk #onetrust-pc-btn-handler{width:100%}#onetrust-banner-sdk .onetrust-close-btn-ui{top:auto;transform:none}#onetrust-banner-sdk #onetrust-policy-title{display:inline;float:none}#onetrust-banner-sdk #banner-options{margin:0;padding:0;width:100%}}@media only screen and (min-width: 426px)and (max-width: 896px){#onetrust-banner-sdk #onetrust-close-btn-container{position:absolute;top:0;right:0}#onetrust-banner-sdk #onetrust-policy{margin-left:1em;margin-right:1em}#onetrust-banner-sdk .onetrust-close-btn-ui{top:10px;right:10px}#onetrust-banner-sdk:not(.ot-iab-2) #onetrust-group-container{width:95%}#onetrust-banner-sdk.ot-iab-2 #onetrust-group-container{width:100%}#onetrust-banner-sdk.ot-bnr-w-logo #onetrust-button-group-parent{padding-left:50px}#onetrust-banner-sdk #onetrust-button-group-parent{width:100%;position:relative;margin-left:0}#onetrust-banner-sdk #onetrust-button-group button{display:inline-block}#onetrust-banner-sdk #onetrust-button-group{margin-right:0;text-align:center}#onetrust-banner-sdk .has-reject-all-button #onetrust-pc-btn-handler{float:left}#onetrust-banner-sdk .has-reject-all-button #onetrust-reject-all-handler,#onetrust-banner-sdk .has-reject-all-button #onetrust-accept-btn-handler{float:right}#onetrust-banner-sdk .has-reject-all-button #onetrust-button-group{width:calc(100% - 2em);margin-right:0}#onetrust-banner-sdk .has-reject-all-button #onetrust-pc-btn-handler.cookie-setting-link{padding-left:0px;text-align:left}#onetrust-banner-sdk.ot-buttons-fw .ot-sdk-three button{width:100%;text-align:center}#onetrust-banner-sdk.ot-buttons-fw #onetrust-button-group-parent button{float:none}#onetrust-banner-sdk.ot-buttons-fw #onetrust-pc-btn-handler.cookie-setting-link{text-align:center}}@media only screen and (min-width: 550px){#onetrust-banner-sdk .banner-option:not(:first-child){border-left:1px solid #d8d8d8;padding-left:25px}}@media only screen and (min-width: 425px)and (max-width: 550px){#onetrust-banner-sdk.ot-iab-2 #onetrust-button-group,#onetrust-banner-sdk.ot-iab-2 #onetrust-policy,#onetrust-banner-sdk.ot-iab-2 .banner-option{width:100%}#onetrust-banner-sdk.ot-iab-2 #onetrust-button-group #onetrust-accept-btn-handler,#onetrust-banner-sdk.ot-iab-2 #onetrust-button-group #onetrust-reject-all-handler,#onetrust-banner-sdk.ot-iab-2 #onetrust-button-group #onetrust-pc-btn-handler{width:100%}#onetrust-banner-sdk.ot-iab-2 #onetrust-button-group #onetrust-accept-btn-handler,#onetrust-banner-sdk.ot-iab-2 #onetrust-button-group #onetrust-reject-all-handler{float:left}}@media only screen and (min-width: 769px){#onetrust-banner-sdk #onetrust-button-group{margin-right:30%}#onetrust-banner-sdk #banner-options{margin-left:2em;margin-right:5em;margin-bottom:1.25em;width:calc(100% - 7em)}}@media only screen and (min-width: 897px)and (max-width: 1023px){#onetrust-banner-sdk.vertical-align-content #onetrust-button-group-parent{position:absolute;top:50%;left:75%;transform:translateY(-50%)}#onetrust-banner-sdk #onetrust-close-btn-container{top:50%;margin:auto;transform:translate(-50%, -50%);position:absolute;padding:0;right:0}#onetrust-banner-sdk #onetrust-close-btn-container button{position:relative;margin:0;right:-22px;top:2px}}@media only screen and (min-width: 1024px){#onetrust-banner-sdk #onetrust-close-btn-container{top:50%;margin:auto;transform:translate(-50%, -50%);position:absolute;right:0}#onetrust-banner-sdk #onetrust-close-btn-container button{right:-12px}#onetrust-banner-sdk #onetrust-policy{margin-left:2em}#onetrust-banner-sdk.vertical-align-content #onetrust-button-group-parent{position:absolute;top:50%;left:60%;transform:translateY(-50%)}#onetrust-banner-sdk .ot-optout-signal{width:50%}#onetrust-banner-sdk.ot-iab-2 #onetrust-policy-title{width:50%}#onetrust-banner-sdk.ot-iab-2 #onetrust-policy-text,#onetrust-banner-sdk.ot-iab-2 :not(.ot-dpd-desc)>.ot-b-addl-desc{margin-bottom:1em;width:50%;border-right:1px solid #d8d8d8;padding-right:1rem}#onetrust-banner-sdk.ot-iab-2 #onetrust-policy-text{margin-bottom:0;padding-bottom:1em}#onetrust-banner-sdk.ot-iab-2 :not(.ot-dpd-desc)>.ot-b-addl-desc{margin-bottom:0;padding-bottom:1em}#onetrust-banner-sdk.ot-iab-2 .ot-dpd-container{width:45%;padding-left:1rem;display:inline-block;float:none}#onetrust-banner-sdk.ot-iab-2 .ot-dpd-title{line-height:1.7}#onetrust-banner-sdk.ot-iab-2 #onetrust-button-group-parent{left:auto;right:4%;margin-left:0}#onetrust-banner-sdk.ot-iab-2 #onetrust-button-group button{display:block}#onetrust-banner-sdk:not(.ot-iab-2) #onetrust-button-group-parent{margin:auto;width:30%}#onetrust-banner-sdk:not(.ot-iab-2) #onetrust-group-container{width:60%}#onetrust-banner-sdk #onetrust-button-group{margin-right:auto}#onetrust-banner-sdk #onetrust-accept-btn-handler,#onetrust-banner-sdk #onetrust-reject-all-handler,#onetrust-banner-sdk #onetrust-pc-btn-handler{margin-top:1em}}@media only screen and (min-width: 890px){#onetrust-banner-sdk.ot-buttons-fw:not(.ot-iab-2) #onetrust-button-group-parent{padding-left:3%;padding-right:4%;margin-left:0}#onetrust-banner-sdk.ot-buttons-fw:not(.ot-iab-2) #onetrust-button-group{margin-right:0;margin-top:1.25em;width:100%}#onetrust-banner-sdk.ot-buttons-fw:not(.ot-iab-2) #onetrust-button-group button{width:100%;margin-bottom:5px;margin-top:5px}#onetrust-banner-sdk.ot-buttons-fw:not(.ot-iab-2) #onetrust-button-group button:last-of-type{margin-bottom:20px}}@media only screen and (min-width: 1280px){#onetrust-banner-sdk:not(.ot-iab-2) #onetrust-group-container{width:55%}#onetrust-banner-sdk:not(.ot-iab-2) #onetrust-button-group-parent{width:44%;padding-left:2%;padding-right:2%}#onetrust-banner-sdk:not(.ot-iab-2).vertical-align-content #onetrust-button-group-parent{position:absolute;left:55%}}
        #onetrust-consent-sdk #onetrust-banner-sdk {background-color: #FFF;}
            #onetrust-consent-sdk #onetrust-policy-title,
                    #onetrust-consent-sdk #onetrust-policy-text,
                    #onetrust-consent-sdk .ot-b-addl-desc,
                    #onetrust-consent-sdk .ot-dpd-desc,
                    #onetrust-consent-sdk .ot-dpd-title,
                    #onetrust-consent-sdk #onetrust-policy-text *:not(.onetrust-vendors-list-handler),
                    #onetrust-consent-sdk .ot-dpd-desc *:not(.onetrust-vendors-list-handler),
                    #onetrust-consent-sdk #onetrust-banner-sdk #banner-options *,
                    #onetrust-banner-sdk .ot-cat-header,
                    #onetrust-banner-sdk .ot-optout-signal
                    {
                        color: #2E2E2E;
                    }
            #onetrust-consent-sdk #onetrust-banner-sdk .banner-option-details {
                    background-color: #E9E9E9;}
             #onetrust-consent-sdk #onetrust-banner-sdk a[href],
                    #onetrust-consent-sdk #onetrust-banner-sdk a[href] font,
                    #onetrust-consent-sdk #onetrust-banner-sdk .ot-link-btn
                        {
                            color: #007398;
                        }#onetrust-consent-sdk #onetrust-accept-btn-handler,
                         #onetrust-banner-sdk #onetrust-reject-all-handler {
                            background-color: #007398;border-color: #007398;
                color: #FFF;
            }
            #onetrust-consent-sdk #onetrust-banner-sdk *:focus,
            #onetrust-consent-sdk #onetrust-banner-sdk:focus {
               outline-color: #000000;
               outline-width: 1px;
            }
            #onetrust-consent-sdk #onetrust-pc-btn-handler,
            #onetrust-consent-sdk #onetrust-pc-btn-handler.cookie-setting-link {
                color: #6CC04A; border-color: #6CC04A;
                background-color:
                #FFF;
            }/*! Extra code to blur out background */
.onetrust-pc-dark-filter{
background:rgba(0,0,0,.5);
z-index:2147483646;
width:100%;
height:100%;
overflow:hidden;
position:fixed;
top:0;
bottom:0;
left:0;
backdrop-filter: initial
}

/*! v6.12.0 2021-01-19 */
div#onetrust-consent-sdk #onetrust-banner-sdk{border-top:2px solid #eb6500!important;outline:1px solid transparent;box-shadow:none;padding:24px}div#onetrust-consent-sdk button{border-radius:0!important;box-shadow:none!important;box-sizing:border-box!important;font-size:20px!important;font-weight:400!important;letter-spacing:0!important;max-width:none!important;white-space:nowrap!important}div#onetrust-consent-sdk button:not(.ot-link-btn){background-color:#007398!important;border:2px solid #007398!important;color:#fff!important;height:48px!important;padding:0 1em!important;width:auto!important}div#onetrust-consent-sdk button:hover{background-color:#fff!important;border-color:#eb6500!important;color:#2e2e2e!important}div#onetrust-consent-sdk button.ot-link-btn{color:#007398!important;font-size:16px!important;text-decoration:underline}div#onetrust-consent-sdk button.ot-link-btn:hover{color:inherit!important;text-decoration-color:#eb6500!important}div#onetrust-consent-sdk a,div#onetrust-pc-sdk a{color:#007398!important;text-decoration:underline!important}div#onetrust-consent-sdk a,div#onetrust-consent-sdk button,div#onetrust-consent-sdk p:hover{opacity:1!important}div#onetrust-consent-sdk a:focus,div#onetrust-consent-sdk button:focus,div#onetrust-consent-sdk input:focus{outline:2px solid #eb6500!important;outline-offset:1px!important}div#onetrust-banner-sdk .ot-sdk-container{padding:0;width:auto}div#onetrust-banner-sdk .ot-sdk-row{align-items:flex-start;box-sizing:border-box;display:flex;flex-direction:column;justify-content:space-between;margin:auto;max-width:1152px}div#onetrust-banner-sdk .ot-sdk-row:after{display:none}div#onetrust-banner-sdk #onetrust-group-container,div#onetrust-banner-sdk.ot-bnr-flift:not(.ot-iab-2) #onetrust-group-container,div#onetrust-banner-sdk:not(.ot-iab-2) #onetrust-group-container{flex-grow:1;width:auto}div#onetrust-banner-sdk #onetrust-policy,div#onetrust-banner-sdk.ot-bnr-flift #onetrust-policy{margin:0;overflow:visible}div#onetrust-banner-sdk.ot-bnr-flift #onetrust-policy-text,div#onetrust-consent-sdk #onetrust-policy-text{font-size:16px;line-height:24px;max-width:44em;margin:0}div#onetrust-consent-sdk #onetrust-policy-text a[href]{font-weight:400;margin-left:8px}div#onetrust-banner-sdk #onetrust-button-group-parent{flex:0 0 auto;margin:32px 0 0;width:100%}div#onetrust-banner-sdk #onetrust-button-group{display:flex;flex-direction:row;flex-wrap:wrap;justify-content:flex-end;margin:-8px}div#onetrust-banner-sdk .banner-actions-container{display:flex;flex:1 0 auto}div#onetrust-banner-sdk.ot-buttons-fw:not(.ot-iab-2) #onetrust-button-group button:last-of-type,div#onetrust-consent-sdk #onetrust-accept-btn-handler,div#onetrust-consent-sdk #onetrust-pc-btn-handler{flex:1 0 auto;margin:8px;width:auto}div#onetrust-consent-sdk #onetrust-pc-btn-handler{background-color:#fff!important;color:inherit!important}div#onetrust-banner-sdk #onetrust-close-btn-container{display:none}@media only screen and (min-width:556px){div#onetrust-consent-sdk #onetrust-banner-sdk{padding:40px}div#onetrust-banner-sdk #onetrust-policy{margin:0 40px 0 0}div#onetrust-banner-sdk .ot-sdk-row{align-items:center;flex-direction:row}div#onetrust-banner-sdk #onetrust-button-group-parent,div#onetrust-banner-sdk.ot-bnr-flift:not(.ot-iab-2) #onetrust-button-group-parent,div#onetrust-banner-sdk:not(.ot-iab-2) #onetrust-button-group-parent{margin:0;padding:0;width:auto}div#onetrust-banner-sdk #onetrust-button-group,div#onetrust-banner-sdk.ot-buttons-fw:not(.ot-iab-2) #onetrust-button-group{align-items:stretch;flex-direction:column-reverse;margin:0}div#onetrust-consent-sdk #onetrust-accept-btn-handler,div#onetrust-consent-sdk #onetrust-pc-btn-handler{flex:1 0 auto}}@media only screen and (min-width:768px){div#onetrust-banner-sdk #onetrust-policy{margin:0 48px 0 0}div#onetrust-consent-sdk #onetrust-banner-sdk{padding:48px}}div#onetrust-consent-sdk #onetrust-pc-sdk h5{font-size:16px;line-height:24px}div#onetrust-consent-sdk #onetrust-pc-sdk p,div#onetrust-pc-sdk #ot-pc-desc,div#onetrust-pc-sdk .category-host-list-handler,div#onetrust-pc-sdk .ot-accordion-layout .ot-cat-header{font-size:16px;font-weight:400;line-height:24px}div#onetrust-consent-sdk a:hover,div#onetrust-pc-sdk a:hover{color:inherit!important;text-decoration-color:#eb6500!important}div#onetrust-pc-sdk{border-radius:0;bottom:0;height:auto;left:0;margin:auto;max-width:100%;overflow:hidden;right:0;top:0;width:512px;max-height:800px}div#onetrust-pc-sdk .ot-pc-header{display:none}div#onetrust-pc-sdk #ot-pc-content{overscroll-behavior:contain;padding:0 12px 0 24px;margin:16px 4px 0 0;top:0;right:16px;left:0;width:auto}div#onetrust-pc-sdk #ot-category-title,div#onetrust-pc-sdk #ot-pc-title{font-size:24px;font-weight:400;line-height:32px;margin:0 0 16px}div#onetrust-pc-sdk #ot-pc-desc{padding:0}div#onetrust-pc-sdk #ot-pc-desc a{display:inline}div#onetrust-pc-sdk #accept-recommended-btn-handler{display:none!important}div#onetrust-pc-sdk input[type=checkbox]:focus+.ot-acc-hdr{outline:2px solid #eb6500;outline-offset:-1px;transition:none}div#onetrust-pc-sdk .ot-accordion-layout.ot-cat-item{border-width:0 0 2px}div#onetrust-pc-sdk .ot-accordion-layout.ot-cat-item:first-of-type{border-width:2px 0}div#onetrust-pc-sdk .ot-accordion-layout .ot-acc-hdr{padding:8px 0;width:100%}div#onetrust-pc-sdk .ot-plus-minus{transform:translateY(2px)}div#onetrust-pc-sdk .ot-accordion-layout.ot-cat-item>button{background:0 0!important;border:0!important;height:44px!important;max-width:none!important;width:calc(100% - 48px)!important}div#onetrust-consent-sdk #onetrust-pc-sdk h5{font-weight:700}div#onetrust-pc-sdk .ot-accordion-layout .ot-hlst-cntr{padding:0}div#onetrust-pc-sdk .ot-accordion-layout.ot-cat-item .ot-acc-grpdesc{padding:0;width:100%}div#onetrust-pc-sdk .ot-acc-grpcntr .ot-subgrp-cntr{border:0;padding:0}div#onetrust-pc-sdk .ot-subgrp-cntr ul.ot-subgrps li.ot-subgrp{margin:0}div#onetrust-pc-sdk .ot-always-active-group .ot-cat-header{width:calc(100% - 160px)}#onetrust-pc-sdk .ot-accordion-layout .ot-cat-header{width:calc(100% - 88px)}div#onetrust-pc-sdk .ot-accordion-layout h4~.ot-always-active{color:inherit;font-size:12px;font-weight:400;line-height:1.5;padding-right:48px}div#onetrust-pc-sdk .ot-accordion-layout h4~.ot-always-active:before{border-radius:12px;position:absolute;right:0;top:0;content:'';background:#fff;border:2px solid #939393;box-sizing:border-box;height:20px;width:40px}div#onetrust-pc-sdk .ot-accordion-layout h4~.ot-always-active:after{border-radius:50%;position:absolute;right:5px;top:4px;content:'';background-color:#eb6500;height:12px;width:12px}div#onetrust-pc-sdk .ot-accordion-layout h4~.ot-always-active,div#onetrust-pc-sdk .ot-accordion-layout h4~.ot-tgl{right:2px}div#onetrust-pc-sdk .ot-switch{display:block;height:20px;width:40px}div#onetrust-pc-sdk .ot-tgl input+.ot-switch .ot-switch-nob,div#onetrust-pc-sdk .ot-tgl input:checked+.ot-switch .ot-switch-nob{background:#fff;border:2px solid #939393;box-sizing:border-box;height:20px;width:40px}div#onetrust-pc-sdk .ot-tgl input+.ot-switch .ot-switch-nob:before{background-color:#737373;height:8px;left:4px;top:4px;width:8px}div#onetrust-pc-sdk .ot-tgl input:checked+.ot-switch .ot-switch-nob:before{background-color:#eb6500;height:12px;left:0;top:2px;width:12px}div#onetrust-pc-sdk .ot-tgl input:focus+.ot-switch .ot-switch-nob{box-shadow:0 0;outline:2px solid #eb6500!important;outline-offset:1px;transition:none}div#onetrust-consent-sdk #onetrust-pc-sdk .ot-acc-grpcntr.ot-acc-txt{background-color:transparent;padding-left:3px}div#onetrust-pc-sdk .ot-accordion-layout .ot-hlst-cntr,div#onetrust-pc-sdk .ot-accordion-layout .ot-vlst-cntr{overflow:visible;width:100%}div#onetrust-pc-sdk .ot-pc-footer{border-top:0 solid}div#onetrust-pc-sdk .ot-btn-container{padding-top:24px;text-align:center}div#onetrust-pc-sdk .ot-pc-footer button{margin:8px 0;background-color:#fff}div#onetrust-pc-sdk .ot-pc-footer-logo{background-color:#fff}div#onetrust-pc-sdk #ot-lst-title span{font-size:24px;font-weight:400;line-height:32px}div#onetrust-pc-sdk #ot-host-lst .ot-host-desc,div#onetrust-pc-sdk #ot-host-lst .ot-host-expand,div#onetrust-pc-sdk #ot-host-lst .ot-host-name,div#onetrust-pc-sdk #ot-host-lst .ot-host-name a,div#onetrust-pc-sdk .back-btn-handler,div#onetrust-pc-sdk .ot-host-opt li>div div{font-size:16px;font-weight:400;line-height:24px}div#onetrust-pc-sdk #ot-host-lst .ot-acc-txt{width:100%}div#onetrust-pc-sdk #ot-pc-lst{top:0}div#onetrust-pc-sdk .back-btn-handler{text-decoration:none!important}div#onetrust-pc-sdk #filter-btn-handler:hover svg{filter:invert(1)}div#onetrust-pc-sdk .back-btn-handler svg{width:16px;height:16px}div#onetrust-pc-sdk .ot-host-item>button{background:0 0!important;border:0!important;height:66px!important;max-width:none!important;width:calc(100% - 5px)!important;transform:translate(2px,2px)}div#onetrust-pc-sdk .ot-host-item{border-bottom:2px solid #b9b9b9;padding:0}div#onetrust-pc-sdk .ot-host-item .ot-acc-hdr{margin:0 0 -6px;padding:8px 0}div#onetrust-pc-sdk ul li:first-child{border-top:2px solid #b9b9b9}div#onetrust-pc-sdk .ot-host-item .ot-plus-minus{margin:0 8px 0 0}div#onetrust-pc-sdk .ot-search-cntr{width:calc(100% - 48px)}div#onetrust-pc-sdk .ot-host-opt .ot-host-info{background-color:transparent}div#onetrust-pc-sdk .ot-host-opt li>div div{padding:0}div#onetrust-pc-sdk #vendor-search-handler{border-radius:0;border-color:#939393;border-style:solid;border-width:2px 0 2px 2px;font-size:20px;height:48px;margin:0}div#onetrust-pc-sdk #ot-pc-hdr{margin-left:24px}div#onetrust-pc-sdk .ot-lst-subhdr{width:calc(100% - 24px)}div#onetrust-pc-sdk .ot-lst-subhdr svg{right:0;top:8px}div#onetrust-pc-sdk .ot-fltr-cntr{box-sizing:border-box;right:0;width:48px}div#onetrust-pc-sdk #filter-btn-handler{width:48px!important;padding:8px!important}div#onetrust-consent-sdk #onetrust-pc-sdk #clear-filters-handler,div#onetrust-pc-sdk button#filter-apply-handler,div#onetrust-pc-sdk button#filter-cancel-handler{height:2em!important;padding-left:14px!important;padding-right:14px!important}div#onetrust-pc-sdk #ot-fltr-cnt{box-shadow:0 0;border:1px solid #8e8e8e;border-radius:0}div#onetrust-pc-sdk .ot-fltr-scrlcnt{max-height:calc(100% - 80px)}div#onetrust-pc-sdk #ot-fltr-modal{max-height:400px}div#onetrust-pc-sdk .ot-fltr-opt{margin-bottom:16px}div#onetrust-pc-sdk #ot-lst-cnt{margin-left:24px;width:calc(100% - 48px)}div#onetrust-pc-sdk #ot-anchor{display:none!important}
/* 2023-12-04  Fix for button order in mobile view*/
@media (max-width: 550px) {
  #onetrust-accept-btn-handler {order: 1;  }
  #onetrust-reject-all-handler { order: 2;  }
  #onetrust-pc-btn-handler { order: 3;  }
}
#onetrust-pc-sdk.otPcCenter{overflow:hidden;position:fixed;margin:0 auto;top:5%;right:0;left:0;width:40%;max-width:575px;min-width:575px;border-radius:2.5px;z-index:2147483647;background-color:#fff;-webkit-box-shadow:0px 2px 10px -3px #999;-moz-box-shadow:0px 2px 10px -3px #999;box-shadow:0px 2px 10px -3px #999}#onetrust-pc-sdk.otPcCenter[dir=rtl]{right:0;left:0}#onetrust-pc-sdk.otRelFont{font-size:1rem}#onetrust-pc-sdk .ot-optout-signal{margin-top:.625rem}#onetrust-pc-sdk #ot-addtl-venlst .ot-arw-cntr,#onetrust-pc-sdk #ot-addtl-venlst .ot-plus-minus,#onetrust-pc-sdk .ot-hide-tgl{visibility:hidden}#onetrust-pc-sdk #ot-addtl-venlst .ot-arw-cntr *,#onetrust-pc-sdk #ot-addtl-venlst .ot-plus-minus *,#onetrust-pc-sdk .ot-hide-tgl *{visibility:hidden}#onetrust-pc-sdk #ot-gn-venlst .ot-ven-item .ot-acc-hdr{min-height:40px}#onetrust-pc-sdk .ot-pc-header{height:39px;padding:10px 0 10px 30px;border-bottom:1px solid #e9e9e9}#onetrust-pc-sdk #ot-pc-title,#onetrust-pc-sdk #ot-category-title,#onetrust-pc-sdk .ot-cat-header,#onetrust-pc-sdk #ot-lst-title,#onetrust-pc-sdk .ot-ven-hdr .ot-ven-name,#onetrust-pc-sdk .ot-always-active{font-weight:bold;color:dimgray}#onetrust-pc-sdk .ot-always-active-group .ot-cat-header{width:55%;font-weight:700}#onetrust-pc-sdk .ot-cat-item p{clear:both;float:left;margin-top:10px;margin-bottom:5px;line-height:1.5;font-size:.812em;color:dimgray}#onetrust-pc-sdk .ot-close-icon{height:44px;width:44px;background-size:10px}#onetrust-pc-sdk #ot-pc-title{float:left;font-size:1em;line-height:1.5;margin-bottom:10px;margin-top:10px;width:100%}#onetrust-pc-sdk #accept-recommended-btn-handler{margin-right:10px;margin-bottom:25px;outline-offset:-1px}#onetrust-pc-sdk #ot-pc-desc{clear:both;width:100%;font-size:.812em;line-height:1.5;margin-bottom:25px}#onetrust-pc-sdk #ot-pc-desc a{margin-left:5px}#onetrust-pc-sdk #ot-pc-desc *{font-size:inherit;line-height:inherit}#onetrust-pc-sdk #ot-pc-desc ul li{padding:10px 0px}#onetrust-pc-sdk a{color:#656565;cursor:pointer}#onetrust-pc-sdk a:hover{color:#3860be}#onetrust-pc-sdk label{margin-bottom:0}#onetrust-pc-sdk #vdr-lst-dsc{font-size:.812em;line-height:1.5;padding:10px 15px 5px 15px}#onetrust-pc-sdk button{max-width:394px;padding:12px 30px;line-height:1;word-break:break-word;word-wrap:break-word;white-space:normal;font-weight:bold;height:auto}#onetrust-pc-sdk .ot-link-btn{padding:0;margin-bottom:0;border:0;font-weight:normal;line-height:normal;width:auto;height:auto}#onetrust-pc-sdk #ot-pc-content{position:absolute;overflow-y:scroll;padding-left:0px;padding-right:30px;top:60px;bottom:110px;margin:1px 3px 0 30px;width:calc(100% - 63px)}#onetrust-pc-sdk .ot-vs-list .ot-always-active,#onetrust-pc-sdk .ot-cat-grp .ot-always-active{float:right;clear:none;color:#3860be;margin:0;font-size:.813em;line-height:1.3}#onetrust-pc-sdk .ot-pc-scrollbar::-webkit-scrollbar-track{margin-right:20px}#onetrust-pc-sdk .ot-pc-scrollbar::-webkit-scrollbar{width:11px}#onetrust-pc-sdk .ot-pc-scrollbar::-webkit-scrollbar-thumb{border-radius:10px;background:#d8d8d8}#onetrust-pc-sdk input[type=checkbox]:focus+.ot-acc-hdr{outline:#000 1px solid}#onetrust-pc-sdk .ot-pc-scrollbar{scrollbar-arrow-color:#d8d8d8;scrollbar-darkshadow-color:#d8d8d8;scrollbar-face-color:#d8d8d8;scrollbar-shadow-color:#d8d8d8}#onetrust-pc-sdk .save-preference-btn-handler{margin-right:20px}#onetrust-pc-sdk .ot-pc-refuse-all-handler{margin-right:10px}#onetrust-pc-sdk #ot-pc-desc .privacy-notice-link{margin-left:0;margin-right:8px}#onetrust-pc-sdk #ot-pc-desc .ot-imprint-handler{margin-left:0;margin-right:8px}#onetrust-pc-sdk .ot-subgrp-cntr{display:inline-block;clear:both;width:100%;padding-top:15px}#onetrust-pc-sdk .ot-switch+.ot-subgrp-cntr{padding-top:10px}#onetrust-pc-sdk ul.ot-subgrps{margin:0;font-size:initial}#onetrust-pc-sdk ul.ot-subgrps li p,#onetrust-pc-sdk ul.ot-subgrps li h5{font-size:.813em;line-height:1.4;color:dimgray}#onetrust-pc-sdk ul.ot-subgrps .ot-switch{min-height:auto}#onetrust-pc-sdk ul.ot-subgrps .ot-switch-nob{top:0}#onetrust-pc-sdk ul.ot-subgrps .ot-acc-hdr{display:inline-block;width:100%}#onetrust-pc-sdk ul.ot-subgrps .ot-acc-txt{margin:0}#onetrust-pc-sdk ul.ot-subgrps li{padding:0;border:none}#onetrust-pc-sdk ul.ot-subgrps li h5{position:relative;top:5px;font-weight:bold;margin-bottom:0;float:left}#onetrust-pc-sdk li.ot-subgrp{margin-left:20px;overflow:auto}#onetrust-pc-sdk li.ot-subgrp>h5{width:calc(100% - 100px)}#onetrust-pc-sdk .ot-cat-item p>ul,#onetrust-pc-sdk li.ot-subgrp p>ul{margin:0px;list-style:disc;margin-left:15px;font-size:inherit}#onetrust-pc-sdk .ot-cat-item p>ul li,#onetrust-pc-sdk li.ot-subgrp p>ul li{font-size:inherit;padding-top:10px;padding-left:0px;padding-right:0px;border:none}#onetrust-pc-sdk .ot-cat-item p>ul li:last-child,#onetrust-pc-sdk li.ot-subgrp p>ul li:last-child{padding-bottom:10px}#onetrust-pc-sdk .ot-pc-logo{height:40px;width:120px}#onetrust-pc-sdk .ot-pc-footer{position:absolute;bottom:0px;width:100%;max-height:160px;border-top:1px solid #d8d8d8}#onetrust-pc-sdk.ot-ftr-stacked .ot-pc-refuse-all-handler{margin-bottom:0px}#onetrust-pc-sdk.ot-ftr-stacked #ot-pc-content{bottom:160px}#onetrust-pc-sdk.ot-ftr-stacked .ot-pc-footer button{width:100%;max-width:none}#onetrust-pc-sdk.ot-ftr-stacked .ot-btn-container{margin:0 30px;width:calc(100% - 60px);padding-right:0}#onetrust-pc-sdk .ot-pc-footer-logo{height:30px;width:100%;text-align:right;background:#f4f4f4}#onetrust-pc-sdk .ot-pc-footer-logo a{display:inline-block;margin-top:5px;margin-right:10px}#onetrust-pc-sdk[dir=rtl] .ot-pc-footer-logo{direction:rtl}#onetrust-pc-sdk[dir=rtl] .ot-pc-footer-logo a{margin-right:25px}#onetrust-pc-sdk .ot-tgl{float:right;position:relative;z-index:1}#onetrust-pc-sdk .ot-tgl input:checked+.ot-switch .ot-switch-nob{background-color:#468254;border:1px solid #fff}#onetrust-pc-sdk .ot-tgl input:checked+.ot-switch .ot-switch-nob:before{-webkit-transform:translateX(20px);-ms-transform:translateX(20px);transform:translateX(20px);background-color:#fff;border-color:#fff}#onetrust-pc-sdk .ot-tgl input:focus+.ot-switch{outline:#000 solid 1px}#onetrust-pc-sdk .ot-switch{position:relative;display:inline-block;width:45px;height:25px}#onetrust-pc-sdk .ot-switch-nob{position:absolute;cursor:pointer;top:0;left:0;right:0;bottom:0;background-color:#767676;border:1px solid #ddd;transition:all .2s ease-in 0s;-moz-transition:all .2s ease-in 0s;-o-transition:all .2s ease-in 0s;-webkit-transition:all .2s ease-in 0s;border-radius:20px}#onetrust-pc-sdk .ot-switch-nob:before{position:absolute;content:"";height:18px;width:18px;bottom:3px;left:3px;background-color:#fff;-webkit-transition:.4s;transition:.4s;border-radius:20px}#onetrust-pc-sdk .ot-chkbox input:checked~label::before{background-color:#3860be}#onetrust-pc-sdk .ot-chkbox input+label::after{content:none;color:#fff}#onetrust-pc-sdk .ot-chkbox input:checked+label::after{content:""}#onetrust-pc-sdk .ot-chkbox input:focus+label::before{outline-style:solid;outline-width:2px;outline-style:auto}#onetrust-pc-sdk .ot-chkbox label{position:relative;display:inline-block;padding-left:30px;cursor:pointer;font-weight:500}#onetrust-pc-sdk .ot-chkbox label::before,#onetrust-pc-sdk .ot-chkbox label::after{position:absolute;content:"";display:inline-block;border-radius:3px}#onetrust-pc-sdk .ot-chkbox label::before{height:18px;width:18px;border:1px solid #3860be;left:0px;top:auto}#onetrust-pc-sdk .ot-chkbox label::after{height:5px;width:9px;border-left:3px solid;border-bottom:3px solid;transform:rotate(-45deg);-o-transform:rotate(-45deg);-ms-transform:rotate(-45deg);-webkit-transform:rotate(-45deg);left:4px;top:5px}#onetrust-pc-sdk .ot-label-txt{display:none}#onetrust-pc-sdk .ot-chkbox input,#onetrust-pc-sdk .ot-tgl input{position:absolute;opacity:0;width:0;height:0}#onetrust-pc-sdk .ot-arw-cntr{float:right;position:relative;pointer-events:none}#onetrust-pc-sdk .ot-arw-cntr .ot-arw{width:16px;height:16px;margin-left:5px;color:dimgray;display:inline-block;vertical-align:middle;-webkit-transition:all 150ms ease-in 0s;-moz-transition:all 150ms ease-in 0s;-o-transition:all 150ms ease-in 0s;transition:all 150ms ease-in 0s}#onetrust-pc-sdk input:checked~.ot-acc-hdr .ot-arw,#onetrust-pc-sdk button[aria-expanded=true]~.ot-acc-hdr .ot-arw-cntr svg{transform:rotate(90deg);-o-transform:rotate(90deg);-ms-transform:rotate(90deg);-webkit-transform:rotate(90deg)}#onetrust-pc-sdk input[type=checkbox]:focus+.ot-acc-hdr{outline:#000 1px solid}#onetrust-pc-sdk .ot-tgl-cntr,#onetrust-pc-sdk .ot-arw-cntr{display:inline-block}#onetrust-pc-sdk .ot-tgl-cntr{width:45px;float:right;margin-top:2px}#onetrust-pc-sdk #ot-lst-cnt .ot-tgl-cntr{margin-top:10px}#onetrust-pc-sdk .ot-always-active-subgroup{width:auto;padding-left:0px !important;top:3px;position:relative}#onetrust-pc-sdk .ot-label-status{padding-left:5px;font-size:.75em;display:none}#onetrust-pc-sdk .ot-arw-cntr{margin-top:-1px}#onetrust-pc-sdk .ot-arw-cntr svg{-webkit-transition:all 300ms ease-in 0s;-moz-transition:all 300ms ease-in 0s;-o-transition:all 300ms ease-in 0s;transition:all 300ms ease-in 0s;height:10px;width:10px}#onetrust-pc-sdk input:checked~.ot-acc-hdr .ot-arw{transform:rotate(90deg);-o-transform:rotate(90deg);-ms-transform:rotate(90deg);-webkit-transform:rotate(90deg)}#onetrust-pc-sdk .ot-arw{width:10px;margin-left:15px;transition:all 300ms ease-in 0s;-webkit-transition:all 300ms ease-in 0s;-moz-transition:all 300ms ease-in 0s;-o-transition:all 300ms ease-in 0s}#onetrust-pc-sdk .ot-vlst-cntr{margin-bottom:0}#onetrust-pc-sdk .ot-hlst-cntr{margin-top:5px;display:inline-block;width:100%}#onetrust-pc-sdk .category-vendors-list-handler,#onetrust-pc-sdk .category-vendors-list-handler+a,#onetrust-pc-sdk .category-host-list-handler{clear:both;color:#3860be;margin-left:0;font-size:.813em;text-decoration:none;float:left;overflow:hidden}#onetrust-pc-sdk .category-vendors-list-handler:hover,#onetrust-pc-sdk .category-vendors-list-handler+a:hover,#onetrust-pc-sdk .category-host-list-handler:hover{text-decoration-line:underline}#onetrust-pc-sdk .category-vendors-list-handler+a{clear:none}#onetrust-pc-sdk .ot-vlst-cntr .ot-ext-lnk,#onetrust-pc-sdk .ot-ven-hdr .ot-ext-lnk{display:inline-block;height:13px;width:13px;background-repeat:no-repeat;margin-left:1px;margin-top:6px;cursor:pointer}#onetrust-pc-sdk .ot-ven-hdr .ot-ext-lnk{margin-bottom:-1px}#onetrust-pc-sdk .back-btn-handler{font-size:1em;text-decoration:none}#onetrust-pc-sdk .back-btn-handler:hover{opacity:.6}#onetrust-pc-sdk #ot-lst-title h3{display:inline-block;word-break:break-word;word-wrap:break-word;margin-bottom:0;color:#656565;font-size:1em;font-weight:bold;margin-left:15px}#onetrust-pc-sdk #ot-lst-title{margin:10px 0 10px 0px;font-size:1em;text-align:left}#onetrust-pc-sdk #ot-pc-hdr{margin:0 0 0 30px;height:auto;width:auto}#onetrust-pc-sdk #ot-pc-hdr input::placeholder{color:#d4d4d4;font-style:italic}#onetrust-pc-sdk #vendor-search-handler{height:31px;width:100%;border-radius:50px;font-size:.8em;padding-right:35px;padding-left:15px;float:left;margin-left:15px}#onetrust-pc-sdk .ot-ven-name{display:block;width:auto;padding-right:5px}#onetrust-pc-sdk #ot-lst-cnt{overflow-y:auto;margin-left:20px;margin-right:7px;width:calc(100% - 27px);max-height:calc(100% - 80px);height:100%;transform:translate3d(0, 0, 0)}#onetrust-pc-sdk #ot-pc-lst{width:100%;bottom:100px;position:absolute;top:60px}#onetrust-pc-sdk #ot-pc-lst:not(.ot-enbl-chr) .ot-tgl-cntr .ot-arw-cntr,#onetrust-pc-sdk #ot-pc-lst:not(.ot-enbl-chr) .ot-tgl-cntr .ot-arw-cntr *{visibility:hidden}#onetrust-pc-sdk #ot-pc-lst .ot-tgl-cntr{right:12px;position:absolute}#onetrust-pc-sdk #ot-pc-lst .ot-arw-cntr{float:right;position:relative}#onetrust-pc-sdk #ot-pc-lst .ot-arw{margin-left:10px}#onetrust-pc-sdk #ot-pc-lst .ot-acc-hdr{overflow:hidden;cursor:pointer}#onetrust-pc-sdk .ot-vlst-cntr{overflow:hidden}#onetrust-pc-sdk #ot-sel-blk{overflow:hidden;width:100%;position:sticky;position:-webkit-sticky;top:0;z-index:3}#onetrust-pc-sdk #ot-back-arw{height:12px;width:12px}#onetrust-pc-sdk .ot-lst-subhdr{width:100%;display:inline-block}#onetrust-pc-sdk .ot-search-cntr{float:left;width:78%;position:relative}#onetrust-pc-sdk .ot-search-cntr>svg{width:30px;height:30px;position:absolute;float:left;right:-15px}#onetrust-pc-sdk .ot-fltr-cntr{float:right;right:50px;position:relative}#onetrust-pc-sdk #filter-btn-handler{background-color:#3860be;border-radius:17px;display:inline-block;position:relative;width:32px;height:32px;-moz-transition:.1s ease;-o-transition:.1s ease;-webkit-transition:1s ease;transition:.1s ease;padding:0;margin:0}#onetrust-pc-sdk #filter-btn-handler:hover{background-color:#3860be}#onetrust-pc-sdk #filter-btn-handler svg{width:12px;height:12px;margin:3px 10px 0 10px;display:block;position:static;right:auto;top:auto}#onetrust-pc-sdk .ot-ven-link,#onetrust-pc-sdk .ot-ven-legclaim-link{color:#3860be;text-decoration:none;font-weight:100;display:inline-block;padding-top:10px;transform:translate(0, 1%);-o-transform:translate(0, 1%);-ms-transform:translate(0, 1%);-webkit-transform:translate(0, 1%);position:relative;z-index:2}#onetrust-pc-sdk .ot-ven-link *,#onetrust-pc-sdk .ot-ven-legclaim-link *{font-size:inherit}#onetrust-pc-sdk .ot-ven-link:hover,#onetrust-pc-sdk .ot-ven-legclaim-link:hover{text-decoration:underline}#onetrust-pc-sdk .ot-ven-hdr{width:calc(100% - 160px);height:auto;float:left;word-break:break-word;word-wrap:break-word;vertical-align:middle;padding-bottom:3px}#onetrust-pc-sdk .ot-ven-link,#onetrust-pc-sdk .ot-ven-legclaim-link{letter-spacing:.03em;font-size:.75em;font-weight:400}#onetrust-pc-sdk .ot-ven-dets{border-radius:2px;background-color:#f8f8f8}#onetrust-pc-sdk .ot-ven-dets li:first-child p:first-child{border-top:none}#onetrust-pc-sdk .ot-ven-dets .ot-ven-disc:not(:first-child){border-top:1px solid #ddd !important}#onetrust-pc-sdk .ot-ven-dets .ot-ven-disc:nth-child(n+3) p{display:inline-block}#onetrust-pc-sdk .ot-ven-dets .ot-ven-disc:nth-child(n+3) p:nth-of-type(odd){width:30%}#onetrust-pc-sdk .ot-ven-dets .ot-ven-disc:nth-child(n+3) p:nth-of-type(even){width:50%;word-break:break-word;word-wrap:break-word}#onetrust-pc-sdk .ot-ven-dets .ot-ven-disc p,#onetrust-pc-sdk .ot-ven-dets .ot-ven-disc h4{padding-top:5px;padding-bottom:5px;display:block}#onetrust-pc-sdk .ot-ven-dets .ot-ven-disc h4{display:inline-block}#onetrust-pc-sdk .ot-ven-dets .ot-ven-disc p:nth-last-child(-n+1){padding-bottom:10px}#onetrust-pc-sdk .ot-ven-dets .ot-ven-disc p:nth-child(-n+2):not(.disc-pur){padding-top:10px}#onetrust-pc-sdk .ot-ven-dets .ot-ven-disc .disc-pur-cont{display:inline}#onetrust-pc-sdk .ot-ven-dets .ot-ven-disc .disc-pur{position:relative;width:50% !important;word-break:break-word;word-wrap:break-word;left:calc(30% + 17px)}#onetrust-pc-sdk .ot-ven-dets .ot-ven-disc .disc-pur:nth-child(-n+1){position:static}#onetrust-pc-sdk .ot-ven-dets p,#onetrust-pc-sdk .ot-ven-dets h4,#onetrust-pc-sdk .ot-ven-dets span{font-size:.69em;text-align:left;vertical-align:middle;word-break:break-word;word-wrap:break-word;margin:0;padding-bottom:10px;padding-left:15px;color:#2e3644}#onetrust-pc-sdk .ot-ven-dets h4{padding-top:5px}#onetrust-pc-sdk .ot-ven-dets span{color:dimgray;padding:0;vertical-align:baseline}#onetrust-pc-sdk .ot-ven-dets .ot-ven-pur h4{border-top:1px solid #e9e9e9;border-bottom:1px solid #e9e9e9;padding-bottom:5px;margin-bottom:5px;font-weight:bold}#onetrust-pc-sdk #ot-host-lst .ot-sel-all{float:right;position:relative;margin-right:42px;top:10px}#onetrust-pc-sdk #ot-host-lst .ot-sel-all input[type=checkbox]{width:auto;height:auto}#onetrust-pc-sdk #ot-host-lst .ot-sel-all label{height:20px;width:20px;padding-left:0px}#onetrust-pc-sdk #ot-host-lst .ot-acc-txt{overflow:hidden;width:95%}#onetrust-pc-sdk .ot-host-hdr{position:relative;z-index:1;pointer-events:none;width:calc(100% - 125px);float:left}#onetrust-pc-sdk .ot-host-name,#onetrust-pc-sdk .ot-host-desc{display:inline-block;width:90%}#onetrust-pc-sdk .ot-host-name{pointer-events:none}#onetrust-pc-sdk .ot-host-hdr>a{text-decoration:underline;font-size:.82em;position:relative;z-index:2;float:left;margin-bottom:5px;pointer-events:initial}#onetrust-pc-sdk .ot-host-name+a{margin-top:5px}#onetrust-pc-sdk .ot-host-name,#onetrust-pc-sdk .ot-host-name a,#onetrust-pc-sdk .ot-host-desc,#onetrust-pc-sdk .ot-host-info{color:dimgray;word-break:break-word;word-wrap:break-word}#onetrust-pc-sdk .ot-host-name,#onetrust-pc-sdk .ot-host-name a{font-weight:bold;font-size:.82em;line-height:1.3}#onetrust-pc-sdk .ot-host-name a{font-size:1em}#onetrust-pc-sdk .ot-host-expand{margin-top:3px;margin-bottom:3px;clear:both;display:block;color:#3860be;font-size:.72em;font-weight:normal}#onetrust-pc-sdk .ot-host-expand *{font-size:inherit}#onetrust-pc-sdk .ot-host-desc,#onetrust-pc-sdk .ot-host-info{font-size:.688em;line-height:1.4;font-weight:normal}#onetrust-pc-sdk .ot-host-desc{margin-top:10px}#onetrust-pc-sdk .ot-host-opt{margin:0;font-size:inherit;display:inline-block;width:100%}#onetrust-pc-sdk .ot-host-opt li>div div{font-size:.8em;padding:5px 0}#onetrust-pc-sdk .ot-host-opt li>div div:nth-child(1){width:30%;float:left}#onetrust-pc-sdk .ot-host-opt li>div div:nth-child(2){width:70%;float:left;word-break:break-word;word-wrap:break-word}#onetrust-pc-sdk .ot-host-info{border:none;display:inline-block;width:calc(100% - 10px);padding:10px;margin-bottom:10px;background-color:#f8f8f8}#onetrust-pc-sdk .ot-host-info>div{overflow:auto}#onetrust-pc-sdk #no-results{text-align:center;margin-top:30px}#onetrust-pc-sdk #no-results p{font-size:1em;color:#2e3644;word-break:break-word;word-wrap:break-word}#onetrust-pc-sdk #no-results p span{font-weight:bold}#onetrust-pc-sdk #ot-fltr-modal{width:100%;height:auto;display:none;-moz-transition:.2s ease;-o-transition:.2s ease;-webkit-transition:2s ease;transition:.2s ease;overflow:hidden;opacity:1;right:0}#onetrust-pc-sdk #ot-fltr-modal .ot-label-txt{display:inline-block;font-size:.85em;color:dimgray}#onetrust-pc-sdk #ot-fltr-cnt{z-index:2147483646;background-color:#fff;position:absolute;height:90%;max-height:300px;width:325px;left:210px;margin-top:10px;margin-bottom:20px;padding-right:10px;border-radius:3px;-webkit-box-shadow:0px 0px 12px 2px #c7c5c7;-moz-box-shadow:0px 0px 12px 2px #c7c5c7;box-shadow:0px 0px 12px 2px #c7c5c7}#onetrust-pc-sdk .ot-fltr-scrlcnt{overflow-y:auto;overflow-x:hidden;clear:both;max-height:calc(100% - 60px)}#onetrust-pc-sdk #ot-anchor{border:12px solid rgba(0,0,0,0);display:none;position:absolute;z-index:2147483647;right:55px;top:75px;transform:rotate(45deg);-o-transform:rotate(45deg);-ms-transform:rotate(45deg);-webkit-transform:rotate(45deg);background-color:#fff;-webkit-box-shadow:-3px -3px 5px -2px #c7c5c7;-moz-box-shadow:-3px -3px 5px -2px #c7c5c7;box-shadow:-3px -3px 5px -2px #c7c5c7}#onetrust-pc-sdk .ot-fltr-btns{margin-left:15px}#onetrust-pc-sdk #filter-apply-handler{margin-right:15px}#onetrust-pc-sdk .ot-fltr-opt{margin-bottom:25px;margin-left:15px;width:75%;position:relative}#onetrust-pc-sdk .ot-fltr-opt p{display:inline-block;margin:0;font-size:.9em;color:#2e3644}#onetrust-pc-sdk .ot-chkbox label span{font-size:.85em;color:dimgray}#onetrust-pc-sdk .ot-chkbox input[type=checkbox]+label::after{content:none;color:#fff}#onetrust-pc-sdk .ot-chkbox input[type=checkbox]:checked+label::after{content:""}#onetrust-pc-sdk .ot-chkbox input[type=checkbox]:focus+label::before{outline-style:solid;outline-width:2px;outline-style:auto}#onetrust-pc-sdk #ot-selall-vencntr,#onetrust-pc-sdk #ot-selall-adtlvencntr,#onetrust-pc-sdk #ot-selall-hostcntr,#onetrust-pc-sdk #ot-selall-licntr,#onetrust-pc-sdk #ot-selall-gnvencntr{right:15px;position:relative;width:20px;height:20px;float:right}#onetrust-pc-sdk #ot-selall-vencntr label,#onetrust-pc-sdk #ot-selall-adtlvencntr label,#onetrust-pc-sdk #ot-selall-hostcntr label,#onetrust-pc-sdk #ot-selall-licntr label,#onetrust-pc-sdk #ot-selall-gnvencntr label{float:left;padding-left:0}#onetrust-pc-sdk #ot-ven-lst:first-child{border-top:1px solid #e2e2e2}#onetrust-pc-sdk ul{list-style:none;padding:0}#onetrust-pc-sdk ul li{position:relative;margin:0;padding:15px 15px 15px 10px;border-bottom:1px solid #e2e2e2}#onetrust-pc-sdk ul li h3{font-size:.75em;color:#656565;margin:0;display:inline-block;width:70%;height:auto;word-break:break-word;word-wrap:break-word}#onetrust-pc-sdk ul li p{margin:0;font-size:.7em}#onetrust-pc-sdk ul li input[type=checkbox]{position:absolute;cursor:pointer;width:100%;height:100%;opacity:0;margin:0;top:0;left:0}#onetrust-pc-sdk .ot-cat-item>button:focus,#onetrust-pc-sdk .ot-acc-cntr>button:focus,#onetrust-pc-sdk li>button:focus{outline:#000 solid 2px}#onetrust-pc-sdk .ot-cat-item>button,#onetrust-pc-sdk .ot-acc-cntr>button,#onetrust-pc-sdk li>button{position:absolute;cursor:pointer;width:100%;height:100%;margin:0;top:0;left:0;z-index:1;max-width:none;border:none}#onetrust-pc-sdk .ot-cat-item>button[aria-expanded=false]~.ot-acc-txt,#onetrust-pc-sdk .ot-acc-cntr>button[aria-expanded=false]~.ot-acc-txt,#onetrust-pc-sdk li>button[aria-expanded=false]~.ot-acc-txt{margin-top:0;max-height:0;opacity:0;overflow:hidden;width:100%;transition:.25s ease-out;display:none}#onetrust-pc-sdk .ot-cat-item>button[aria-expanded=true]~.ot-acc-txt,#onetrust-pc-sdk .ot-acc-cntr>button[aria-expanded=true]~.ot-acc-txt,#onetrust-pc-sdk li>button[aria-expanded=true]~.ot-acc-txt{transition:.1s ease-in;margin-top:10px;width:100%;overflow:auto;display:block}#onetrust-pc-sdk .ot-cat-item>button[aria-expanded=true]~.ot-acc-grpcntr,#onetrust-pc-sdk .ot-acc-cntr>button[aria-expanded=true]~.ot-acc-grpcntr,#onetrust-pc-sdk li>button[aria-expanded=true]~.ot-acc-grpcntr{width:auto;margin-top:0px;padding-bottom:10px}#onetrust-pc-sdk .ot-host-item>button:focus,#onetrust-pc-sdk .ot-ven-item>button:focus{outline:0;border:2px solid #000}#onetrust-pc-sdk .ot-hide-acc>button{pointer-events:none}#onetrust-pc-sdk .ot-hide-acc .ot-plus-minus>*,#onetrust-pc-sdk .ot-hide-acc .ot-arw-cntr>*{visibility:hidden}#onetrust-pc-sdk .ot-hide-acc .ot-acc-hdr{min-height:30px}#onetrust-pc-sdk.ot-addtl-vendors #ot-lst-cnt:not(.ot-host-cnt){padding-right:10px;width:calc(100% - 37px);margin-top:10px;max-height:calc(100% - 90px)}#onetrust-pc-sdk.ot-addtl-vendors #ot-lst-cnt:not(.ot-host-cnt) #ot-sel-blk{background-color:#f9f9fc;border:1px solid #e2e2e2;width:calc(100% - 2px);padding-bottom:5px;padding-top:5px}#onetrust-pc-sdk.ot-addtl-vendors #ot-lst-cnt:not(.ot-host-cnt) #ot-sel-blk.ot-vnd-list-cnt{border:unset;background-color:unset}#onetrust-pc-sdk.ot-addtl-vendors #ot-lst-cnt:not(.ot-host-cnt) #ot-sel-blk.ot-vnd-list-cnt .ot-sel-all-hdr{display:none}#onetrust-pc-sdk.ot-addtl-vendors #ot-lst-cnt:not(.ot-host-cnt) #ot-sel-blk.ot-vnd-list-cnt .ot-sel-all{padding-right:.5rem}#onetrust-pc-sdk.ot-addtl-vendors #ot-lst-cnt:not(.ot-host-cnt) #ot-sel-blk.ot-vnd-list-cnt .ot-sel-all .ot-chkbox{right:0}#onetrust-pc-sdk.ot-addtl-vendors #ot-lst-cnt:not(.ot-host-cnt) .ot-sel-all{padding-right:34px}#onetrust-pc-sdk.ot-addtl-vendors #ot-lst-cnt:not(.ot-host-cnt) .ot-sel-all-chkbox{width:auto}#onetrust-pc-sdk.ot-addtl-vendors #ot-lst-cnt:not(.ot-host-cnt) ul li{border:1px solid #e2e2e2;margin-bottom:10px}#onetrust-pc-sdk.ot-addtl-vendors #ot-lst-cnt:not(.ot-host-cnt) .ot-acc-cntr>.ot-acc-hdr{padding:10px 0 10px 15px}#onetrust-pc-sdk.ot-addtl-vendors .ot-sel-all-chkbox{float:right}#onetrust-pc-sdk.ot-addtl-vendors .ot-plus-minus~.ot-sel-all-chkbox{right:34px}#onetrust-pc-sdk.ot-addtl-vendors #ot-ven-lst:first-child{border-top:none}#onetrust-pc-sdk .ot-acc-cntr{position:relative;border-left:1px solid #e2e2e2;border-right:1px solid #e2e2e2;border-bottom:1px solid #e2e2e2}#onetrust-pc-sdk .ot-acc-cntr input{z-index:1}#onetrust-pc-sdk .ot-acc-cntr>.ot-acc-hdr{background-color:#f9f9fc;padding:5px 0 5px 15px;width:auto}#onetrust-pc-sdk .ot-acc-cntr>.ot-acc-hdr .ot-plus-minus{vertical-align:middle;top:auto}#onetrust-pc-sdk .ot-acc-cntr>.ot-acc-hdr .ot-arw-cntr{right:10px}#onetrust-pc-sdk .ot-acc-cntr>.ot-acc-hdr input{z-index:2}#onetrust-pc-sdk .ot-acc-cntr.ot-add-tech .ot-acc-hdr{padding:10px 0 10px 15px}#onetrust-pc-sdk .ot-acc-cntr>input[type=checkbox]:checked~.ot-acc-hdr{border-bottom:1px solid #e2e2e2}#onetrust-pc-sdk .ot-acc-cntr>.ot-acc-txt{padding-left:10px;padding-right:10px}#onetrust-pc-sdk .ot-acc-cntr button[aria-expanded=true]~.ot-acc-txt{width:auto}#onetrust-pc-sdk .ot-acc-cntr .ot-addtl-venbox{display:none}#onetrust-pc-sdk .ot-vlst-cntr{margin-bottom:0;width:100%}#onetrust-pc-sdk .ot-vensec-title{font-size:.813em;vertical-align:middle;display:inline-block}#onetrust-pc-sdk .category-vendors-list-handler,#onetrust-pc-sdk .category-vendors-list-handler+a{margin-left:0;margin-top:10px}#onetrust-pc-sdk #ot-selall-vencntr.line-through label::after,#onetrust-pc-sdk #ot-selall-adtlvencntr.line-through label::after,#onetrust-pc-sdk #ot-selall-licntr.line-through label::after,#onetrust-pc-sdk #ot-selall-hostcntr.line-through label::after,#onetrust-pc-sdk #ot-selall-gnvencntr.line-through label::after{height:auto;border-left:0;transform:none;-o-transform:none;-ms-transform:none;-webkit-transform:none;left:5px;top:9px}#onetrust-pc-sdk #ot-category-title{float:left;padding-bottom:10px;font-size:1em;width:100%}#onetrust-pc-sdk .ot-cat-grp{margin-top:10px}#onetrust-pc-sdk .ot-cat-item{line-height:1.1;margin-top:10px;display:inline-block;width:100%}#onetrust-pc-sdk .ot-btn-container{text-align:right}#onetrust-pc-sdk .ot-btn-container button{display:inline-block;font-size:.75em;letter-spacing:.08em;margin-top:19px}#onetrust-pc-sdk #close-pc-btn-handler.ot-close-icon{position:absolute;top:10px;right:0;z-index:1;padding:0;background-color:rgba(0,0,0,0);border:none}#onetrust-pc-sdk #close-pc-btn-handler.ot-close-icon svg{display:block;height:10px;width:10px}#onetrust-pc-sdk #clear-filters-handler{margin-top:20px;margin-bottom:10px;float:right;max-width:200px;text-decoration:none;color:#3860be;font-size:.9em;font-weight:bold;background-color:rgba(0,0,0,0);border-color:rgba(0,0,0,0);padding:1px}#onetrust-pc-sdk #clear-filters-handler:hover{color:#2285f7}#onetrust-pc-sdk #clear-filters-handler:focus{outline:#000 solid 1px}#onetrust-pc-sdk .ot-enbl-chr h4~.ot-tgl,#onetrust-pc-sdk .ot-enbl-chr h4~.ot-always-active{right:45px}#onetrust-pc-sdk .ot-enbl-chr h4~.ot-tgl+.ot-tgl{right:120px}#onetrust-pc-sdk .ot-enbl-chr .ot-pli-hdr.ot-leg-border-color span:first-child{width:90px}#onetrust-pc-sdk .ot-enbl-chr li.ot-subgrp>h5+.ot-tgl-cntr{padding-right:25px}#onetrust-pc-sdk .ot-plus-minus{width:20px;height:20px;font-size:1.5em;position:relative;display:inline-block;margin-right:5px;top:3px}#onetrust-pc-sdk .ot-plus-minus span{position:absolute;background:#27455c;border-radius:1px}#onetrust-pc-sdk .ot-plus-minus span:first-of-type{top:25%;bottom:25%;width:10%;left:45%}#onetrust-pc-sdk .ot-plus-minus span:last-of-type{left:25%;right:25%;height:10%;top:45%}#onetrust-pc-sdk button[aria-expanded=true]~.ot-acc-hdr .ot-arw,#onetrust-pc-sdk button[aria-expanded=true]~.ot-acc-hdr .ot-plus-minus span:first-of-type,#onetrust-pc-sdk button[aria-expanded=true]~.ot-acc-hdr .ot-plus-minus span:last-of-type{transform:rotate(90deg)}#onetrust-pc-sdk button[aria-expanded=true]~.ot-acc-hdr .ot-plus-minus span:last-of-type{left:50%;right:50%}#onetrust-pc-sdk #ot-selall-vencntr label,#onetrust-pc-sdk #ot-selall-adtlvencntr label,#onetrust-pc-sdk #ot-selall-hostcntr label,#onetrust-pc-sdk #ot-selall-licntr label{position:relative;display:inline-block;width:20px;height:20px}#onetrust-pc-sdk .ot-host-item .ot-plus-minus,#onetrust-pc-sdk .ot-ven-item .ot-plus-minus{float:left;margin-right:8px;top:10px}#onetrust-pc-sdk .ot-ven-item ul{list-style:none inside;font-size:100%;margin:0}#onetrust-pc-sdk .ot-ven-item ul li{margin:0 !important;padding:0;border:none !important}#onetrust-pc-sdk .ot-pli-hdr{color:#77808e;overflow:hidden;padding-top:7.5px;padding-bottom:7.5px;width:calc(100% - 2px);border-top-left-radius:3px;border-top-right-radius:3px}#onetrust-pc-sdk .ot-pli-hdr span:first-child{top:50%;transform:translateY(50%);max-width:90px}#onetrust-pc-sdk .ot-pli-hdr span:last-child{padding-right:10px;max-width:95px;text-align:center}#onetrust-pc-sdk .ot-li-title{float:right;font-size:.813em}#onetrust-pc-sdk .ot-pli-hdr.ot-leg-border-color{background-color:#f4f4f4;border:1px solid #d8d8d8}#onetrust-pc-sdk .ot-pli-hdr.ot-leg-border-color span:first-child{text-align:left;width:70px}#onetrust-pc-sdk li.ot-subgrp>h5,#onetrust-pc-sdk .ot-cat-header{width:calc(100% - 130px)}#onetrust-pc-sdk li.ot-subgrp>h5+.ot-tgl-cntr{padding-left:13px}#onetrust-pc-sdk .ot-acc-grpcntr .ot-acc-grpdesc{margin-bottom:5px}#onetrust-pc-sdk .ot-acc-grpcntr .ot-subgrp-cntr{border-top:1px solid #d8d8d8}#onetrust-pc-sdk .ot-acc-grpcntr .ot-vlst-cntr+.ot-subgrp-cntr{border-top:none}#onetrust-pc-sdk .ot-acc-hdr .ot-arw-cntr+.ot-tgl-cntr,#onetrust-pc-sdk .ot-acc-txt h4+.ot-tgl-cntr{padding-left:13px}#onetrust-pc-sdk .ot-pli-hdr~.ot-cat-item .ot-subgrp>h5,#onetrust-pc-sdk .ot-pli-hdr~.ot-cat-item .ot-cat-header{width:calc(100% - 145px)}#onetrust-pc-sdk .ot-pli-hdr~.ot-cat-item h5+.ot-tgl-cntr,#onetrust-pc-sdk .ot-pli-hdr~.ot-cat-item .ot-cat-header+.ot-tgl{padding-left:28px}#onetrust-pc-sdk .ot-sel-all-hdr,#onetrust-pc-sdk .ot-sel-all-chkbox{display:inline-block;width:100%;position:relative}#onetrust-pc-sdk .ot-sel-all-chkbox{z-index:1}#onetrust-pc-sdk .ot-sel-all{margin:0;position:relative;padding-right:23px;float:right}#onetrust-pc-sdk .ot-consent-hdr,#onetrust-pc-sdk .ot-li-hdr{float:right;font-size:.812em;line-height:normal;text-align:center;word-break:break-word;word-wrap:break-word}#onetrust-pc-sdk .ot-li-hdr{max-width:100px;padding-right:10px}#onetrust-pc-sdk .ot-consent-hdr{max-width:55px}#onetrust-pc-sdk #ot-selall-licntr{display:block;width:21px;height:auto;float:right;position:relative;right:80px}#onetrust-pc-sdk #ot-selall-licntr label{position:absolute}#onetrust-pc-sdk .ot-ven-ctgl{margin-left:66px}#onetrust-pc-sdk .ot-ven-litgl+.ot-arw-cntr{margin-left:81px}#onetrust-pc-sdk .ot-enbl-chr .ot-host-cnt .ot-tgl-cntr{width:auto}#onetrust-pc-sdk #ot-lst-cnt:not(.ot-host-cnt) .ot-tgl-cntr{width:auto;top:auto;height:20px}#onetrust-pc-sdk #ot-lst-cnt .ot-chkbox{position:relative;display:inline-block;width:20px;height:20px}#onetrust-pc-sdk #ot-lst-cnt .ot-chkbox label{position:absolute;padding:0;width:20px;height:20px}#onetrust-pc-sdk #ot-lst-cnt .ot-vnd-info-cntr{border:1px solid #d8d8d8;padding:.75rem 2rem;padding-bottom:0;width:auto;margin-top:.5rem}#onetrust-pc-sdk .ot-acc-grpdesc+.ot-leg-btn-container{padding-left:20px;padding-right:20px;width:calc(100% - 40px);margin-bottom:5px}#onetrust-pc-sdk .ot-subgrp .ot-leg-btn-container{margin-bottom:5px}#onetrust-pc-sdk #ot-ven-lst .ot-leg-btn-container{margin-top:10px}#onetrust-pc-sdk .ot-leg-btn-container{display:inline-block;width:100%;margin-bottom:10px}#onetrust-pc-sdk .ot-leg-btn-container button{height:auto;padding:6.5px 8px;margin-bottom:0;letter-spacing:0;font-size:.75em;line-height:normal}#onetrust-pc-sdk .ot-leg-btn-container svg{display:none;height:14px;width:14px;padding-right:5px;vertical-align:sub}#onetrust-pc-sdk .ot-active-leg-btn{cursor:default;pointer-events:none}#onetrust-pc-sdk .ot-active-leg-btn svg{display:inline-block}#onetrust-pc-sdk .ot-remove-objection-handler{text-decoration:underline;padding:0;font-size:.75em;font-weight:600;line-height:1;padding-left:10px}#onetrust-pc-sdk .ot-obj-leg-btn-handler span{font-weight:bold;text-align:center;font-size:inherit;line-height:1.5}#onetrust-pc-sdk.ot-close-btn-link #close-pc-btn-handler{border:none;height:auto;line-height:1.5;text-decoration:underline;font-size:.69em;background:none;right:15px;top:15px;width:auto;font-weight:normal}#onetrust-pc-sdk .ot-pgph-link{font-size:.813em !important;margin-top:5px;position:relative}#onetrust-pc-sdk .ot-pgph-link.ot-pgph-link-subgroup{margin-bottom:1rem}#onetrust-pc-sdk .ot-pgph-contr{margin:0 2.5rem}#onetrust-pc-sdk .ot-pgph-title{font-size:1.18rem;margin-bottom:2rem}#onetrust-pc-sdk .ot-pgph-desc{font-size:1rem;font-weight:400;margin-bottom:2rem;line-height:1.5rem}#onetrust-pc-sdk .ot-pgph-desc:not(:last-child):after{content:"";width:96%;display:block;margin:0 auto;padding-bottom:2rem;border-bottom:1px solid #e9e9e9}#onetrust-pc-sdk .ot-cat-header{float:left;font-weight:600;font-size:.875em;line-height:1.5;max-width:90%;vertical-align:middle}#onetrust-pc-sdk .ot-vnd-item>button:focus{outline:#000 solid 2px}#onetrust-pc-sdk .ot-vnd-item>button{position:absolute;cursor:pointer;width:100%;height:100%;margin:0;top:0;left:0;z-index:1;max-width:none;border:none}#onetrust-pc-sdk .ot-vnd-item>button[aria-expanded=false]~.ot-acc-txt{margin-top:0;max-height:0;opacity:0;overflow:hidden;width:100%;transition:.25s ease-out;display:none}#onetrust-pc-sdk .ot-vnd-item>button[aria-expanded=true]~.ot-acc-txt{transition:.1s ease-in;margin-top:10px;width:100%;overflow:auto;display:block}#onetrust-pc-sdk .ot-vnd-item>button[aria-expanded=true]~.ot-acc-grpcntr{width:auto;margin-top:0px;padding-bottom:10px}#onetrust-pc-sdk .ot-accordion-layout.ot-cat-item{position:relative;border-radius:2px;margin:0;padding:0;border:1px solid #d8d8d8;border-top:none;width:calc(100% - 2px);float:left}#onetrust-pc-sdk .ot-accordion-layout.ot-cat-item:first-of-type{margin-top:10px;border-top:1px solid #d8d8d8}#onetrust-pc-sdk .ot-accordion-layout .ot-acc-grpdesc{padding-left:20px;padding-right:20px;width:calc(100% - 40px);font-size:.812em;margin-bottom:10px;margin-top:15px}#onetrust-pc-sdk .ot-accordion-layout .ot-acc-grpdesc>ul{padding-top:10px}#onetrust-pc-sdk .ot-accordion-layout .ot-acc-grpdesc>ul li{padding-top:0;line-height:1.5;padding-bottom:10px}#onetrust-pc-sdk .ot-accordion-layout div+.ot-acc-grpdesc{margin-top:5px}#onetrust-pc-sdk .ot-accordion-layout .ot-vlst-cntr:first-child{margin-top:10px}#onetrust-pc-sdk .ot-accordion-layout .ot-vlst-cntr:last-child,#onetrust-pc-sdk .ot-accordion-layout .ot-hlst-cntr:last-child{margin-bottom:5px}#onetrust-pc-sdk .ot-accordion-layout .ot-acc-hdr{padding-top:11.5px;padding-bottom:11.5px;padding-left:20px;padding-right:20px;width:calc(100% - 40px);display:inline-block}#onetrust-pc-sdk .ot-accordion-layout .ot-acc-txt{width:100%;padding:0}#onetrust-pc-sdk .ot-accordion-layout .ot-subgrp-cntr{padding-left:20px;padding-right:15px;padding-bottom:0;width:calc(100% - 35px)}#onetrust-pc-sdk .ot-accordion-layout .ot-subgrp{padding-right:5px}#onetrust-pc-sdk .ot-accordion-layout .ot-acc-grpcntr{z-index:1;position:relative}#onetrust-pc-sdk .ot-accordion-layout .ot-cat-header+.ot-arw-cntr{position:absolute;top:50%;transform:translateY(-50%);right:20px;margin-top:-2px}#onetrust-pc-sdk .ot-accordion-layout .ot-cat-header+.ot-arw-cntr .ot-arw{width:15px;height:20px;margin-left:5px;color:dimgray}#onetrust-pc-sdk .ot-accordion-layout .ot-cat-header{float:none;color:#2e3644;margin:0;display:inline-block;height:auto;word-wrap:break-word;min-height:inherit}#onetrust-pc-sdk .ot-accordion-layout .ot-vlst-cntr,#onetrust-pc-sdk .ot-accordion-layout .ot-hlst-cntr{padding-left:20px;width:calc(100% - 20px);display:inline-block;margin-top:0;padding-bottom:2px}#onetrust-pc-sdk .ot-accordion-layout .ot-acc-hdr{position:relative;min-height:25px}#onetrust-pc-sdk .ot-accordion-layout h4~.ot-tgl,#onetrust-pc-sdk .ot-accordion-layout h4~.ot-always-active{position:absolute;top:50%;transform:translateY(-50%);right:20px}#onetrust-pc-sdk .ot-accordion-layout h4~.ot-tgl+.ot-tgl{right:95px}#onetrust-pc-sdk .ot-accordion-layout .category-vendors-list-handler,#onetrust-pc-sdk .ot-accordion-layout .category-vendors-list-handler+a{margin-top:5px}#onetrust-pc-sdk #ot-lst-cnt{margin-top:1rem;max-height:calc(100% - 96px)}#onetrust-pc-sdk #ot-lst-cnt .ot-vnd-info-cntr{border:1px solid #d8d8d8;padding:.75rem 2rem;padding-bottom:0;width:auto;margin-top:.5rem}#onetrust-pc-sdk #ot-lst-cnt .ot-vnd-info{margin-bottom:1rem;padding-left:.75rem;padding-right:.75rem;display:flex;flex-direction:column}#onetrust-pc-sdk #ot-lst-cnt .ot-vnd-info[data-vnd-info-key*=DPOEmail]{border-top:1px solid #d8d8d8;padding-top:1rem}#onetrust-pc-sdk #ot-lst-cnt .ot-vnd-info[data-vnd-info-key*=DPOLink]{border-bottom:1px solid #d8d8d8;padding-bottom:1rem}#onetrust-pc-sdk #ot-lst-cnt .ot-vnd-info .ot-vnd-lbl{font-weight:bold;font-size:.85em;margin-bottom:.5rem}#onetrust-pc-sdk #ot-lst-cnt .ot-vnd-info .ot-vnd-cnt{margin-left:.5rem;font-weight:500;font-size:.85rem}#onetrust-pc-sdk .ot-vs-list,#onetrust-pc-sdk .ot-vnd-serv{width:auto;padding:1rem 1.25rem;padding-bottom:0}#onetrust-pc-sdk .ot-vs-list .ot-vnd-serv-hdr-cntr,#onetrust-pc-sdk .ot-vnd-serv .ot-vnd-serv-hdr-cntr{padding-bottom:.75rem;border-bottom:1px solid #d8d8d8}#onetrust-pc-sdk .ot-vs-list .ot-vnd-serv-hdr-cntr .ot-vnd-serv-hdr,#onetrust-pc-sdk .ot-vnd-serv .ot-vnd-serv-hdr-cntr .ot-vnd-serv-hdr{font-weight:600;font-size:.95em;line-height:2;margin-left:.5rem}#onetrust-pc-sdk .ot-vs-list .ot-vnd-item,#onetrust-pc-sdk .ot-vnd-serv .ot-vnd-item{border:none;margin:0;padding:0}#onetrust-pc-sdk .ot-vs-list .ot-vnd-item button,#onetrust-pc-sdk .ot-vnd-serv .ot-vnd-item button{outline:none;border-bottom:1px solid #d8d8d8}#onetrust-pc-sdk .ot-vs-list .ot-vnd-item button[aria-expanded=true],#onetrust-pc-sdk .ot-vnd-serv .ot-vnd-item button[aria-expanded=true]{border-bottom:none}#onetrust-pc-sdk .ot-vs-list .ot-vnd-item:first-child,#onetrust-pc-sdk .ot-vnd-serv .ot-vnd-item:first-child{margin-top:.25rem;border-top:unset}#onetrust-pc-sdk .ot-vs-list .ot-vnd-item:last-child,#onetrust-pc-sdk .ot-vnd-serv .ot-vnd-item:last-child{margin-bottom:.5rem}#onetrust-pc-sdk .ot-vs-list .ot-vnd-item:last-child button,#onetrust-pc-sdk .ot-vnd-serv .ot-vnd-item:last-child button{border-bottom:none}#onetrust-pc-sdk .ot-vs-list .ot-vnd-item .ot-vnd-info-cntr,#onetrust-pc-sdk .ot-vnd-serv .ot-vnd-item .ot-vnd-info-cntr{border:1px solid #d8d8d8;padding:.75rem 1.75rem;padding-bottom:0;width:auto;margin-top:.5rem}#onetrust-pc-sdk .ot-vs-list .ot-vnd-item .ot-vnd-info,#onetrust-pc-sdk .ot-vnd-serv .ot-vnd-item .ot-vnd-info{margin-bottom:1rem;padding-left:.75rem;padding-right:.75rem;display:flex;flex-direction:column}#onetrust-pc-sdk .ot-vs-list .ot-vnd-item .ot-vnd-info[data-vnd-info-key*=DPOEmail],#onetrust-pc-sdk .ot-vnd-serv .ot-vnd-item .ot-vnd-info[data-vnd-info-key*=DPOEmail]{border-top:1px solid #d8d8d8;padding-top:1rem}#onetrust-pc-sdk .ot-vs-list .ot-vnd-item .ot-vnd-info[data-vnd-info-key*=DPOLink],#onetrust-pc-sdk .ot-vnd-serv .ot-vnd-item .ot-vnd-info[data-vnd-info-key*=DPOLink]{border-bottom:1px solid #d8d8d8;padding-bottom:1rem}#onetrust-pc-sdk .ot-vs-list .ot-vnd-item .ot-vnd-info .ot-vnd-lbl,#onetrust-pc-sdk .ot-vnd-serv .ot-vnd-item .ot-vnd-info .ot-vnd-lbl{font-weight:bold;font-size:.85em;margin-bottom:.5rem}#onetrust-pc-sdk .ot-vs-list .ot-vnd-item .ot-vnd-info .ot-vnd-cnt,#onetrust-pc-sdk .ot-vnd-serv .ot-vnd-item .ot-vnd-info .ot-vnd-cnt{margin-left:.5rem;font-weight:500;font-size:.85rem}#onetrust-pc-sdk .ot-vs-list.ot-vnd-subgrp-cnt,#onetrust-pc-sdk .ot-vnd-serv.ot-vnd-subgrp-cnt{padding-left:40px}#onetrust-pc-sdk .ot-vs-list.ot-vnd-subgrp-cnt .ot-vnd-serv-hdr-cntr .ot-vnd-serv-hdr,#onetrust-pc-sdk .ot-vnd-serv.ot-vnd-subgrp-cnt .ot-vnd-serv-hdr-cntr .ot-vnd-serv-hdr{font-size:.8em}#onetrust-pc-sdk .ot-vs-list.ot-vnd-subgrp-cnt .ot-cat-header,#onetrust-pc-sdk .ot-vnd-serv.ot-vnd-subgrp-cnt .ot-cat-header{font-size:.8em}#onetrust-pc-sdk .ot-subgrp-cntr .ot-vnd-serv{margin-bottom:1rem;padding:1rem .95rem}#onetrust-pc-sdk .ot-subgrp-cntr .ot-vnd-serv .ot-vnd-serv-hdr-cntr{padding-bottom:.75rem;border-bottom:1px solid #d8d8d8}#onetrust-pc-sdk .ot-subgrp-cntr .ot-vnd-serv .ot-vnd-serv-hdr-cntr .ot-vnd-serv-hdr{font-weight:700;font-size:.8em;line-height:20px;margin-left:.82rem}#onetrust-pc-sdk .ot-subgrp-cntr .ot-cat-header{font-weight:700;font-size:.8em;line-height:20px}#onetrust-pc-sdk .ot-subgrp-cntr ul.ot-subgrps .ot-vnd-serv .ot-vnd-lst-cont .ot-accordion-layout .ot-acc-hdr div.ot-chkbox{margin-left:.82rem}#onetrust-pc-sdk .ot-vs-config .ot-acc-hdr,#onetrust-pc-sdk ul.ot-subgrps .ot-acc-hdr,#onetrust-pc-sdk .ot-subgrp-cntr ul.ot-subgrps .ot-acc-hdr,#onetrust-pc-sdk .ot-vs-list .ot-vnd-item .ot-acc-hdr,#onetrust-pc-sdk .ot-vnd-serv .ot-vnd-item .ot-acc-hdr,#onetrust-pc-sdk #ot-pc-lst .ot-vs-list .ot-vnd-item .ot-acc-hdr,#onetrust-pc-sdk .ot-accordion-layout.ot-checkbox-consent .ot-acc-hdr{padding:.7rem 0;margin:0;display:flex;width:100%;align-items:center;justify-content:space-between}#onetrust-pc-sdk .ot-vs-config .ot-acc-hdr div:first-child,#onetrust-pc-sdk ul.ot-subgrps .ot-acc-hdr div:first-child,#onetrust-pc-sdk .ot-subgrp-cntr ul.ot-subgrps .ot-acc-hdr div:first-child,#onetrust-pc-sdk .ot-vs-list .ot-vnd-item .ot-acc-hdr div:first-child,#onetrust-pc-sdk .ot-vnd-serv .ot-vnd-item .ot-acc-hdr div:first-child,#onetrust-pc-sdk #ot-pc-lst .ot-vs-list .ot-vnd-item .ot-acc-hdr div:first-child,#onetrust-pc-sdk .ot-accordion-layout.ot-checkbox-consent .ot-acc-hdr div:first-child{margin-left:.5rem}#onetrust-pc-sdk .ot-vs-config .ot-acc-hdr div:last-child,#onetrust-pc-sdk ul.ot-subgrps .ot-acc-hdr div:last-child,#onetrust-pc-sdk .ot-subgrp-cntr ul.ot-subgrps .ot-acc-hdr div:last-child,#onetrust-pc-sdk .ot-vs-list .ot-vnd-item .ot-acc-hdr div:last-child,#onetrust-pc-sdk .ot-vnd-serv .ot-vnd-item .ot-acc-hdr div:last-child,#onetrust-pc-sdk #ot-pc-lst .ot-vs-list .ot-vnd-item .ot-acc-hdr div:last-child,#onetrust-pc-sdk .ot-accordion-layout.ot-checkbox-consent .ot-acc-hdr div:last-child{margin-right:.5rem;margin-left:.5rem}#onetrust-pc-sdk .ot-vs-config .ot-acc-hdr .ot-always-active,#onetrust-pc-sdk ul.ot-subgrps .ot-acc-hdr .ot-always-active,#onetrust-pc-sdk .ot-subgrp-cntr ul.ot-subgrps .ot-acc-hdr .ot-always-active,#onetrust-pc-sdk .ot-vs-list .ot-vnd-item .ot-acc-hdr .ot-always-active,#onetrust-pc-sdk .ot-vnd-serv .ot-vnd-item .ot-acc-hdr .ot-always-active,#onetrust-pc-sdk #ot-pc-lst .ot-vs-list .ot-vnd-item .ot-acc-hdr .ot-always-active,#onetrust-pc-sdk .ot-accordion-layout.ot-checkbox-consent .ot-acc-hdr .ot-always-active{position:relative;right:unset;top:unset;transform:unset}#onetrust-pc-sdk .ot-vs-config .ot-acc-hdr .ot-plus-minus,#onetrust-pc-sdk ul.ot-subgrps .ot-acc-hdr .ot-plus-minus,#onetrust-pc-sdk .ot-subgrp-cntr ul.ot-subgrps .ot-acc-hdr .ot-plus-minus,#onetrust-pc-sdk .ot-vs-list .ot-vnd-item .ot-acc-hdr .ot-plus-minus,#onetrust-pc-sdk .ot-vnd-serv .ot-vnd-item .ot-acc-hdr .ot-plus-minus,#onetrust-pc-sdk #ot-pc-lst .ot-vs-list .ot-vnd-item .ot-acc-hdr .ot-plus-minus,#onetrust-pc-sdk .ot-accordion-layout.ot-checkbox-consent .ot-acc-hdr .ot-plus-minus{top:0}#onetrust-pc-sdk .ot-vs-config .ot-acc-hdr .ot-arw-cntr,#onetrust-pc-sdk ul.ot-subgrps .ot-acc-hdr .ot-arw-cntr,#onetrust-pc-sdk .ot-subgrp-cntr ul.ot-subgrps .ot-acc-hdr .ot-arw-cntr,#onetrust-pc-sdk .ot-vs-list .ot-vnd-item .ot-acc-hdr .ot-arw-cntr,#onetrust-pc-sdk .ot-vnd-serv .ot-vnd-item .ot-acc-hdr .ot-arw-cntr,#onetrust-pc-sdk #ot-pc-lst .ot-vs-list .ot-vnd-item .ot-acc-hdr .ot-arw-cntr,#onetrust-pc-sdk .ot-accordion-layout.ot-checkbox-consent .ot-acc-hdr .ot-arw-cntr{float:none;top:unset;right:unset;transform:unset;margin-top:-2px;position:relative}#onetrust-pc-sdk .ot-vs-config .ot-acc-hdr .ot-cat-header,#onetrust-pc-sdk ul.ot-subgrps .ot-acc-hdr .ot-cat-header,#onetrust-pc-sdk .ot-subgrp-cntr ul.ot-subgrps .ot-acc-hdr .ot-cat-header,#onetrust-pc-sdk .ot-vs-list .ot-vnd-item .ot-acc-hdr .ot-cat-header,#onetrust-pc-sdk .ot-vnd-serv .ot-vnd-item .ot-acc-hdr .ot-cat-header,#onetrust-pc-sdk #ot-pc-lst .ot-vs-list .ot-vnd-item .ot-acc-hdr .ot-cat-header,#onetrust-pc-sdk .ot-accordion-layout.ot-checkbox-consent .ot-acc-hdr .ot-cat-header{flex:1;margin:0 .5rem}#onetrust-pc-sdk .ot-vs-config .ot-acc-hdr .ot-tgl,#onetrust-pc-sdk ul.ot-subgrps .ot-acc-hdr .ot-tgl,#onetrust-pc-sdk .ot-subgrp-cntr ul.ot-subgrps .ot-acc-hdr .ot-tgl,#onetrust-pc-sdk .ot-vs-list .ot-vnd-item .ot-acc-hdr .ot-tgl,#onetrust-pc-sdk .ot-vnd-serv .ot-vnd-item .ot-acc-hdr .ot-tgl,#onetrust-pc-sdk #ot-pc-lst .ot-vs-list .ot-vnd-item .ot-acc-hdr .ot-tgl,#onetrust-pc-sdk .ot-accordion-layout.ot-checkbox-consent .ot-acc-hdr .ot-tgl{position:relative;transform:none;right:0;top:0;float:none}#onetrust-pc-sdk .ot-vs-config .ot-acc-hdr .ot-chkbox,#onetrust-pc-sdk ul.ot-subgrps .ot-acc-hdr .ot-chkbox,#onetrust-pc-sdk .ot-subgrp-cntr ul.ot-subgrps .ot-acc-hdr .ot-chkbox,#onetrust-pc-sdk .ot-vs-list .ot-vnd-item .ot-acc-hdr .ot-chkbox,#onetrust-pc-sdk .ot-vnd-serv .ot-vnd-item .ot-acc-hdr .ot-chkbox,#onetrust-pc-sdk #ot-pc-lst .ot-vs-list .ot-vnd-item .ot-acc-hdr .ot-chkbox,#onetrust-pc-sdk .ot-accordion-layout.ot-checkbox-consent .ot-acc-hdr .ot-chkbox{position:relative;margin:0 .5rem}#onetrust-pc-sdk .ot-vs-config .ot-acc-hdr .ot-chkbox label,#onetrust-pc-sdk ul.ot-subgrps .ot-acc-hdr .ot-chkbox label,#onetrust-pc-sdk .ot-subgrp-cntr ul.ot-subgrps .ot-acc-hdr .ot-chkbox label,#onetrust-pc-sdk .ot-vs-list .ot-vnd-item .ot-acc-hdr .ot-chkbox label,#onetrust-pc-sdk .ot-vnd-serv .ot-vnd-item .ot-acc-hdr .ot-chkbox label,#onetrust-pc-sdk #ot-pc-lst .ot-vs-list .ot-vnd-item .ot-acc-hdr .ot-chkbox label,#onetrust-pc-sdk .ot-accordion-layout.ot-checkbox-consent .ot-acc-hdr .ot-chkbox label{padding:0}#onetrust-pc-sdk .ot-vs-config .ot-acc-hdr .ot-chkbox label::before,#onetrust-pc-sdk ul.ot-subgrps .ot-acc-hdr .ot-chkbox label::before,#onetrust-pc-sdk .ot-subgrp-cntr ul.ot-subgrps .ot-acc-hdr .ot-chkbox label::before,#onetrust-pc-sdk .ot-vs-list .ot-vnd-item .ot-acc-hdr .ot-chkbox label::before,#onetrust-pc-sdk .ot-vnd-serv .ot-vnd-item .ot-acc-hdr .ot-chkbox label::before,#onetrust-pc-sdk #ot-pc-lst .ot-vs-list .ot-vnd-item .ot-acc-hdr .ot-chkbox label::before,#onetrust-pc-sdk .ot-accordion-layout.ot-checkbox-consent .ot-acc-hdr .ot-chkbox label::before{position:relative}#onetrust-pc-sdk .ot-vs-config .ot-acc-hdr .ot-chkbox input,#onetrust-pc-sdk ul.ot-subgrps .ot-acc-hdr .ot-chkbox input,#onetrust-pc-sdk .ot-subgrp-cntr ul.ot-subgrps .ot-acc-hdr .ot-chkbox input,#onetrust-pc-sdk .ot-vs-list .ot-vnd-item .ot-acc-hdr .ot-chkbox input,#onetrust-pc-sdk .ot-vnd-serv .ot-vnd-item .ot-acc-hdr .ot-chkbox input,#onetrust-pc-sdk #ot-pc-lst .ot-vs-list .ot-vnd-item .ot-acc-hdr .ot-chkbox input,#onetrust-pc-sdk .ot-accordion-layout.ot-checkbox-consent .ot-acc-hdr .ot-chkbox input{position:absolute;cursor:pointer;width:100%;height:100%;opacity:0;margin:0;top:0;left:0;z-index:1}#onetrust-pc-sdk .ot-subgrp-cntr ul.ot-subgrps li.ot-subgrp .ot-acc-hdr h5.ot-cat-header,#onetrust-pc-sdk .ot-subgrp-cntr ul.ot-subgrps li.ot-subgrp .ot-acc-hdr h4.ot-cat-header{margin:0}#onetrust-pc-sdk .ot-vs-config .ot-subgrp-cntr ul.ot-subgrps li.ot-subgrp h5{top:0;line-height:20px}#onetrust-pc-sdk .ot-vs-list{display:flex;flex-direction:column;padding:0;margin:.5rem 4px}#onetrust-pc-sdk .ot-vs-selc-all{display:flex;padding:0;float:unset;align-items:center;justify-content:flex-start}#onetrust-pc-sdk .ot-vs-selc-all.ot-toggle-conf{justify-content:flex-end}#onetrust-pc-sdk .ot-vs-selc-all.ot-toggle-conf.ot-caret-conf .ot-sel-all-chkbox{margin-right:48px}#onetrust-pc-sdk .ot-vs-selc-all.ot-toggle-conf .ot-sel-all-chkbox{margin:0;padding:0;margin-right:14px;justify-content:flex-end}#onetrust-pc-sdk .ot-vs-selc-all.ot-toggle-conf #ot-selall-vencntr.ot-chkbox,#onetrust-pc-sdk .ot-vs-selc-all.ot-toggle-conf #ot-selall-vencntr.ot-tgl{display:inline-block;right:unset;width:auto;height:auto;float:none}#onetrust-pc-sdk .ot-vs-selc-all.ot-toggle-conf #ot-selall-vencntr label{width:45px;height:25px}#onetrust-pc-sdk .ot-vs-selc-all .ot-sel-all-chkbox{margin-right:11px;margin-left:.75rem;display:flex;align-items:center}#onetrust-pc-sdk .ot-vs-selc-all .sel-all-hdr{margin:0 1.25rem;font-size:.812em;line-height:normal;text-align:center;word-break:break-word;word-wrap:break-word}#onetrust-pc-sdk .ot-vnd-list-cnt #ot-selall-vencntr.ot-chkbox{float:unset;right:0}#onetrust-pc-sdk[dir=rtl] #ot-back-arw,#onetrust-pc-sdk[dir=rtl] input~.ot-acc-hdr .ot-arw{transform:rotate(180deg);-o-transform:rotate(180deg);-ms-transform:rotate(180deg);-webkit-transform:rotate(180deg)}#onetrust-pc-sdk[dir=rtl] input:checked~.ot-acc-hdr .ot-arw{transform:rotate(270deg);-o-transform:rotate(270deg);-ms-transform:rotate(270deg);-webkit-transform:rotate(270deg)}#onetrust-pc-sdk[dir=rtl] .ot-chkbox label::after{transform:rotate(45deg);-webkit-transform:rotate(45deg);-o-transform:rotate(45deg);-ms-transform:rotate(45deg);border-left:0;border-right:3px solid}#onetrust-pc-sdk[dir=rtl] .ot-search-cntr>svg{right:0}@media only screen and (max-width: 600px){#onetrust-pc-sdk.otPcCenter{left:0;min-width:100%;height:100%;top:0;border-radius:0}#onetrust-pc-sdk #ot-pc-content,#onetrust-pc-sdk.ot-ftr-stacked .ot-btn-container{margin:1px 3px 0 10px;padding-right:10px;width:calc(100% - 23px)}#onetrust-pc-sdk .ot-btn-container button{max-width:none;letter-spacing:.01em}#onetrust-pc-sdk #close-pc-btn-handler{top:10px;right:17px}#onetrust-pc-sdk p{font-size:.7em}#onetrust-pc-sdk #ot-pc-hdr{margin:10px 10px 0 5px;width:calc(100% - 15px)}#onetrust-pc-sdk .vendor-search-handler{font-size:1em}#onetrust-pc-sdk #ot-back-arw{margin-left:12px}#onetrust-pc-sdk #ot-lst-cnt{margin:0;padding:0 5px 0 10px;min-width:95%}#onetrust-pc-sdk .switch+p{max-width:80%}#onetrust-pc-sdk .ot-ftr-stacked button{width:100%}#onetrust-pc-sdk #ot-fltr-cnt{max-width:320px;width:90%;border-top-right-radius:0;border-bottom-right-radius:0;margin:0;margin-left:15px;left:auto;right:40px;top:85px}#onetrust-pc-sdk .ot-fltr-opt{margin-left:25px;margin-bottom:10px}#onetrust-pc-sdk .ot-pc-refuse-all-handler{margin-bottom:0}#onetrust-pc-sdk #ot-fltr-cnt{right:40px}}@media only screen and (max-width: 476px){#onetrust-pc-sdk .ot-fltr-cntr,#onetrust-pc-sdk #ot-fltr-cnt{right:10px}#onetrust-pc-sdk #ot-anchor{right:25px}#onetrust-pc-sdk button{width:100%}#onetrust-pc-sdk:not(.ot-addtl-vendors) #ot-pc-lst:not(.ot-enbl-chr) .ot-sel-all{padding-right:9px}#onetrust-pc-sdk:not(.ot-addtl-vendors) #ot-pc-lst:not(.ot-enbl-chr) .ot-tgl-cntr{right:0}}@media only screen and (max-width: 896px)and (max-height: 425px)and (orientation: landscape){#onetrust-pc-sdk.otPcCenter{left:0;top:0;min-width:100%;height:100%;border-radius:0}#onetrust-pc-sdk .ot-pc-header{height:auto;min-height:20px}#onetrust-pc-sdk .ot-pc-header .ot-pc-logo{max-height:30px}#onetrust-pc-sdk .ot-pc-footer{max-height:60px;overflow-y:auto}#onetrust-pc-sdk #ot-pc-content,#onetrust-pc-sdk #ot-pc-lst{bottom:70px}#onetrust-pc-sdk.ot-ftr-stacked #ot-pc-content{bottom:70px}#onetrust-pc-sdk #ot-anchor{left:initial;right:50px}#onetrust-pc-sdk #ot-lst-title{margin-top:12px}#onetrust-pc-sdk #ot-lst-title *{font-size:inherit}#onetrust-pc-sdk #ot-pc-hdr input{margin-right:0;padding-right:45px}#onetrust-pc-sdk .switch+p{max-width:85%}#onetrust-pc-sdk #ot-sel-blk{position:static}#onetrust-pc-sdk #ot-pc-lst{overflow:auto}#onetrust-pc-sdk #ot-lst-cnt{max-height:none;overflow:initial}#onetrust-pc-sdk #ot-lst-cnt.no-results{height:auto}#onetrust-pc-sdk input{font-size:1em !important}#onetrust-pc-sdk p{font-size:.6em}#onetrust-pc-sdk #ot-fltr-modal{width:100%;top:0}#onetrust-pc-sdk ul li p,#onetrust-pc-sdk .category-vendors-list-handler,#onetrust-pc-sdk .category-vendors-list-handler+a,#onetrust-pc-sdk .category-host-list-handler{font-size:.6em}#onetrust-pc-sdk.ot-shw-fltr #ot-anchor{display:none !important}#onetrust-pc-sdk.ot-shw-fltr #ot-pc-lst{height:100% !important;overflow:hidden;top:0px}#onetrust-pc-sdk.ot-shw-fltr #ot-fltr-cnt{margin:0;height:100%;max-height:none;padding:10px;top:0;width:calc(100% - 20px);position:absolute;right:0;left:0;max-width:none}#onetrust-pc-sdk.ot-shw-fltr .ot-fltr-scrlcnt{max-height:calc(100% - 65px)}}
            #onetrust-consent-sdk #onetrust-pc-sdk,
                #onetrust-consent-sdk #ot-search-cntr,
                #onetrust-consent-sdk #onetrust-pc-sdk .ot-switch.ot-toggle,
                #onetrust-consent-sdk #onetrust-pc-sdk ot-grp-hdr1 .checkbox,
                #onetrust-consent-sdk #onetrust-pc-sdk #ot-pc-title:after
                ,#onetrust-consent-sdk #onetrust-pc-sdk #ot-sel-blk,
                        #onetrust-consent-sdk #onetrust-pc-sdk #ot-fltr-cnt,
                        #onetrust-consent-sdk #onetrust-pc-sdk #ot-anchor {
                    background-color: #FFF;
                }
               
            #onetrust-consent-sdk #onetrust-pc-sdk h3,
                #onetrust-consent-sdk #onetrust-pc-sdk h4,
                #onetrust-consent-sdk #onetrust-pc-sdk h5,
                #onetrust-consent-sdk #onetrust-pc-sdk h6,
                #onetrust-consent-sdk #onetrust-pc-sdk p,
                #onetrust-consent-sdk #onetrust-pc-sdk #ot-ven-lst .ot-ven-opts p,
                #onetrust-consent-sdk #onetrust-pc-sdk #ot-pc-desc,
                #onetrust-consent-sdk #onetrust-pc-sdk #ot-pc-title,
                #onetrust-consent-sdk #onetrust-pc-sdk .ot-li-title,
                #onetrust-consent-sdk #onetrust-pc-sdk .ot-sel-all-hdr span,
                #onetrust-consent-sdk #onetrust-pc-sdk #ot-host-lst .ot-host-info,
                #onetrust-consent-sdk #onetrust-pc-sdk #ot-fltr-modal #modal-header,
                #onetrust-consent-sdk #onetrust-pc-sdk .ot-checkbox label span,
                #onetrust-consent-sdk #onetrust-pc-sdk #ot-pc-lst #ot-sel-blk p,
                #onetrust-consent-sdk #onetrust-pc-sdk #ot-pc-lst #ot-lst-title h3,
                #onetrust-consent-sdk #onetrust-pc-sdk #ot-pc-lst .back-btn-handler p,
                #onetrust-consent-sdk #onetrust-pc-sdk #ot-pc-lst .ot-ven-name,
                #onetrust-consent-sdk #onetrust-pc-sdk #ot-pc-lst #ot-ven-lst .consent-category,
                #onetrust-consent-sdk #onetrust-pc-sdk .ot-leg-btn-container .ot-inactive-leg-btn,
                #onetrust-consent-sdk #onetrust-pc-sdk .ot-label-status,
                #onetrust-consent-sdk #onetrust-pc-sdk .ot-chkbox label span,
                #onetrust-consent-sdk #onetrust-pc-sdk #clear-filters-handler,
                #onetrust-consent-sdk #onetrust-pc-sdk .ot-optout-signal
                {
                    color: #2E2E2E;
                }
             #onetrust-consent-sdk #onetrust-pc-sdk .privacy-notice-link,
                    #onetrust-consent-sdk #onetrust-pc-sdk .ot-pgph-link,
                    #onetrust-consent-sdk #onetrust-pc-sdk .category-vendors-list-handler,
                    #onetrust-consent-sdk #onetrust-pc-sdk .category-vendors-list-handler + a,
                    #onetrust-consent-sdk #onetrust-pc-sdk .category-host-list-handler,
                    #onetrust-consent-sdk #onetrust-pc-sdk .ot-ven-link,
                    #onetrust-consent-sdk #onetrust-pc-sdk .ot-ven-legclaim-link,
                    #onetrust-consent-sdk #onetrust-pc-sdk #ot-host-lst .ot-host-name a,
                    #onetrust-consent-sdk #onetrust-pc-sdk #ot-host-lst .ot-acc-hdr .ot-host-expand,
                    #onetrust-consent-sdk #onetrust-pc-sdk #ot-host-lst .ot-host-info a,
                    #onetrust-consent-sdk #onetrust-pc-sdk #ot-pc-content #ot-pc-desc .ot-link-btn,
                    #onetrust-consent-sdk #onetrust-pc-sdk .ot-vnd-serv .ot-vnd-item .ot-vnd-info a,
                    #onetrust-consent-sdk #onetrust-pc-sdk #ot-lst-cnt .ot-vnd-info a
                    {
                        color: #007398;
                    }
            #onetrust-consent-sdk #onetrust-pc-sdk .category-vendors-list-handler:hover { text-decoration: underline;}
            #onetrust-consent-sdk #onetrust-pc-sdk .ot-acc-grpcntr.ot-acc-txt,
            #onetrust-consent-sdk #onetrust-pc-sdk .ot-acc-txt .ot-subgrp-tgl .ot-switch.ot-toggle
             {
                background-color: #F8F8F8;
            }
             #onetrust-consent-sdk #onetrust-pc-sdk #ot-host-lst .ot-host-info,
                    #onetrust-consent-sdk #onetrust-pc-sdk .ot-acc-txt .ot-ven-dets
                            {
                                background-color: #F8F8F8;
                            }
        #onetrust-consent-sdk #onetrust-pc-sdk
            button:not(#clear-filters-handler):not(.ot-close-icon):not(#filter-btn-handler):not(.ot-remove-objection-handler):not(.ot-obj-leg-btn-handler):not([aria-expanded]):not(.ot-link-btn),
            #onetrust-consent-sdk #onetrust-pc-sdk .ot-leg-btn-container .ot-active-leg-btn {
                background-color: #007398;border-color: #007398;
                color: #FFF;
            }
            #onetrust-consent-sdk #onetrust-pc-sdk .ot-active-menu {
                border-color: #007398;
            }
            
            #onetrust-consent-sdk #onetrust-pc-sdk .ot-leg-btn-container .ot-remove-objection-handler{
                background-color: transparent;
                border: 1px solid transparent;
            }
            #onetrust-consent-sdk #onetrust-pc-sdk .ot-leg-btn-container .ot-inactive-leg-btn {
                background-color: #FFFFFF;
                color: #78808E; border-color: #78808E;
            }
            #onetrust-consent-sdk #onetrust-pc-sdk .ot-tgl input:focus + .ot-switch, .ot-switch .ot-switch-nob, .ot-switch .ot-switch-nob:before,
            #onetrust-pc-sdk .ot-checkbox input[type="checkbox"]:focus + label::before,
            #onetrust-pc-sdk .ot-chkbox input[type="checkbox"]:focus + label::before {
                outline-color: #000000;
                outline-width: 1px;
            }
            #onetrust-pc-sdk .ot-host-item > button:focus, #onetrust-pc-sdk .ot-ven-item > button:focus {
                border: 1px solid #000000;
            }
            #onetrust-consent-sdk #onetrust-pc-sdk *:focus,
            #onetrust-consent-sdk #onetrust-pc-sdk .ot-vlst-cntr > a:focus {
               outline: 1px solid #000000;
            }#onetrust-pc-sdk .ot-vlst-cntr .ot-ext-lnk,  #onetrust-pc-sdk .ot-ven-hdr .ot-ext-lnk{
                    background-image: url('https://cdn.cookielaw.org/logos/static/ot_external_link.svg');
                }
            /*! Extra code to blur out background */
.onetrust-pc-dark-filter{
background:rgba(0,0,0,.5);
z-index:2147483646;
width:100%;
height:100%;
overflow:hidden;
position:fixed;
top:0;
bottom:0;
left:0;
backdrop-filter: initial
}

/*! v6.12.0 2021-01-19 */
div#onetrust-consent-sdk #onetrust-banner-sdk{border-top:2px solid #eb6500!important;outline:1px solid transparent;box-shadow:none;padding:24px}div#onetrust-consent-sdk button{border-radius:0!important;box-shadow:none!important;box-sizing:border-box!important;font-size:20px!important;font-weight:400!important;letter-spacing:0!important;max-width:none!important;white-space:nowrap!important}div#onetrust-consent-sdk button:not(.ot-link-btn){background-color:#007398!important;border:2px solid #007398!important;color:#fff!important;height:48px!important;padding:0 1em!important;width:auto!important}div#onetrust-consent-sdk button:hover{background-color:#fff!important;border-color:#eb6500!important;color:#2e2e2e!important}div#onetrust-consent-sdk button.ot-link-btn{color:#007398!important;font-size:16px!important;text-decoration:underline}div#onetrust-consent-sdk button.ot-link-btn:hover{color:inherit!important;text-decoration-color:#eb6500!important}div#onetrust-consent-sdk a,div#onetrust-pc-sdk a{color:#007398!important;text-decoration:underline!important}div#onetrust-consent-sdk a,div#onetrust-consent-sdk button,div#onetrust-consent-sdk p:hover{opacity:1!important}div#onetrust-consent-sdk a:focus,div#onetrust-consent-sdk button:focus,div#onetrust-consent-sdk input:focus{outline:2px solid #eb6500!important;outline-offset:1px!important}div#onetrust-banner-sdk .ot-sdk-container{padding:0;width:auto}div#onetrust-banner-sdk .ot-sdk-row{align-items:flex-start;box-sizing:border-box;display:flex;flex-direction:column;justify-content:space-between;margin:auto;max-width:1152px}div#onetrust-banner-sdk .ot-sdk-row:after{display:none}div#onetrust-banner-sdk #onetrust-group-container,div#onetrust-banner-sdk.ot-bnr-flift:not(.ot-iab-2) #onetrust-group-container,div#onetrust-banner-sdk:not(.ot-iab-2) #onetrust-group-container{flex-grow:1;width:auto}div#onetrust-banner-sdk #onetrust-policy,div#onetrust-banner-sdk.ot-bnr-flift #onetrust-policy{margin:0;overflow:visible}div#onetrust-banner-sdk.ot-bnr-flift #onetrust-policy-text,div#onetrust-consent-sdk #onetrust-policy-text{font-size:16px;line-height:24px;max-width:44em;margin:0}div#onetrust-consent-sdk #onetrust-policy-text a[href]{font-weight:400;margin-left:8px}div#onetrust-banner-sdk #onetrust-button-group-parent{flex:0 0 auto;margin:32px 0 0;width:100%}div#onetrust-banner-sdk #onetrust-button-group{display:flex;flex-direction:row;flex-wrap:wrap;justify-content:flex-end;margin:-8px}div#onetrust-banner-sdk .banner-actions-container{display:flex;flex:1 0 auto}div#onetrust-banner-sdk.ot-buttons-fw:not(.ot-iab-2) #onetrust-button-group button:last-of-type,div#onetrust-consent-sdk #onetrust-accept-btn-handler,div#onetrust-consent-sdk #onetrust-pc-btn-handler{flex:1 0 auto;margin:8px;width:auto}div#onetrust-consent-sdk #onetrust-pc-btn-handler{background-color:#fff!important;color:inherit!important}div#onetrust-banner-sdk #onetrust-close-btn-container{display:none}@media only screen and (min-width:556px){div#onetrust-consent-sdk #onetrust-banner-sdk{padding:40px}div#onetrust-banner-sdk #onetrust-policy{margin:0 40px 0 0}div#onetrust-banner-sdk .ot-sdk-row{align-items:center;flex-direction:row}div#onetrust-banner-sdk #onetrust-button-group-parent,div#onetrust-banner-sdk.ot-bnr-flift:not(.ot-iab-2) #onetrust-button-group-parent,div#onetrust-banner-sdk:not(.ot-iab-2) #onetrust-button-group-parent{margin:0;padding:0;width:auto}div#onetrust-banner-sdk #onetrust-button-group,div#onetrust-banner-sdk.ot-buttons-fw:not(.ot-iab-2) #onetrust-button-group{align-items:stretch;flex-direction:column-reverse;margin:0}div#onetrust-consent-sdk #onetrust-accept-btn-handler,div#onetrust-consent-sdk #onetrust-pc-btn-handler{flex:1 0 auto}}@media only screen and (min-width:768px){div#onetrust-banner-sdk #onetrust-policy{margin:0 48px 0 0}div#onetrust-consent-sdk #onetrust-banner-sdk{padding:48px}}div#onetrust-consent-sdk #onetrust-pc-sdk h5{font-size:16px;line-height:24px}div#onetrust-consent-sdk #onetrust-pc-sdk p,div#onetrust-pc-sdk #ot-pc-desc,div#onetrust-pc-sdk .category-host-list-handler,div#onetrust-pc-sdk .ot-accordion-layout .ot-cat-header{font-size:16px;font-weight:400;line-height:24px}div#onetrust-consent-sdk a:hover,div#onetrust-pc-sdk a:hover{color:inherit!important;text-decoration-color:#eb6500!important}div#onetrust-pc-sdk{border-radius:0;bottom:0;height:auto;left:0;margin:auto;max-width:100%;overflow:hidden;right:0;top:0;width:512px;max-height:800px}div#onetrust-pc-sdk .ot-pc-header{display:none}div#onetrust-pc-sdk #ot-pc-content{overscroll-behavior:contain;padding:0 12px 0 24px;margin:16px 4px 0 0;top:0;right:16px;left:0;width:auto}div#onetrust-pc-sdk #ot-category-title,div#onetrust-pc-sdk #ot-pc-title{font-size:24px;font-weight:400;line-height:32px;margin:0 0 16px}div#onetrust-pc-sdk #ot-pc-desc{padding:0}div#onetrust-pc-sdk #ot-pc-desc a{display:inline}div#onetrust-pc-sdk #accept-recommended-btn-handler{display:none!important}div#onetrust-pc-sdk input[type=checkbox]:focus+.ot-acc-hdr{outline:2px solid #eb6500;outline-offset:-1px;transition:none}div#onetrust-pc-sdk .ot-accordion-layout.ot-cat-item{border-width:0 0 2px}div#onetrust-pc-sdk .ot-accordion-layout.ot-cat-item:first-of-type{border-width:2px 0}div#onetrust-pc-sdk .ot-accordion-layout .ot-acc-hdr{padding:8px 0;width:100%}div#onetrust-pc-sdk .ot-plus-minus{transform:translateY(2px)}div#onetrust-pc-sdk .ot-accordion-layout.ot-cat-item>button{background:0 0!important;border:0!important;height:44px!important;max-width:none!important;width:calc(100% - 48px)!important}div#onetrust-consent-sdk #onetrust-pc-sdk h5{font-weight:700}div#onetrust-pc-sdk .ot-accordion-layout .ot-hlst-cntr{padding:0}div#onetrust-pc-sdk .ot-accordion-layout.ot-cat-item .ot-acc-grpdesc{padding:0;width:100%}div#onetrust-pc-sdk .ot-acc-grpcntr .ot-subgrp-cntr{border:0;padding:0}div#onetrust-pc-sdk .ot-subgrp-cntr ul.ot-subgrps li.ot-subgrp{margin:0}div#onetrust-pc-sdk .ot-always-active-group .ot-cat-header{width:calc(100% - 160px)}#onetrust-pc-sdk .ot-accordion-layout .ot-cat-header{width:calc(100% - 88px)}div#onetrust-pc-sdk .ot-accordion-layout h4~.ot-always-active{color:inherit;font-size:12px;font-weight:400;line-height:1.5;padding-right:48px}div#onetrust-pc-sdk .ot-accordion-layout h4~.ot-always-active:before{border-radius:12px;position:absolute;right:0;top:0;content:'';background:#fff;border:2px solid #939393;box-sizing:border-box;height:20px;width:40px}div#onetrust-pc-sdk .ot-accordion-layout h4~.ot-always-active:after{border-radius:50%;position:absolute;right:5px;top:4px;content:'';background-color:#eb6500;height:12px;width:12px}div#onetrust-pc-sdk .ot-accordion-layout h4~.ot-always-active,div#onetrust-pc-sdk .ot-accordion-layout h4~.ot-tgl{right:2px}div#onetrust-pc-sdk .ot-switch{display:block;height:20px;width:40px}div#onetrust-pc-sdk .ot-tgl input+.ot-switch .ot-switch-nob,div#onetrust-pc-sdk .ot-tgl input:checked+.ot-switch .ot-switch-nob{background:#fff;border:2px solid #939393;box-sizing:border-box;height:20px;width:40px}div#onetrust-pc-sdk .ot-tgl input+.ot-switch .ot-switch-nob:before{background-color:#737373;height:8px;left:4px;top:4px;width:8px}div#onetrust-pc-sdk .ot-tgl input:checked+.ot-switch .ot-switch-nob:before{background-color:#eb6500;height:12px;left:0;top:2px;width:12px}div#onetrust-pc-sdk .ot-tgl input:focus+.ot-switch .ot-switch-nob{box-shadow:0 0;outline:2px solid #eb6500!important;outline-offset:1px;transition:none}div#onetrust-consent-sdk #onetrust-pc-sdk .ot-acc-grpcntr.ot-acc-txt{background-color:transparent;padding-left:3px}div#onetrust-pc-sdk .ot-accordion-layout .ot-hlst-cntr,div#onetrust-pc-sdk .ot-accordion-layout .ot-vlst-cntr{overflow:visible;width:100%}div#onetrust-pc-sdk .ot-pc-footer{border-top:0 solid}div#onetrust-pc-sdk .ot-btn-container{padding-top:24px;text-align:center}div#onetrust-pc-sdk .ot-pc-footer button{margin:8px 0;background-color:#fff}div#onetrust-pc-sdk .ot-pc-footer-logo{background-color:#fff}div#onetrust-pc-sdk #ot-lst-title span{font-size:24px;font-weight:400;line-height:32px}div#onetrust-pc-sdk #ot-host-lst .ot-host-desc,div#onetrust-pc-sdk #ot-host-lst .ot-host-expand,div#onetrust-pc-sdk #ot-host-lst .ot-host-name,div#onetrust-pc-sdk #ot-host-lst .ot-host-name a,div#onetrust-pc-sdk .back-btn-handler,div#onetrust-pc-sdk .ot-host-opt li>div div{font-size:16px;font-weight:400;line-height:24px}div#onetrust-pc-sdk #ot-host-lst .ot-acc-txt{width:100%}div#onetrust-pc-sdk #ot-pc-lst{top:0}div#onetrust-pc-sdk .back-btn-handler{text-decoration:none!important}div#onetrust-pc-sdk #filter-btn-handler:hover svg{filter:invert(1)}div#onetrust-pc-sdk .back-btn-handler svg{width:16px;height:16px}div#onetrust-pc-sdk .ot-host-item>button{background:0 0!important;border:0!important;height:66px!important;max-width:none!important;width:calc(100% - 5px)!important;transform:translate(2px,2px)}div#onetrust-pc-sdk .ot-host-item{border-bottom:2px solid #b9b9b9;padding:0}div#onetrust-pc-sdk .ot-host-item .ot-acc-hdr{margin:0 0 -6px;padding:8px 0}div#onetrust-pc-sdk ul li:first-child{border-top:2px solid #b9b9b9}div#onetrust-pc-sdk .ot-host-item .ot-plus-minus{margin:0 8px 0 0}div#onetrust-pc-sdk .ot-search-cntr{width:calc(100% - 48px)}div#onetrust-pc-sdk .ot-host-opt .ot-host-info{background-color:transparent}div#onetrust-pc-sdk .ot-host-opt li>div div{padding:0}div#onetrust-pc-sdk #vendor-search-handler{border-radius:0;border-color:#939393;border-style:solid;border-width:2px 0 2px 2px;font-size:20px;height:48px;margin:0}div#onetrust-pc-sdk #ot-pc-hdr{margin-left:24px}div#onetrust-pc-sdk .ot-lst-subhdr{width:calc(100% - 24px)}div#onetrust-pc-sdk .ot-lst-subhdr svg{right:0;top:8px}div#onetrust-pc-sdk .ot-fltr-cntr{box-sizing:border-box;right:0;width:48px}div#onetrust-pc-sdk #filter-btn-handler{width:48px!important;padding:8px!important}div#onetrust-consent-sdk #onetrust-pc-sdk #clear-filters-handler,div#onetrust-pc-sdk button#filter-apply-handler,div#onetrust-pc-sdk button#filter-cancel-handler{height:2em!important;padding-left:14px!important;padding-right:14px!important}div#onetrust-pc-sdk #ot-fltr-cnt{box-shadow:0 0;border:1px solid #8e8e8e;border-radius:0}div#onetrust-pc-sdk .ot-fltr-scrlcnt{max-height:calc(100% - 80px)}div#onetrust-pc-sdk #ot-fltr-modal{max-height:400px}div#onetrust-pc-sdk .ot-fltr-opt{margin-bottom:16px}div#onetrust-pc-sdk #ot-lst-cnt{margin-left:24px;width:calc(100% - 48px)}div#onetrust-pc-sdk #ot-anchor{display:none!important}
/*! Extra code to blur our background */
.onetrust-pc-dark-filter{
backdrop-filter: blur(3px)
}
.ot-sdk-cookie-policy{font-family:inherit;font-size:16px}.ot-sdk-cookie-policy.otRelFont{font-size:1rem}.ot-sdk-cookie-policy h3,.ot-sdk-cookie-policy h4,.ot-sdk-cookie-policy h6,.ot-sdk-cookie-policy p,.ot-sdk-cookie-policy li,.ot-sdk-cookie-policy a,.ot-sdk-cookie-policy th,.ot-sdk-cookie-policy #cookie-policy-description,.ot-sdk-cookie-policy .ot-sdk-cookie-policy-group,.ot-sdk-cookie-policy #cookie-policy-title{color:dimgray}.ot-sdk-cookie-policy #cookie-policy-description{margin-bottom:1em}.ot-sdk-cookie-policy h4{font-size:1.2em}.ot-sdk-cookie-policy h6{font-size:1em;margin-top:2em}.ot-sdk-cookie-policy th{min-width:75px}.ot-sdk-cookie-policy a,.ot-sdk-cookie-policy a:hover{background:#fff}.ot-sdk-cookie-policy thead{background-color:#f6f6f4;font-weight:bold}.ot-sdk-cookie-policy .ot-mobile-border{display:none}.ot-sdk-cookie-policy section{margin-bottom:2em}.ot-sdk-cookie-policy table{border-collapse:inherit}#ot-sdk-cookie-policy-v2.ot-sdk-cookie-policy{font-family:inherit;font-size:1rem}#ot-sdk-cookie-policy-v2.ot-sdk-cookie-policy h3,#ot-sdk-cookie-policy-v2.ot-sdk-cookie-policy h4,#ot-sdk-cookie-policy-v2.ot-sdk-cookie-policy h6,#ot-sdk-cookie-policy-v2.ot-sdk-cookie-policy p,#ot-sdk-cookie-policy-v2.ot-sdk-cookie-policy li,#ot-sdk-cookie-policy-v2.ot-sdk-cookie-policy a,#ot-sdk-cookie-policy-v2.ot-sdk-cookie-policy th,#ot-sdk-cookie-policy-v2.ot-sdk-cookie-policy #cookie-policy-description,#ot-sdk-cookie-policy-v2.ot-sdk-cookie-policy .ot-sdk-cookie-policy-group,#ot-sdk-cookie-policy-v2.ot-sdk-cookie-policy #cookie-policy-title{color:dimgray}#ot-sdk-cookie-policy-v2.ot-sdk-cookie-policy #cookie-policy-description{margin-bottom:1em}#ot-sdk-cookie-policy-v2.ot-sdk-cookie-policy .ot-sdk-subgroup{margin-left:1.5em}#ot-sdk-cookie-policy-v2.ot-sdk-cookie-policy #cookie-policy-description,#ot-sdk-cookie-policy-v2.ot-sdk-cookie-policy .ot-sdk-cookie-policy-group-desc,#ot-sdk-cookie-policy-v2.ot-sdk-cookie-policy .ot-table-header,#ot-sdk-cookie-policy-v2.ot-sdk-cookie-policy a,#ot-sdk-cookie-policy-v2.ot-sdk-cookie-policy span,#ot-sdk-cookie-policy-v2.ot-sdk-cookie-policy td{font-size:.9em}#ot-sdk-cookie-policy-v2.ot-sdk-cookie-policy td span,#ot-sdk-cookie-policy-v2.ot-sdk-cookie-policy td a{font-size:inherit}#ot-sdk-cookie-policy-v2.ot-sdk-cookie-policy .ot-sdk-cookie-policy-group{font-size:1em;margin-bottom:.6em}#ot-sdk-cookie-policy-v2.ot-sdk-cookie-policy .ot-sdk-cookie-policy-title{margin-bottom:1.2em}#ot-sdk-cookie-policy-v2.ot-sdk-cookie-policy>section{margin-bottom:1em}#ot-sdk-cookie-policy-v2.ot-sdk-cookie-policy th{min-width:75px}#ot-sdk-cookie-policy-v2.ot-sdk-cookie-policy a,#ot-sdk-cookie-policy-v2.ot-sdk-cookie-policy a:hover{background:#fff}#ot-sdk-cookie-policy-v2.ot-sdk-cookie-policy thead{background-color:#f6f6f4;font-weight:bold}#ot-sdk-cookie-policy-v2.ot-sdk-cookie-policy .ot-mobile-border{display:none}#ot-sdk-cookie-policy-v2.ot-sdk-cookie-policy section{margin-bottom:2em}#ot-sdk-cookie-policy-v2.ot-sdk-cookie-policy .ot-sdk-subgroup ul li{list-style:disc;margin-left:1.5em}#ot-sdk-cookie-policy-v2.ot-sdk-cookie-policy .ot-sdk-subgroup ul li h4{display:inline-block}#ot-sdk-cookie-policy-v2.ot-sdk-cookie-policy table{border-collapse:inherit;margin:auto;border:1px solid #d7d7d7;border-radius:5px;border-spacing:initial;width:100%;overflow:hidden}#ot-sdk-cookie-policy-v2.ot-sdk-cookie-policy table th,#ot-sdk-cookie-policy-v2.ot-sdk-cookie-policy table td{border-bottom:1px solid #d7d7d7;border-right:1px solid #d7d7d7}#ot-sdk-cookie-policy-v2.ot-sdk-cookie-policy table tr:last-child td{border-bottom:0px}#ot-sdk-cookie-policy-v2.ot-sdk-cookie-policy table tr th:last-child,#ot-sdk-cookie-policy-v2.ot-sdk-cookie-policy table tr td:last-child{border-right:0px}#ot-sdk-cookie-policy-v2.ot-sdk-cookie-policy table .ot-host,#ot-sdk-cookie-policy-v2.ot-sdk-cookie-policy table .ot-cookies-type{width:25%}.ot-sdk-cookie-policy[dir=rtl]{text-align:left}#ot-sdk-cookie-policy h3{font-size:1.5em}@media only screen and (max-width: 530px){.ot-sdk-cookie-policy:not(#ot-sdk-cookie-policy-v2) table,.ot-sdk-cookie-policy:not(#ot-sdk-cookie-policy-v2) thead,.ot-sdk-cookie-policy:not(#ot-sdk-cookie-policy-v2) tbody,.ot-sdk-cookie-policy:not(#ot-sdk-cookie-policy-v2) th,.ot-sdk-cookie-policy:not(#ot-sdk-cookie-policy-v2) td,.ot-sdk-cookie-policy:not(#ot-sdk-cookie-policy-v2) tr{display:block}.ot-sdk-cookie-policy:not(#ot-sdk-cookie-policy-v2) thead tr{position:absolute;top:-9999px;left:-9999px}.ot-sdk-cookie-policy:not(#ot-sdk-cookie-policy-v2) tr{margin:0 0 1em 0}.ot-sdk-cookie-policy:not(#ot-sdk-cookie-policy-v2) tr:nth-child(odd),.ot-sdk-cookie-policy:not(#ot-sdk-cookie-policy-v2) tr:nth-child(odd) a{background:#f6f6f4}.ot-sdk-cookie-policy:not(#ot-sdk-cookie-policy-v2) td{border:none;border-bottom:1px solid #eee;position:relative;padding-left:50%}.ot-sdk-cookie-policy:not(#ot-sdk-cookie-policy-v2) td:before{position:absolute;height:100%;left:6px;width:40%;padding-right:10px}.ot-sdk-cookie-policy:not(#ot-sdk-cookie-policy-v2) .ot-mobile-border{display:inline-block;background-color:#e4e4e4;position:absolute;height:100%;top:0;left:45%;width:2px}.ot-sdk-cookie-policy:not(#ot-sdk-cookie-policy-v2) td:before{content:attr(data-label);font-weight:bold}.ot-sdk-cookie-policy:not(#ot-sdk-cookie-policy-v2) li{word-break:break-word;word-wrap:break-word}#ot-sdk-cookie-policy-v2.ot-sdk-cookie-policy table{overflow:hidden}#ot-sdk-cookie-policy-v2.ot-sdk-cookie-policy table td{border:none;border-bottom:1px solid #d7d7d7}#ot-sdk-cookie-policy-v2.ot-sdk-cookie-policy table,#ot-sdk-cookie-policy-v2.ot-sdk-cookie-policy thead,#ot-sdk-cookie-policy-v2.ot-sdk-cookie-policy tbody,#ot-sdk-cookie-policy-v2.ot-sdk-cookie-policy th,#ot-sdk-cookie-policy-v2.ot-sdk-cookie-policy td,#ot-sdk-cookie-policy-v2.ot-sdk-cookie-policy tr{display:block}#ot-sdk-cookie-policy-v2.ot-sdk-cookie-policy table .ot-host,#ot-sdk-cookie-policy-v2.ot-sdk-cookie-policy table .ot-cookies-type{width:auto}#ot-sdk-cookie-policy-v2.ot-sdk-cookie-policy tr{margin:0 0 1em 0}#ot-sdk-cookie-policy-v2.ot-sdk-cookie-policy td:before{height:100%;width:40%;padding-right:10px}#ot-sdk-cookie-policy-v2.ot-sdk-cookie-policy td:before{content:attr(data-label);font-weight:bold}#ot-sdk-cookie-policy-v2.ot-sdk-cookie-policy li{word-break:break-word;word-wrap:break-word}#ot-sdk-cookie-policy-v2.ot-sdk-cookie-policy thead tr{position:absolute;top:-9999px;left:-9999px;z-index:-9999}#ot-sdk-cookie-policy-v2.ot-sdk-cookie-policy table tr:last-child td{border-bottom:1px solid #d7d7d7;border-right:0px}#ot-sdk-cookie-policy-v2.ot-sdk-cookie-policy table tr:last-child td:last-child{border-bottom:0px}}
                
                    #ot-sdk-cookie-policy-v2.ot-sdk-cookie-policy h5,
                    #ot-sdk-cookie-policy-v2.ot-sdk-cookie-policy h6,
                    #ot-sdk-cookie-policy-v2.ot-sdk-cookie-policy li,
                    #ot-sdk-cookie-policy-v2.ot-sdk-cookie-policy p,
                    #ot-sdk-cookie-policy-v2.ot-sdk-cookie-policy a,
                    #ot-sdk-cookie-policy-v2.ot-sdk-cookie-policy span,
                    #ot-sdk-cookie-policy-v2.ot-sdk-cookie-policy td,
                    #ot-sdk-cookie-policy-v2.ot-sdk-cookie-policy #cookie-policy-description {
                        color: #696969;
                    }
                    #ot-sdk-cookie-policy-v2.ot-sdk-cookie-policy th {
                        color: #696969;
                    }
                    #ot-sdk-cookie-policy-v2.ot-sdk-cookie-policy .ot-sdk-cookie-policy-group {
                        color: #696969;
                    }
                    
                    #ot-sdk-cookie-policy-v2.ot-sdk-cookie-policy #cookie-policy-title {
                            color: #696969;
                        }
                    
            
                    #ot-sdk-cookie-policy-v2.ot-sdk-cookie-policy table th {
                            background-color: #F8F8F8;
                        }
                    
            .ot-floating-button__front{background-image:url('https://cdn.cookielaw.org/logos/static/ot_persistent_cookie_icon.png')}</style><style data-styled="active" data-styled-version="6.1.13"></style><link type="text/css" rel="stylesheet" href="https://pendo-static-5661679399600128.storage.googleapis.com/guide.-323232.1721046486120.css" id="_pendo-css_"><style type="text/css" scoped="scoped" class=" pendo-style-D_T2uHq_M1r-XQq8htU6Z3GjHfE" style="white-space: pre-wrap;"></style><style type="text/css">.MathJax_SVG_Display {text-align: center; margin: 1em 0em; position: relative; display: block!important; text-indent: 0; max-width: none; max-height: none; min-width: 0; min-height: 0; width: 100%}
.MathJax_SVG .MJX-monospace {font-family: monospace}
.MathJax_SVG .MJX-sans-serif {font-family: sans-serif}
#MathJax_SVG_Tooltip {background-color: InfoBackground; color: InfoText; border: 1px solid black; box-shadow: 2px 2px 5px #AAAAAA; -webkit-box-shadow: 2px 2px 5px #AAAAAA; -moz-box-shadow: 2px 2px 5px #AAAAAA; -khtml-box-shadow: 2px 2px 5px #AAAAAA; padding: 3px 4px; z-index: 401; position: absolute; left: 0; top: 0; width: auto; height: auto; display: none}
.MathJax_SVG {display: inline; font-style: normal; font-weight: normal; line-height: normal; font-size: 100%; font-size-adjust: none; text-indent: 0; text-align: left; text-transform: none; letter-spacing: normal; word-spacing: normal; word-wrap: normal; white-space: nowrap; float: none; direction: ltr; max-width: none; max-height: none; min-width: 0; min-height: 0; border: 0; padding: 0; margin: 0}
.MathJax_SVG * {transition: none; -webkit-transition: none; -moz-transition: none; -ms-transition: none; -o-transition: none}
.MathJax_SVG > div {display: inline-block}
.mjx-svg-href {fill: blue; stroke: blue}
.MathJax_SVG_Processing {visibility: hidden; position: absolute; top: 0; left: 0; width: 0; height: 0; overflow: hidden; display: block!important}
.MathJax_SVG_Processed {display: none!important}
.MathJax_SVG_test {font-style: normal; font-weight: normal; font-size: 100%; font-size-adjust: none; text-indent: 0; text-transform: none; letter-spacing: normal; word-spacing: normal; overflow: hidden; height: 1px}
.MathJax_SVG_test.mjx-test-display {display: table!important}
.MathJax_SVG_test.mjx-test-inline {display: inline!important; margin-right: -1px}
.MathJax_SVG_test.mjx-test-default {display: block!important; clear: both}
.MathJax_SVG_ex_box {display: inline-block!important; position: absolute; overflow: hidden; min-height: 0; max-height: none; padding: 0; border: 0; margin: 0; width: 1px; height: 60ex}
.mjx-test-inline .MathJax_SVG_left_box {display: inline-block; width: 0; float: left}
.mjx-test-inline .MathJax_SVG_right_box {display: inline-block; width: 0; float: right}
.mjx-test-display .MathJax_SVG_right_box {display: table-cell!important; width: 10000em!important; min-width: 0; max-width: none; padding: 0; border: 0; margin: 0}
</style></head>
    <body data-sd-ui-layer-boundary="true" class="toolbar-stuck" style=""><div style="visibility: hidden; overflow: hidden; position: absolute; top: 0px; height: 1px; width: auto; padding: 0px; border: 0px; margin: 0px; text-align: left; text-indent: 0px; text-transform: none; line-height: normal; letter-spacing: normal; word-spacing: normal;"><div id="MathJax_SVG_Hidden"></div><svg><defs id="MathJax_SVG_glyphs"><path stroke-width="1" id="MJMATHI-6D" d="M21 287Q22 293 24 303T36 341T56 388T88 425T132 442T175 435T205 417T221 395T229 376L231 369Q231 367 232 367L243 378Q303 442 384 442Q401 442 415 440T441 433T460 423T475 411T485 398T493 385T497 373T500 364T502 357L510 367Q573 442 659 442Q713 442 746 415T780 336Q780 285 742 178T704 50Q705 36 709 31T724 26Q752 26 776 56T815 138Q818 149 821 151T837 153Q857 153 857 145Q857 144 853 130Q845 101 831 73T785 17T716 -10Q669 -10 648 17T627 73Q627 92 663 193T700 345Q700 404 656 404H651Q565 404 506 303L499 291L466 157Q433 26 428 16Q415 -11 385 -11Q372 -11 364 -4T353 8T350 18Q350 29 384 161L420 307Q423 322 423 345Q423 404 379 404H374Q288 404 229 303L222 291L189 157Q156 26 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 112 181Q151 335 151 342Q154 357 154 369Q154 405 129 405Q107 405 92 377T69 316T57 280Q55 278 41 278H27Q21 284 21 287Z"></path><path stroke-width="1" id="MJMAIN-2212" d="M84 237T84 250T98 270H679Q694 262 694 250T679 230H98Q84 237 84 250Z"></path><path stroke-width="1" id="MJMATHI-6E" d="M21 287Q22 293 24 303T36 341T56 388T89 425T135 442Q171 442 195 424T225 390T231 369Q231 367 232 367L243 378Q304 442 382 442Q436 442 469 415T503 336T465 179T427 52Q427 26 444 26Q450 26 453 27Q482 32 505 65T540 145Q542 153 560 153Q580 153 580 145Q580 144 576 130Q568 101 554 73T508 17T439 -10Q392 -10 371 17T350 73Q350 92 386 193T423 345Q423 404 379 404H374Q288 404 229 303L222 291L189 157Q156 26 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 112 180T152 343Q153 348 153 366Q153 405 129 405Q91 405 66 305Q60 285 60 284Q58 278 41 278H27Q21 284 21 287Z"></path><path stroke-width="1" id="MJMAIN-2B" d="M56 237T56 250T70 270H369V420L370 570Q380 583 389 583Q402 583 409 568V270H707Q722 262 722 250T707 230H409V-68Q401 -82 391 -82H389H387Q375 -82 369 -68V230H70Q56 237 56 250Z"></path><path stroke-width="1" id="MJMAIN-31" d="M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z"></path><path stroke-width="1" id="MJMATHI-74" d="M26 385Q19 392 19 395Q19 399 22 411T27 425Q29 430 36 430T87 431H140L159 511Q162 522 166 540T173 566T179 586T187 603T197 615T211 624T229 626Q247 625 254 615T261 596Q261 589 252 549T232 470L222 433Q222 431 272 431H323Q330 424 330 420Q330 398 317 385H210L174 240Q135 80 135 68Q135 26 162 26Q197 26 230 60T283 144Q285 150 288 151T303 153H307Q322 153 322 145Q322 142 319 133Q314 117 301 95T267 48T216 6T155 -11Q125 -11 98 4T59 56Q57 64 57 83V101L92 241Q127 382 128 383Q128 385 77 385H26Z"></path><path stroke-width="1" id="MJMATHI-77" d="M580 385Q580 406 599 424T641 443Q659 443 674 425T690 368Q690 339 671 253Q656 197 644 161T609 80T554 12T482 -11Q438 -11 404 5T355 48Q354 47 352 44Q311 -11 252 -11Q226 -11 202 -5T155 14T118 53T104 116Q104 170 138 262T173 379Q173 380 173 381Q173 390 173 393T169 400T158 404H154Q131 404 112 385T82 344T65 302T57 280Q55 278 41 278H27Q21 284 21 287Q21 293 29 315T52 366T96 418T161 441Q204 441 227 416T250 358Q250 340 217 250T184 111Q184 65 205 46T258 26Q301 26 334 87L339 96V119Q339 122 339 128T340 136T341 143T342 152T345 165T348 182T354 206T362 238T373 281Q402 395 406 404Q419 431 449 431Q468 431 475 421T483 402Q483 389 454 274T422 142Q420 131 420 107V100Q420 85 423 71T442 42T487 26Q558 26 600 148Q609 171 620 213T632 273Q632 306 619 325T593 357T580 385Z"></path><path stroke-width="1" id="MJMAIN-3D" d="M56 347Q56 360 70 367H707Q722 359 722 347Q722 336 708 328L390 327H72Q56 332 56 347ZM56 153Q56 168 72 173H708Q722 163 722 153Q722 140 707 133H70Q56 140 56 153Z"></path><path stroke-width="1" id="MJMATHI-3B1" d="M34 156Q34 270 120 356T309 442Q379 442 421 402T478 304Q484 275 485 237V208Q534 282 560 374Q564 388 566 390T582 393Q603 393 603 385Q603 376 594 346T558 261T497 161L486 147L487 123Q489 67 495 47T514 26Q528 28 540 37T557 60Q559 67 562 68T577 70Q597 70 597 62Q597 56 591 43Q579 19 556 5T512 -10H505Q438 -10 414 62L411 69L400 61Q390 53 370 41T325 18T267 -2T203 -11Q124 -11 79 39T34 156ZM208 26Q257 26 306 47T379 90L403 112Q401 255 396 290Q382 405 304 405Q235 405 183 332Q156 292 139 224T121 120Q121 71 146 49T208 26Z"></path><path stroke-width="1" id="MJMAIN-2207" d="M46 676Q46 679 51 683H781Q786 679 786 676Q786 674 617 326T444 -26Q439 -33 416 -33T388 -26Q385 -22 216 326T46 676ZM697 596Q697 597 445 597T193 596Q195 591 319 336T445 80L697 596Z"></path><path stroke-width="1" id="MJMATHI-45" d="M492 213Q472 213 472 226Q472 230 477 250T482 285Q482 316 461 323T364 330H312Q311 328 277 192T243 52Q243 48 254 48T334 46Q428 46 458 48T518 61Q567 77 599 117T670 248Q680 270 683 272Q690 274 698 274Q718 274 718 261Q613 7 608 2Q605 0 322 0H133Q31 0 31 11Q31 13 34 25Q38 41 42 43T65 46Q92 46 125 49Q139 52 144 61Q146 66 215 342T285 622Q285 629 281 629Q273 632 228 634H197Q191 640 191 642T193 659Q197 676 203 680H757Q764 676 764 669Q764 664 751 557T737 447Q735 440 717 440H705Q698 445 698 453L701 476Q704 500 704 528Q704 558 697 578T678 609T643 625T596 632T532 634H485Q397 633 392 631Q388 629 386 622Q385 619 355 499T324 377Q347 376 372 376H398Q464 376 489 391T534 472Q538 488 540 490T557 493Q562 493 565 493T570 492T572 491T574 487T577 483L544 351Q511 218 508 216Q505 213 492 213Z"></path><path stroke-width="1" id="MJMAIN-7C" d="M139 -249H137Q125 -249 119 -235V251L120 737Q130 750 139 750Q152 750 159 735V-235Q151 -249 141 -249H139Z"></path><path stroke-width="1" id="MJMATHI-4A" d="M447 625Q447 637 354 637H329Q323 642 323 645T325 664Q329 677 335 683H352Q393 681 498 681Q541 681 568 681T605 682T619 682Q633 682 633 672Q633 670 630 658Q626 642 623 640T604 637Q552 637 545 623Q541 610 483 376Q420 128 419 127Q397 64 333 21T195 -22Q137 -22 97 8T57 88Q57 130 80 152T132 174Q177 174 182 130Q182 98 164 80T123 56Q115 54 115 53T122 44Q148 15 197 15Q235 15 271 47T324 130Q328 142 387 380T447 625Z"></path><path stroke-width="1" id="MJMAIN-28" d="M94 250Q94 319 104 381T127 488T164 576T202 643T244 695T277 729T302 750H315H319Q333 750 333 741Q333 738 316 720T275 667T226 581T184 443T167 250T184 58T225 -81T274 -167T316 -220T333 -241Q333 -250 318 -250H315H302L274 -226Q180 -141 137 -14T94 250Z"></path><path stroke-width="1" id="MJMAIN-29" d="M60 749L64 750Q69 750 74 750H86L114 726Q208 641 251 514T294 250Q294 182 284 119T261 12T224 -76T186 -143T145 -194T113 -227T90 -246Q87 -249 86 -250H74Q66 -250 63 -250T58 -247T55 -238Q56 -237 66 -225Q221 -64 221 250T66 725Q56 737 55 738Q55 746 60 749Z"></path><path stroke-width="1" id="MJMATHI-3BC" d="M58 -216Q44 -216 34 -208T23 -186Q23 -176 96 116T173 414Q186 442 219 442Q231 441 239 435T249 423T251 413Q251 401 220 279T187 142Q185 131 185 107V99Q185 26 252 26Q261 26 270 27T287 31T302 38T315 45T327 55T338 65T348 77T356 88T365 100L372 110L408 253Q444 395 448 404Q461 431 491 431Q504 431 512 424T523 412T525 402L449 84Q448 79 448 68Q448 43 455 35T476 26Q485 27 496 35Q517 55 537 131Q543 151 547 152Q549 153 557 153H561Q580 153 580 144Q580 138 575 117T555 63T523 13Q510 0 491 -8Q483 -10 467 -10Q446 -10 429 -4T402 11T385 29T376 44T374 51L368 45Q362 39 350 30T324 12T288 -4T246 -11Q199 -11 153 12L129 -85Q108 -167 104 -180T92 -202Q76 -216 58 -216Z"></path><path stroke-width="1" id="MJMATHI-76" d="M173 380Q173 405 154 405Q130 405 104 376T61 287Q60 286 59 284T58 281T56 279T53 278T49 278T41 278H27Q21 284 21 287Q21 294 29 316T53 368T97 419T160 441Q202 441 225 417T249 361Q249 344 246 335Q246 329 231 291T200 202T182 113Q182 86 187 69Q200 26 250 26Q287 26 319 60T369 139T398 222T409 277Q409 300 401 317T383 343T365 361T357 383Q357 405 376 424T417 443Q436 443 451 425T467 367Q467 340 455 284T418 159T347 40T241 -11Q177 -11 139 22Q102 54 102 117Q102 148 110 181T151 298Q173 362 173 380Z"></path><path stroke-width="1" id="MJMATHI-79" d="M21 287Q21 301 36 335T84 406T158 442Q199 442 224 419T250 355Q248 336 247 334Q247 331 231 288T198 191T182 105Q182 62 196 45T238 27Q261 27 281 38T312 61T339 94Q339 95 344 114T358 173T377 247Q415 397 419 404Q432 431 462 431Q475 431 483 424T494 412T496 403Q496 390 447 193T391 -23Q363 -106 294 -155T156 -205Q111 -205 77 -183T43 -117Q43 -95 50 -80T69 -58T89 -48T106 -45Q150 -45 150 -87Q150 -107 138 -122T115 -142T102 -147L99 -148Q101 -153 118 -160T152 -167H160Q177 -167 186 -165Q219 -156 247 -127T290 -65T313 -9T321 21L315 17Q309 13 296 6T270 -6Q250 -11 231 -11Q185 -11 150 11T104 82Q103 89 103 113Q103 170 138 262T173 379Q173 380 173 381Q173 390 173 393T169 400T158 404H154Q131 404 112 385T82 344T65 302T57 280Q55 278 41 278H27Q21 284 21 287Z"></path><path stroke-width="1" id="MJMAIN-5E" d="M112 560L249 694L257 686Q387 562 387 560L361 531Q359 532 303 581L250 627L195 580Q182 569 169 557T148 538L140 532Q138 530 125 546L112 560Z"></path><path stroke-width="1" id="MJMAIN-2C6" d="M112 560L249 694L257 686Q387 562 387 560L361 531Q359 532 303 581L250 627L195 580Q182 569 169 557T148 538L140 532Q138 530 125 546L112 560Z"></path><path stroke-width="1" id="MJSZ1-2211" d="M61 748Q64 750 489 750H913L954 640Q965 609 976 579T993 533T999 516H979L959 517Q936 579 886 621T777 682Q724 700 655 705T436 710H319Q183 710 183 709Q186 706 348 484T511 259Q517 250 513 244L490 216Q466 188 420 134T330 27L149 -187Q149 -188 362 -188Q388 -188 436 -188T506 -189Q679 -189 778 -162T936 -43Q946 -27 959 6H999L913 -249L489 -250Q65 -250 62 -248Q56 -246 56 -239Q56 -234 118 -161Q186 -81 245 -11L428 206Q428 207 242 462L57 717L56 728Q56 744 61 748Z"></path><path stroke-width="1" id="MJMATHI-4E" d="M234 637Q231 637 226 637Q201 637 196 638T191 649Q191 676 202 682Q204 683 299 683Q376 683 387 683T401 677Q612 181 616 168L670 381Q723 592 723 606Q723 633 659 637Q635 637 635 648Q635 650 637 660Q641 676 643 679T653 683Q656 683 684 682T767 680Q817 680 843 681T873 682Q888 682 888 672Q888 650 880 642Q878 637 858 637Q787 633 769 597L620 7Q618 0 599 0Q585 0 582 2Q579 5 453 305L326 604L261 344Q196 88 196 79Q201 46 268 46H278Q284 41 284 38T282 19Q278 6 272 0H259Q228 2 151 2Q123 2 100 2T63 2T46 1Q31 1 31 10Q31 14 34 26T39 40Q41 46 62 46Q130 49 150 85Q154 91 221 362L289 634Q287 635 234 637Z"></path><path stroke-width="1" id="MJMAIN-32" d="M109 429Q82 429 66 447T50 491Q50 562 103 614T235 666Q326 666 387 610T449 465Q449 422 429 383T381 315T301 241Q265 210 201 149L142 93L218 92Q375 92 385 97Q392 99 409 186V189H449V186Q448 183 436 95T421 3V0H50V19V31Q50 38 56 46T86 81Q115 113 136 137Q145 147 170 174T204 211T233 244T261 278T284 308T305 340T320 369T333 401T340 431T343 464Q343 527 309 573T212 619Q179 619 154 602T119 569T109 550Q109 549 114 549Q132 549 151 535T170 489Q170 464 154 447T109 429Z"></path><path stroke-width="1" id="MJMATHI-3BB" d="M166 673Q166 685 183 694H202Q292 691 316 644Q322 629 373 486T474 207T524 67Q531 47 537 34T546 15T551 6T555 2T556 -2T550 -11H482Q457 3 450 18T399 152L354 277L340 262Q327 246 293 207T236 141Q211 112 174 69Q123 9 111 -1T83 -12Q47 -12 47 20Q47 37 61 52T199 187Q229 216 266 252T321 306L338 322Q338 323 288 462T234 612Q214 657 183 657Q166 657 166 673Z"></path><path stroke-width="1" id="MJMATHI-4C" d="M228 637Q194 637 192 641Q191 643 191 649Q191 673 202 682Q204 683 217 683Q271 680 344 680Q485 680 506 683H518Q524 677 524 674T522 656Q517 641 513 637H475Q406 636 394 628Q387 624 380 600T313 336Q297 271 279 198T252 88L243 52Q243 48 252 48T311 46H328Q360 46 379 47T428 54T478 72T522 106T564 161Q580 191 594 228T611 270Q616 273 628 273H641Q647 264 647 262T627 203T583 83T557 9Q555 4 553 3T537 0T494 -1Q483 -1 418 -1T294 0H116Q32 0 32 10Q32 17 34 24Q39 43 44 45Q48 46 59 46H65Q92 46 125 49Q139 52 144 61Q147 65 216 339T285 628Q285 635 228 637Z"></path><path stroke-width="1" id="MJMATHI-6C" d="M117 59Q117 26 142 26Q179 26 205 131Q211 151 215 152Q217 153 225 153H229Q238 153 241 153T246 151T248 144Q247 138 245 128T234 90T214 43T183 6T137 -11Q101 -11 70 11T38 85Q38 97 39 102L104 360Q167 615 167 623Q167 626 166 628T162 632T157 634T149 635T141 636T132 637T122 637Q112 637 109 637T101 638T95 641T94 647Q94 649 96 661Q101 680 107 682T179 688Q194 689 213 690T243 693T254 694Q266 694 266 686Q266 675 193 386T118 83Q118 81 118 75T117 65V59Z"></path><path stroke-width="1" id="MJMATHI-70" d="M23 287Q24 290 25 295T30 317T40 348T55 381T75 411T101 433T134 442Q209 442 230 378L240 387Q302 442 358 442Q423 442 460 395T497 281Q497 173 421 82T249 -10Q227 -10 210 -4Q199 1 187 11T168 28L161 36Q160 35 139 -51T118 -138Q118 -144 126 -145T163 -148H188Q194 -155 194 -157T191 -175Q188 -187 185 -190T172 -194Q170 -194 161 -194T127 -193T65 -192Q-5 -192 -24 -194H-32Q-39 -187 -39 -183Q-37 -156 -26 -148H-6Q28 -147 33 -136Q36 -130 94 103T155 350Q156 355 156 364Q156 405 131 405Q109 405 94 377T71 316T59 280Q57 278 43 278H29Q23 284 23 287ZM178 102Q200 26 252 26Q282 26 310 49T356 107Q374 141 392 215T411 325V331Q411 405 350 405Q339 405 328 402T306 393T286 380T269 365T254 350T243 336T235 326L232 322Q232 321 229 308T218 264T204 212Q178 106 178 102Z"></path><path stroke-width="1" id="MJMAIN-2DC" d="M179 601Q164 601 151 595T131 584T111 565L97 577L83 588Q83 589 95 603T121 633T142 654Q165 668 187 668T253 650T320 632Q335 632 348 638T368 649T388 668L402 656L416 645Q375 586 344 572Q330 565 313 565Q292 565 248 583T179 601Z"></path><path stroke-width="1" id="MJMATHI-72" d="M21 287Q22 290 23 295T28 317T38 348T53 381T73 411T99 433T132 442Q161 442 183 430T214 408T225 388Q227 382 228 382T236 389Q284 441 347 441H350Q398 441 422 400Q430 381 430 363Q430 333 417 315T391 292T366 288Q346 288 334 299T322 328Q322 376 378 392Q356 405 342 405Q286 405 239 331Q229 315 224 298T190 165Q156 25 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 114 189T154 366Q154 405 128 405Q107 405 92 377T68 316T57 280Q55 278 41 278H27Q21 284 21 287Z"></path><path stroke-width="1" id="MJMAIN-223C" d="M55 166Q55 241 101 304T222 367Q260 367 296 349T362 304T421 252T484 208T554 189Q616 189 655 236T694 338Q694 350 698 358T708 367Q722 367 722 334Q722 260 677 197T562 134H554Q517 134 481 152T414 196T355 248T292 293T223 311Q179 311 145 286Q109 257 96 218T80 156T69 133Q55 133 55 166Z"></path><path stroke-width="1" id="MJMATHI-42" d="M231 637Q204 637 199 638T194 649Q194 676 205 682Q206 683 335 683Q594 683 608 681Q671 671 713 636T756 544Q756 480 698 429T565 360L555 357Q619 348 660 311T702 219Q702 146 630 78T453 1Q446 0 242 0Q42 0 39 2Q35 5 35 10Q35 17 37 24Q42 43 47 45Q51 46 62 46H68Q95 46 128 49Q142 52 147 61Q150 65 219 339T288 628Q288 635 231 637ZM649 544Q649 574 634 600T585 634Q578 636 493 637Q473 637 451 637T416 636H403Q388 635 384 626Q382 622 352 506Q352 503 351 500L320 374H401Q482 374 494 376Q554 386 601 434T649 544ZM595 229Q595 273 572 302T512 336Q506 337 429 337Q311 337 310 336Q310 334 293 263T258 122L240 52Q240 48 252 48T333 46Q422 46 429 47Q491 54 543 105T595 229Z"></path><path stroke-width="1" id="MJMATHI-65" d="M39 168Q39 225 58 272T107 350T174 402T244 433T307 442H310Q355 442 388 420T421 355Q421 265 310 237Q261 224 176 223Q139 223 138 221Q138 219 132 186T125 128Q125 81 146 54T209 26T302 45T394 111Q403 121 406 121Q410 121 419 112T429 98T420 82T390 55T344 24T281 -1T205 -11Q126 -11 83 42T39 168ZM373 353Q367 405 305 405Q272 405 244 391T199 357T170 316T154 280T149 261Q149 260 169 260Q282 260 327 284T373 353Z"></path><path stroke-width="1" id="MJMATHI-6F" d="M201 -11Q126 -11 80 38T34 156Q34 221 64 279T146 380Q222 441 301 441Q333 441 341 440Q354 437 367 433T402 417T438 387T464 338T476 268Q476 161 390 75T201 -11ZM121 120Q121 70 147 48T206 26Q250 26 289 58T351 142Q360 163 374 216T388 308Q388 352 370 375Q346 405 306 405Q243 405 195 347Q158 303 140 230T121 120Z"></path><path stroke-width="1" id="MJMATHI-75" d="M21 287Q21 295 30 318T55 370T99 420T158 442Q204 442 227 417T250 358Q250 340 216 246T182 105Q182 62 196 45T238 27T291 44T328 78L339 95Q341 99 377 247Q407 367 413 387T427 416Q444 431 463 431Q480 431 488 421T496 402L420 84Q419 79 419 68Q419 43 426 35T447 26Q469 29 482 57T512 145Q514 153 532 153Q551 153 551 144Q550 139 549 130T540 98T523 55T498 17T462 -8Q454 -10 438 -10Q372 -10 347 46Q345 45 336 36T318 21T296 6T267 -6T233 -11Q189 -11 155 7Q103 38 103 113Q103 170 138 262T173 379Q173 380 173 381Q173 390 173 393T169 400T158 404H154Q131 404 112 385T82 344T65 302T57 280Q55 278 41 278H27Q21 284 21 287Z"></path><path stroke-width="1" id="MJMATHI-69" d="M184 600Q184 624 203 642T247 661Q265 661 277 649T290 619Q290 596 270 577T226 557Q211 557 198 567T184 600ZM21 287Q21 295 30 318T54 369T98 420T158 442Q197 442 223 419T250 357Q250 340 236 301T196 196T154 83Q149 61 149 51Q149 26 166 26Q175 26 185 29T208 43T235 78T260 137Q263 149 265 151T282 153Q302 153 302 143Q302 135 293 112T268 61T223 11T161 -11Q129 -11 102 10T74 74Q74 91 79 106T122 220Q160 321 166 341T173 380Q173 404 156 404H154Q124 404 99 371T61 287Q60 286 59 284T58 281T56 279T53 278T49 278T41 278H27Q21 284 21 287Z"></path><path stroke-width="1" id="MJMAIN-2218" d="M55 251Q55 328 112 386T249 444T386 388T444 249Q444 171 388 113T250 55Q170 55 113 112T55 251ZM245 403Q188 403 142 361T96 250Q96 183 141 140T250 96Q284 96 313 109T354 135T375 160Q403 197 403 250Q403 313 360 358T245 403Z"></path><path stroke-width="1" id="MJMAIN-30" d="M96 585Q152 666 249 666Q297 666 345 640T423 548Q460 465 460 320Q460 165 417 83Q397 41 362 16T301 -15T250 -22Q224 -22 198 -16T137 16T82 83Q39 165 39 320Q39 494 96 585ZM321 597Q291 629 250 629Q208 629 178 597Q153 571 145 525T137 333Q137 175 145 125T181 46Q209 16 250 16Q290 16 318 46Q347 76 354 130T362 333Q362 478 354 524T321 597Z"></path><path stroke-width="1" id="MJMAIN-2E" d="M78 60Q78 84 95 102T138 120Q162 120 180 104T199 61Q199 36 182 18T139 0T96 17T78 60Z"></path><path stroke-width="1" id="MJMAIN-35" d="M164 157Q164 133 148 117T109 101H102Q148 22 224 22Q294 22 326 82Q345 115 345 210Q345 313 318 349Q292 382 260 382H254Q176 382 136 314Q132 307 129 306T114 304Q97 304 95 310Q93 314 93 485V614Q93 664 98 664Q100 666 102 666Q103 666 123 658T178 642T253 634Q324 634 389 662Q397 666 402 666Q410 666 410 648V635Q328 538 205 538Q174 538 149 544L139 546V374Q158 388 169 396T205 412T256 420Q337 420 393 355T449 201Q449 109 385 44T229 -22Q148 -22 99 32T50 154Q50 178 61 192T84 210T107 214Q132 214 148 197T164 157Z"></path><path stroke-width="1" id="MJMATHI-47" d="M50 252Q50 367 117 473T286 641T490 704Q580 704 633 653Q642 643 648 636T656 626L657 623Q660 623 684 649Q691 655 699 663T715 679T725 690L740 705H746Q760 705 760 698Q760 694 728 561Q692 422 692 421Q690 416 687 415T669 413H653Q647 419 647 422Q647 423 648 429T650 449T651 481Q651 552 619 605T510 659Q492 659 471 656T418 643T357 615T294 567T236 496T189 394T158 260Q156 242 156 221Q156 173 170 136T206 79T256 45T308 28T353 24Q407 24 452 47T514 106Q517 114 529 161T541 214Q541 222 528 224T468 227H431Q425 233 425 235T427 254Q431 267 437 273H454Q494 271 594 271Q634 271 659 271T695 272T707 272Q721 272 721 263Q721 261 719 249Q714 230 709 228Q706 227 694 227Q674 227 653 224Q646 221 643 215T629 164Q620 131 614 108Q589 6 586 3Q584 1 581 1Q571 1 553 21T530 52Q530 53 528 52T522 47Q448 -22 322 -22Q201 -22 126 55T50 252Z"></path><path stroke-width="1" id="MJMATHI-3F5" d="M227 -11Q149 -11 95 41T40 174Q40 262 87 322Q121 367 173 396T287 430Q289 431 329 431H367Q382 426 382 411Q382 385 341 385H325H312Q191 385 154 277L150 265H327Q340 256 340 246Q340 228 320 219H138V217Q128 187 128 143Q128 77 160 52T231 26Q258 26 284 36T326 57T343 68Q350 68 354 58T358 39Q358 36 357 35Q354 31 337 21T289 0T227 -11Z"></path><path stroke-width="1" id="MJSZ1-221A" d="M263 249Q264 249 315 130T417 -108T470 -228L725 302Q981 837 982 839Q989 850 1001 850Q1008 850 1013 844T1020 832V826L741 243Q645 43 540 -176Q479 -303 469 -324T453 -348Q449 -350 436 -350L424 -349L315 -96Q206 156 205 156L171 130Q138 104 137 104L111 130L263 249Z"></path><path stroke-width="1" id="MJMAIN-2299" d="M56 250Q56 394 156 488T384 583Q530 583 626 485T722 250Q722 110 625 14T390 -83Q249 -83 153 14T56 250ZM682 250Q682 322 649 387T546 497T381 542Q272 542 184 459T95 250Q95 132 178 45T389 -42Q515 -42 598 45T682 250ZM311 250Q311 285 332 304T375 328Q376 328 382 328T392 329Q424 326 445 305T466 250Q466 217 445 195T389 172Q354 172 333 195T311 250Z"></path><path stroke-width="1" id="MJMATHI-67" d="M311 43Q296 30 267 15T206 0Q143 0 105 45T66 160Q66 265 143 353T314 442Q361 442 401 394L404 398Q406 401 409 404T418 412T431 419T447 422Q461 422 470 413T480 394Q480 379 423 152T363 -80Q345 -134 286 -169T151 -205Q10 -205 10 -137Q10 -111 28 -91T74 -71Q89 -71 102 -80T116 -111Q116 -121 114 -130T107 -144T99 -154T92 -162L90 -164H91Q101 -167 151 -167Q189 -167 211 -155Q234 -144 254 -122T282 -75Q288 -56 298 -13Q311 35 311 43ZM384 328L380 339Q377 350 375 354T369 368T359 382T346 393T328 402T306 405Q262 405 221 352Q191 313 171 233T151 117Q151 38 213 38Q269 38 323 108L331 118L384 328Z"></path><path stroke-width="1" id="MJMAIN-5B" d="M118 -250V750H255V710H158V-210H255V-250H118Z"></path><path stroke-width="1" id="MJMAIN-5D" d="M22 710V750H159V-250H22V-210H119V710H22Z"></path><path stroke-width="1" id="MJSZ2-221A" d="M1001 1150Q1017 1150 1020 1132Q1020 1127 741 244L460 -643Q453 -650 436 -650H424Q423 -647 423 -645T421 -640T419 -631T415 -617T408 -594T399 -560T385 -512T367 -448T343 -364T312 -259L203 119L138 41L111 67L212 188L264 248L472 -474L983 1140Q988 1150 1001 1150Z"></path><path stroke-width="1" id="MJSZ1-5B" d="M202 -349V850H394V810H242V-309H394V-349H202Z"></path><path stroke-width="1" id="MJSZ1-5D" d="M22 810V850H214V-349H22V-309H174V810H22Z"></path><path stroke-width="1" id="MJMATHI-3B3" d="M31 249Q11 249 11 258Q11 275 26 304T66 365T129 418T206 441Q233 441 239 440Q287 429 318 386T371 255Q385 195 385 170Q385 166 386 166L398 193Q418 244 443 300T486 391T508 430Q510 431 524 431H537Q543 425 543 422Q543 418 522 378T463 251T391 71Q385 55 378 6T357 -100Q341 -165 330 -190T303 -216Q286 -216 286 -188Q286 -138 340 32L346 51L347 69Q348 79 348 100Q348 257 291 317Q251 355 196 355Q148 355 108 329T51 260Q49 251 47 251Q45 249 31 249Z"></path><path stroke-width="1" id="MJMAIN-39" d="M352 287Q304 211 232 211Q154 211 104 270T44 396Q42 412 42 436V444Q42 537 111 606Q171 666 243 666Q245 666 249 666T257 665H261Q273 665 286 663T323 651T370 619T413 560Q456 472 456 334Q456 194 396 97Q361 41 312 10T208 -22Q147 -22 108 7T68 93T121 149Q143 149 158 135T173 96Q173 78 164 65T148 49T135 44L131 43Q131 41 138 37T164 27T206 22H212Q272 22 313 86Q352 142 352 280V287ZM244 248Q292 248 321 297T351 430Q351 508 343 542Q341 552 337 562T323 588T293 615T246 625Q208 625 181 598Q160 576 154 546T147 441Q147 358 152 329T172 282Q197 248 244 248Z"></path><path stroke-width="1" id="MJMAIN-221A" d="M95 178Q89 178 81 186T72 200T103 230T169 280T207 309Q209 311 212 311H213Q219 311 227 294T281 177Q300 134 312 108L397 -77Q398 -77 501 136T707 565T814 786Q820 800 834 800Q841 800 846 794T853 782V776L620 293L385 -193Q381 -200 366 -200Q357 -200 354 -197Q352 -195 256 15L160 225L144 214Q129 202 113 190T95 178Z"></path><path stroke-width="1" id="MJMATHI-3B2" d="M29 -194Q23 -188 23 -186Q23 -183 102 134T186 465Q208 533 243 584T309 658Q365 705 429 705H431Q493 705 533 667T573 570Q573 465 469 396L482 383Q533 332 533 252Q533 139 448 65T257 -10Q227 -10 203 -2T165 17T143 40T131 59T126 65L62 -188Q60 -194 42 -194H29ZM353 431Q392 431 427 419L432 422Q436 426 439 429T449 439T461 453T472 471T484 495T493 524T501 560Q503 569 503 593Q503 611 502 616Q487 667 426 667Q384 667 347 643T286 582T247 514T224 455Q219 439 186 308T152 168Q151 163 151 147Q151 99 173 68Q204 26 260 26Q302 26 349 51T425 137Q441 171 449 214T457 279Q457 337 422 372Q380 358 347 358H337Q258 358 258 389Q258 396 261 403Q275 431 353 431Z"></path><path stroke-width="1" id="MJMAIN-2C" d="M78 35T78 60T94 103T137 121Q165 121 187 96T210 8Q210 -27 201 -60T180 -117T154 -158T130 -185T117 -194Q113 -194 104 -185T95 -172Q95 -168 106 -156T131 -126T157 -76T173 -3V9L172 8Q170 7 167 6T161 3T152 1T140 0Q113 0 96 17Z"></path><path stroke-width="1" id="MJMAIN-D7" d="M630 29Q630 9 609 9Q604 9 587 25T493 118L389 222L284 117Q178 13 175 11Q171 9 168 9Q160 9 154 15T147 29Q147 36 161 51T255 146L359 250L255 354Q174 435 161 449T147 471Q147 480 153 485T168 490Q173 490 175 489Q178 487 284 383L389 278L493 382Q570 459 587 475T609 491Q630 491 630 471Q630 464 620 453T522 355L418 250L522 145Q606 61 618 48T630 29Z"></path><path stroke-width="1" id="MJMAIN-34" d="M462 0Q444 3 333 3Q217 3 199 0H190V46H221Q241 46 248 46T265 48T279 53T286 61Q287 63 287 115V165H28V211L179 442Q332 674 334 675Q336 677 355 677H373L379 671V211H471V165H379V114Q379 73 379 66T385 54Q393 47 442 46H471V0H462ZM293 211V545L74 212L183 211H293Z"></path><path stroke-width="1" id="MJMATHI-3C3" d="M184 -11Q116 -11 74 34T31 147Q31 247 104 333T274 430Q275 431 414 431H552Q553 430 555 429T559 427T562 425T565 422T567 420T569 416T570 412T571 407T572 401Q572 357 507 357Q500 357 490 357T476 358H416L421 348Q439 310 439 263Q439 153 359 71T184 -11ZM361 278Q361 358 276 358Q152 358 115 184Q114 180 114 178Q106 141 106 117Q106 67 131 47T188 26Q242 26 287 73Q316 103 334 153T356 233T361 278Z"></path><path stroke-width="1" id="MJMAIN-38" d="M70 417T70 494T124 618T248 666Q319 666 374 624T429 515Q429 485 418 459T392 417T361 389T335 371T324 363L338 354Q352 344 366 334T382 323Q457 264 457 174Q457 95 399 37T249 -22Q159 -22 101 29T43 155Q43 263 172 335L154 348Q133 361 127 368Q70 417 70 494ZM286 386L292 390Q298 394 301 396T311 403T323 413T334 425T345 438T355 454T364 471T369 491T371 513Q371 556 342 586T275 624Q268 625 242 625Q201 625 165 599T128 534Q128 511 141 492T167 463T217 431Q224 426 228 424L286 386ZM250 21Q308 21 350 55T392 137Q392 154 387 169T375 194T353 216T330 234T301 253T274 270Q260 279 244 289T218 306L210 311Q204 311 181 294T133 239T107 157Q107 98 150 60T250 21Z"></path><path stroke-width="1" id="MJMAIN-B1" d="M56 320T56 333T70 353H369V502Q369 651 371 655Q376 666 388 666Q402 666 405 654T409 596V500V353H707Q722 345 722 333Q722 320 707 313H409V40H707Q722 32 722 20T707 0H70Q56 7 56 20T70 40H369V313H70Q56 320 56 333Z"></path><path stroke-width="1" id="MJMAIN-33" d="M127 463Q100 463 85 480T69 524Q69 579 117 622T233 665Q268 665 277 664Q351 652 390 611T430 522Q430 470 396 421T302 350L299 348Q299 347 308 345T337 336T375 315Q457 262 457 175Q457 96 395 37T238 -22Q158 -22 100 21T42 130Q42 158 60 175T105 193Q133 193 151 175T169 130Q169 119 166 110T159 94T148 82T136 74T126 70T118 67L114 66Q165 21 238 21Q293 21 321 74Q338 107 338 175V195Q338 290 274 322Q259 328 213 329L171 330L168 332Q166 335 166 348Q166 366 174 366Q202 366 232 371Q266 376 294 413T322 525V533Q322 590 287 612Q265 626 240 626Q208 626 181 615T143 592T132 580H135Q138 579 143 578T153 573T165 566T175 555T183 540T186 520Q186 498 172 481T127 463Z"></path><path stroke-width="1" id="MJMAIN-36" d="M42 313Q42 476 123 571T303 666Q372 666 402 630T432 550Q432 525 418 510T379 495Q356 495 341 509T326 548Q326 592 373 601Q351 623 311 626Q240 626 194 566Q147 500 147 364L148 360Q153 366 156 373Q197 433 263 433H267Q313 433 348 414Q372 400 396 374T435 317Q456 268 456 210V192Q456 169 451 149Q440 90 387 34T253 -22Q225 -22 199 -14T143 16T92 75T56 172T42 313ZM257 397Q227 397 205 380T171 335T154 278T148 216Q148 133 160 97T198 39Q222 21 251 21Q302 21 329 59Q342 77 347 104T352 209Q352 289 347 316T329 361Q302 397 257 397Z"></path></defs></svg></div><div id="MathJax_Message" style="display: none;"></div>
      <script type="text/javascript">
        window.__PRELOADED_STATE__ = {"abstracts":{"content":[{"$$":[{"$":{"id":"sectt0001"},"#name":"section-title","_":"Highlights"},{"$$":[{"$$":[{"$$":[{"$$":[{"#name":"label","_":"•"},{"$":{"view":"all","id":"para0001"},"#name":"para","_":"A convolutional neural network approach for head pose estimation is proposed."}],"$":{"id":"celistitem0001"},"#name":"list-item"},{"$$":[{"#name":"label","_":"•"},{"$":{"view":"all","id":"para0002"},"#name":"para","_":"The performance of different network architectures has been measured."}],"$":{"id":"celistitem0002"},"#name":"list-item"},{"$$":[{"#name":"label","_":"•"},{"$":{"view":"all","id":"para0003"},"#name":"para","_":"The use of adaptive gradient methods leads to the state-of-the-art in wild datasets."}],"$":{"id":"celistitem0003"},"#name":"list-item"},{"$$":[{"#name":"label","_":"•"},{"$":{"view":"all","id":"para0004"},"#name":"para","_":"We release a library based on our work which is available under open source licence."}],"$":{"id":"celistitem0004"},"#name":"list-item"}],"$":{"id":"celist0004"},"#name":"list"}],"$":{"view":"all","id":"spara0003"},"#name":"simple-para"}],"$":{"view":"all","id":"abssec0001"},"#name":"abstract-sec"}],"$":{"view":"all","id":"absh001","class":"author-highlights"},"#name":"abstract"},{"$$":[{"$":{"id":"sectt0002"},"#name":"section-title","_":"Abstract"},{"$$":[{"$":{"view":"all","id":"spara0004"},"#name":"simple-para","_":"Head pose estimation is an old problem that is recently receiving new attention because of possible applications in human-robot interaction, augmented reality and driving assistance. However, most of the existing work has been tested in controlled environments and is not robust enough for real-world applications. In order to handle these limitations we propose an approach based on Convolutional Neural Networks (CNNs) supplemented with the most recent techniques adopted from the deep learning community. We evaluate the performance of four architectures on recently released in-the-wild datasets. Moreover, we investigate the use of dropout and adaptive gradient methods giving a contribution to their ongoing validation. The results show that joining CNNs and adaptive gradient methods leads to the state-of-the-art in unconstrained head pose estimation."}],"$":{"view":"all","id":"abssec0002"},"#name":"abstract-sec"}],"$":{"view":"all","id":"abs0001","class":"author"},"#name":"abstract"}],"floats":[],"footnotes":[],"attachments":[]},"accessbarConfig":{"fallback":false,"id":"accessbar","version":"0.0.1","analytics":{"location":"accessbar","eventName":"ctaImpression"},"label":{},"ariaLabel":{"accessbar":"Download options and search","componentsList":"PDF Options"},"banner":{"id":"Banner"},"banners":[{"id":"Banner"},{"id":"BannerSsrn"}],"components":[{"target":"_blank","analytics":[{"ids":["accessbar:fta:single-article"],"eventName":"ctaClick"}],"label":"View&nbsp;**PDF**","ariaLabel":"View PDF. Opens in a new window.","id":"ViewPDF"},{"analytics":[{"ids":["accessbar:fta:full-issue"],"eventName":"ctaClick"}],"label":"Download full issue","id":"DownloadFullIssue"},{"target":"_blank","analytics":[{"ids":["accessbar:article:chorus-am"],"eventName":"ctaClick"}],"label":"View Open Manuscript","href":"/science/article/am/pii/S0031320317302327","id":"OpenManuscript"}],"search":{"inputPlaceHolder":"Search ScienceDirect","ariaLabel":{"input":"Search ScienceDirect","submit":"Submit search"},"formAction":"/search#submit","analytics":[{"ids":["accessbar:search"],"eventName":"searchStart"}],"id":"QuickSearch"}},"adobeTarget":{"sd:genai-question-and-answer":{}},"article":{"analyticsMetadata":{"accountId":"50401","accountName":"IT University of Copenhagen","loginStatus":"logged in","userId":"71970787","isLoggedIn":true},"cid":"272206","content-family":"serial","copyright-line":"© 2017 Elsevier Ltd. All rights reserved.","cover-date-years":["2017"],"cover-date-start":"2017-11-01","cover-date-text":"November 2017","document-subtype":"fla","document-type":"article","entitledToken":"494015495801530BC08AB2DC0B2FBCBE6276572C028AA4FF8752F1D90F408BE025986401A866B70F","genAiToken":"eyJ0eXAiOiJKV1QiLCJhbGciOiJIUzI1NiJ9.eyJhdWQiOiJnZW5BaUFwcHMiLCJzdWIiOiI1MDQwMSIsInBpaSI6IlMwMDMxMzIwMzE3MzAyMzI3IiwiaXNzIjoiYXJwIiwic2Vzc2lvbklkIjoiNWUwYThhMzI3ZjI3YTA0OGE4NWIyM2E2YTM3MTU2NmQ2OThkZ3hycWEiLCJleHAiOjE3MzAyMDU3MDYsImlhdCI6MTczMDIwMzkwNiwidmVyc2lvbiI6MSwianRpIjoiMDJhNjU5YzEtZDdmMi00NGE3LThkODAtMTBiNTEzY2IzM2RmIn0.NyIY6s0VMFQv9ut4ThRsHKp1WUdR56Ei8NUwBwV5i-k","eid":"1-s2.0-S0031320317302327","doi":"10.1016/j.patcog.2017.06.009","first-fp":"132","hub-eid":"1-s2.0-S0031320317X00071","issuePii":"S0031320317X00071","item-weight":"FULL-TEXT","language":"en","last-lp":"143","last-author":{"#name":"last-author","$":{"xmlns:ce":true,"xmlns:dm":true,"xmlns:sb":true},"$$":[{"#name":"author","$":{"id":"au0002","biographyid":"b2","author-id":"S0031320317302327-29076a84ddc556b582ab88e9babd0c32"},"$$":[{"#name":"given-name","_":"Angelo"},{"#name":"surname","_":"Cangelosi"}]}]},"normalized-first-auth-initial":"M","normalized-first-auth-surname":"PATACCHIOLA","open-research":{"#name":"open-research","$":{"xmlns:xocs":true},"$$":[{"#name":"or-agreements","$$":[{"#name":"or-agreement","$$":[{"#name":"or-agreement-id","_":"https://vtw.elsevier.com/content/oragreement/10130"},{"#name":"or-agreement-name","_":"CHU_DOD"},{"#name":"or-agreement-terms","_":"publishAcceptedManuscriptIndexable"}]}]},{"#name":"or-embargo-opening-date","_":"2018-06-10T00:00:00Z"},{"#name":"or-agreement-license","_":"http://www.elsevier.com/open-access/userlicense/1.0/"}]},"pages":[{"last-page":"143","first-page":"132"}],"pii":"S0031320317302327","self-archiving":{"#name":"self-archiving","$":{"xmlns:xocs":true},"$$":[{"#name":"sa-start-date","_":"2018-06-10T00:00:00Z"},{"#name":"sa-user-license","_":"http://creativecommons.org/licenses/by-nc-nd/4.0/"}]},"srctitle":"Pattern Recognition","suppl":"C","timestamp":"2024-04-05T03:18:55.488823Z","title":{"content":[{"#name":"title","$":{"id":"ct0001"},"_":"Head pose estimation in the wild using Convolutional Neural Networks and adaptive gradient methods"}],"floats":[],"footnotes":[],"attachments":[]},"vol-first":"71","vol-iss-suppl-text":"Volume 71","userSettings":{"forceAbstract":false,"creditCardPurchaseAllowed":true,"blockFullTextForAnonymousAccess":false,"disableWholeIssueDownload":false,"preventTransactionalAccess":false,"preventDocumentDelivery":true},"contentType":"JL","crossmark":true,"document-references":47,"freeHtmlGiven":false,"userProfile":{"departmentName":"Library","webUserId":"71970787","accountName":"IT University of Copenhagen","shibProfile":{"canRegister":false},"departmentId":"71310","hasMultipleOrganizations":false,"accountNumber":"C000050401","userName":"Gergo Gyori","supportUserData":"xyhJEXWoHAMsz8VQOu3h2LHHIekBL3hT38urfpOCxeAty3TF61ibE7vsQPaZh4C6srqm9MNOxus2v65ykDkikA4MoWWax9xsxmy7qS6Jhq1MDk8fC~ZGE1crT~IU0fB88KgH29YS658ka3vhWTqW3QsF38M7JrWC3EPvnlMgTGg39gl1xRqh4DNloSU9hGNUBWmK_Teu~5LuRZ6Al86jUzFxO7CiLa3WIvaVAP5f3g900Gfh5TZfq33GuKqA9hfimBRbW0fFzY3a21RwOu4PLgTJkGu8dMJdwZTxXGeKI1g*","accessType":"SHIBREG","accountId":"50401","userType":"NORMAL","privilegeType":"BASIC","email":"gegy@itu.dk"},"access":{"openAccess":false,"openArchive":false},"aipType":"none","articleEntitlement":{"authenticationMethod":"SHIBBOLETH","entitled":true,"isCasaUser":false,"usageInfo":"(71970787,U|71310,D|50401,A|26,S|34,P|2,PL)(SDFE,CON|5e0a8a327f27a048a85b23a6a371566d698dgxrqa,SSO|REG_SHIBBOLETH,ACCESS_TYPE)","entitledByAccount":false},"crawlerInformation":{"canCrawlPDFContent":false,"isCrawler":false},"dates":{"Available online":"3 June 2017","Received":"11 September 2016","Revised":["28 March 2017"],"Accepted":"1 June 2017","Publication date":"1 November 2017","Version of Record":"10 June 2017"},"downloadFullIssue":true,"entitlementReason":"package","hasBody":true,"has-large-authors":false,"hasScholarlyAbstract":true,"headerConfig":{"helpUrl":"https://service.elsevier.com/ci/pta/login/redirect/home/supporthub/sciencedirect/p_li/xyhJEXWoHAMsz8VQOu3h2LHHIekBL3hT38urfpOCxeAty3TF61ibE7vsQPaZh4C6srqm9MNOxus2v65ykDkikA4MoWWax9xsxmy7qS6Jhq1MDk8fC~ZGE1crT~IU0fB88KgH29YS658ka3vhWTqW3QsF38M7JrWC3EPvnlMgTGg39gl1xRqh4DNloSU9hGNUBWmK_Teu~5LuRZ6Al86jUzFxO7CiLa3WIvaVAP5f3g900Gfh5TZfq33GuKqA9hfimBRbW0fFzY3a21RwOu4PLgTJkGu8dMJdwZTxXGeKI1g*","contactUrl":"https://service.elsevier.com/ci/pta/login/redirect/contact/supporthub/sciencedirect/p_li/xyhJEXWoHAMsz8VQOu3h2LHHIekBL3hT38urfpOCxeAty3TF61ibE7vsQPaZh4C6srqm9MNOxus2v65ykDkikA4MoWWax9xsxmy7qS6Jhq1MDk8fC~ZGE1crT~IU0fB88KgH29YS658ka3vhWTqW3QsF38M7JrWC3EPvnlMgTGg39gl1xRqh4DNloSU9hGNUBWmK_Teu~5LuRZ6Al86jUzFxO7CiLa3WIvaVAP5f3g900Gfh5TZfq33GuKqA9hfimBRbW0fFzY3a21RwOu4PLgTJkGu8dMJdwZTxXGeKI1g*","userName":"Gergo Gyori","userEmail":"gegy@itu.dk","orgName":"IT University of Copenhagen","webUserId":"71970787","libraryBanner":null,"shib_regUrl":"","tick_regUrl":"","recentInstitutions":[],"canActivatePersonalization":false,"hasInstitutionalAssociation":true,"hasMultiOrg":false,"userType":"SHIBREG","userAnonymity":"INDIVIDUAL","allowCart":true,"environment":"prod","cdnAssetsHost":"https://sdfestaticassets-eu-west-1.sciencedirectassets.com","supportUserData":"xyhJEXWoHAMsz8VQOu3h2LHHIekBL3hT38urfpOCxeAty3TF61ibE7vsQPaZh4C6srqm9MNOxus2v65ykDkikA4MoWWax9xsxmy7qS6Jhq1MDk8fC~ZGE1crT~IU0fB88KgH29YS658ka3vhWTqW3QsF38M7JrWC3EPvnlMgTGg39gl1xRqh4DNloSU9hGNUBWmK_Teu~5LuRZ6Al86jUzFxO7CiLa3WIvaVAP5f3g900Gfh5TZfq33GuKqA9hfimBRbW0fFzY3a21RwOu4PLgTJkGu8dMJdwZTxXGeKI1g*","institutionName":"your institution"},"isCorpReq":false,"isPdfFullText":false,"issn":"00313203","issn-primary-formatted":"0031-3203","issRange":"","isThirdParty":false,"pageCount":12,"pdfDownload":{"isPdfFullText":false,"urlMetadata":{"queryParams":{"md5":"6a763db38d65b723de3b16308f896772","pid":"1-s2.0-S0031320317302327-main.pdf"},"pii":"S0031320317302327","pdfExtension":"/pdfft","path":"science/article/pii"}},"publication-content":{"noElsevierLogo":false,"imprintPublisher":{"displayName":"Pergamon","id":"67"},"isSpecialIssue":false,"isSampleIssue":false,"transactionsBlocked":false,"publicationOpenAccess":{"oaStatus":"","oaArticleCount":300,"openArchiveStatus":false,"openArchiveArticleCount":20,"openAccessStartDate":"","oaAllowsAuthorPaid":true},"issue-cover":{"attachment":[{"attachment-eid":"1-s2.0-S0031320317X00071-cov200h.gif","file-basename":"cov200h","extension":"gif","filename":"cov200h.gif","ucs-locator":["https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0031320317X00071/cover/DOWNSAMPLED200/image/gif/74fd9a589f7e535a76ce945db49360dc/cov200h.gif"],"attachment-type":"IMAGE-COVER-H200","filesize":"10953","pixel-height":"200","pixel-width":"150"},{"attachment-eid":"1-s2.0-S0031320317X00071-cov150h.gif","file-basename":"cov150h","extension":"gif","filename":"cov150h.gif","ucs-locator":["https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0031320317X00071/cover/DOWNSAMPLED/image/gif/065b9ecddf6013b4e10dd94a6d6ff45f/cov150h.gif"],"attachment-type":"IMAGE-COVER-H150","filesize":"7831","pixel-height":"150","pixel-width":"113"}]},"smallCoverUrl":"https://ars.els-cdn.com/content/image/S00313203.gif","title":"pattern-recognition","contentTypeCode":"JL","images":{"coverImage":"https://ars.els-cdn.com/content/image/1-s2.0-S0031320317X00071-cov150h.gif","logo":"https://sdfestaticassets-eu-west-1.sciencedirectassets.com/prod/562c52f0a29e84041e12a6c3286c1d8a5b89ba0b/image/elsevier-non-solus.png","logoAltText":"Elsevier"},"publicationCoverImageUrl":"https://ars.els-cdn.com/content/image/1-s2.0-S0031320317X00071-cov150h.gif"},"volRange":"71","features":["aamAttachments","keywords","references","biography","preview"],"titleString":"Head pose estimation in the wild using Convolutional Neural Networks and adaptive gradient methods","openManuscriptUrl":"/science/article/am/pii/S0031320317302327","ssrn":{},"renderingMode":"Article","isAbstract":false,"isContentVisible":false,"ajaxLinks":{"referenceLinks":true,"references":true,"referredToBy":true,"recommendations-entitled":true,"toc":true,"body":true,"recommendations":true,"citingArticles":true,"authorMetadata":true},"pdfEmbed":false,"displayViewFullText":false},"authors":{"content":[{"#name":"author-group","$":{"id":"aut0001"},"$$":[{"#name":"author","$":{"id":"au0001","biographyid":"b1","author-id":"S0031320317302327-a7e8ccb45e22b1c0a46ccd57e2cab7b0"},"$$":[{"#name":"given-name","_":"Massimiliano"},{"#name":"surname","_":"Patacchiola"},{"#name":"cross-ref","$":{"id":"crf0024","refid":"cor0001"},"$$":[{"#name":"sup","$":{"loc":"post"},"_":"⁎"}]},{"#name":"encoded-e-address","__encoded":"JTdCJTIyJTIzbmFtZSUyMiUzQSUyMmUtYWRkcmVzcyUyMiUyQyUyMiUyNCUyMiUzQSU3QiUyMnR5cGUlMjIlM0ElMjJlbWFpbCUyMiUyQyUyMmlkJTIyJTNBJTIyZWFkMDAwMSUyMiU3RCUyQyUyMl8lMjIlM0ElMjJtYXNzaW1pbGlhbm8ucGF0YWNjaGlvbGElNDBwbHltb3V0aC5hYy51ayUyMiU3RA=="},{"#name":"encoded-e-address","__encoded":"JTdCJTIyJTIzbmFtZSUyMiUzQSUyMmUtYWRkcmVzcyUyMiUyQyUyMiUyNCUyMiUzQSU3QiUyMnR5cGUlMjIlM0ElMjJlbWFpbCUyMiUyQyUyMmlkJTIyJTNBJTIyZWFkMDAwMWElMjIlN0QlMkMlMjJfJTIyJTNBJTIybWFzc2ltaWxpYW5vLnBhdGFjY2hpb2xhJTQwZ21haWwuY29tJTIyJTdE"}]},{"#name":"author","$":{"id":"au0002","biographyid":"b2","author-id":"S0031320317302327-29076a84ddc556b582ab88e9babd0c32"},"$$":[{"#name":"given-name","_":"Angelo"},{"#name":"surname","_":"Cangelosi"}]},{"#name":"affiliation","$":{"id":"aff0001"},"$$":[{"#name":"textfn","$":{"id":"cetextfn0001"},"_":"Centre for Robotics and Neural Systems, School of Computing Electronics and Mathematics, Plymouth University, Plymouth, PL4 8AA, UK"},{"#name":"affiliation","$":{"xmlns:sa":true},"$$":[{"#name":"organization","_":"Centre for Robotics and Neural Systems, School of Computing Electronics and Mathematics"},{"#name":"organization","_":"Plymouth University"},{"#name":"address-line","_":"Plymouth, PL4 8AA"},{"#name":"country","_":"UK"}]}]},{"#name":"correspondence","$":{"id":"cor0001"},"$$":[{"#name":"label","_":"⁎"},{"#name":"text","$":{"id":"cor1"},"_":"Corresponding author."}]}]}],"floats":[],"footnotes":[],"affiliations":{"aff0001":{"#name":"affiliation","$":{"id":"aff0001"},"$$":[{"#name":"textfn","$":{"id":"cetextfn0001"},"_":"Centre for Robotics and Neural Systems, School of Computing Electronics and Mathematics, Plymouth University, Plymouth, PL4 8AA, UK"},{"#name":"affiliation","$":{"xmlns:sa":true},"$$":[{"#name":"organization","_":"Centre for Robotics and Neural Systems, School of Computing Electronics and Mathematics"},{"#name":"organization","_":"Plymouth University"},{"#name":"address-line","_":"Plymouth, PL4 8AA"},{"#name":"country","_":"UK"}]}]}},"correspondences":{"cor0001":{"#name":"correspondence","$":{"id":"cor0001"},"$$":[{"#name":"label","_":"⁎"},{"#name":"text","$":{"id":"cor1"},"_":"Corresponding author."}]}},"attachments":[],"scopusAuthorIds":{},"articles":{}},"authorMetadata":[],"banner":{"expanded":false},"biographies":{"content":[{"#name":"biography","$":{"xmlns:ce":true,"xmlns:aep":true,"xmlns:mml":true,"xmlns:xs":true,"xmlns:xlink":true,"xmlns:xocs":true,"xmlns:tb":true,"xmlns:xsi":true,"xmlns:cals":true,"xmlns:sb":true,"xmlns:sa":true,"xmlns:ja":true,"xmlns":true,"id":"b1","view":"all"},"$$":[{"#name":"simple-para","$":{"id":"spara0001","view":"all"},"$$":[{"#name":"bold","_":"Massimiliano Patacchiola"},{"#name":"__text__","_":" attended his studies at La Sapienza University (Rome). After his internship at the Laboratory of Artificial Life and Robotics (Rome), in 2012 he started working as robotics engineer at Eurolink Systems group (Rome), where he spent more than two years creating algorithms and designing systems for the control of UGV (Unmanned Ground Vehicle) and UAV (Unmanned Aerial Vehicle). In 2015 he started a PhD program in robotics and computational modelling at Plymouth University. He is currently designing the social skills of different humanoid robots."}]}]},{"#name":"biography","$":{"xmlns:ce":true,"xmlns:aep":true,"xmlns:mml":true,"xmlns:xs":true,"xmlns:xlink":true,"xmlns:xocs":true,"xmlns:tb":true,"xmlns:xsi":true,"xmlns:cals":true,"xmlns:sb":true,"xmlns:sa":true,"xmlns:ja":true,"xmlns":true,"id":"b2","view":"all"},"$$":[{"#name":"simple-para","$":{"id":"spara0002","view":"all"},"$$":[{"#name":"bold","_":"Angelo Cangelosi"},{"#name":"__text__","_":" is professor of Artificial Intelligence and Cognition and the Director of the Centre for Robotics and Neural Systems at Plymouth University (UK). Cangelosi studied psychology and cognitive science at the Universities of Rome La Sapienza and at the University of Genoa, and was visiting scholar at the University of California San Diego and the University of Southampton. Cangelosi’s main research expertise is on language grounding and embodiment in humanoid robots, developmental robotics, human-robot interaction, and on the application of neuromorphic systems for robot learning."}]}]}],"floats":[],"footnotes":[],"attachments":[]},"body":{},"chapters":{"toc":[],"isLoading":false},"changeViewLinks":{"showFullTextLink":false,"showAbstractLink":true},"citingArticles":{},"combinedContentItems":{"content":[{"#name":"keywords","$$":[{"#name":"keywords","$":{"xmlns:ce":true,"xmlns:aep":true,"xmlns:xoe":true,"xmlns:mml":true,"xmlns:xs":true,"xmlns:xlink":true,"xmlns:xocs":true,"xmlns:tb":true,"xmlns:xsi":true,"xmlns:cals":true,"xmlns:sb":true,"xmlns:sa":true,"xmlns:ja":true,"xmlns":true,"id":"keys0001","class":"keyword","view":"all"},"$$":[{"#name":"section-title","$":{"id":"sectt0003"},"_":"Keywords"},{"#name":"keyword","$":{"id":"key0002"},"$$":[{"#name":"text","$":{"id":"cetext0001"},"_":"Convolutional Neural Networks"}]},{"#name":"keyword","$":{"id":"key0003"},"$$":[{"#name":"text","$":{"id":"cetext0002"},"_":"Head pose estimation"}]},{"#name":"keyword","$":{"id":"key0004"},"$$":[{"#name":"text","$":{"id":"cetext0003"},"_":"Adaptive gradient"}]},{"#name":"keyword","$":{"id":"key0005"},"$$":[{"#name":"text","$":{"id":"cetext0004"},"_":"Deep learning"}]}]}]}],"floats":[],"footnotes":[],"attachments":[]},"crossMark":{"isOpen":false},"domainConfig":{"cdnAssetsHost":"https://sdfestaticassets-eu-west-1.sciencedirectassets.com","assetRoute":"https://sdfestaticassets-eu-west-1.sciencedirectassets.com/prod/562c52f0a29e84041e12a6c3286c1d8a5b89ba0b"},"downloadIssue":{"openOnPageLoad":false,"isOpen":false,"downloadCapOpen":false,"articles":[],"selected":[]},"enrichedContent":{"tableOfContents":false,"researchData":{"hasResearchData":false,"dataProfile":{},"openData":{},"mendeleyData":{},"databaseLinking":{}},"geospatialData":{"attachments":[]},"interactiveCaseInsights":{},"virtualMicroscope":{}},"entitledRecommendations":{"openOnPageLoad":false,"isOpen":false,"articles":[],"selected":[],"currentPage":1,"totalPages":1},"exam":{},"helpText":{"keyDates":{"html":"<div class=\"key-dates-help\"><h3 class=\"u-margin-s-bottom u-h4\">Publication milestones</h3><p class=\"u-margin-m-bottom\">The dates displayed for an article provide information on when various publication milestones were reached at the journal that has published the article. Where applicable, activities on preceding journals at which the article was previously under consideration are not shown (for instance submission, revisions, rejection).</p><p class=\"u-margin-xs-bottom\">The publication milestones include:</p><ul class=\"key-dates-help-list u-margin-m-bottom u-padding-s-left\"><li><span class=\"u-text-italic\">Received</span>: The date the article was originally submitted to the journal.</li><li><span class=\"u-text-italic\">Revised</span>: The date the most recent revision of the article was submitted to the journal. Dates corresponding to intermediate revisions are not shown.</li><li><span class=\"u-text-italic\">Accepted</span>: The date the article was accepted for publication in the journal.</li><li><span class=\"u-text-italic\">Available online</span>: The date a version of the article was made available online in the journal.</li><li><span class=\"u-text-italic\">Version of Record</span>: The date the finalized version of the article was made available in the journal.</li></ul><p>More information on publishing policies can be found on the <a class=\"anchor anchor-secondary u-display-inline anchor-underline\" href=\"https://www.elsevier.com/about/policies-and-standards/publishing-ethics\" target=\"_blank\"><span class=\"anchor-text-container\"><span class=\"anchor-text\">Publishing Ethics Policies</span></span></a> page. View our <a class=\"anchor anchor-secondary u-display-inline anchor-underline\" href=\"https://www.elsevier.com/researcher/author/submit-your-paper\" target=\"_blank\"><span class=\"anchor-text-container\"><span class=\"anchor-text\">Publishing with Elsevier: step-by-step</span></span></a> page to learn more about the publishing process. For any questions on your own submission or other questions related to publishing an article, <a class=\"anchor anchor-secondary u-display-inline anchor-underline\" href=\"https://service.elsevier.com/app/phone/supporthub/publishing\" target=\"_blank\"><span class=\"anchor-text-container\"><span class=\"anchor-text\">contact our Researcher support team.</span></span></a></p></div>","title":"What do these dates mean?"}},"glossary":{},"issueNavigation":{"previous":{},"next":{}},"linkingHubLinks":{},"metrics":{"isOpen":true},"preview":{},"rawtext":"","recommendations":{},"references":{},"referenceLinks":{"internal":[],"internalLoaded":false,"external":[]},"refersTo":{},"referredToBy":{},"relatedContent":{"isModal":false,"isOpenSpecialIssueArticles":false,"isOpenVirtualSpecialIssueLink":false,"isOpenRecommendations":true,"isOpenSubstances":true,"citingArticles":[false,false,false,false,false,false],"recommendations":[false,false,false,false,false,false]},"seamlessAccess":{},"specialIssueArticles":{},"substances":{},"supplementaryFilesData":[],"tableOfContents":{"showEntitledTocLinks":true},"tail":{},"transientError":{"isOpen":false},"sidePanel":{"openState":1},"viewConfig":{"articleFeature":{"rightsAndContentLink":true,"sdAnswersButton":false},"pathPrefix":""},"virtualSpecialIssue":{"showVirtualSpecialIssueLink":false},"userCookiePreferences":{"STRICTLY_NECESSARY":true,"PERFORMANCE":true,"FUNCTIONAL":true,"TARGETING":true}};
      </script>
      <noscript>
      JavaScript is disabled on your browser.
      Please enable JavaScript to use all the features on this page.
      <img src=https://smetrics.elsevier.com/b/ss/elsevier-sd-prod/1/G.4--NS/1730203906804?pageName=sd%3Aproduct%3Ajournal%3Aarticle&c16=els%3Arp%3Ast&c2=sd&v185=img&v33=ae%3AREG_SHIBBOLETH&c1=ae%3A50401&c12=ae%3A71970787 />
    </noscript>
      <a class="anchor sr-only sr-only-focusable u-display-inline anchor-primary" href="#screen-reader-main-content"><span class="anchor-text-container"><span class="anchor-text">Skip to main content</span></span></a><a class="anchor sr-only sr-only-focusable u-display-inline anchor-primary" href="#screen-reader-main-title"><span class="anchor-text-container"><span class="anchor-text">Skip to article</span></span></a>
      <div id="root"><div class="App" id="app" data-aa-name="root"><div class="page"><div class="sd-flex-container"><div class="sd-flex-content"><header id="gh-cnt"><div id="gh-main-cnt" class="u-flex-center-ver u-position-relative u-padding-s-hor u-padding-l-hor-from-xl"><a id="gh-branding" class="u-flex-center-ver" href="/" aria-label="ScienceDirect home page" data-aa-region="header" data-aa-name="ScienceDirect"><img class="gh-logo" src="https://sdfestaticassets-eu-west-1.sciencedirectassets.com/shared-assets/24/images/elsevier-non-solus-new-grey.svg" alt="Elsevier logo" height="48" width="54"><svg xmlns="http://www.w3.org/2000/svg" version="1.1" height="15" viewBox="0 0 190 23" role="img" class="gh-wordmark u-margin-s-left" aria-labelledby="gh-wm-science-direct" focusable="false" aria-hidden="true" alt="ScienceDirect Wordmark"><title id="gh-wm-science-direct">ScienceDirect</title><g><path fill="#EB6500" d="M3.81 6.9c0-1.48 0.86-3.04 3.7-3.04 1.42 0 3.1 0.43 4.65 1.32l0.13-2.64c-1.42-0.63-2.97-0.96-4.78-0.96 -4.62 0-6.6 2.44-6.6 5.45 0 5.61 8.78 6.14 8.78 9.93 0 1.48-1.15 3.04-3.86 3.04 -1.72 0-3.4-0.56-4.72-1.39l-0.36 2.64c1.55 0.76 3.57 1.06 5.15 1.06 4.26 0 6.7-2.48 6.7-5.51C12.59 11.49 3.81 10.76 3.81 6.9M20.27 9.01c0.23-0.13 0.69-0.26 1.72-0.26 1.72 0 2.41 0.3 2.41 1.58h2.38c0-0.36 0-0.79-0.03-1.09 -0.23-1.98-2.15-2.67-4.88-2.67 -3 0-6.7 2.31-6.7 7.76 0 5.22 2.77 7.99 6.63 7.99 1.68 0 3.47-0.36 4.95-1.39l-0.2-2.31c-0.99 0.82-2.84 1.52-4.06 1.52 -2.14 0-4.55-1.71-4.55-5.91C17.93 10.2 20.01 9.18 20.27 9.01"></path><rect x="29.42" y="6.97" fill="#EB6500" width="2.54" height="14.95"></rect><path fill="#EB6500" d="M30.67 0.7c-0.92 0-1.65 0.92-1.65 1.81 0 0.93 0.76 1.85 1.65 1.85 0.89 0 1.68-0.96 1.68-1.88C32.35 1.55 31.56 0.7 30.67 0.7M48.06 14.13c0-5.18-1.42-7.56-6.01-7.56 -3.86 0-6.67 2.77-6.67 7.92 0 4.92 2.97 7.82 6.73 7.82 2.81 0 4.36-0.63 5.68-1.42l-0.2-2.31c-0.89 0.79-2.94 1.55-4.69 1.55 -3.14 0-4.88-1.95-4.88-5.51v-0.49H48.06M39.91 9.18c0.17-0.17 1.29-0.46 1.98-0.46 2.48 0 3.76 0.53 3.86 3.43h-7.46C38.56 10.27 39.71 9.37 39.91 9.18zM58.82 6.57c-2.24 0-3.63 1.12-4.85 2.61l-0.4-2.21h-2.34l0.13 1.19c0.1 0.76 0.13 1.78 0.13 2.97v10.79h2.54V11.88c0.69-0.96 2.15-2.48 2.48-2.64 0.23-0.13 1.29-0.4 2.08-0.4 2.28 0 2.48 1.15 2.54 3.43 0.03 1.19 0.03 3.17 0.03 3.17 0.03 3-0.1 6.47-0.1 6.47h2.54c0 0 0.07-4.49 0.07-6.96 0-1.48 0.03-2.97-0.1-4.46C63.31 7.43 61.49 6.57 58.82 6.57M72.12 9.01c0.23-0.13 0.69-0.26 1.72-0.26 1.72 0 2.41 0.3 2.41 1.58h2.38c0-0.36 0-0.79-0.03-1.09 -0.23-1.98-2.15-2.67-4.88-2.67 -3 0-6.7 2.31-6.7 7.76 0 5.22 2.77 7.99 6.63 7.99 1.68 0 3.47-0.36 4.95-1.39l-0.2-2.31c-0.99 0.82-2.84 1.52-4.06 1.52 -2.15 0-4.55-1.71-4.55-5.91C69.77 10.2 71.85 9.18 72.12 9.01M92.74 14.13c0-5.18-1.42-7.56-6.01-7.56 -3.86 0-6.67 2.77-6.67 7.92 0 4.92 2.97 7.82 6.73 7.82 2.81 0 4.36-0.63 5.68-1.42l-0.2-2.31c-0.89 0.79-2.94 1.55-4.69 1.55 -3.14 0-4.88-1.95-4.88-5.51v-0.49H92.74M84.59 9.18c0.17-0.17 1.29-0.46 1.98-0.46 2.48 0 3.76 0.53 3.86 3.43h-7.46C83.24 10.27 84.39 9.37 84.59 9.18zM103.9 1.98h-7.13v19.93h6.83c7.26 0 9.77-5.68 9.77-10.03C113.37 7.33 110.93 1.98 103.9 1.98M103.14 19.8h-3.76V4.1h4.09c5.38 0 6.96 4.39 6.96 7.79C110.43 16.87 108.19 19.8 103.14 19.8zM118.38 0.7c-0.92 0-1.65 0.92-1.65 1.81 0 0.93 0.76 1.85 1.65 1.85 0.89 0 1.69-0.96 1.69-1.88C120.07 1.55 119.28 0.7 118.38 0.7"></path><rect x="117.13" y="6.97" fill="#EB6500" width="2.54" height="14.95"></rect><path fill="#EB6500" d="M130.2 6.6c-1.62 0-2.87 1.45-3.4 2.74l-0.43-2.37h-2.34l0.13 1.19c0.1 0.76 0.13 1.75 0.13 2.9v10.86h2.54v-9.51c0.53-1.29 1.72-3.7 3.17-3.7 0.96 0 1.06 0.99 1.06 1.22l2.08-0.6V9.18c0-0.03-0.03-0.17-0.06-0.4C132.8 7.36 131.91 6.6 130.2 6.6M145.87 14.13c0-5.18-1.42-7.56-6.01-7.56 -3.86 0-6.67 2.77-6.67 7.92 0 4.92 2.97 7.82 6.73 7.82 2.81 0 4.36-0.63 5.68-1.42l-0.2-2.31c-0.89 0.79-2.94 1.55-4.69 1.55 -3.14 0-4.89-1.95-4.89-5.51v-0.49H145.87M137.72 9.18c0.17-0.17 1.29-0.46 1.98-0.46 2.48 0 3.76 0.53 3.86 3.43h-7.46C136.37 10.27 137.52 9.37 137.72 9.18zM153.23 9.01c0.23-0.13 0.69-0.26 1.72-0.26 1.72 0 2.41 0.3 2.41 1.58h2.38c0-0.36 0-0.79-0.03-1.09 -0.23-1.98-2.14-2.67-4.88-2.67 -3 0-6.7 2.31-6.7 7.76 0 5.22 2.77 7.99 6.63 7.99 1.69 0 3.47-0.36 4.95-1.39l-0.2-2.31c-0.99 0.82-2.84 1.52-4.06 1.52 -2.15 0-4.55-1.71-4.55-5.91C150.89 10.2 152.97 9.18 153.23 9.01M170 19.44c-0.92 0.36-1.72 0.69-2.51 0.69 -1.16 0-1.58-0.66-1.58-2.34V8.95h3.93V6.97h-3.93V2.97h-2.48v3.99h-2.71v1.98h2.71v9.67c0 2.64 1.39 3.73 3.33 3.73 1.15 0 2.54-0.39 3.43-0.79L170 19.44M173.68 5.96c-1.09 0-2-0.87-2-1.97 0-1.1 0.91-1.97 2-1.97s1.98 0.88 1.98 1.98C175.66 5.09 174.77 5.96 173.68 5.96zM173.67 2.46c-0.85 0-1.54 0.67-1.54 1.52 0 0.85 0.69 1.54 1.54 1.54 0.85 0 1.54-0.69 1.54-1.54C175.21 3.13 174.52 2.46 173.67 2.46zM174.17 5.05c-0.09-0.09-0.17-0.19-0.25-0.3l-0.41-0.56h-0.16v0.87h-0.39V2.92c0.22-0.01 0.47-0.03 0.66-0.03 0.41 0 0.82 0.16 0.82 0.64 0 0.29-0.21 0.55-0.49 0.63 0.23 0.32 0.45 0.62 0.73 0.91H174.17zM173.56 3.22l-0.22 0.01v0.63h0.22c0.26 0 0.43-0.05 0.43-0.34C174 3.28 173.83 3.21 173.56 3.22z"></path></g></svg></a><div class="gh-nav-cnt u-hide-from-print"><div class="gh-nav-links-container gh-nav-links-container-h u-hide-from-print gh-nav-content-container"><nav aria-label="links" class="gh-nav gh-nav-links gh-nav-h"><ul class="gh-nav-list u-list-reset"><li class="gh-nav-item gh-move-to-spine"><a class="anchor gh-nav-action text-s anchor-secondary anchor-medium" href="/browse/journals-and-books" id="gh-journals-books-link" data-aa-region="header" data-aa-name="Journals &amp; Books"><span class="anchor-text-container"><span class="anchor-text">Journals &amp; Books</span></span></a></li></ul></nav><nav aria-label="utilities" class="gh-nav gh-nav-utilities gh-nav-h"><ul class="gh-nav-list u-list-reset"><li class="gh-nav-help text-s u-flex-center-ver u-gap-6 gh-nav-action"><div class="gh-move-to-spine gh-help-button gh-help-icon gh-nav-item"><div class="popover" id="gh-help-icon-popover"><div id="popover-trigger-gh-help-icon-popover"><input type="hidden"><button class="button-link button-link-secondary gh-icon-btn button-link-medium button-link-icon-left" title="Help" aria-expanded="false" type="button"><svg focusable="false" viewBox="0 0 114 128" height="20" width="20" class="icon icon-help gh-icon"><path d="M57 8C35.69 7.69 15.11 21.17 6.68 40.71c-8.81 19.38-4.91 43.67 9.63 59.25 13.81 15.59 36.85 21.93 56.71 15.68 21.49-6.26 37.84-26.81 38.88-49.21 1.59-21.15-10.47-42.41-29.29-52.1C74.76 10.17 65.88 7.99 57 8zm0 10c20.38-.37 39.57 14.94 43.85 34.85 4.59 18.53-4.25 39.23-20.76 48.79-17.05 10.59-40.96 7.62-54.9-6.83-14.45-13.94-17.42-37.85-6.83-54.9C26.28 26.5 41.39 17.83 57 18zm-.14 14C45.31 32.26 40 40.43 40 50v2h10v-2c0-4.22 2.22-9.66 8-9.24 5.5.4 6.32 5.14 5.78 8.14C62.68 55.06 52 58.4 52 69.4V76h10v-5.56c0-8.16 11.22-11.52 12-21.7.74-9.86-5.56-16.52-16-16.74-.39-.01-.76-.01-1.14 0zM52 82v10h10V82H52z"></path></svg><span class="button-link-text-container"><span class="button-link-text">Help</span></span></button></div></div></div></li><li class="gh-nav-search text-s u-flex-center-ver u-gap-6 gh-nav-action"><div class="gh-search-toggle gh-nav-item search-button-link"><a class="anchor button-link-secondary anchor-secondary u-margin-l-left gh-nav-action gh-icon-btn anchor-medium anchor-icon-left anchor-with-icon" href="/search" id="gh-search-link" title="Search" data-aa-button="search-in-header-opened-from-article" role="button"><svg focusable="false" viewBox="0 0 100 128" height="20" class="icon icon-search gh-icon"><path d="M19.22 76.91c-5.84-5.84-9.05-13.6-9.05-21.85s3.21-16.01 9.05-21.85c5.84-5.83 13.59-9.05 21.85-9.05 8.25 0 16.01 3.22 21.84 9.05 5.84 5.84 9.05 13.6 9.05 21.85s-3.21 16.01-9.05 21.85c-5.83 5.83-13.59 9.05-21.84 9.05-8.26 0-16.01-3.22-21.85-9.05zm80.33 29.6L73.23 80.19c5.61-7.15 8.68-15.9 8.68-25.13 0-10.91-4.25-21.17-11.96-28.88-7.72-7.71-17.97-11.96-28.88-11.96S19.9 18.47 12.19 26.18C4.47 33.89.22 44.15.22 55.06s4.25 21.17 11.97 28.88C19.9 91.65 30.16 95.9 41.07 95.9c9.23 0 17.98-3.07 25.13-8.68l26.32 26.32 7.03-7.03"></path></svg><span class="anchor-text-container"><span class="anchor-text">Search</span></span></a></div></li></ul></nav></div></div><div class="gh-profile-container u-hide-from-print"><div id="gh-profile-cnt" class="u-flex-center-ver gh-move-to-spine"><div class="popover" id="gh-profile-dropdown"><div id="popover-trigger-gh-profile-dropdown"><input type="hidden"><button class="button-link gh-icon-btn gh-user-icon u-margin-l-left gh-truncate text-s button-link-secondary button-link-medium button-link-icon-left" title="Gergo Gyori" aria-expanded="false" type="button"><svg focusable="false" viewBox="0 0 106 128" height="20" class="icon icon-person"><path d="M11.07 120l.84-9.29C13.88 91.92 35.25 87.78 53 87.78c17.74 0 39.11 4.13 41.08 22.84l.84 9.38h10.04l-.93-10.34C101.88 89.23 83.89 78 53 78S4.11 89.22 1.95 109.73L1.04 120h10.03M53 17.71c-9.72 0-18.24 8.69-18.24 18.59 0 13.67 7.84 23.98 18.24 23.98S71.24 49.97 71.24 36.3c0-9.9-8.52-18.59-18.24-18.59zM53 70c-15.96 0-28-14.48-28-33.67C25 20.97 37.82 8 53 8s28 12.97 28 28.33C81 55.52 68.96 70 53 70"></path></svg><span class="button-link-text-container"><span class="button-link-text">Gergo Gyori</span></span></button></div></div></div></div><div class="gh-move-to-spine u-hide-from-print gh-institution-item"><div class="popover text-s" id="institution-popover"><div id="popover-trigger-institution-popover"><input type="hidden"><button class="button-link gh-icon-btn gh-has-institution gh-truncate text-s button-link-secondary u-margin-l-left button-link-medium button-link-icon-left" id="gh-inst-icon-btn" aria-expanded="false" aria-label="Institutional Access" title="IT University of Copenhagen" type="button"><svg focusable="false" viewBox="0 0 106 128" height="20" class="icon icon-institution gh-inst-icon"><path d="M84 98h10v10H12V98h10V52h14v46h10V52h14v46h10V52h14v46zM12 36.86l41-20.84 41 20.84V42H12v-5.14zM104 52V30.74L53 4.8 2 30.74V52h10v36H2v30h102V88H94V52h10z"></path></svg><span class="button-link-text-container"><span class="button-link-text">IT University of Copenhagen</span></span></button></div></div></div><div id="gh-mobile-menu" class="mobile-menu u-hide-from-print"><div class="gh-hamburger u-fill-grey7"><button class="button-link u-flex-center-ver button-link-primary button-link-icon-left" aria-label="Toggle mobile menu" aria-expanded="false" type="button"><svg class="gh-hamburger-svg-el gh-hamburger-closed" role="img" aria-hidden="true" height="20" width="20"><path d="M0 14h40v2H0zm0-7h40v2H0zm0-7h40v2H0z"></path></svg></button></div><div id="gh-overlay" class="mobile-menu-overlay u-overlay u-display-none" role="button" tabindex="-1"></div><div id="gh-drawer" aria-label="Mobile menu" class="" role="navigation"></div></div></div></header><div class="Article" id="mathjax-container" role="main"><div class="accessbar-sticky"><div id="screen-reader-main-content"></div><div role="region" aria-label="Download options and search"><div class="accessbar"><div class="accessbar-label"></div><ul aria-label="PDF Options"><li class="accessbar-item-show-from-initial accessbar-item-show-from-xs accessbar-item-show-from-md ViewPDF"><a class="link-button accessbar-utility-component accessbar-utility-link link-button-primary link-button-icon-left" target="_blank" aria-label="View PDF. Opens in a new window." href="/science/article/pii/S0031320317302327/pdfft?md5=6a763db38d65b723de3b16308f896772&amp;pid=1-s2.0-S0031320317302327-main.pdf" rel="nofollow"><svg focusable="false" viewBox="0 0 35 32" height="20" class="icon icon-pdf-multicolor"><path d="M7 .362h17.875l6.763 6.1V31.64H6.948V16z" stroke="#000" stroke-width=".703" fill="#fff"></path><path d="M.167 2.592H22.39V9.72H.166z" fill="#da0000"></path><path fill="#fff9f9" d="M5.97 3.638h1.62c1.053 0 1.483.677 1.488 1.564.008.96-.6 1.564-1.492 1.564h-.644v1.66h-.977V3.64m.977.897v1.34h.542c.27 0 .596-.068.596-.673-.002-.6-.32-.667-.596-.667h-.542m3.8.036v2.92h.35c.933 0 1.223-.448 1.228-1.462.008-1.06-.316-1.45-1.23-1.45h-.347m-.977-.94h1.03c1.68 0 2.523.586 2.534 2.39.01 1.688-.607 2.4-2.534 2.4h-1.03V3.64m4.305 0h2.63v.934h-1.657v.894H16.6V6.4h-1.56v2.026h-.97V3.638"></path><path d="M19.462 13.46c.348 4.274-6.59 16.72-8.508 15.792-1.82-.85 1.53-3.317 2.92-4.366-2.864.894-5.394 3.252-3.837 3.93 2.113.895 7.048-9.25 9.41-15.394zM14.32 24.874c4.767-1.526 14.735-2.974 15.152-1.407.824-3.157-13.72-.37-15.153 1.407zm5.28-5.043c2.31 3.237 9.816 7.498 9.788 3.82-.306 2.046-6.66-1.097-8.925-4.164-4.087-5.534-2.39-8.772-1.682-8.732.917.047 1.074 1.307.67 2.442-.173-1.406-.58-2.44-1.224-2.415-1.835.067-1.905 4.46 1.37 9.065z" fill="#f91d0a"></path></svg><span class="link-button-text-container"><span class="link-button-text"><span>View&nbsp;<strong>PDF</strong></span></span></span></a></li><li class="accessbar-item-hide-from-initial accessbar-item-hide-from-xs accessbar-item-show-from-md DownloadFullIssue"><button class="button-link accessbar-utility-component button-link-primary" aria-label="Download full issue" type="button"><span class="button-link-text-container"><span class="button-link-text"><span>Download full issue</span></span></span></button></li><li class="accessbar-item-hide-from-initial accessbar-item-hide-from-xs accessbar-item-show-from-md Divider"><span class="accessbar-divider"></span></li><li class="accessbar-item-hide-from-initial accessbar-item-hide-from-xs accessbar-item-show-from-md OpenManuscript"><a class="anchor accessbar-utility-component accessbar-utility-link anchor-primary" href="/science/article/am/pii/S0031320317302327" target="_blank" aria-label="View Open Manuscript"><span class="anchor-text-container"><span class="anchor-text"><span>View Open Manuscript</span></span></span></a></li><li class="accessbar-item-show-from-initial accessbar-item-show-from-xs accessbar-item-hide-from-md OverflowPopover"><div class="popover accessbar-overflow-popover" id="OverflowPopoverAnchor"><div id="popover-trigger-OverflowPopoverAnchor"><button class="button-link accessbar-utility-component button-link-primary button-link-icon-right" aria-label="Other access options" type="button"><span class="button-link-text-container"><span class="button-link-text"><span>Other access options</span></span></span><svg focusable="false" viewBox="0 0 92 128" height="20" class="icon icon-navigate-down"><path d="M1 51l7-7 38 38 38-38 7 7-45 45z"></path></svg></button></div></div></li></ul><form class="QuickSearch" action="/search#submit" method="get" aria-label="form"><div class="search-input"><div class="search-input-container search-input-container-no-label"><label class="search-input-label u-hide-visually" for="article-quick-search">Search ScienceDirect</label><input type="search" id="article-quick-search" name="qs" class="search-input-field" aria-describedby="article-quick-search-description-message" aria-invalid="false" aria-label="Search ScienceDirect" placeholder="Search ScienceDirect" value=""></div><div class="search-input-message-container"><div class="search-input-validation-error" aria-live="polite"></div><div id="article-quick-search-description-message"></div></div></div><button type="submit" class="button u-margin-xs-left button-primary small button-icon-only" aria-disabled="false" aria-label="Submit search"><svg focusable="false" viewBox="0 0 100 128" height="20" class="icon icon-search"><path d="M19.22 76.91c-5.84-5.84-9.05-13.6-9.05-21.85s3.21-16.01 9.05-21.85c5.84-5.83 13.59-9.05 21.85-9.05 8.25 0 16.01 3.22 21.84 9.05 5.84 5.84 9.05 13.6 9.05 21.85s-3.21 16.01-9.05 21.85c-5.83 5.83-13.59 9.05-21.84 9.05-8.26 0-16.01-3.22-21.85-9.05zm80.33 29.6L73.23 80.19c5.61-7.15 8.68-15.9 8.68-25.13 0-10.91-4.25-21.17-11.96-28.88-7.72-7.71-17.97-11.96-28.88-11.96S19.9 18.47 12.19 26.18C4.47 33.89.22 44.15.22 55.06s4.25 21.17 11.97 28.88C19.9 91.65 30.16 95.9 41.07 95.9c9.23 0 17.98-3.07 25.13-8.68l26.32 26.32 7.03-7.03"></path></svg></button><input type="hidden" name="origin" value="article"><input type="hidden" name="zone" value="qSearch"></form></div></div></div><div class="article-wrapper grid row"><div role="navigation" class="u-display-block-from-lg col-lg-6 u-padding-s-top sticky-table-of-contents" aria-label="Table of contents"><div class="TableOfContents" lang="en"><div class="Outline" id="toc-outline"><h2 class="u-h4">Outline</h2><ol class="u-padding-xs-bottom"><li class="toc-list-entry-outline-padding"><a class="anchor u-truncate-anchor-text anchor-primary" href="#absh001" data-aa-button="sd:product:journal:article:type=anchor:name=outlinelink" title="Highlights"><span class="anchor-text-container"><span class="anchor-text">Highlights</span></span></a></li><li class="toc-list-entry-outline-padding"><a class="anchor u-truncate-anchor-text anchor-primary" href="#abs0001" data-aa-button="sd:product:journal:article:type=anchor:name=outlinelink" title="Abstract"><span class="anchor-text-container"><span class="anchor-text">Abstract</span></span></a></li><li class="ai-components-toc-entry" id="ai-components-toc-entry"></li><li class="toc-list-entry-outline-padding"><a class="anchor u-truncate-anchor-text anchor-primary" href="#keys0001" data-aa-button="sd:product:journal:article:type=anchor:name=outlinelink" title="Keywords"><span class="anchor-text-container"><span class="anchor-text">Keywords</span></span></a></li><li class="toc-list-entry-outline-padding"><a class="anchor u-truncate-anchor-text anchor-primary" href="#sec0001" data-aa-button="sd:product:journal:article:type=anchor:name=outlinelink" title="1. Introduction"><span class="anchor-text-container"><span class="anchor-text">1. Introduction</span></span></a></li><li class="toc-list-entry-outline-padding"><a class="anchor u-truncate-anchor-text anchor-primary" href="#sec0002" data-aa-button="sd:product:journal:article:type=anchor:name=outlinelink" title="2. Related work"><span class="anchor-text-container"><span class="anchor-text">2. Related work</span></span></a></li><li class="toc-list-entry-outline-padding"><a class="anchor u-truncate-anchor-text anchor-primary" href="#sec0003" data-aa-button="sd:product:journal:article:type=anchor:name=outlinelink" title="3. Convolutional Neural Networks"><span class="anchor-text-container"><span class="anchor-text">3. Convolutional Neural Networks</span></span></a></li><li class="toc-list-entry-outline-padding"><a class="anchor u-truncate-anchor-text anchor-primary" href="#sec0007" data-aa-button="sd:product:journal:article:type=anchor:name=outlinelink" title="4. Experiments"><span class="anchor-text-container"><span class="anchor-text">4. Experiments</span></span></a></li><li class="toc-list-entry-outline-padding"><a class="anchor u-truncate-anchor-text anchor-primary" href="#sec0018" data-aa-button="sd:product:journal:article:type=anchor:name=outlinelink" title="5. Conclusions"><span class="anchor-text-container"><span class="anchor-text">5. Conclusions</span></span></a></li><li class="toc-list-entry-outline-padding"><a class="anchor u-truncate-anchor-text anchor-primary" href="#ack0001" data-aa-button="sd:product:journal:article:type=anchor:name=outlinelink" title="Acknowledgment"><span class="anchor-text-container"><span class="anchor-text">Acknowledgment</span></span></a></li><li class="toc-list-entry-outline-padding"><a class="anchor u-truncate-anchor-text anchor-primary" href="#bib001" data-aa-button="sd:product:journal:article:type=anchor:name=outlinelink" title="References"><span class="anchor-text-container"><span class="anchor-text">References</span></span></a></li><li class="toc-list-entry-outline-padding"><a class="anchor u-truncate-anchor-text anchor-primary" href="#b1" data-aa-button="sd:product:journal:article:type=anchor:name=outlinelink" title="Vitae"><span class="anchor-text-container"><span class="anchor-text">Vitae</span></span></a></li></ol><button class="button-link u-margin-xs-top u-margin-s-bottom button-link-primary button-link-icon-right" aria-expanded="false" data-aa-button="sd:product:journal:article:type=menu:name=show-full-outline" type="button"><span class="button-link-text-container"><span class="button-link-text">Show full outline</span></span><svg focusable="false" viewBox="0 0 92 128" height="20" class="icon icon-navigate-down"><path d="M1 51l7-7 38 38 38-38 7 7-45 45z"></path></svg></button><div class="PageDivider"></div></div><div class="CitedBy" id="toc-cited-by"><h2 class="u-h4"><a class="anchor anchor-primary" href="#section-cited-by"><span class="anchor-text-container"><span class="anchor-text">Cited by (188)</span></span></a></h2><div class="PageDivider"></div></div><div class="Figures" id="toc-figures"><h2 class="u-h4">Figures (15)</h2><ol class="u-margin-s-bottom"><li><a class="anchor u-display-block anchor-primary anchor-icon-only anchor-with-icon" href="#fig0001" data-aa-button="sd:product:journal:article:type=anchor:name=figure"><img alt="Fig. 1. Graphical representation of the dropout process" class="u-display-block" height="124px" src="https://ars.els-cdn.com/content/image/1-s2.0-S0031320317302327-gr1.sml" width="219px"></a></li><li><a class="anchor u-display-block anchor-primary anchor-icon-only anchor-with-icon" href="#fig0002" data-aa-button="sd:product:journal:article:type=anchor:name=figure"><img alt="Fig. 2. Graphical representation of a Convolutional Neural Network with two…" class="u-display-block" height="54px" src="https://ars.els-cdn.com/content/image/1-s2.0-S0031320317302327-gr2.sml" width="219px"></a></li><li><a class="anchor u-display-block anchor-primary anchor-icon-only anchor-with-icon" href="#fig0003" data-aa-button="sd:product:journal:article:type=anchor:name=figure"><img alt="Fig. 3. Comparison of the four architectures used in our experiments" class="u-display-block" height="164px" src="https://ars.els-cdn.com/content/image/1-s2.0-S0031320317302327-gr3.sml" width="126px"></a></li><li><a class="anchor u-display-block anchor-primary anchor-icon-only anchor-with-icon" href="#fig0004" data-aa-button="sd:product:journal:article:type=anchor:name=figure"><img alt="Fig. 4. This figure represents a collection of images taken from the Prima dataset as…" class="u-display-block" height="53px" src="https://ars.els-cdn.com/content/image/1-s2.0-S0031320317302327-gr4.sml" width="219px"></a></li><li><a class="anchor u-display-block anchor-primary anchor-icon-only anchor-with-icon" href="#fig0005" data-aa-button="sd:product:journal:article:type=anchor:name=figure"><img alt="Fig. 5. Comparison of different optimisers (trained on network A) for the estimation of…" class="u-display-block" height="164px" src="https://ars.els-cdn.com/content/image/1-s2.0-S0031320317302327-gr5.sml" width="209px"></a></li><li><a class="anchor u-display-block anchor-primary anchor-icon-only anchor-with-icon" href="#fig0006" data-aa-button="sd:product:journal:article:type=anchor:name=figure"><img alt="Fig. 6. Comparison of different optimisers (trained on network A) for the estimation of…" class="u-display-block" height="164px" src="https://ars.els-cdn.com/content/image/1-s2.0-S0031320317302327-gr6.sml" width="209px"></a></li></ol><button class="button-link u-margin-xs-top u-margin-s-bottom button-link-primary button-link-icon-right" data-aa-button="sd:product:journal:article:type=menu:name=show-figures" type="button"><span class="button-link-text-container"><span class="button-link-text">Show 9 more figures</span></span><svg focusable="false" viewBox="0 0 92 128" height="20" class="icon icon-navigate-down"><path d="M1 51l7-7 38 38 38-38 7 7-45 45z"></path></svg></button><div class="PageDivider"></div></div><div class="Tables" id="toc-tables"><h2 class="u-h4">Tables (4)</h2><ol class="u-padding-s-bottom"><li class="toc-list-entry-outline-padding"><a class="anchor u-truncate-anchor-text anchor-primary anchor-icon-left anchor-with-icon" href="#tbl0001" data-aa-button="sd:product:journal:article:type=anchor:name=table" title="In this table we report the results obtained on the Prima dataset for leave-one-out (unknown subjects) test using different optimisers. These results have been obtained training the architecture A for..."><svg focusable="false" viewBox="0 0 98 128" height="20" class="icon icon-table"><path d="M54 68h32v32H54V68zm-42 0h32v32H12V68zm0-42h32v32H12V26zm42 0h32v32H54V26zM2 110h94V16H2v94z"></path></svg><span class="anchor-text-container"><span class="anchor-text">Table 1</span></span></a></li><li class="toc-list-entry-outline-padding"><a class="anchor u-truncate-anchor-text anchor-primary anchor-icon-left anchor-with-icon" href="#tbl0002" data-aa-button="sd:product:journal:article:type=anchor:name=table" title="In this table we compare the results of our method with the result obtained by other authors on the Prima head pose dataset. These results have been obtained training architecture A for 20, 000 epochs..."><svg focusable="false" viewBox="0 0 98 128" height="20" class="icon icon-table"><path d="M54 68h32v32H54V68zm-42 0h32v32H12V68zm0-42h32v32H12V26zm42 0h32v32H54V26zM2 110h94V16H2v94z"></path></svg><span class="anchor-text-container"><span class="anchor-text">Table 2</span></span></a></li><li class="toc-list-entry-outline-padding"><a class="anchor u-truncate-anchor-text anchor-primary anchor-icon-left anchor-with-icon" href="#tbl0003" data-aa-button="sd:product:journal:article:type=anchor:name=table" title="In this table we report the results obtained on the AFLW dataset for the five-fold cross validation test. These results have been obtained training the architecture A for 30, 000 epochs (14.6h). The r..."><svg focusable="false" viewBox="0 0 98 128" height="20" class="icon icon-table"><path d="M54 68h32v32H54V68zm-42 0h32v32H12V68zm0-42h32v32H12V26zm42 0h32v32H54V26zM2 110h94V16H2v94z"></path></svg><span class="anchor-text-container"><span class="anchor-text">Table 3</span></span></a></li><li class="toc-list-entry-outline-padding"><a class="anchor u-truncate-anchor-text anchor-primary anchor-icon-left anchor-with-icon" href="#tbl0004" data-aa-button="sd:product:journal:article:type=anchor:name=table" title="In this table we report the results in term of MAE (degrees) and accuracy (percentage) obtained with different methods for the yaw estimation on the AFLW and the AFW datasets. Our results have been ob..."><svg focusable="false" viewBox="0 0 98 128" height="20" class="icon icon-table"><path d="M54 68h32v32H54V68zm-42 0h32v32H12V68zm0-42h32v32H12V26zm42 0h32v32H54V26zM2 110h94V16H2v94z"></path></svg><span class="anchor-text-container"><span class="anchor-text">Table 4</span></span></a></li></ol><div class="PageDivider"></div></div></div></div><article class="col-lg-12 col-md-16 pad-left pad-right u-padding-s-top" lang="en"><div class="Publication" id="publication"><div class="publication-brand u-display-block-from-sm"><a class="anchor anchor-primary" href="/journal/pattern-recognition" title="Go to Pattern Recognition on ScienceDirect"><span class="anchor-text-container"><span class="anchor-text"><img class="publication-brand-image" src="https://sdfestaticassets-eu-west-1.sciencedirectassets.com/prod/562c52f0a29e84041e12a6c3286c1d8a5b89ba0b/image/elsevier-non-solus.png" alt="Elsevier"></span></span></a></div><div class="publication-volume u-text-center"><h2 class="publication-title u-h3" id="publication-title"><a class="anchor anchor-secondary publication-title-link" href="/journal/pattern-recognition" title="Go to Pattern Recognition on ScienceDirect"><span class="anchor-text-container"><span class="anchor-text">Pattern Recognition</span></span></a></h2><div class="text-xs"><a class="anchor anchor-primary" href="/journal/pattern-recognition/vol/71/suppl/C" title="Go to table of contents for this volume/issue"><span class="anchor-text-container"><span class="anchor-text">Volume 71</span></span></a>, <!-- -->November 2017<!-- -->, Pages 132-143</div></div><div class="publication-cover u-display-block-from-sm"><a class="anchor anchor-primary" href="/journal/pattern-recognition/vol/71/suppl/C"><span class="anchor-text-container"><span class="anchor-text"><img class="publication-cover-image" src="https://ars.els-cdn.com/content/image/1-s2.0-S0031320317X00071-cov150h.gif" alt="Pattern Recognition"></span></span></a></div></div><h1 id="screen-reader-main-title" class="Head u-font-serif u-h2 u-margin-s-ver"><span class="title-text">Head pose estimation in the wild using Convolutional Neural Networks and adaptive gradient methods</span></h1><div class="Banner" id="banner"><div class="wrapper truncated"><div class="AuthorGroups"><div class="author-group" id="author-group"><span class="sr-only">Author links open overlay panel</span><button class="button-link button-link-secondary button-link-underline" data-sd-ui-side-panel-opener="true" data-xocs-content-type="author" data-xocs-content-id="au0001" type="button"><span class="button-link-text-container"><span class="button-link-text"><span class="react-xocs-alternative-link"><span class="given-name">Massimiliano</span> <span class="text surname">Patacchiola</span></span><svg focusable="false" viewBox="0 0 106 128" height="20" title="Correspondence author icon" class="icon icon-person react-xocs-author-icon u-fill-grey8"><path d="M11.07 120l.84-9.29C13.88 91.92 35.25 87.78 53 87.78c17.74 0 39.11 4.13 41.08 22.84l.84 9.38h10.04l-.93-10.34C101.88 89.23 83.89 78 53 78S4.11 89.22 1.95 109.73L1.04 120h10.03M53 17.71c-9.72 0-18.24 8.69-18.24 18.59 0 13.67 7.84 23.98 18.24 23.98S71.24 49.97 71.24 36.3c0-9.9-8.52-18.59-18.24-18.59zM53 70c-15.96 0-28-14.48-28-33.67C25 20.97 37.82 8 53 8s28 12.97 28 28.33C81 55.52 68.96 70 53 70"></path></svg><svg focusable="false" viewBox="0 0 102 128" height="20" title="Author email or social media contact details icon" class="icon icon-envelope react-xocs-author-icon u-fill-grey8"><path d="M55.8 57.2c-1.78 1.31-5.14 1.31-6.9 0L17.58 34h69.54L55.8 57.19zM0 32.42l42.94 32.62c2.64 1.95 6.02 2.93 9.4 2.93s6.78-.98 9.42-2.93L102 34.34V24H0zM92 88.9L73.94 66.16l-8.04 5.95L83.28 94H18.74l18.38-23.12-8.04-5.96L10 88.94V51.36L0 42.9V104h102V44.82l-10 8.46V88.9"></path></svg></span></span></button>, <button class="button-link button-link-secondary button-link-underline" data-sd-ui-side-panel-opener="true" data-xocs-content-type="author" data-xocs-content-id="au0002" type="button"><span class="button-link-text-container"><span class="button-link-text"><span class="react-xocs-alternative-link"><span class="given-name">Angelo</span> <span class="text surname">Cangelosi</span></span></span></span></button></div></div></div><button class="button-link u-margin-s-ver button-link-primary button-link-icon-right" id="show-more-btn" type="button" data-aa-button="icon-expand"><span class="button-link-text-container"><span class="button-link-text">Show more</span></span><svg focusable="false" viewBox="0 0 92 128" height="20" class="icon icon-navigate-down"><path d="M1 51l7-7 38 38 38-38 7 7-45 45z"></path></svg></button><div class="banner-options u-padding-xs-bottom"><div class="toc-button-wrap u-display-inline-block u-display-none-from-lg u-margin-s-right"><button class="button-link button-link-secondary button-link-icon-left button-link-has-colored-icon" type="button"><svg focusable="false" viewBox="0 0 128 128" height="20" class="icon icon-list"><path d="M23 26a9 9 0 0 0-9 9 9 9 0 0 0 9 9 9 9 0 0 0 9-9 9 9 0 0 0-9-9zm23 4v10h68V30zM23 56a9 9 0 0 0-9 9 9 9 0 0 0 9 9 9 9 0 0 0 9-9 9 9 0 0 0-9-9zm23 4v10h68V60zM23 86a9 9 0 0 0-9 9 9 9 0 0 0 9 9 9 9 0 0 0 9-9 9 9 0 0 0-9-9zm23 4v10h68V90z"></path></svg><span class="button-link-text-container"><span class="button-link-text">Outline</span></span></button></div><button class="button-link AddToMendeley button-link-secondary u-margin-s-right u-display-inline-flex-from-md button-link-icon-left button-link-has-colored-icon" type="button"><svg focusable="false" viewBox="0 0 86 128" height="20" class="icon icon-plus"><path d="M48 58V20H38v38H0v10h38v38h10V68h38V58z"></path></svg><span class="button-link-text-container"><span class="button-link-text">Add to Mendeley</span></span></button><div class="Social u-display-inline-block" id="social"><div class="popover social-popover" id="social-popover"><div id="popover-trigger-social-popover"><button class="button-link button-link-secondary u-margin-s-right button-link-icon-left button-link-has-colored-icon" aria-expanded="false" aria-haspopup="true" type="button"><svg focusable="false" viewBox="0 0 114 128" height="20" class="icon icon-share"><path d="M90 112c-6.62 0-12-5.38-12-12s5.38-12 12-12 12 5.38 12 12-5.38 12-12 12zM24 76c-6.62 0-12-5.38-12-12s5.38-12 12-12 12 5.38 12 12-5.38 12-12 12zm66-60c6.62 0 12 5.38 12 12s-5.38 12-12 12-12-5.38-12-12 5.38-12 12-12zm0 62c-6.56 0-12.44 2.9-16.48 7.48L45.1 70.2c.58-1.98.9-4.04.9-6.2s-.32-4.22-.9-6.2l28.42-15.28C77.56 47.1 83.44 50 90 50c12.14 0 22-9.86 22-22S102.14 6 90 6s-22 9.86-22 22c0 1.98.28 3.9.78 5.72L40.14 49.1C36.12 44.76 30.38 42 24 42 11.86 42 2 51.86 2 64s9.86 22 22 22c6.38 0 12.12-2.76 16.14-7.12l28.64 15.38c-.5 1.84-.78 3.76-.78 5.74 0 12.14 9.86 22 22 22s22-9.86 22-22-9.86-22-22-22z"></path></svg><span class="button-link-text-container"><span class="button-link-text">Share</span></span></button></div></div></div><div class="ExportCitation u-display-inline-block" id="export-citation"><div class="popover export-citation-popover" id="export-citation-popover"><div id="popover-trigger-export-citation-popover"><button class="button-link button-link-secondary button-link-icon-left button-link-has-colored-icon" aria-expanded="false" aria-haspopup="true" type="button"><svg focusable="false" viewBox="0 0 104 128" height="20" class="icon icon-cited-by-66"><path d="M2 58.78V106h44V64H12v-5.22C12 40.28 29.08 32 46 32V22C20.1 22 2 37.12 2 58.78zM102 32V22c-25.9 0-44 15.12-44 36.78V106h44V64H68v-5.22C68 40.28 85.08 32 102 32z"></path></svg><span class="button-link-text-container"><span class="button-link-text">Cite</span></span></button></div></div></div></div></div><div class="ArticleIdentifierLinks u-margin-xs-bottom text-xs" id="article-identifier-links"><a class="anchor doi anchor-primary" href="https://doi.org/10.1016/j.patcog.2017.06.009" target="_blank" rel="noreferrer noopener" aria-label="Persistent link using digital object identifier" title="Persistent link using digital object identifier"><span class="anchor-text-container"><span class="anchor-text">https://doi.org/10.1016/j.patcog.2017.06.009</span><svg focusable="false" viewBox="0 0 8 8" height="20" aria-label="Opens in new window" class="icon icon-arrow-up-right-tiny arrow-external-link"><path d="M1.12949 2.1072V1H7V6.85795H5.89111V2.90281L0.784057 8L0 7.21635L5.11902 2.1072H1.12949Z"></path></svg></span></a><a class="anchor rights-and-content anchor-primary" href="https://s100.copyright.com/AppDispatchServlet?publisherName=ELS&amp;contentID=S0031320317302327&amp;orderBeanReset=true" target="_blank" rel="noreferrer noopener"><span class="anchor-text-container"><span class="anchor-text">Get rights and content</span><svg focusable="false" viewBox="0 0 8 8" height="20" aria-label="Opens in new window" class="icon icon-arrow-up-right-tiny arrow-external-link"><path d="M1.12949 2.1072V1H7V6.85795H5.89111V2.90281L0.784057 8L0 7.21635L5.11902 2.1072H1.12949Z"></path></svg></span></a></div><section class="ReferencedArticles"></section><section class="ReferencedArticles"></section><div class="PageDivider border-black-mobile"></div><div class="Abstracts u-font-serif" id="abstracts"><div class="abstract author-highlights" id="absh001"><h2 class="section-title u-h4 u-margin-l-top u-margin-xs-bottom">Highlights</h2><div id="abssec0001"><div class="u-margin-s-bottom" id="spara0003"><ul class="list"><li class="react-xocs-list-item"><span class="list-label">•</span><span><div class="u-margin-s-bottom" id="para0001">A convolutional neural network approach for head pose estimation is proposed.</div></span></li><li class="react-xocs-list-item"><span class="list-label">•</span><span><div class="u-margin-s-bottom" id="para0002">The performance of different network architectures has been measured.</div></span></li><li class="react-xocs-list-item"><span class="list-label">•</span><span><div class="u-margin-s-bottom" id="para0003">The use of adaptive gradient methods leads to the state-of-the-art in wild datasets.</div></span></li><li class="react-xocs-list-item"><span class="list-label">•</span><span><div class="u-margin-s-bottom" id="para0004">We release a library based on our work which is available under open source licence.</div></span></li></ul></div></div></div><div class="abstract author" id="abs0001"><h2 class="section-title u-h4 u-margin-l-top u-margin-xs-bottom">Abstract</h2><div id="abssec0002"><div class="u-margin-s-bottom" id="spara0004"><a href="/topics/engineering/head-pose-estimation" title="Learn more about Head pose estimation from ScienceDirect's AI-generated Topic Pages" class="topic-link">Head pose estimation</a><span><span> is an old problem that is recently receiving new attention because of possible applications in human-robot interaction, <a href="/topics/engineering/augmented-reality" title="Learn more about augmented reality from ScienceDirect's AI-generated Topic Pages" class="topic-link">augmented reality</a> and driving assistance. However, most of the existing work has been tested in controlled environments and is not robust enough for real-world applications. In order to handle these limitations we propose an approach based on </span><a href="/topics/engineering/convolutional-neural-network" title="Learn more about Convolutional Neural Networks from ScienceDirect's AI-generated Topic Pages" class="topic-link">Convolutional Neural Networks</a><span> (CNNs) supplemented with the most recent techniques adopted from the <a href="/topics/engineering/deep-learning" title="Learn more about deep learning from ScienceDirect's AI-generated Topic Pages" class="topic-link">deep learning</a> community. We evaluate the performance of four architectures on recently released in-the-wild datasets. Moreover, we investigate the use of dropout and adaptive gradient methods giving a contribution to their ongoing validation. The results show that joining CNNs and adaptive gradient methods leads to the state-of-the-art in unconstrained head pose estimation.</span></span></div></div></div></div><div id="reading-assistant-main-body-section"></div><ul id="issue-navigation" class="issue-navigation u-margin-s-bottom u-bg-grey1"><li class="previous move-left u-padding-s-ver u-padding-s-left"><a class="button-alternative button-alternative-tertiary u-display-flex button-alternative-icon-left" href="/science/article/pii/S0031320317302212"><svg focusable="false" viewBox="0 0 54 128" height="20" class="icon icon-navigate-left"><path d="M1 61l45-45 7 7-38 38 38 38-7 7z"></path></svg><span class="button-alternative-text-container"><span class="button-alternative-text">Previous <span class="extra-detail-1">article</span><span class="extra-detail-2"> in issue</span></span></span></a></li><li class="next move-right u-padding-s-ver u-padding-s-right"><a class="button-alternative button-alternative-tertiary u-display-flex button-alternative-icon-right" href="/science/article/pii/S003132031730242X"><span class="button-alternative-text-container"><span class="button-alternative-text">Next <span class="extra-detail-1">article</span><span class="extra-detail-2"> in issue</span></span></span><svg focusable="false" viewBox="0 0 54 128" height="20" class="icon icon-navigate-right"><path d="M1 99l38-38L1 23l7-7 45 45-45 45z"></path></svg></a></li></ul><div class="Keywords u-font-serif"><div id="keys0001" class="keywords-section"><h2 class="section-title u-h4 u-margin-l-top u-margin-xs-bottom">Keywords</h2><div id="key0002" class="keyword"><span id="cetext0001">Convolutional Neural Networks</span></div><div id="key0003" class="keyword"><span id="cetext0002">Head pose estimation</span></div><div id="key0004" class="keyword"><span id="cetext0003">Adaptive gradient</span></div><div id="key0005" class="keyword"><span id="cetext0004">Deep learning</span></div></div></div><div class="Body u-font-serif" id="body"><div><section id="sec0001"><h2 id="sectt0004" class="u-h4 u-margin-l-top u-margin-xs-bottom">1. Introduction</h2><div class="u-margin-s-bottom" id="para0005"><span>In the last few years major advancements in robotics, <a href="/topics/engineering/augmented-reality" title="Learn more about augmented reality from ScienceDirect's AI-generated Topic Pages" class="topic-link">augmented reality</a> and driving assistance have highlighted the need for robust methods to estimate the head pose in real-world scenarios. For instance, robots are gradually leaving factories and becoming part of our lives as companions and as assistants. It has been shown that in human-robot interaction a coarse pose estimation of the head is a fundamental prerequisite for building trust with users during joint-attention tasks </span><a class="anchor anchor-primary" href="#bib0001" name="bbib0001" data-sd-ui-side-panel-opener="true" data-xocs-content-type="reference" data-xocs-content-id="bib0001"><span class="anchor-text-container"><span class="anchor-text">[1]</span></span></a><span>. In the context of autonomous cars a driving assistance system could take advantage of <a href="/topics/engineering/head-pose-estimation" title="Learn more about head pose estimation from ScienceDirect's AI-generated Topic Pages" class="topic-link">head pose estimation</a> for decelerating the car when pedestrians do not notice the presence of the vehicle </span><a class="anchor anchor-primary" href="#bib0002" name="bbib0002" data-sd-ui-side-panel-opener="true" data-xocs-content-type="reference" data-xocs-content-id="bib0002"><span class="anchor-text-container"><span class="anchor-text">[2]</span></span></a><span>. Moreover a similar system can be installed inside the vehicle and used to monitor the driver’s awareness. The need of a robust head pose estimation is not limited to these domains. There have been significant applications in surveillance and <a href="/topics/engineering/anomaly-detection" title="Learn more about anomaly detection from ScienceDirect's AI-generated Topic Pages" class="topic-link">anomaly detection</a>, human-computer interaction and crowd behavioural dynamics analysis </span><a class="anchor anchor-primary" href="#bib0003" name="bbib0003" data-sd-ui-side-panel-opener="true" data-xocs-content-type="reference" data-xocs-content-id="bib0003"><span class="anchor-text-container"><span class="anchor-text">[3]</span></span></a><span>. All of these unconstrained scenarios need an estimator which is resistant to variable environmental conditions, and which can evaluate the focus of attention in absence of more accurate information such as the gaze. Here it is necessary to specify what we consider as a wild environment. We define as taken in a wild environment those face images exhibiting a large variety in appearance (pose, expression, ethnicity, age, gender, etc.), environmental conditions (artificial light, shadows, etc.), and containing relevant occlusions (sunglasses, masks, scarves, etc.). We will show how <a href="/topics/engineering/convolutional-neural-network" title="Learn more about Convolutional Neural Networks from ScienceDirect's AI-generated Topic Pages" class="topic-link">Convolutional Neural Networks</a> (CNNs) can be considered one of the best algorithms for robust head pose estimation in a wild environment.</span></div><div class="u-margin-s-bottom" id="para0006">We can summarise the main contribution of our work in three points:
<ul class="list"><li class="react-xocs-list-item"><span class="list-label">1.</span><span><div class="u-margin-s-bottom" id="para0007">As far as we know this is the first work that has deeply investigated the use of CNNs in head pose estimation. Our main contribution is a rigorous evaluation of multiple CNN models and factors. The results are compared with other algorithms, and show how an approach based on CNNs, dropout and adaptive gradient methods represents the state of the art in head pose estimation.</div></span></li><li class="react-xocs-list-item"><span class="list-label">2.</span><span><div class="u-margin-s-bottom" id="para0008"><a href="/topics/engineering/deep-learning" title="Learn more about Deep learning from ScienceDirect's AI-generated Topic Pages" class="topic-link">Deep learning</a> is a rapidly growing field, which is bringing new techniques that can significantly improve the performance of CNNs. Because these techniques have been released in the last few years, there is still a validation process for establishing their cross-domain usefulness. We explored the role of adaptive gradient methods and we gave a valuable contribution to their ongoing validation.</div></span></li><li class="react-xocs-list-item"><span class="list-label">3.</span><span><div class="u-margin-s-bottom" id="para0009">The results obtained in this work have been used to implement a Python library called Deepgaze. The library includes pre-trained CNNs based on Tensorflow <a class="anchor anchor-primary" href="#bib0004" name="bbib0004" data-sd-ui-side-panel-opener="true" data-xocs-content-type="reference" data-xocs-content-id="bib0004"><span class="anchor-text-container"><span class="anchor-text">[4]</span></span></a><span> which can run in real-time on <a href="/topics/engineering/graphics-processing-unit" title="Learn more about GPUs from ScienceDirect's AI-generated Topic Pages" class="topic-link">GPUs</a> and mobile devices. Deepgaze is released under an open-source license and is available for both academic and commercial purposes. The software is available on the author’s repository.</span><a class="anchor anchor-primary" href="#fn0001" name="bfn0001" data-sd-ui-side-panel-opener="true" data-xocs-content-type="reference" data-xocs-content-id="fn0001"><span class="anchor-text-container"><span class="anchor-text"><sup>1</sup></span></span></a></div></span></li></ul></div></section><section id="sec0002"><h2 id="sectt0005" class="u-h4 u-margin-l-top u-margin-xs-bottom">2. Related work</h2><div class="u-margin-s-bottom" id="para0010"><span><span>The <a href="/topics/engineering/head-pose-estimation" title="Learn more about head pose estimation from ScienceDirect's AI-generated Topic Pages" class="topic-link">head pose estimation</a><span> problem has been investigated from different points of view and with different techniques. Devices such as <a href="/topics/engineering/laser-pointer" title="Learn more about laser pointers from ScienceDirect's AI-generated Topic Pages" class="topic-link">laser pointers</a>, camera arrays, stereo-cameras, magnetic and </span></span><a href="/topics/engineering/inertial-sensor" title="Learn more about inertial sensors from ScienceDirect's AI-generated Topic Pages" class="topic-link">inertial sensors</a>, have been used to get a stable estimation in controlled situations </span><a class="anchor anchor-primary" href="#bib0005" name="bbib0005" data-sd-ui-side-panel-opener="true" data-xocs-content-type="reference" data-xocs-content-id="bib0005"><span class="anchor-text-container"><span class="anchor-text">[5]</span></span></a>. More recently some good results have been obtained with commercial depth cameras <a class="anchor anchor-primary" href="#bib0006" name="bbib0006" data-sd-ui-side-panel-opener="true" data-xocs-content-type="reference" data-xocs-content-id="bib0006"><span class="anchor-text-container"><span class="anchor-text">[6]</span></span></a><span><span>. However the use of these devices is not always feasible due to space constraints and to technical problems when operating outdoors. Our work made use of <a href="/topics/engineering/rgb-image" title="Learn more about RGB images from ScienceDirect's AI-generated Topic Pages" class="topic-link">RGB images</a> taken from monocular cameras which permits the greatest portability in real-world applications, given the proliferation of such cameras in </span><a href="/topics/earth-and-planetary-sciences/mobile-phone" title="Learn more about mobile phones from ScienceDirect's AI-generated Topic Pages" class="topic-link">mobile phones</a> and laptops. This introduction is thus limited to this kind of approach. A complete description of all the methods available is out of the scope of this article so we refer the reader to a recent survey </span><a class="anchor anchor-primary" href="#bib0005" name="bbib0005" data-sd-ui-side-panel-opener="true" data-xocs-content-type="reference" data-xocs-content-id="bib0005"><span class="anchor-text-container"><span class="anchor-text">[5]</span></span></a>.</div><div class="u-margin-s-bottom" id="para0011"><span>The main branches of a functional taxonomy in head pose estimation can be considered to be appearance-based methods, model-based methods, manifold <a href="/topics/biochemistry-genetics-and-molecular-biology/embedding" title="Learn more about embedding methods from ScienceDirect's AI-generated Topic Pages" class="topic-link">embedding methods</a><span> and <a href="/topics/engineering/nonlinear-regression" title="Learn more about nonlinear regression from ScienceDirect's AI-generated Topic Pages" class="topic-link">nonlinear regression</a> methods. Appearance-based methods compare the view of a person’s head with discrete models which represent pose labels </span></span><a class="anchor anchor-primary" href="#bib0007" name="bbib0007" data-sd-ui-side-panel-opener="true" data-xocs-content-type="reference" data-xocs-content-id="bib0007"><span class="anchor-text-container"><span class="anchor-text">[7]</span></span></a>, <a class="anchor anchor-primary" href="#bib0008" name="bbib0008" data-sd-ui-side-panel-opener="true" data-xocs-content-type="reference" data-xocs-content-id="bib0008"><span class="anchor-text-container"><span class="anchor-text">[8]</span></span></a><span>. With different kinds of <a href="/topics/engineering/template-matching" title="Learn more about template matching from ScienceDirect's AI-generated Topic Pages" class="topic-link">template matching</a> techniques it is possible to evaluate the similarity of the input features with the exemplar set. Appearance-based methods are quite simple to implement but suffer from some serious limitations. For instance, they cannot estimate discrete pose locations without using interpolation methods. They assume that there is a close similarity between the image and the pose space, and they can easily associate a pose based on the resemblance with a wrong model. A common solution to compensate these errors is to filter and convolve the models </span><a class="anchor anchor-primary" href="#bib0009" name="bbib0009" data-sd-ui-side-panel-opener="true" data-xocs-content-type="reference" data-xocs-content-id="bib0009"><span class="anchor-text-container"><span class="anchor-text">[9]</span></span></a>. The effect of these manipulations is to highlight some features (e.g. vertical and horizontal lines) and to remove part of the variations across the models. However this solution is expensive because it requires to manually find the right filters and to test the effects on the pose estimation. For all these limitations the use of appearance-based algorithms has been decreasing over time.</div><div class="u-margin-s-bottom" id="para0012">Model-based methods use geometric information, non-rigid facial models or landmark locations to estimate the head pose. The most common model-based approach consists in finding coplanar facial key-points and to estimate the distance from a reference coordinate system <a class="anchor anchor-primary" href="#bib0010" name="bbib0010" data-sd-ui-side-panel-opener="true" data-xocs-content-type="reference" data-xocs-content-id="bib0010"><span class="anchor-text-container"><span class="anchor-text">[10]</span></span></a>. This method requires high precision and does not work for certain degenerative angles. Another common approach consists in evaluating the position of multiple non-coplanar key-points. The head pose is estimated assuming fixed geometric relationships between the landmarks and comparing the position of the points with an average mask obtained through anthropometric measurements <a class="anchor anchor-primary" href="#bib0011" name="bbib0011" data-sd-ui-side-panel-opener="true" data-xocs-content-type="reference" data-xocs-content-id="bib0011"><span class="anchor-text-container"><span class="anchor-text">[11]</span></span></a>. Although there have been improvements in key-points detection and tracking in real world conditions <a class="anchor anchor-primary" href="#bib0012" name="bbib0012" data-sd-ui-side-panel-opener="true" data-xocs-content-type="reference" data-xocs-content-id="bib0012"><span class="anchor-text-container"><span class="anchor-text">[12]</span></span></a>, <a class="anchor anchor-primary" href="#bib0013" name="bbib0013" data-sd-ui-side-panel-opener="true" data-xocs-content-type="reference" data-xocs-content-id="bib0013"><span class="anchor-text-container"><span class="anchor-text">[13]</span></span></a>, the landmarks detection is the major limitation of this approach. In general we can say that the accuracy of model-based methods is correlated with the quality and quantity of the geometric cues extrapolated from the image. In real world scenarios occlusions can often obscure facial landmarks having a negative effect on the head pose prediction.</div><div class="u-margin-s-bottom" id="para0013"><span><span>Manifold embedding methods consider an high-dimensional image to be constrained in a low-dimensional manifold in which the head pose is estimated. <a href="/topics/engineering/dimensionality-reduction-technique" title="Learn more about Dimensionality reduction techniques from ScienceDirect's AI-generated Topic Pages" class="topic-link">Dimensionality reduction techniques</a> can be considered as part of the manifold embedding category. In the standard approach </span><a href="/topics/engineering/principal-components" title="Learn more about principal component from ScienceDirect's AI-generated Topic Pages" class="topic-link">principal component</a> analysis (PCA) is used in order to project the input images in a subspace and compare them to the models </span><a class="anchor anchor-primary" href="#bib0014" name="bbib0014" data-sd-ui-side-panel-opener="true" data-xocs-content-type="reference" data-xocs-content-id="bib0014"><span class="anchor-text-container"><span class="anchor-text">[14]</span></span></a>. The main problem of manifold embedding is that the pose must be recovered across multiple sources of variation. In this sense, other manifold embedding techniques have recently shown to be promising. In <a class="anchor anchor-primary" href="#bib0015" name="bbib0015" data-sd-ui-side-panel-opener="true" data-xocs-content-type="reference" data-xocs-content-id="bib0015"><span class="anchor-text-container"><span class="anchor-text">[15]</span></span></a> the problem of the source variation has been tackled learning a similarity kernel through geometric invariant features. This method showed a good reliability on benchmark datasets. However further research is needed in order to reach state of the art performances.</div><div class="u-margin-s-bottom" id="para0014"><span><span><span>Nonlinear regression methods use a labelled training set to create a nonlinear mapping from images to poses. We can consider <a href="/topics/engineering/convolutional-neural-network" title="Learn more about CNNs from ScienceDirect's AI-generated Topic Pages" class="topic-link">CNNs</a> as part of these methods. Nonlinear methods have many advantages. These algorithms work properly with high and </span><a href="/topics/engineering/low-resolution-image" title="Learn more about low resolution images from ScienceDirect's AI-generated Topic Pages" class="topic-link">low resolution images</a>, and they have demonstrated their representational ability in tolerating systematic errors in the training set data. For instance, an approach based on a multilayer </span><a href="/topics/earth-and-planetary-sciences/self-organizing-systems" title="Learn more about perceptron from ScienceDirect's AI-generated Topic Pages" class="topic-link">perceptron</a> </span><a class="anchor anchor-primary" href="#bib0016" name="bbib0016" data-sd-ui-side-panel-opener="true" data-xocs-content-type="reference" data-xocs-content-id="bib0016"><span class="anchor-text-container"><span class="anchor-text">[16]</span></span></a><span> had for long time the lowest reported mean <a href="/topics/engineering/angular-error" title="Learn more about angular error from ScienceDirect's AI-generated Topic Pages" class="topic-link">angular error</a> on the Prima head pose dataset </span><a class="anchor anchor-primary" href="#bib0005" name="bbib0005" data-sd-ui-side-panel-opener="true" data-xocs-content-type="reference" data-xocs-content-id="bib0005"><span class="anchor-text-container"><span class="anchor-text">[5]</span></span></a><span><span>. The <a href="/topics/engineering/main-disadvantage" title="Learn more about main disadvantages from ScienceDirect's AI-generated Topic Pages" class="topic-link">main disadvantages</a> of these methods are two. The first is the need of a consistent dataset in order to train the parameters. The second is the need of a precise head localisation before the pose estimation step. The first issue can be overcome thanks to recently released datasets containing a large number of images. The second issue can be attenuated using CNNs instead of multi layer perceptrons which guarantee a good shift and distortion invariance. In this sense CNNs could be the elective technique for mastering the head pose estimation problem, since recent advances in </span><a href="/topics/engineering/deep-learning" title="Learn more about deep learning from ScienceDirect's AI-generated Topic Pages" class="topic-link">deep learning</a> made possible to easily train complex CNNs on large datasets. Despite their potential, the use of CNNs for head pose estimation has been sporadic. An approach based on CNNs and energy-based models has been proposed for simultaneous face detection and pose estimation </span><a class="anchor anchor-primary" href="#bib0017" name="bbib0017" data-sd-ui-side-panel-opener="true" data-xocs-content-type="reference" data-xocs-content-id="bib0017"><span class="anchor-text-container"><span class="anchor-text">[17]</span></span></a><span>. The authors trained the model on a dataset containing images taken in laboratory conditions, and validated it on datasets containing frontal faces with in-plane rotations and faces in profile. The prediction of the network was limited to <a href="/topics/engineering/two-degree-of-freedom" title="Learn more about two degrees of freedom from ScienceDirect's AI-generated Topic Pages" class="topic-link">two degrees of freedom</a>. This work is valuable but it is ten years old and at that time advanced techniques for training deep networks were not available. Moreover the results relative to the head pose estimation accuracy were not included. A more recent work investigated the use of CNNs with low-resolution images from monocular cameras </span><a class="anchor anchor-primary" href="#bib0018" name="bbib0018" data-sd-ui-side-panel-opener="true" data-xocs-content-type="reference" data-xocs-content-id="bib0018"><span class="anchor-text-container"><span class="anchor-text">[18]</span></span></a>, obtaining the best reported result on the Biwi Kinect Head Pose dataset <a class="anchor anchor-primary" href="#bib0019" name="bbib0019" data-sd-ui-side-panel-opener="true" data-xocs-content-type="reference" data-xocs-content-id="bib0019"><span class="anchor-text-container"><span class="anchor-text">[19]</span></span></a>. The authors did not use any of the most recent techniques available such as dropout or adaptive methods, and their results have been validated on a single dataset that does not contain in-the-wild images. However the results obtained confirm the validity of CNNs in head pose estimation. In <a class="anchor anchor-primary" href="#bib0020" name="bbib0020" data-sd-ui-side-panel-opener="true" data-xocs-content-type="reference" data-xocs-content-id="bib0020"><span class="anchor-text-container"><span class="anchor-text">[20]</span></span></a> CNNs have been used for monitoring the driver alertness. The authors used a six-layer CNN to classify five discrete head poses: left, right, up, down and frontal. Because of the limits implicit in a discrete classification with only five poses we cannot compare this work with the others presented here. In <a class="anchor anchor-primary" href="#bib0021" name="bbib0021" data-sd-ui-side-panel-opener="true" data-xocs-content-type="reference" data-xocs-content-id="bib0021"><span class="anchor-text-container"><span class="anchor-text">[21]</span></span></a><span> the authors used deep convolutional networks to estimate the head pose in multimodal RGB-D videos. Depth information is not always available due to space constraints and to problems operating outdoors. The authors did not test the effect of different numbers of layers or parameters, moreover they did not use any kind of adaptive gradient method or <a href="/topics/engineering/regularization" title="Learn more about regularisation from ScienceDirect's AI-generated Topic Pages" class="topic-link">regularisation</a> to improve the performance of the network.</span></div><div class="u-margin-s-bottom" id="para0015">Given the lack of satisfying work we wanted to add something more complete and modern to the existing literature. In the next sections we shortly explain how CNNs work and how dropout and adaptive gradient methods can boost their performance. The next section is not intended to be an exhaustive description of the mechanics behind CNNs, instead it is a way to introduce some key concepts and to define the notation used in the rest of the article.</div></section><section id="sec0003"><h2 id="sectt0006" class="u-h4 u-margin-l-top u-margin-xs-bottom">3. Convolutional Neural Networks</h2><div class="u-margin-s-bottom" id="para0016"><span>In recent years deep convolutional networks have showed their <a href="/topics/materials-science/mechanical-strength" title="Learn more about strength from ScienceDirect's AI-generated Topic Pages" class="topic-link">strength</a> in numerous pattern recognition contests. Some remarkable achievements have been recently obtained in object detection </span><a class="anchor anchor-primary" href="#bib0022" name="bbib0022" data-sd-ui-side-panel-opener="true" data-xocs-content-type="reference" data-xocs-content-id="bib0022"><span class="anchor-text-container"><span class="anchor-text">[22]</span></span></a><span>, <a href="/topics/biochemistry-genetics-and-molecular-biology/facial-recognition" title="Learn more about facial expression recognition from ScienceDirect's AI-generated Topic Pages" class="topic-link">facial expression recognition</a> </span><a class="anchor anchor-primary" href="#bib0023" name="bbib0023" data-sd-ui-side-panel-opener="true" data-xocs-content-type="reference" data-xocs-content-id="bib0023"><span class="anchor-text-container"><span class="anchor-text">[23]</span></span></a> and scene classification <a class="anchor anchor-primary" href="#bib0024" name="bbib0024" data-sd-ui-side-panel-opener="true" data-xocs-content-type="reference" data-xocs-content-id="bib0024"><span class="anchor-text-container"><span class="anchor-text">[24]</span></span></a><span><span>. This technology is increasingly used in commercial applications such as content filtering in social networks, recommendation systems in e-commerce websites or image classifiers in web-search engines. The deep learning revolution has been driven by the diffusion of cheap <a href="/topics/engineering/graphics-processing-unit" title="Learn more about graphics processing units from ScienceDirect's AI-generated Topic Pages" class="topic-link">graphics processing units</a> (GPUs), originally used for video games. The use of GPUs speeds up matrix and vector multiplications, which are the core operations in </span><a href="/topics/engineering/neural-network-training" title="Learn more about neural network training from ScienceDirect's AI-generated Topic Pages" class="topic-link">neural network training</a>. Because the general introduction of CNNs is well established by now, we will not extend this section any further. Instead we refer the reader to the following article </span><a class="anchor anchor-primary" href="#bib0025" name="bbib0025" data-sd-ui-side-panel-opener="true" data-xocs-content-type="reference" data-xocs-content-id="bib0025"><span class="anchor-text-container"><span class="anchor-text">[25]</span></span></a>. In the next section we give a brief description of the main building blocks of a CNN, introducing the notation used in the rest of the article.</div><section id="sec0004"><h3 id="sectt0007" class="u-h4 u-margin-m-top u-margin-xs-bottom">3.1. Notation</h3><div class="u-margin-s-bottom" id="para0017">We define a CNN as an ensemble of many single units grouped in three-dimensional layers. The units inside a layer are connected to a small region of the layer before it with connections called kernels (or filters, weights, parameters). The input to a CNN is a matrix <em>X</em> of dimension <em>m</em> × <em>m</em> × <em>r</em>, where <em>m</em> is the height and width of the matrix and <em>r</em><span> is the number of channels. The <a href="/topics/engineering/convolutional-layer" title="Learn more about convolutional layer from ScienceDirect's AI-generated Topic Pages" class="topic-link">convolutional layer</a> has </span><em>k</em> kernels of size <em>n</em> × <em>n</em> × <em>q</em>, where <em>n</em> &lt; <em>m</em> and <em>q</em> ≤ <em>r</em>. The convolution multiplies each element of <em>X</em> with its local neighbours, weighted by the kernel <em>W</em>, generating <em>k</em> feature maps of size <span class="math"><span class="MathJax_Preview" style=""></span><span class="MathJax_SVG" id="MathJax-Element-39-Frame" tabindex="0" data-mathml="<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mrow is=&quot;true&quot;><mi is=&quot;true&quot;>m</mi><mo is=&quot;true&quot;>&amp;#x2212;</mo><mi is=&quot;true&quot;>n</mi><mo is=&quot;true&quot;>+</mo><mn is=&quot;true&quot;>1</mn></mrow></math>" role="presentation" style="font-size: 90%; display: inline-block; position: relative;"><svg xmlns:xlink="http://www.w3.org/1999/xlink" width="10.278ex" height="2.086ex" viewBox="0 -747.2 4425.4 898.2" role="img" focusable="false" style="vertical-align: -0.351ex;" aria-hidden="true"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><g is="true"><g is="true"><use xlink:href="#MJMATHI-6D"></use></g><g is="true" transform="translate(1100,0)"><use xlink:href="#MJMAIN-2212"></use></g><g is="true" transform="translate(2101,0)"><use xlink:href="#MJMATHI-6E"></use></g><g is="true" transform="translate(2924,0)"><use xlink:href="#MJMAIN-2B"></use></g><g is="true" transform="translate(3924,0)"><use xlink:href="#MJMAIN-31"></use></g></g></g></svg><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow is="true"><mi is="true">m</mi><mo is="true">−</mo><mi is="true">n</mi><mo is="true">+</mo><mn is="true">1</mn></mrow></math></span></span><script type="math/mml" id="MathJax-Element-39"><math><mrow is="true"><mi is="true">m</mi><mo is="true">−</mo><mi is="true">n</mi><mo is="true">+</mo><mn is="true">1</mn></mrow></math></script></span><span>. The convolutional layer is often followed by a mean or max pooling layer which permits <a href="/topics/engineering/subsamplings" title="Learn more about subsampling from ScienceDirect's AI-generated Topic Pages" class="topic-link">subsampling</a> the maps over a </span><em>p</em> × <em>p</em> local region, with 2 ≤ <em>p</em><span> ≤ 5. During the training phase the kernels are adjusted following a well-known algorithm called <a href="/topics/engineering/backpropagation" title="Learn more about backpropagation from ScienceDirect's AI-generated Topic Pages" class="topic-link">backpropagation</a> </span><a class="anchor anchor-primary" href="#bib0026" name="bbib0026" data-sd-ui-side-panel-opener="true" data-xocs-content-type="reference" data-xocs-content-id="bib0026"><span class="anchor-text-container"><span class="anchor-text">[26]</span></span></a>. The backpropagation minimises a loss (or error) function <em>J</em>(<em>w</em><span>) with an iterative process of <a href="/topics/engineering/gradient-descent" title="Learn more about gradient descent from ScienceDirect's AI-generated Topic Pages" class="topic-link">gradient descent</a> that updates </span><em>w</em> at <span class="math"><span class="MathJax_Preview" style=""></span><span class="MathJax_SVG" id="MathJax-Element-40-Frame" tabindex="0" data-mathml="<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mrow is=&quot;true&quot;><mi is=&quot;true&quot;>t</mi><mo is=&quot;true&quot;>+</mo><mn is=&quot;true&quot;>1</mn></mrow></math>" role="presentation" style="font-size: 90%; display: inline-block; position: relative;"><svg xmlns:xlink="http://www.w3.org/1999/xlink" width="4.842ex" height="2.086ex" viewBox="0 -747.2 2084.9 898.2" role="img" focusable="false" style="vertical-align: -0.351ex;" aria-hidden="true"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><g is="true"><g is="true"><use xlink:href="#MJMATHI-74"></use></g><g is="true" transform="translate(583,0)"><use xlink:href="#MJMAIN-2B"></use></g><g is="true" transform="translate(1584,0)"><use xlink:href="#MJMAIN-31"></use></g></g></g></svg><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow is="true"><mi is="true">t</mi><mo is="true">+</mo><mn is="true">1</mn></mrow></math></span></span><script type="math/mml" id="MathJax-Element-40"><math><mrow is="true"><mi is="true">t</mi><mo is="true">+</mo><mn is="true">1</mn></mrow></math></script></span><span> using the <a href="/topics/engineering/gradient-information" title="Learn more about gradient information from ScienceDirect's AI-generated Topic Pages" class="topic-link">gradient information</a> at </span><em>t</em>, as expressed in the following equation:
<span class="display"><span id="eq0001" class="formula"><span class="label">(1)</span><span class="math"><span class="MathJax_Preview" style=""></span><span class="MathJax_SVG" id="MathJax-Element-41-Frame" tabindex="0" data-mathml="<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mrow is=&quot;true&quot;><msub is=&quot;true&quot;><mi is=&quot;true&quot;>w</mi><mrow is=&quot;true&quot;><mi is=&quot;true&quot;>t</mi><mo is=&quot;true&quot;>+</mo><mn is=&quot;true&quot;>1</mn></mrow></msub><mo is=&quot;true&quot;>=</mo><msub is=&quot;true&quot;><mi is=&quot;true&quot;>w</mi><mi is=&quot;true&quot;>t</mi></msub><mo is=&quot;true&quot;>&amp;#x2212;</mo><mi is=&quot;true&quot;>&amp;#x3B1;</mi><mi is=&quot;true&quot;>&amp;#x2207;</mi><mi is=&quot;true&quot;>E</mi><mrow is=&quot;true&quot;><mo is=&quot;true&quot;>|</mo><mi is=&quot;true&quot;>J</mi><mrow is=&quot;true&quot;><mo is=&quot;true&quot;>(</mo><msub is=&quot;true&quot;><mi is=&quot;true&quot;>w</mi><mi is=&quot;true&quot;>t</mi></msub><mo is=&quot;true&quot;>)</mo></mrow><mo is=&quot;true&quot;>|</mo></mrow><mo is=&quot;true&quot;>+</mo><mi is=&quot;true&quot;>&amp;#x3BC;</mi><msub is=&quot;true&quot;><mi is=&quot;true&quot;>v</mi><mi is=&quot;true&quot;>t</mi></msub></mrow></math>" role="presentation" style="font-size: 90%; display: inline-block; position: relative;"><svg xmlns:xlink="http://www.w3.org/1999/xlink" width="32.253ex" height="2.779ex" viewBox="0 -846.5 13886.6 1196.3" role="img" focusable="false" style="vertical-align: -0.812ex;" aria-hidden="true"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><g is="true"><g is="true"><g is="true"><use xlink:href="#MJMATHI-77"></use></g><g is="true" transform="translate(716,-150)"><g is="true"><use transform="scale(0.707)" xlink:href="#MJMATHI-74"></use></g><g is="true" transform="translate(255,0)"><use transform="scale(0.707)" xlink:href="#MJMAIN-2B"></use></g><g is="true" transform="translate(806,0)"><use transform="scale(0.707)" xlink:href="#MJMAIN-31"></use></g></g></g><g is="true" transform="translate(2254,0)"><use xlink:href="#MJMAIN-3D"></use></g><g is="true" transform="translate(3310,0)"><g is="true"><use xlink:href="#MJMATHI-77"></use></g><g is="true" transform="translate(716,-150)"><use transform="scale(0.707)" xlink:href="#MJMATHI-74"></use></g></g><g is="true" transform="translate(4604,0)"><use xlink:href="#MJMAIN-2212"></use></g><g is="true" transform="translate(5605,0)"><use xlink:href="#MJMATHI-3B1"></use></g><g is="true" transform="translate(6246,0)"><use xlink:href="#MJMAIN-2207"></use></g><g is="true" transform="translate(7079,0)"><use xlink:href="#MJMATHI-45"></use></g><g is="true" transform="translate(8010,0)"><use xlink:href="#MJMAIN-7C" is="true"></use><g is="true" transform="translate(278,0)"><use xlink:href="#MJMATHI-4A"></use></g><g is="true" transform="translate(1078,0)"><g is="true"><use xlink:href="#MJMAIN-28"></use></g><g is="true" transform="translate(389,0)"><g is="true"><use xlink:href="#MJMATHI-77"></use></g><g is="true" transform="translate(716,-150)"><use transform="scale(0.707)" xlink:href="#MJMATHI-74"></use></g></g><g is="true" transform="translate(1461,0)"><use xlink:href="#MJMAIN-29"></use></g></g><use xlink:href="#MJMAIN-7C" is="true" x="2929" y="-1"></use></g><g is="true" transform="translate(11441,0)"><use xlink:href="#MJMAIN-2B"></use></g><g is="true" transform="translate(12442,0)"><use xlink:href="#MJMATHI-3BC"></use></g><g is="true" transform="translate(13045,0)"><g is="true"><use xlink:href="#MJMATHI-76"></use></g><g is="true" transform="translate(485,-150)"><use transform="scale(0.707)" xlink:href="#MJMATHI-74"></use></g></g></g></g></svg><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow is="true"><msub is="true"><mi is="true">w</mi><mrow is="true"><mi is="true">t</mi><mo is="true">+</mo><mn is="true">1</mn></mrow></msub><mo is="true">=</mo><msub is="true"><mi is="true">w</mi><mi is="true">t</mi></msub><mo is="true">−</mo><mi is="true">α</mi><mi is="true">∇</mi><mi is="true">E</mi><mrow is="true"><mo is="true">|</mo><mi is="true">J</mi><mrow is="true"><mo is="true">(</mo><msub is="true"><mi is="true">w</mi><mi is="true">t</mi></msub><mo is="true">)</mo></mrow><mo is="true">|</mo></mrow><mo is="true">+</mo><mi is="true">μ</mi><msub is="true"><mi is="true">v</mi><mi is="true">t</mi></msub></mrow></math></span></span><script type="math/mml" id="MathJax-Element-41"><math><mrow is="true"><msub is="true"><mi is="true">w</mi><mrow is="true"><mi is="true">t</mi><mo is="true">+</mo><mn is="true">1</mn></mrow></msub><mo is="true">=</mo><msub is="true"><mi is="true">w</mi><mi is="true">t</mi></msub><mo is="true">−</mo><mi is="true">α</mi><mi is="true">∇</mi><mi is="true">E</mi><mrow is="true"><mo is="true">|</mo><mi is="true">J</mi><mrow is="true"><mo is="true">(</mo><msub is="true"><mi is="true">w</mi><mi is="true">t</mi></msub><mo is="true">)</mo></mrow><mo is="true">|</mo></mrow><mo is="true">+</mo><mi is="true">μ</mi><msub is="true"><mi is="true">v</mi><mi is="true">t</mi></msub></mrow></math></script></span></span></span></div><div class="u-margin-s-bottom" id="para0018">The expectation is approximated with the cost and gradient over the full training set. The value <em>α</em> is called learning rate and corresponds to the step taken by the algorithm in the direction of the gradient. The value <em>μ</em><span> ∈ [0, 1] is called momentum and is a technique for accumulating a <a href="/topics/materials-science/velocity-vector" title="Learn more about velocity vector from ScienceDirect's AI-generated Topic Pages" class="topic-link">velocity vector</a> </span><em>v</em><span><span> in the direction of persistent reduction of the loss function. A variation of the standard gradient descent is called <a href="/topics/earth-and-planetary-sciences/stochastic-gradient-descent" title="Learn more about Stochastic Gradient Descent from ScienceDirect's AI-generated Topic Pages" class="topic-link">Stochastic Gradient Descent</a> (SGD). The SGD computes the gradient using a few training examples or mini-batches instead of the whole training set. Using the </span><a href="/topics/engineering/stochastic-approach" title="Learn more about stochastic approach from ScienceDirect's AI-generated Topic Pages" class="topic-link">stochastic approach</a> the variance is reduced leading to a more stable convergence.</span></div><div class="u-margin-s-bottom" id="para0019">There are different kinds of loss functions. In our experiments we used the sum of squares of the differences between the target value <em>y</em> and the estimated value <span class="math"><span class="MathJax_Preview" style=""></span><span class="MathJax_SVG" id="MathJax-Element-42-Frame" tabindex="0" data-mathml="<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mover accent=&quot;true&quot; is=&quot;true&quot;><mi is=&quot;true&quot;>y</mi><mo is=&quot;true&quot;>^</mo></mover></math>" role="presentation" style="font-size: 90%; display: inline-block; position: relative;"><svg xmlns:xlink="http://www.w3.org/1999/xlink" width="1.302ex" height="2.432ex" viewBox="0 -747.2 560.7 1047.3" role="img" focusable="false" style="vertical-align: -0.697ex;" aria-hidden="true"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><g is="true"><g is="true" transform="translate(1,0)"><use xlink:href="#MJMATHI-79"></use></g><use xlink:href="#MJMAIN-2C6" is="true" x="60" y="-12"></use></g></g></svg><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><mover accent="true" is="true"><mi is="true">y</mi><mo is="true">^</mo></mover></math></span></span><script type="math/mml" id="MathJax-Element-42"><math><mover accent="true" is="true"><mi is="true">y</mi><mo is="true">^</mo></mover></math></script></span>:
<span class="display"><span id="eq0002" class="formula"><span class="label">(2)</span><span class="math"><span class="MathJax_Preview" style=""></span><span class="MathJax_SVG" id="MathJax-Element-43-Frame" tabindex="0" data-mathml="<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mrow is=&quot;true&quot;><mi is=&quot;true&quot;>J</mi><mrow is=&quot;true&quot;><mo is=&quot;true&quot;>(</mo><mi is=&quot;true&quot;>w</mi><mo is=&quot;true&quot;>)</mo></mrow><mo is=&quot;true&quot;>=</mo><munderover is=&quot;true&quot;><mo is=&quot;true&quot;>&amp;#x2211;</mo><mrow is=&quot;true&quot;><mi is=&quot;true&quot;>n</mi><mo is=&quot;true&quot;>=</mo><mn is=&quot;true&quot;>1</mn></mrow><mi is=&quot;true&quot;>N</mi></munderover><msup is=&quot;true&quot;><mrow is=&quot;true&quot;><mo is=&quot;true&quot;>(</mo><msub is=&quot;true&quot;><mi is=&quot;true&quot;>y</mi><mi is=&quot;true&quot;>n</mi></msub><mo is=&quot;true&quot;>&amp;#x2212;</mo><msub is=&quot;true&quot;><mover accent=&quot;true&quot; is=&quot;true&quot;><mi is=&quot;true&quot;>y</mi><mo is=&quot;true&quot;>^</mo></mover><mi is=&quot;true&quot;>n</mi></msub><mo is=&quot;true&quot;>)</mo></mrow><mn is=&quot;true&quot;>2</mn></msup><mo is=&quot;true&quot;>+</mo><mi is=&quot;true&quot;>&amp;#x3BB;</mi><munderover is=&quot;true&quot;><mo is=&quot;true&quot;>&amp;#x2211;</mo><mrow is=&quot;true&quot;><mi is=&quot;true&quot;>l</mi><mo is=&quot;true&quot;>=</mo><mn is=&quot;true&quot;>1</mn></mrow><mi is=&quot;true&quot;>L</mi></munderover><msubsup is=&quot;true&quot;><mi is=&quot;true&quot;>w</mi><mrow is=&quot;true&quot;><mi is=&quot;true&quot;>l</mi></mrow><mn is=&quot;true&quot;>2</mn></msubsup></mrow></math>" role="presentation" style="font-size: 90%; display: inline-block; position: relative;"><svg xmlns:xlink="http://www.w3.org/1999/xlink" width="38.138ex" height="3.355ex" viewBox="0 -1045.3 16420.3 1444.7" role="img" focusable="false" style="vertical-align: -0.928ex;" aria-hidden="true"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><g is="true"><g is="true"><use xlink:href="#MJMATHI-4A"></use></g><g is="true" transform="translate(800,0)"><g is="true"><use xlink:href="#MJMAIN-28"></use></g><g is="true" transform="translate(389,0)"><use xlink:href="#MJMATHI-77"></use></g><g is="true" transform="translate(1106,0)"><use xlink:href="#MJMAIN-29"></use></g></g><g is="true" transform="translate(2573,0)"><use xlink:href="#MJMAIN-3D"></use></g><g is="true" transform="translate(3629,0)"><g is="true"><use xlink:href="#MJSZ1-2211"></use></g><g is="true" transform="translate(1056,477)"><use transform="scale(0.707)" xlink:href="#MJMATHI-4E"></use></g><g is="true" transform="translate(1056,-287)"><g is="true"><use transform="scale(0.707)" xlink:href="#MJMATHI-6E"></use></g><g is="true" transform="translate(424,0)"><use transform="scale(0.707)" xlink:href="#MJMAIN-3D"></use></g><g is="true" transform="translate(975,0)"><use transform="scale(0.707)" xlink:href="#MJMAIN-31"></use></g></g></g><g is="true" transform="translate(6281,0)"><g is="true"><g is="true"><use xlink:href="#MJMAIN-28"></use></g><g is="true" transform="translate(389,0)"><g is="true"><use xlink:href="#MJMATHI-79"></use></g><g is="true" transform="translate(490,-150)"><use transform="scale(0.707)" xlink:href="#MJMATHI-6E"></use></g></g><g is="true" transform="translate(1626,0)"><use xlink:href="#MJMAIN-2212"></use></g><g is="true" transform="translate(2627,0)"><g is="true"><g is="true" transform="translate(1,0)"><use xlink:href="#MJMATHI-79"></use></g><use xlink:href="#MJMAIN-2C6" is="true" x="60" y="-12"></use></g><g is="true" transform="translate(560,-242)"><use transform="scale(0.707)" xlink:href="#MJMATHI-6E"></use></g></g><g is="true" transform="translate(3712,0)"><use xlink:href="#MJMAIN-29"></use></g></g><g is="true" transform="translate(4102,477)"><use transform="scale(0.707)" xlink:href="#MJMAIN-32"></use></g></g><g is="true" transform="translate(11060,0)"><use xlink:href="#MJMAIN-2B"></use></g><g is="true" transform="translate(12061,0)"><use xlink:href="#MJMATHI-3BB"></use></g><g is="true" transform="translate(12811,0)"><g is="true"><use xlink:href="#MJSZ1-2211"></use></g><g is="true" transform="translate(1056,477)"><use transform="scale(0.707)" xlink:href="#MJMATHI-4C"></use></g><g is="true" transform="translate(1056,-287)"><g is="true"><use transform="scale(0.707)" xlink:href="#MJMATHI-6C"></use></g><g is="true" transform="translate(211,0)"><use transform="scale(0.707)" xlink:href="#MJMAIN-3D"></use></g><g is="true" transform="translate(761,0)"><use transform="scale(0.707)" xlink:href="#MJMAIN-31"></use></g></g></g><g is="true" transform="translate(15249,0)"><g is="true"><use xlink:href="#MJMATHI-77"></use></g><g is="true" transform="translate(716,345)"><use transform="scale(0.707)" xlink:href="#MJMAIN-32"></use></g><g is="true" transform="translate(716,-328)"><g is="true"><use transform="scale(0.707)" xlink:href="#MJMATHI-6C"></use></g></g></g></g></g></svg><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow is="true"><mi is="true">J</mi><mrow is="true"><mo is="true">(</mo><mi is="true">w</mi><mo is="true">)</mo></mrow><mo is="true">=</mo><munderover is="true"><mo is="true">∑</mo><mrow is="true"><mi is="true">n</mi><mo is="true">=</mo><mn is="true">1</mn></mrow><mi is="true">N</mi></munderover><msup is="true"><mrow is="true"><mo is="true">(</mo><msub is="true"><mi is="true">y</mi><mi is="true">n</mi></msub><mo is="true">−</mo><msub is="true"><mover accent="true" is="true"><mi is="true">y</mi><mo is="true">^</mo></mover><mi is="true">n</mi></msub><mo is="true">)</mo></mrow><mn is="true">2</mn></msup><mo is="true">+</mo><mi is="true">λ</mi><munderover is="true"><mo is="true">∑</mo><mrow is="true"><mi is="true">l</mi><mo is="true">=</mo><mn is="true">1</mn></mrow><mi is="true">L</mi></munderover><msubsup is="true"><mi is="true">w</mi><mrow is="true"><mi is="true">l</mi></mrow><mn is="true">2</mn></msubsup></mrow></math></span></span><script type="math/mml" id="MathJax-Element-43"><math><mrow is="true"><mi is="true">J</mi><mrow is="true"><mo is="true">(</mo><mi is="true">w</mi><mo is="true">)</mo></mrow><mo is="true">=</mo><munderover is="true"><mo is="true">∑</mo><mrow is="true"><mi is="true">n</mi><mo is="true">=</mo><mn is="true">1</mn></mrow><mi is="true">N</mi></munderover><msup is="true"><mrow is="true"><mo is="true">(</mo><msub is="true"><mi is="true">y</mi><mi is="true">n</mi></msub><mo is="true">−</mo><msub is="true"><mover accent="true" is="true"><mi is="true">y</mi><mo is="true">^</mo></mover><mi is="true">n</mi></msub><mo is="true">)</mo></mrow><mn is="true">2</mn></msup><mo is="true">+</mo><mi is="true">λ</mi><munderover is="true"><mo is="true">∑</mo><mrow is="true"><mi is="true">l</mi><mo is="true">=</mo><mn is="true">1</mn></mrow><mi is="true">L</mi></munderover><msubsup is="true"><mi is="true">w</mi><mrow is="true"><mi is="true">l</mi></mrow><mn is="true">2</mn></msubsup></mrow></math></script></span></span></span></div><div class="u-margin-s-bottom" id="para0020">The additive factor <em>λ</em> is an <em>L</em><span>2 <a href="/topics/engineering/regularization" title="Learn more about regularisation from ScienceDirect's AI-generated Topic Pages" class="topic-link">regularisation</a> term, used in each hidden layer </span><em>l</em> to prevent a very large growth of the parameters during the minimisation process.</div><div class="u-margin-s-bottom" id="para0021">In the next sections we will focus on some recent techniques developed by the deep learning community in the very last few years, which made the training of deep architectures more manageable leading to better results. These techniques are dropout and adaptive gradient methods.</div></section><section id="sec0005"><h3 id="sectt0008" class="u-h4 u-margin-m-top u-margin-xs-bottom">3.2. Dropout</h3><div class="u-margin-s-bottom" id="para0022">In networks with a large number of parameters the generalisation on a new set of data can be compromised due to memorisation of the training set which leads to overfitting. Dropout <a class="anchor anchor-primary" href="#bib0027" name="bbib0027" data-sd-ui-side-panel-opener="true" data-xocs-content-type="reference" data-xocs-content-id="bib0027"><span class="anchor-text-container"><span class="anchor-text">[27]</span></span></a> addresses this problem by randomly dropping units and connections during the training phase, preventing co-adaptation. We can summarise the operations involved in dropout in a few lines. Let’s define <em>r</em><span> as a vector of Bernoulli <a href="/topics/engineering/random-variable-xi" title="Learn more about random variables from ScienceDirect's AI-generated Topic Pages" class="topic-link">random variables</a>, where each variable has probability </span><em>p</em> of being 1 and a probability <span class="math"><span class="MathJax_Preview" style=""></span><span class="MathJax_SVG" id="MathJax-Element-44-Frame" tabindex="0" data-mathml="<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mrow is=&quot;true&quot;><mn is=&quot;true&quot;>1</mn><mo is=&quot;true&quot;>&amp;#x2212;</mo><mi is=&quot;true&quot;>p</mi></mrow></math>" role="presentation" style="font-size: 90%; display: inline-block; position: relative;"><svg xmlns:xlink="http://www.w3.org/1999/xlink" width="5.172ex" height="2.317ex" viewBox="0 -747.2 2226.9 997.6" role="img" focusable="false" style="vertical-align: -0.582ex;" aria-hidden="true"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><g is="true"><g is="true"><use xlink:href="#MJMAIN-31"></use></g><g is="true" transform="translate(722,0)"><use xlink:href="#MJMAIN-2212"></use></g><g is="true" transform="translate(1723,0)"><use xlink:href="#MJMATHI-70"></use></g></g></g></svg><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow is="true"><mn is="true">1</mn><mo is="true">−</mo><mi is="true">p</mi></mrow></math></span></span><script type="math/mml" id="MathJax-Element-44"><math><mrow is="true"><mn is="true">1</mn><mo is="true">−</mo><mi is="true">p</mi></mrow></math></script></span> of being 0. For each hidden layer <em>l</em> the vector <em>r</em> is sampled and then multiplied elementwise with <em>y</em> the output vector of that layer. The result is a thinned vector <span class="math"><span class="MathJax_Preview" style=""></span><span class="MathJax_SVG" id="MathJax-Element-45-Frame" tabindex="0" data-mathml="<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mover accent=&quot;true&quot; is=&quot;true&quot;><mi is=&quot;true&quot;>y</mi><mo is=&quot;true&quot;>&amp;#x2DC;</mo></mover></math>" role="presentation" style="font-size: 90%; display: inline-block; position: relative;"><svg xmlns:xlink="http://www.w3.org/1999/xlink" width="1.302ex" height="2.317ex" viewBox="0 -697.5 560.7 997.6" role="img" focusable="false" style="vertical-align: -0.697ex;" aria-hidden="true"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><g is="true"><g is="true" transform="translate(1,0)"><use xlink:href="#MJMATHI-79"></use></g><use xlink:href="#MJMAIN-2DC" is="true" x="60" y="-46"></use></g></g></svg><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><mover accent="true" is="true"><mi is="true">y</mi><mo is="true">˜</mo></mover></math></span></span><script type="math/mml" id="MathJax-Element-45"><math><mover accent="true" is="true"><mi is="true">y</mi><mo is="true">˜</mo></mover></math></script></span>:
<span class="display"><span id="eq0003" class="formula"><span class="label">(3)</span><span class="math"><span class="MathJax_Preview" style=""></span><span class="MathJax_SVG" id="MathJax-Element-46-Frame" tabindex="0" data-mathml="<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mtable is=&quot;true&quot;><mtr is=&quot;true&quot;><mtd columnalign=&quot;left&quot; is=&quot;true&quot;><mrow is=&quot;true&quot;><msup is=&quot;true&quot;><mi is=&quot;true&quot;>r</mi><mrow is=&quot;true&quot;><mo is=&quot;true&quot;>(</mo><mi is=&quot;true&quot;>l</mi><mo is=&quot;true&quot;>)</mo></mrow></msup><mo is=&quot;true&quot;>&amp;#x223C;</mo><mi is=&quot;true&quot;>B</mi><mi is=&quot;true&quot;>e</mi><mi is=&quot;true&quot;>r</mi><mi is=&quot;true&quot;>n</mi><mi is=&quot;true&quot;>o</mi><mi is=&quot;true&quot;>u</mi><mi is=&quot;true&quot;>l</mi><mi is=&quot;true&quot;>l</mi><mi is=&quot;true&quot;>i</mi><mrow is=&quot;true&quot;><mo is=&quot;true&quot;>(</mo><mi is=&quot;true&quot;>p</mi><mo is=&quot;true&quot;>)</mo></mrow></mrow></mtd></mtr><mtr is=&quot;true&quot;><mtd is=&quot;true&quot; /></mtr><mtr is=&quot;true&quot;><mtd columnalign=&quot;left&quot; is=&quot;true&quot;><mrow is=&quot;true&quot;><msup is=&quot;true&quot;><mover accent=&quot;true&quot; is=&quot;true&quot;><mi is=&quot;true&quot;>y</mi><mo is=&quot;true&quot;>&amp;#x2DC;</mo></mover><mrow is=&quot;true&quot;><mo is=&quot;true&quot;>(</mo><mi is=&quot;true&quot;>l</mi><mo is=&quot;true&quot;>)</mo></mrow></msup><mo is=&quot;true&quot;>=</mo><msup is=&quot;true&quot;><mi is=&quot;true&quot;>r</mi><mrow is=&quot;true&quot;><mo is=&quot;true&quot;>(</mo><mi is=&quot;true&quot;>l</mi><mo is=&quot;true&quot;>)</mo></mrow></msup><mo is=&quot;true&quot;>&amp;#x2218;</mo><msup is=&quot;true&quot;><mi is=&quot;true&quot;>y</mi><mrow is=&quot;true&quot;><mo is=&quot;true&quot;>(</mo><mi is=&quot;true&quot;>l</mi><mo is=&quot;true&quot;>)</mo></mrow></msup></mrow></mtd></mtr></mtable></math>" role="presentation" style="font-size: 90%; display: inline-block; position: relative;"><svg xmlns:xlink="http://www.w3.org/1999/xlink" width="20.193ex" height="9.932ex" viewBox="0 -2386.6 8694 4276.4" role="img" focusable="false" style="vertical-align: -4.389ex;" aria-hidden="true"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><g is="true" transform="translate(167,0)"><g transform="translate(-16,0)"><g is="true" transform="translate(0,1409)"><g is="true"><g is="true"><g is="true"><use xlink:href="#MJMATHI-72"></use></g><g is="true" transform="translate(451,362)"><g is="true"><use transform="scale(0.707)" xlink:href="#MJMAIN-28"></use></g><g is="true" transform="translate(275,0)"><use transform="scale(0.707)" xlink:href="#MJMATHI-6C"></use></g><g is="true" transform="translate(486,0)"><use transform="scale(0.707)" xlink:href="#MJMAIN-29"></use></g></g></g><g is="true" transform="translate(1591,0)"><use xlink:href="#MJMAIN-223C"></use></g><g is="true" transform="translate(2647,0)"><use xlink:href="#MJMATHI-42"></use></g><g is="true" transform="translate(3406,0)"><use xlink:href="#MJMATHI-65"></use></g><g is="true" transform="translate(3873,0)"><use xlink:href="#MJMATHI-72"></use></g><g is="true" transform="translate(4324,0)"><use xlink:href="#MJMATHI-6E"></use></g><g is="true" transform="translate(4925,0)"><use xlink:href="#MJMATHI-6F"></use></g><g is="true" transform="translate(5410,0)"><use xlink:href="#MJMATHI-75"></use></g><g is="true" transform="translate(5983,0)"><use xlink:href="#MJMATHI-6C"></use></g><g is="true" transform="translate(6281,0)"><use xlink:href="#MJMATHI-6C"></use></g><g is="true" transform="translate(6580,0)"><use xlink:href="#MJMATHI-69"></use></g><g is="true" transform="translate(7092,0)"><g is="true"><use xlink:href="#MJMAIN-28"></use></g><g is="true" transform="translate(389,0)"><use xlink:href="#MJMATHI-70"></use></g><g is="true" transform="translate(893,0)"><use xlink:href="#MJMAIN-29"></use></g></g></g></g><g is="true"></g><g is="true" transform="translate(0,-1597)"><g is="true"><g is="true"><g is="true"><g is="true" transform="translate(1,0)"><use xlink:href="#MJMATHI-79"></use></g><use xlink:href="#MJMAIN-2DC" is="true" x="60" y="-46"></use></g><g is="true" transform="translate(560,362)"><g is="true"><use transform="scale(0.707)" xlink:href="#MJMAIN-28"></use></g><g is="true" transform="translate(275,0)"><use transform="scale(0.707)" xlink:href="#MJMATHI-6C"></use></g><g is="true" transform="translate(486,0)"><use transform="scale(0.707)" xlink:href="#MJMAIN-29"></use></g></g></g><g is="true" transform="translate(1700,0)"><use xlink:href="#MJMAIN-3D"></use></g><g is="true" transform="translate(2756,0)"><g is="true"><use xlink:href="#MJMATHI-72"></use></g><g is="true" transform="translate(451,362)"><g is="true"><use transform="scale(0.707)" xlink:href="#MJMAIN-28"></use></g><g is="true" transform="translate(275,0)"><use transform="scale(0.707)" xlink:href="#MJMATHI-6C"></use></g><g is="true" transform="translate(486,0)"><use transform="scale(0.707)" xlink:href="#MJMAIN-29"></use></g></g></g><g is="true" transform="translate(4292,0)"><use xlink:href="#MJMAIN-2218"></use></g><g is="true" transform="translate(5014,0)"><g is="true"><use xlink:href="#MJMATHI-79"></use></g><g is="true" transform="translate(499,362)"><g is="true"><use transform="scale(0.707)" xlink:href="#MJMAIN-28"></use></g><g is="true" transform="translate(275,0)"><use transform="scale(0.707)" xlink:href="#MJMATHI-6C"></use></g><g is="true" transform="translate(486,0)"><use transform="scale(0.707)" xlink:href="#MJMAIN-29"></use></g></g></g></g></g></g></g></g></svg><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><mtable is="true"><mtr is="true"><mtd columnalign="left" is="true"><mrow is="true"><msup is="true"><mi is="true">r</mi><mrow is="true"><mo is="true">(</mo><mi is="true">l</mi><mo is="true">)</mo></mrow></msup><mo is="true">∼</mo><mi is="true">B</mi><mi is="true">e</mi><mi is="true">r</mi><mi is="true">n</mi><mi is="true">o</mi><mi is="true">u</mi><mi is="true">l</mi><mi is="true">l</mi><mi is="true">i</mi><mrow is="true"><mo is="true">(</mo><mi is="true">p</mi><mo is="true">)</mo></mrow></mrow></mtd></mtr><mtr is="true"><mtd is="true"></mtd></mtr><mtr is="true"><mtd columnalign="left" is="true"><mrow is="true"><msup is="true"><mover accent="true" is="true"><mi is="true">y</mi><mo is="true">˜</mo></mover><mrow is="true"><mo is="true">(</mo><mi is="true">l</mi><mo is="true">)</mo></mrow></msup><mo is="true">=</mo><msup is="true"><mi is="true">r</mi><mrow is="true"><mo is="true">(</mo><mi is="true">l</mi><mo is="true">)</mo></mrow></msup><mo is="true">∘</mo><msup is="true"><mi is="true">y</mi><mrow is="true"><mo is="true">(</mo><mi is="true">l</mi><mo is="true">)</mo></mrow></msup></mrow></mtd></mtr></mtable></math></span></span><script type="math/mml" id="MathJax-Element-46"><math><mtable is="true"><mtr is="true"><mtd columnalign="left" is="true"><mrow is="true"><msup is="true"><mi is="true">r</mi><mrow is="true"><mo is="true">(</mo><mi is="true">l</mi><mo is="true">)</mo></mrow></msup><mo is="true">∼</mo><mi is="true">B</mi><mi is="true">e</mi><mi is="true">r</mi><mi is="true">n</mi><mi is="true">o</mi><mi is="true">u</mi><mi is="true">l</mi><mi is="true">l</mi><mi is="true">i</mi><mrow is="true"><mo is="true">(</mo><mi is="true">p</mi><mo is="true">)</mo></mrow></mrow></mtd></mtr><mtr is="true"><mtd is="true"></mtd></mtr><mtr is="true"><mtd columnalign="left" is="true"><mrow is="true"><msup is="true"><mover accent="true" is="true"><mi is="true">y</mi><mo is="true">˜</mo></mover><mrow is="true"><mo is="true">(</mo><mi is="true">l</mi><mo is="true">)</mo></mrow></msup><mo is="true">=</mo><msup is="true"><mi is="true">r</mi><mrow is="true"><mo is="true">(</mo><mi is="true">l</mi><mo is="true">)</mo></mrow></msup><mo is="true">∘</mo><msup is="true"><mi is="true">y</mi><mrow is="true"><mo is="true">(</mo><mi is="true">l</mi><mo is="true">)</mo></mrow></msup></mrow></mtd></mtr></mtable></math></script></span></span></span></div><div class="u-margin-s-bottom"><div id="para0023">Experimental evidence shows how dropout introduces noise in the gradients and produces a cancellation effect <a class="anchor anchor-primary" href="#bib0027" name="bbib0027" data-sd-ui-side-panel-opener="true" data-xocs-content-type="reference" data-xocs-content-id="bib0027"><span class="anchor-text-container"><span class="anchor-text">[27]</span></span></a>. To deal with this issue it is recommended to use a higher learning rate and momentum. In order to use a higher learning rate without a very large growth of the weights, another form of regularization can be used at the same time, such as <em>L</em>2 or max-norm. The probability <em>p</em> is another hyperparameter to tune. However numerous experimental results suggest that a value of <span class="math"><span class="MathJax_Preview" style=""></span><span class="MathJax_SVG" id="MathJax-Element-47-Frame" tabindex="0" data-mathml="<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mrow is=&quot;true&quot;><mi is=&quot;true&quot;>p</mi><mo is=&quot;true&quot;>=</mo><mn is=&quot;true&quot;>0.5</mn></mrow></math>" role="presentation" style="font-size: 90%; display: inline-block; position: relative;"><svg xmlns:xlink="http://www.w3.org/1999/xlink" width="7.329ex" height="2.317ex" viewBox="-38.5 -747.2 3155.6 997.6" role="img" focusable="false" style="vertical-align: -0.582ex; margin-left: -0.089ex;" aria-hidden="true"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><g is="true"><g is="true"><use xlink:href="#MJMATHI-70"></use></g><g is="true" transform="translate(781,0)"><use xlink:href="#MJMAIN-3D"></use></g><g is="true" transform="translate(1837,0)"><use xlink:href="#MJMAIN-30"></use><use xlink:href="#MJMAIN-2E" x="500" y="0"></use><use xlink:href="#MJMAIN-35" x="779" y="0"></use></g></g></g></svg><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow is="true"><mi is="true">p</mi><mo is="true">=</mo><mn is="true">0.5</mn></mrow></math></span></span><script type="math/mml" id="MathJax-Element-47"><math><mrow is="true"><mi is="true">p</mi><mo is="true">=</mo><mn is="true">0.5</mn></mrow></math></script></span> produces the best performance <a class="anchor anchor-primary" href="#bib0027" name="bbib0027" data-sd-ui-side-panel-opener="true" data-xocs-content-type="reference" data-xocs-content-id="bib0027"><span class="anchor-text-container"><span class="anchor-text">[27]</span></span></a><span>, so we used this value in our experiments. A <a href="/topics/engineering/graphical-representation" title="Learn more about graphical representation from ScienceDirect's AI-generated Topic Pages" class="topic-link">graphical representation</a> of dropout is presented in </span><a class="anchor anchor-primary" href="#fig0001" name="bfig0001" data-sd-ui-side-panel-opener="true" data-xocs-content-type="reference" data-xocs-content-id="fig0001"><span class="anchor-text-container"><span class="anchor-text">Fig.&nbsp;1</span></span></a>.</div><figure class="figure text-xs" id="fig0001"><span><img src="https://ars.els-cdn.com/content/image/1-s2.0-S0031320317302327-gr1.jpg" height="192" alt="Fig. 1" aria-describedby="cap0001"><ol class="u-margin-s-bottom"><li><a class="anchor download-link u-font-sans anchor-primary" href="https://ars.els-cdn.com/content/image/1-s2.0-S0031320317302327-gr1_lrg.jpg" target="_blank" download="" title="Download high-res image (88KB)"><span class="anchor-text-container"><span class="anchor-text">Download: <span class="download-link-title">Download high-res image (88KB)</span></span></span></a></li><li><a class="anchor download-link u-font-sans anchor-primary" href="https://ars.els-cdn.com/content/image/1-s2.0-S0031320317302327-gr1.jpg" target="_blank" download="" title="Download full-size image"><span class="anchor-text-container"><span class="anchor-text">Download: <span class="download-link-title">Download full-size image</span></span></span></a></li></ol></span><span class="captions text-s"><span id="cap0001"><p id="spara0008"><span class="label">Fig. 1</span>. Graphical representation of the dropout process. The figure on the left represents a generic neural network composed of three layers. The figure on the right represents the same network after applying the dropout with 50% probability of keeping a unit.</p></span></span></figure></div></section><section id="sec0006"><h3 id="sectt0009" class="u-h4 u-margin-m-top u-margin-xs-bottom">3.3. Adaptive gradient methods</h3><div class="u-margin-s-bottom" id="para0024">Neural networks are not off-the-shelf algorithms, and generally the research of the best hyperparameters can be extremely time consuming. One of the most important parameters is the learning rate. When the learning rate is too high the optimisation can diverge, on the contrary if it is too low the optimisation can be slow. To solve these problems some adaptive gradient methods have been proposed recently. Adaptive gradient methods use first order information to approximate second order information and then find an optimal step size.</div><div class="u-margin-s-bottom" id="para0025">One of the best adaptive methods introduced recently is Adagrad <a class="anchor anchor-primary" href="#bib0028" name="bbib0028" data-sd-ui-side-panel-opener="true" data-xocs-content-type="reference" data-xocs-content-id="bib0028"><span class="anchor-text-container"><span class="anchor-text">[28]</span></span></a><span>. This optimiser incorporates information about the features to control the <a href="/topics/engineering/gradient-step" title="Learn more about gradient step from ScienceDirect's AI-generated Topic Pages" class="topic-link">gradient step</a>. The procedure associates a low learning rate with frequently occurring features and high learning rate with infrequent features. Therefore, the adaptation facilitates identifying the most predictive features and it is well suited for sparse data. The authors tested the algorithm on different image and text databases </span><a class="anchor anchor-primary" href="#bib0028" name="bbib0028" data-sd-ui-side-panel-opener="true" data-xocs-content-type="reference" data-xocs-content-id="bib0028"><span class="anchor-text-container"><span class="anchor-text">[28]</span></span></a>, showing how it outperforms the non-adaptive counterpart. The updating rule for the weights <em>w</em> following the Adagrad algorithm can be expressed with the following equation:
<span class="display"><span id="eq0004" class="formula"><span class="label">(4)</span><span class="math"><span class="MathJax_Preview" style=""></span><span class="MathJax_SVG" id="MathJax-Element-48-Frame" tabindex="0" data-mathml="<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mrow is=&quot;true&quot;><msub is=&quot;true&quot;><mi is=&quot;true&quot;>w</mi><mrow is=&quot;true&quot;><mi is=&quot;true&quot;>t</mi><mo is=&quot;true&quot;>+</mo><mn is=&quot;true&quot;>1</mn></mrow></msub><mo is=&quot;true&quot;>=</mo><msub is=&quot;true&quot;><mi is=&quot;true&quot;>w</mi><mi is=&quot;true&quot;>t</mi></msub><mo is=&quot;true&quot;>&amp;#x2212;</mo><mfrac is=&quot;true&quot;><mi is=&quot;true&quot;>&amp;#x3B1;</mi><msqrt is=&quot;true&quot;><mrow is=&quot;true&quot;><msub is=&quot;true&quot;><mi is=&quot;true&quot;>G</mi><mi is=&quot;true&quot;>t</mi></msub><mo is=&quot;true&quot;>+</mo><mi is=&quot;true&quot;>&amp;#x3F5;</mi></mrow></msqrt></mfrac><mo is=&quot;true&quot;>&amp;#x2299;</mo><msub is=&quot;true&quot;><mi is=&quot;true&quot;>g</mi><mi is=&quot;true&quot;>t</mi></msub></mrow></math>" role="presentation" style="font-size: 90%; display: inline-block; position: relative;"><svg xmlns:xlink="http://www.w3.org/1999/xlink" width="24.096ex" height="3.932ex" viewBox="0 -796.9 10374.7 1693.1" role="img" focusable="false" style="vertical-align: -2.082ex;" aria-hidden="true"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><g is="true"><g is="true"><g is="true"><use xlink:href="#MJMATHI-77"></use></g><g is="true" transform="translate(716,-150)"><g is="true"><use transform="scale(0.707)" xlink:href="#MJMATHI-74"></use></g><g is="true" transform="translate(255,0)"><use transform="scale(0.707)" xlink:href="#MJMAIN-2B"></use></g><g is="true" transform="translate(806,0)"><use transform="scale(0.707)" xlink:href="#MJMAIN-31"></use></g></g></g><g is="true" transform="translate(2254,0)"><use xlink:href="#MJMAIN-3D"></use></g><g is="true" transform="translate(3310,0)"><g is="true"><use xlink:href="#MJMATHI-77"></use></g><g is="true" transform="translate(716,-150)"><use transform="scale(0.707)" xlink:href="#MJMATHI-74"></use></g></g><g is="true" transform="translate(4604,0)"><use xlink:href="#MJMAIN-2212"></use></g><g is="true" transform="translate(5383,0)"><g transform="translate(342,0)"><rect stroke="none" width="2472" height="60" x="0" y="220"></rect><g is="true" transform="translate(1010,411)"><use transform="scale(0.707)" xlink:href="#MJMATHI-3B1"></use></g><g is="true" transform="translate(60,-570)"><use transform="scale(0.707)" xlink:href="#MJSZ1-221A" x="0" y="31"></use><rect stroke="none" width="1645" height="42" x="707" y="581"></rect><g transform="translate(707,0)"><g is="true"><g is="true"><g is="true"><use transform="scale(0.707)" xlink:href="#MJMATHI-47"></use></g><g is="true" transform="translate(556,-107)"><use transform="scale(0.5)" xlink:href="#MJMATHI-74"></use></g></g><g is="true" transform="translate(807,0)"><use transform="scale(0.707)" xlink:href="#MJMAIN-2B"></use></g><g is="true" transform="translate(1358,0)"><use transform="scale(0.707)" xlink:href="#MJMATHI-3F5"></use></g></g></g></g></g></g><g is="true" transform="translate(8540,0)"><use xlink:href="#MJMAIN-2299"></use></g><g is="true" transform="translate(9541,0)"><g is="true"><use xlink:href="#MJMATHI-67"></use></g><g is="true" transform="translate(477,-150)"><use transform="scale(0.707)" xlink:href="#MJMATHI-74"></use></g></g></g></g></svg><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow is="true"><msub is="true"><mi is="true">w</mi><mrow is="true"><mi is="true">t</mi><mo is="true">+</mo><mn is="true">1</mn></mrow></msub><mo is="true">=</mo><msub is="true"><mi is="true">w</mi><mi is="true">t</mi></msub><mo is="true">−</mo><mfrac is="true"><mi is="true">α</mi><msqrt is="true"><mrow is="true"><msub is="true"><mi is="true">G</mi><mi is="true">t</mi></msub><mo is="true">+</mo><mi is="true">ϵ</mi></mrow></msqrt></mfrac><mo is="true">⊙</mo><msub is="true"><mi is="true">g</mi><mi is="true">t</mi></msub></mrow></math></span></span><script type="math/mml" id="MathJax-Element-48"><math><mrow is="true"><msub is="true"><mi is="true">w</mi><mrow is="true"><mi is="true">t</mi><mo is="true">+</mo><mn is="true">1</mn></mrow></msub><mo is="true">=</mo><msub is="true"><mi is="true">w</mi><mi is="true">t</mi></msub><mo is="true">−</mo><mfrac is="true"><mi is="true">α</mi><msqrt is="true"><mrow is="true"><msub is="true"><mi is="true">G</mi><mi is="true">t</mi></msub><mo is="true">+</mo><mi is="true">ϵ</mi></mrow></msqrt></mfrac><mo is="true">⊙</mo><msub is="true"><mi is="true">g</mi><mi is="true">t</mi></msub></mrow></math></script></span></span></span></div><div class="u-margin-s-bottom" id="para0026">The matrix <em>G</em><span><span> is a <a href="/topics/engineering/diagonal-matrix" title="Learn more about diagonal matrix from ScienceDirect's AI-generated Topic Pages" class="topic-link">diagonal matrix</a> where each entry in the </span><a href="/topics/engineering/main-diagonal" title="Learn more about main diagonal from ScienceDirect's AI-generated Topic Pages" class="topic-link">main diagonal</a> is the sum of the squares of the previous gradients up to time </span><em>t</em>. The value ϵ is a small value used to avoid division by zero. The symbol ⊙ represent a matrix-vector multiplication. The main problem with Adagrad is the accumulation of squared gradients in <em>G</em> that lead to an infinitesimally small learning rate <em>α</em> and then to a loss in knowledge accumulation.</div><div class="u-margin-s-bottom" id="para0027">To solve the problem related with Adagrad an extension called Adadelta <a class="anchor anchor-primary" href="#bib0029" name="bbib0029" data-sd-ui-side-panel-opener="true" data-xocs-content-type="reference" data-xocs-content-id="bib0029"><span class="anchor-text-container"><span class="anchor-text">[29]</span></span></a> has been proposed. Adadelta does not accumulate all the past gradients but it constrains the window to a fixed interval. The denominator of the <a class="anchor anchor-primary" href="#eq0004" name="beq0004" data-sd-ui-side-panel-opener="true" data-xocs-content-type="reference" data-xocs-content-id="eq0004"><span class="anchor-text-container"><span class="anchor-text">Eq. (4)</span></span></a> is then replaced by a moving average <em>E</em>[<em>g</em><sup>2</sup>] which represents all the past squared gradients. The advantage of this solution is that the moving average depends only on the previous average and the current gradient, as follows:
<span class="display"><span id="eq0005" class="formula"><span class="label">(5)</span><span class="math"><span class="MathJax_Preview" style=""></span><span class="MathJax_SVG" id="MathJax-Element-49-Frame" tabindex="0" data-mathml="<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mrow is=&quot;true&quot;><msub is=&quot;true&quot;><mi is=&quot;true&quot;>w</mi><mrow is=&quot;true&quot;><mi is=&quot;true&quot;>t</mi><mo is=&quot;true&quot;>+</mo><mn is=&quot;true&quot;>1</mn></mrow></msub><mo is=&quot;true&quot;>=</mo><msub is=&quot;true&quot;><mi is=&quot;true&quot;>w</mi><mi is=&quot;true&quot;>t</mi></msub><mo is=&quot;true&quot;>&amp;#x2212;</mo><mfrac is=&quot;true&quot;><mi is=&quot;true&quot;>&amp;#x3B1;</mi><msqrt is=&quot;true&quot;><mrow is=&quot;true&quot;><mi is=&quot;true&quot;>E</mi><msub is=&quot;true&quot;><mrow is=&quot;true&quot;><mo is=&quot;true&quot;>[</mo><msup is=&quot;true&quot;><mi is=&quot;true&quot;>g</mi><mn is=&quot;true&quot;>2</mn></msup><mo is=&quot;true&quot;>]</mo></mrow><mi is=&quot;true&quot;>t</mi></msub><mo is=&quot;true&quot;>+</mo><mi is=&quot;true&quot;>&amp;#x3F5;</mi></mrow></msqrt></mfrac><msub is=&quot;true&quot;><mi is=&quot;true&quot;>g</mi><mi is=&quot;true&quot;>t</mi></msub></mrow></math>" role="presentation" style="font-size: 90%; display: inline-block; position: relative;"><svg xmlns:xlink="http://www.w3.org/1999/xlink" width="23.671ex" height="4.855ex" viewBox="0 -796.9 10191.4 2090.5" role="img" focusable="false" style="vertical-align: -3.005ex;" aria-hidden="true"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><g is="true"><g is="true"><g is="true"><use xlink:href="#MJMATHI-77"></use></g><g is="true" transform="translate(716,-150)"><g is="true"><use transform="scale(0.707)" xlink:href="#MJMATHI-74"></use></g><g is="true" transform="translate(255,0)"><use transform="scale(0.707)" xlink:href="#MJMAIN-2B"></use></g><g is="true" transform="translate(806,0)"><use transform="scale(0.707)" xlink:href="#MJMAIN-31"></use></g></g></g><g is="true" transform="translate(2254,0)"><use xlink:href="#MJMAIN-3D"></use></g><g is="true" transform="translate(3310,0)"><g is="true"><use xlink:href="#MJMATHI-77"></use></g><g is="true" transform="translate(716,-150)"><use transform="scale(0.707)" xlink:href="#MJMATHI-74"></use></g></g><g is="true" transform="translate(4604,0)"><use xlink:href="#MJMAIN-2212"></use></g><g is="true" transform="translate(5383,0)"><g transform="translate(342,0)"><rect stroke="none" width="3512" height="60" x="0" y="220"></rect><g is="true" transform="translate(1529,411)"><use transform="scale(0.707)" xlink:href="#MJMATHI-3B1"></use></g><g is="true" transform="translate(60,-753)"><use transform="scale(0.707)" xlink:href="#MJSZ2-221A" x="0" y="-10"></use><rect stroke="none" width="2685" height="42" x="707" y="764"></rect><g transform="translate(707,0)"><g is="true"><g is="true"><use transform="scale(0.707)" xlink:href="#MJMATHI-45"></use></g><g is="true" transform="translate(540,0)"><g is="true"><use transform="scale(0.707)" xlink:href="#MJMAIN-5B" is="true"></use><g is="true" transform="translate(196,0)"><g is="true"><use transform="scale(0.707)" xlink:href="#MJMATHI-67"></use></g><g is="true" transform="translate(340,204)"><use transform="scale(0.5)" xlink:href="#MJMAIN-32"></use></g></g><use transform="scale(0.707)" xlink:href="#MJMAIN-5D" is="true" x="1213" y="0"></use></g><g is="true" transform="translate(1055,-203)"><use transform="scale(0.5)" xlink:href="#MJMATHI-74"></use></g></g><g is="true" transform="translate(1847,0)"><use transform="scale(0.707)" xlink:href="#MJMAIN-2B"></use></g><g is="true" transform="translate(2397,0)"><use transform="scale(0.707)" xlink:href="#MJMATHI-3F5"></use></g></g></g></g></g></g><g is="true" transform="translate(9358,0)"><g is="true"><use xlink:href="#MJMATHI-67"></use></g><g is="true" transform="translate(477,-150)"><use transform="scale(0.707)" xlink:href="#MJMATHI-74"></use></g></g></g></g></svg><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow is="true"><msub is="true"><mi is="true">w</mi><mrow is="true"><mi is="true">t</mi><mo is="true">+</mo><mn is="true">1</mn></mrow></msub><mo is="true">=</mo><msub is="true"><mi is="true">w</mi><mi is="true">t</mi></msub><mo is="true">−</mo><mfrac is="true"><mi is="true">α</mi><msqrt is="true"><mrow is="true"><mi is="true">E</mi><msub is="true"><mrow is="true"><mo is="true">[</mo><msup is="true"><mi is="true">g</mi><mn is="true">2</mn></msup><mo is="true">]</mo></mrow><mi is="true">t</mi></msub><mo is="true">+</mo><mi is="true">ϵ</mi></mrow></msqrt></mfrac><msub is="true"><mi is="true">g</mi><mi is="true">t</mi></msub></mrow></math></span></span><script type="math/mml" id="MathJax-Element-49"><math><mrow is="true"><msub is="true"><mi is="true">w</mi><mrow is="true"><mi is="true">t</mi><mo is="true">+</mo><mn is="true">1</mn></mrow></msub><mo is="true">=</mo><msub is="true"><mi is="true">w</mi><mi is="true">t</mi></msub><mo is="true">−</mo><mfrac is="true"><mi is="true">α</mi><msqrt is="true"><mrow is="true"><mi is="true">E</mi><msub is="true"><mrow is="true"><mo is="true">[</mo><msup is="true"><mi is="true">g</mi><mn is="true">2</mn></msup><mo is="true">]</mo></mrow><mi is="true">t</mi></msub><mo is="true">+</mo><mi is="true">ϵ</mi></mrow></msqrt></mfrac><msub is="true"><mi is="true">g</mi><mi is="true">t</mi></msub></mrow></math></script></span></span></span></div><div class="u-margin-s-bottom" id="para0028">As experimentally shown in <a class="anchor anchor-primary" href="#bib0029" name="bbib0029" data-sd-ui-side-panel-opener="true" data-xocs-content-type="reference" data-xocs-content-id="bib0029"><span class="anchor-text-container"><span class="anchor-text">[29]</span></span></a> Adadelta is particularly robust and it guarantees convergence with different learning rate values. Another effective method to solve the Adagrad issue is an unpublished algorithm called RMSProp <a class="anchor anchor-primary" href="#bib0030" name="bbib0030" data-sd-ui-side-panel-opener="true" data-xocs-content-type="reference" data-xocs-content-id="bib0030"><span class="anchor-text-container"><span class="anchor-text">[30]</span></span></a>. RMSProp has an updating rule which is similar to <a class="anchor anchor-primary" href="#eq0005" name="beq0005" data-sd-ui-side-panel-opener="true" data-xocs-content-type="reference" data-xocs-content-id="eq0005"><span class="anchor-text-container"><span class="anchor-text">Eq. (5)</span></span></a> with the only difference being that it introduces a decaying value <em>γ</em> which specifies how long the old gradients in <em>E</em>[<em>g</em><sup>2</sup>] are kept. The value <em>E</em>[<em>g</em><sup>2</sup>] at time <em>t</em> is then updated in this way:
<span class="display"><span id="eq0006" class="formula"><span class="label">(6)</span><span class="math"><span class="MathJax_Preview" style=""></span><span class="MathJax_SVG" id="MathJax-Element-50-Frame" tabindex="0" data-mathml="<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mrow is=&quot;true&quot;><mi is=&quot;true&quot;>E</mi><msub is=&quot;true&quot;><mrow is=&quot;true&quot;><mo is=&quot;true&quot;>[</mo><msup is=&quot;true&quot;><mi is=&quot;true&quot;>g</mi><mn is=&quot;true&quot;>2</mn></msup><mo is=&quot;true&quot;>]</mo></mrow><mi is=&quot;true&quot;>t</mi></msub><mo is=&quot;true&quot;>=</mo><mi is=&quot;true&quot;>&amp;#x3B3;</mi><mi is=&quot;true&quot;>E</mi><msub is=&quot;true&quot;><mrow is=&quot;true&quot;><mo is=&quot;true&quot;>[</mo><msup is=&quot;true&quot;><mi is=&quot;true&quot;>g</mi><mn is=&quot;true&quot;>2</mn></msup><mo is=&quot;true&quot;>]</mo></mrow><mrow is=&quot;true&quot;><mi is=&quot;true&quot;>t</mi><mo is=&quot;true&quot;>&amp;#x2212;</mo><mn is=&quot;true&quot;>1</mn></mrow></msub><mo is=&quot;true&quot;>+</mo><msubsup is=&quot;true&quot;><mi is=&quot;true&quot;>g</mi><mi is=&quot;true&quot;>t</mi><mn is=&quot;true&quot;>2</mn></msubsup></mrow></math>" role="presentation" style="font-size: 90%; display: inline-block; position: relative;"><svg xmlns:xlink="http://www.w3.org/1999/xlink" width="24.901ex" height="3.355ex" viewBox="0 -945.9 10721.2 1444.7" role="img" focusable="false" style="vertical-align: -1.158ex;" aria-hidden="true"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><g is="true"><g is="true"><use xlink:href="#MJMATHI-45"></use></g><g is="true" transform="translate(764,0)"><g is="true"><use xlink:href="#MJSZ1-5B" is="true"></use><g is="true" transform="translate(417,0)"><g is="true"><use xlink:href="#MJMATHI-67"></use></g><g is="true" transform="translate(481,362)"><use transform="scale(0.707)" xlink:href="#MJMAIN-32"></use></g></g><use xlink:href="#MJSZ1-5D" is="true" x="1352" y="-1"></use></g><g is="true" transform="translate(1770,-386)"><use transform="scale(0.707)" xlink:href="#MJMATHI-74"></use></g></g><g is="true" transform="translate(3168,0)"><use xlink:href="#MJMAIN-3D"></use></g><g is="true" transform="translate(4224,0)"><use xlink:href="#MJMATHI-3B3"></use></g><g is="true" transform="translate(4768,0)"><use xlink:href="#MJMATHI-45"></use></g><g is="true" transform="translate(5532,0)"><g is="true"><use xlink:href="#MJSZ1-5B" is="true"></use><g is="true" transform="translate(417,0)"><g is="true"><use xlink:href="#MJMATHI-67"></use></g><g is="true" transform="translate(481,362)"><use transform="scale(0.707)" xlink:href="#MJMAIN-32"></use></g></g><use xlink:href="#MJSZ1-5D" is="true" x="1352" y="-1"></use></g><g is="true" transform="translate(1770,-386)"><g is="true"><use transform="scale(0.707)" xlink:href="#MJMATHI-74"></use></g><g is="true" transform="translate(255,0)"><use transform="scale(0.707)" xlink:href="#MJMAIN-2212"></use></g><g is="true" transform="translate(806,0)"><use transform="scale(0.707)" xlink:href="#MJMAIN-31"></use></g></g></g><g is="true" transform="translate(8785,0)"><use xlink:href="#MJMAIN-2B"></use></g><g is="true" transform="translate(9785,0)"><g is="true"><use xlink:href="#MJMATHI-67"></use></g><g is="true" transform="translate(481,345)"><use transform="scale(0.707)" xlink:href="#MJMAIN-32"></use></g><g is="true" transform="translate(477,-279)"><use transform="scale(0.707)" xlink:href="#MJMATHI-74"></use></g></g></g></g></svg><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow is="true"><mi is="true">E</mi><msub is="true"><mrow is="true"><mo is="true">[</mo><msup is="true"><mi is="true">g</mi><mn is="true">2</mn></msup><mo is="true">]</mo></mrow><mi is="true">t</mi></msub><mo is="true">=</mo><mi is="true">γ</mi><mi is="true">E</mi><msub is="true"><mrow is="true"><mo is="true">[</mo><msup is="true"><mi is="true">g</mi><mn is="true">2</mn></msup><mo is="true">]</mo></mrow><mrow is="true"><mi is="true">t</mi><mo is="true">−</mo><mn is="true">1</mn></mrow></msub><mo is="true">+</mo><msubsup is="true"><mi is="true">g</mi><mi is="true">t</mi><mn is="true">2</mn></msubsup></mrow></math></span></span><script type="math/mml" id="MathJax-Element-50"><math><mrow is="true"><mi is="true">E</mi><msub is="true"><mrow is="true"><mo is="true">[</mo><msup is="true"><mi is="true">g</mi><mn is="true">2</mn></msup><mo is="true">]</mo></mrow><mi is="true">t</mi></msub><mo is="true">=</mo><mi is="true">γ</mi><mi is="true">E</mi><msub is="true"><mrow is="true"><mo is="true">[</mo><msup is="true"><mi is="true">g</mi><mn is="true">2</mn></msup><mo is="true">]</mo></mrow><mrow is="true"><mi is="true">t</mi><mo is="true">−</mo><mn is="true">1</mn></mrow></msub><mo is="true">+</mo><msubsup is="true"><mi is="true">g</mi><mi is="true">t</mi><mn is="true">2</mn></msubsup></mrow></math></script></span></span></span></div><div class="u-margin-s-bottom" id="para0029">The authors suggest some default values for the learning rate and the decaying value which should be closer to <span class="math"><span class="MathJax_Preview" style=""></span><span class="MathJax_SVG" id="MathJax-Element-51-Frame" tabindex="0" data-mathml="<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mrow is=&quot;true&quot;><mi is=&quot;true&quot;>&amp;#x3B1;</mi><mo is=&quot;true&quot;>=</mo><mn is=&quot;true&quot;>0.001</mn></mrow></math>" role="presentation" style="font-size: 90%; display: inline-block; position: relative;"><svg xmlns:xlink="http://www.w3.org/1999/xlink" width="9.883ex" height="1.971ex" viewBox="0 -747.2 4255.1 848.5" role="img" focusable="false" style="vertical-align: -0.235ex;" aria-hidden="true"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><g is="true"><g is="true"><use xlink:href="#MJMATHI-3B1"></use></g><g is="true" transform="translate(918,0)"><use xlink:href="#MJMAIN-3D"></use></g><g is="true" transform="translate(1974,0)"><use xlink:href="#MJMAIN-30"></use><use xlink:href="#MJMAIN-2E" x="500" y="0"></use><use xlink:href="#MJMAIN-30" x="779" y="0"></use><use xlink:href="#MJMAIN-30" x="1279" y="0"></use><use xlink:href="#MJMAIN-31" x="1780" y="0"></use></g></g></g></svg><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow is="true"><mi is="true">α</mi><mo is="true">=</mo><mn is="true">0.001</mn></mrow></math></span></span><script type="math/mml" id="MathJax-Element-51"><math><mrow is="true"><mi is="true">α</mi><mo is="true">=</mo><mn is="true">0.001</mn></mrow></math></script></span> and <span class="math"><span class="MathJax_Preview" style=""></span><span class="MathJax_SVG" id="MathJax-Element-52-Frame" tabindex="0" data-mathml="<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mrow is=&quot;true&quot;><mi is=&quot;true&quot;>&amp;#x3B3;</mi><mo is=&quot;true&quot;>=</mo><mn is=&quot;true&quot;>0.9</mn></mrow></math>" role="presentation" style="font-size: 90%; display: inline-block; position: relative;"><svg xmlns:xlink="http://www.w3.org/1999/xlink" width="7.333ex" height="2.432ex" viewBox="0 -747.2 3157.1 1047.3" role="img" focusable="false" style="vertical-align: -0.697ex;" aria-hidden="true"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><g is="true"><g is="true"><use xlink:href="#MJMATHI-3B3"></use></g><g is="true" transform="translate(821,0)"><use xlink:href="#MJMAIN-3D"></use></g><g is="true" transform="translate(1877,0)"><use xlink:href="#MJMAIN-30"></use><use xlink:href="#MJMAIN-2E" x="500" y="0"></use><use xlink:href="#MJMAIN-39" x="779" y="0"></use></g></g></g></svg><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow is="true"><mi is="true">γ</mi><mo is="true">=</mo><mn is="true">0.9</mn></mrow></math></span></span><script type="math/mml" id="MathJax-Element-52"><math><mrow is="true"><mi is="true">γ</mi><mo is="true">=</mo><mn is="true">0.9</mn></mrow></math></script></span>. In our experiments we used this configuration.</div><div class="u-margin-s-bottom" id="para0030">Finally we want to introduce another method called Adaptive Moment Estimation (Adam) <a class="anchor anchor-primary" href="#bib0031" name="bbib0031" data-sd-ui-side-panel-opener="true" data-xocs-content-type="reference" data-xocs-content-id="bib0031"><span class="anchor-text-container"><span class="anchor-text">[31]</span></span></a>. Like Adadelta and RMSProp, Adam stores a decaying average of past gradients and squared gradients. The two decaying averages are then used to estimate <em>m</em><sub>1</sub> and <em>m</em><sub>2</sub> which are the first and second moment (mean and variance) of the gradient. The updating rule for Adam can be expressed as follows:
<span class="display"><span id="eq0007" class="formula"><span class="label">(7)</span><span class="math"><span class="MathJax_Preview" style=""></span><span class="MathJax_SVG" id="MathJax-Element-53-Frame" tabindex="0" data-mathml="<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mrow is=&quot;true&quot;><msub is=&quot;true&quot;><mi is=&quot;true&quot;>w</mi><mrow is=&quot;true&quot;><mi is=&quot;true&quot;>t</mi><mo is=&quot;true&quot;>+</mo><mn is=&quot;true&quot;>1</mn></mrow></msub><mo is=&quot;true&quot;>=</mo><msub is=&quot;true&quot;><mi is=&quot;true&quot;>w</mi><mi is=&quot;true&quot;>t</mi></msub><mo is=&quot;true&quot;>&amp;#x2212;</mo><mfrac is=&quot;true&quot;><mi is=&quot;true&quot;>&amp;#x3B1;</mi><mrow is=&quot;true&quot;><msqrt is=&quot;true&quot;><msub is=&quot;true&quot;><mi is=&quot;true&quot;>m</mi><mn is=&quot;true&quot;>2</mn></msub></msqrt><mo is=&quot;true&quot;>+</mo><mi is=&quot;true&quot;>&amp;#x3F5;</mi></mrow></mfrac><msub is=&quot;true&quot;><mi is=&quot;true&quot;>m</mi><mn is=&quot;true&quot;>1</mn></msub></mrow></math>" role="presentation" style="font-size: 90%; display: inline-block; position: relative;"><svg xmlns:xlink="http://www.w3.org/1999/xlink" width="22.454ex" height="3.586ex" viewBox="0 -796.9 9667.5 1544.1" role="img" focusable="false" style="vertical-align: -1.735ex;" aria-hidden="true"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><g is="true"><g is="true"><g is="true"><use xlink:href="#MJMATHI-77"></use></g><g is="true" transform="translate(716,-150)"><g is="true"><use transform="scale(0.707)" xlink:href="#MJMATHI-74"></use></g><g is="true" transform="translate(255,0)"><use transform="scale(0.707)" xlink:href="#MJMAIN-2B"></use></g><g is="true" transform="translate(806,0)"><use transform="scale(0.707)" xlink:href="#MJMAIN-31"></use></g></g></g><g is="true" transform="translate(2254,0)"><use xlink:href="#MJMAIN-3D"></use></g><g is="true" transform="translate(3310,0)"><g is="true"><use xlink:href="#MJMATHI-77"></use></g><g is="true" transform="translate(716,-150)"><use transform="scale(0.707)" xlink:href="#MJMATHI-74"></use></g></g><g is="true" transform="translate(4604,0)"><use xlink:href="#MJMAIN-2212"></use></g><g is="true" transform="translate(5383,0)"><g transform="translate(342,0)"><rect stroke="none" width="2489" height="60" x="0" y="220"></rect><g is="true" transform="translate(1018,411)"><use transform="scale(0.707)" xlink:href="#MJMATHI-3B1"></use></g><g is="true" transform="translate(60,-409)"><g is="true"><use transform="scale(0.707)" xlink:href="#MJMAIN-221A" x="0" y="-147"></use><rect stroke="none" width="942" height="42" x="589" y="420"></rect><g transform="translate(589,0)"><g is="true"><g is="true"><use transform="scale(0.707)" xlink:href="#MJMATHI-6D"></use></g><g is="true" transform="translate(621,-107)"><use transform="scale(0.5)" xlink:href="#MJMAIN-32"></use></g></g></g></g><g is="true" transform="translate(1531,0)"><use transform="scale(0.707)" xlink:href="#MJMAIN-2B"></use></g><g is="true" transform="translate(2082,0)"><use transform="scale(0.707)" xlink:href="#MJMATHI-3F5"></use></g></g></g></g><g is="true" transform="translate(8335,0)"><g is="true"><use xlink:href="#MJMATHI-6D"></use></g><g is="true" transform="translate(878,-150)"><use transform="scale(0.707)" xlink:href="#MJMAIN-31"></use></g></g></g></g></svg><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow is="true"><msub is="true"><mi is="true">w</mi><mrow is="true"><mi is="true">t</mi><mo is="true">+</mo><mn is="true">1</mn></mrow></msub><mo is="true">=</mo><msub is="true"><mi is="true">w</mi><mi is="true">t</mi></msub><mo is="true">−</mo><mfrac is="true"><mi is="true">α</mi><mrow is="true"><msqrt is="true"><msub is="true"><mi is="true">m</mi><mn is="true">2</mn></msub></msqrt><mo is="true">+</mo><mi is="true">ϵ</mi></mrow></mfrac><msub is="true"><mi is="true">m</mi><mn is="true">1</mn></msub></mrow></math></span></span><script type="math/mml" id="MathJax-Element-53"><math><mrow is="true"><msub is="true"><mi is="true">w</mi><mrow is="true"><mi is="true">t</mi><mo is="true">+</mo><mn is="true">1</mn></mrow></msub><mo is="true">=</mo><msub is="true"><mi is="true">w</mi><mi is="true">t</mi></msub><mo is="true">−</mo><mfrac is="true"><mi is="true">α</mi><mrow is="true"><msqrt is="true"><msub is="true"><mi is="true">m</mi><mn is="true">2</mn></msub></msqrt><mo is="true">+</mo><mi is="true">ϵ</mi></mrow></mfrac><msub is="true"><mi is="true">m</mi><mn is="true">1</mn></msub></mrow></math></script></span></span></span></div><div class="u-margin-s-bottom" id="para0031">The two moments <em>m</em><sub>1</sub> and <em>m</em><sub>2</sub> are taken at time <em>t</em> and before the weights update they are corrected to limit a bias toward zero during the first steps. The moments are regulated by two decaying factors <em>β</em><sub>1</sub> and <em>β</em>2. The authors suggest to initialise these parameters to standard values <span class="math"><span class="MathJax_Preview" style=""></span><span class="MathJax_SVG" id="MathJax-Element-54-Frame" tabindex="0" data-mathml="<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mrow is=&quot;true&quot;><msub is=&quot;true&quot;><mi is=&quot;true&quot;>&amp;#x3B2;</mi><mn is=&quot;true&quot;>1</mn></msub><mo is=&quot;true&quot;>=</mo><mn is=&quot;true&quot;>0.9</mn></mrow></math>" role="presentation" style="font-size: 90%; display: inline-block; position: relative;"><svg xmlns:xlink="http://www.w3.org/1999/xlink" width="8.44ex" height="2.432ex" viewBox="0 -796.9 3634 1047.3" role="img" focusable="false" style="vertical-align: -0.582ex;" aria-hidden="true"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><g is="true"><g is="true"><g is="true"><use xlink:href="#MJMATHI-3B2"></use></g><g is="true" transform="translate(566,-150)"><use transform="scale(0.707)" xlink:href="#MJMAIN-31"></use></g></g><g is="true" transform="translate(1298,0)"><use xlink:href="#MJMAIN-3D"></use></g><g is="true" transform="translate(2354,0)"><use xlink:href="#MJMAIN-30"></use><use xlink:href="#MJMAIN-2E" x="500" y="0"></use><use xlink:href="#MJMAIN-39" x="779" y="0"></use></g></g></g></svg><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow is="true"><msub is="true"><mi is="true">β</mi><mn is="true">1</mn></msub><mo is="true">=</mo><mn is="true">0.9</mn></mrow></math></span></span><script type="math/mml" id="MathJax-Element-54"><math><mrow is="true"><msub is="true"><mi is="true">β</mi><mn is="true">1</mn></msub><mo is="true">=</mo><mn is="true">0.9</mn></mrow></math></script></span> and <span class="math"><span class="MathJax_Preview" style=""></span><span class="MathJax_SVG" id="MathJax-Element-55-Frame" tabindex="0" data-mathml="<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mrow is=&quot;true&quot;><msub is=&quot;true&quot;><mi is=&quot;true&quot;>&amp;#x3B2;</mi><mn is=&quot;true&quot;>2</mn></msub><mo is=&quot;true&quot;>=</mo><mn is=&quot;true&quot;>0.999</mn></mrow></math>" role="presentation" style="font-size: 90%; display: inline-block; position: relative;"><svg xmlns:xlink="http://www.w3.org/1999/xlink" width="10.765ex" height="2.432ex" viewBox="0 -796.9 4635 1047.3" role="img" focusable="false" style="vertical-align: -0.582ex;" aria-hidden="true"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><g is="true"><g is="true"><g is="true"><use xlink:href="#MJMATHI-3B2"></use></g><g is="true" transform="translate(566,-150)"><use transform="scale(0.707)" xlink:href="#MJMAIN-32"></use></g></g><g is="true" transform="translate(1298,0)"><use xlink:href="#MJMAIN-3D"></use></g><g is="true" transform="translate(2354,0)"><use xlink:href="#MJMAIN-30"></use><use xlink:href="#MJMAIN-2E" x="500" y="0"></use><use xlink:href="#MJMAIN-39" x="779" y="0"></use><use xlink:href="#MJMAIN-39" x="1279" y="0"></use><use xlink:href="#MJMAIN-39" x="1780" y="0"></use></g></g></g></svg><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow is="true"><msub is="true"><mi is="true">β</mi><mn is="true">2</mn></msub><mo is="true">=</mo><mn is="true">0.999</mn></mrow></math></span></span><script type="math/mml" id="MathJax-Element-55"><math><mrow is="true"><msub is="true"><mi is="true">β</mi><mn is="true">2</mn></msub><mo is="true">=</mo><mn is="true">0.999</mn></mrow></math></script></span>. We used these values in our experiments.</div></section></section><section id="sec0007"><h2 id="sectt0010" class="u-h4 u-margin-l-top u-margin-xs-bottom">4. Experiments</h2><div class="u-margin-s-bottom" id="para0032">In this section we report the results obtained using CNNs, dropout and adaptive gradient methods on three public datasets: the Prima head-pose dataset <a class="anchor anchor-primary" href="#bib0032" name="bbib0032" data-sd-ui-side-panel-opener="true" data-xocs-content-type="reference" data-xocs-content-id="bib0032"><span class="anchor-text-container"><span class="anchor-text">[32]</span></span></a>, the Annotated Facial Landmarks in the Wild (AFLW) dataset <a class="anchor anchor-primary" href="#bib0033" name="bbib0033" data-sd-ui-side-panel-opener="true" data-xocs-content-type="reference" data-xocs-content-id="bib0033"><span class="anchor-text-container"><span class="anchor-text">[33]</span></span></a>, and the Annotated Face in the Wild (AFW) dataset <a class="anchor anchor-primary" href="#bib0034" name="bbib0034" data-sd-ui-side-panel-opener="true" data-xocs-content-type="reference" data-xocs-content-id="bib0034"><span class="anchor-text-container"><span class="anchor-text">[34]</span></span></a>. The former is a well-known dataset which has been around for more than ten years, and it is considered a classic benchmark for head pose algorithms. The second is a recently released in-the-wild dataset, and it has the largest number of annotated poses currently available. The third is a small in-the-wild dataset used mainly for benchmarks. Other details about these datasets are available in <a class="anchor anchor-primary" href="#sec0008" name="bsec0008" data-sd-ui-side-panel-opener="true" data-xocs-content-type="reference" data-xocs-content-id="sec0008"><span class="anchor-text-container"><span class="anchor-text">Sections&nbsp;4.1</span></span></a>–<a class="anchor anchor-primary" href="#sec0014" name="bsec0014" data-sd-ui-side-panel-opener="true" data-xocs-content-type="reference" data-xocs-content-id="sec0014"><span class="anchor-text-container"><span class="anchor-text">4.3</span></span></a>.</div><div class="u-margin-s-bottom"><div id="para0033">In these experiments we used a total of four networks: A, B, C, D. The architecture A is a standard LeNet-5 <a class="anchor anchor-primary" href="#bib0035" name="bbib0035" data-sd-ui-side-panel-opener="true" data-xocs-content-type="reference" data-xocs-content-id="bib0035"><span class="anchor-text-container"><span class="anchor-text">[35]</span></span></a> and with six layers and 4.3 × 10<sup>6</sup><span> parameters. The <a href="/topics/engineering/graphical-representation" title="Learn more about graphical representation from ScienceDirect's AI-generated Topic Pages" class="topic-link">graphical representation</a> of this architecture is presented in </span><a class="anchor anchor-primary" href="#fig0002" name="bfig0002" data-sd-ui-side-panel-opener="true" data-xocs-content-type="reference" data-xocs-content-id="fig0002"><span class="anchor-text-container"><span class="anchor-text">Fig.&nbsp;2</span></span></a><span>. The architecture B has one more <a href="/topics/engineering/convolutional-layer" title="Learn more about convolutional layer from ScienceDirect's AI-generated Topic Pages" class="topic-link">convolutional layer</a> and one more pooling layer. The number of parameters is slightly higher (4.6 × 10</span><sup>6</sup>). The idea is to keep the architectures as similar as possible to isolate the effect of the additional layers. It is hard to define a priori how many parameters lead to a good performance, for this reason the third and fourth networks have more weights. The architecture C has a high number of parameters (8.5 × 10<sup>6</sup>). The fourth architecture (D) is similar to a standard AlexNet <a class="anchor anchor-primary" href="#bib0022" name="bbib0022" data-sd-ui-side-panel-opener="true" data-xocs-content-type="reference" data-xocs-content-id="bib0022"><span class="anchor-text-container"><span class="anchor-text">[22]</span></span></a> and it has a total of 9.0 × 10<sup>6</sup> parameters. A graphical comparison of the four architectures is reported in <a class="anchor anchor-primary" href="#fig0003" name="bfig0003" data-sd-ui-side-panel-opener="true" data-xocs-content-type="reference" data-xocs-content-id="fig0003"><span class="anchor-text-container"><span class="anchor-text">Fig.&nbsp;3</span></span></a>.</div><figure class="figure text-xs" id="fig0002"><span><img src="https://ars.els-cdn.com/content/image/1-s2.0-S0031320317302327-gr2.jpg" height="125" alt="Fig. 2" aria-describedby="cap0002"><ol class="u-margin-s-bottom"><li><a class="anchor download-link u-font-sans anchor-primary" href="https://ars.els-cdn.com/content/image/1-s2.0-S0031320317302327-gr2_lrg.jpg" target="_blank" download="" title="Download high-res image (136KB)"><span class="anchor-text-container"><span class="anchor-text">Download: <span class="download-link-title">Download high-res image (136KB)</span></span></span></a></li><li><a class="anchor download-link u-font-sans anchor-primary" href="https://ars.els-cdn.com/content/image/1-s2.0-S0031320317302327-gr2.jpg" target="_blank" download="" title="Download full-size image"><span class="anchor-text-container"><span class="anchor-text">Download: <span class="download-link-title">Download full-size image</span></span></span></a></li></ol></span><span class="captions text-s"><span id="cap0002"><p id="spara0009"><span class="label">Fig. 2</span>. Graphical representation of a Convolutional Neural Network with two convolutional (C1 and C2), two <a href="/topics/engineering/subsamplings" title="Learn more about subsampling from ScienceDirect's AI-generated Topic Pages" class="topic-link">subsampling</a> (P1 and P2) and two fully connected (D1 and D2) layers. The label above each layer specifies number of elements and size (rows × columns) of the future maps. For the dense layers we reported the number of units. We used the following colour convention to identify the different layers: green for convolution, orange for subsampling, and red for dense layers. (For interpretation of the references to colour in this figure legend, the reader is referred to the web version of this article.)</p></span></span></figure><figure class="figure text-xs" id="fig0003"><span><img src="https://ars.els-cdn.com/content/image/1-s2.0-S0031320317302327-gr3.jpg" height="440" alt="Fig. 3" aria-describedby="cap0003"><ol class="u-margin-s-bottom"><li><a class="anchor download-link u-font-sans anchor-primary" href="https://ars.els-cdn.com/content/image/1-s2.0-S0031320317302327-gr3_lrg.jpg" target="_blank" download="" title="Download high-res image (406KB)"><span class="anchor-text-container"><span class="anchor-text">Download: <span class="download-link-title">Download high-res image (406KB)</span></span></span></a></li><li><a class="anchor download-link u-font-sans anchor-primary" href="https://ars.els-cdn.com/content/image/1-s2.0-S0031320317302327-gr3.jpg" target="_blank" download="" title="Download full-size image"><span class="anchor-text-container"><span class="anchor-text">Download: <span class="download-link-title">Download full-size image</span></span></span></a></li></ol></span><span class="captions text-s"><span id="cap0003"><p id="spara0010"><span class="label">Fig. 3</span>. Comparison of the four architectures used in our experiments. The label below each layer represents the number and size (rows × columns) of the future maps. For the dense layers we reported only the number of units. The networks are organised in order of complexity, on the left there is the network with less parameters and on the right the network with more. Network A has 4.3 × 10<sup>6</sup> parameters, whereas network B has two more layers and a total of 4.6 × 10<sup>6</sup>. Network C has 8.5 × 10<sup>6</sup> parameters, whereas network D has two more layers for a total of 9.0 × 10<sup>6</sup> parameters. We used the following colour convention to identify the different layers: green for convolution, orange for subsampling, and red for dense layers. (For interpretation of the references to colour in this figure legend, the reader is referred to the web version of this article.)</p></span></span></figure></div><div class="u-margin-s-bottom" id="para0034">The approach we used is based on a divide-and-conquer strategy. We trained different CNNs for each degree of freedom. This kind of strategy has the advantage of splitting the main problem into different sub-problems which are easier to manage. Having a specialised network for roll, pitch and yaw, permits fine tuning the network for a specific degree of freedom without losing the predictive power obtained on another one. Our methodology consisted of two parts. First, we evaluate which optimiser was better suited to a specific dataset. Second, we tested CNNs with a variable number of layers and parameters to understand the impact of deeper architectures. As discussed in <a class="anchor anchor-primary" href="#bib0005" name="bbib0005" data-sd-ui-side-panel-opener="true" data-xocs-content-type="reference" data-xocs-content-id="bib0005"><span class="anchor-text-container"><span class="anchor-text">[5]</span></span></a><span><span> the <a href="/topics/engineering/mean-absolute-error" title="Learn more about Mean Absolute Error from ScienceDirect's AI-generated Topic Pages" class="topic-link">Mean Absolute Error</a> (MAE) and the Standard Deviation (STD) are the best metric of accuracy in head pose datasets with discrete or continuous labels. We report both MAE and STD and we use them for comparing results. In all of the experiments we used the same hardware configuration: a multi-core workstation with 32GB of </span><a href="/topics/engineering/reliability-availability-and-maintainability-reliability-engineering" title="Learn more about RAM from ScienceDirect's AI-generated Topic Pages" class="topic-link">RAM</a><span> and a GPU NVIDIA <a href="/topics/engineering/tesla-roadster" title="Learn more about Tesla from ScienceDirect's AI-generated Topic Pages" class="topic-link">Tesla</a> K-40. The experiments have been implemented in Python using the TensorFlow library </span></span><a class="anchor anchor-primary" href="#bib0004" name="bbib0004" data-sd-ui-side-panel-opener="true" data-xocs-content-type="reference" data-xocs-content-id="bib0004"><span class="anchor-text-container"><span class="anchor-text">[4]</span></span></a>.</div><section id="sec0008"><h3 id="sectt0011" class="u-h4 u-margin-m-top u-margin-xs-bottom">4.1. Prima head-pose dataset</h3><div class="u-margin-s-bottom"><div id="para0035"><span>This dataset consists of 2790 monocular face images of 15 subjects. The subjects range in age from 20 to 40 years old, five possessing facial hair and seven wearing glasses. Pitch and <a href="/topics/engineering/yaw-angle" title="Learn more about yaw angles from ScienceDirect's AI-generated Topic Pages" class="topic-link">yaw angles</a> are in the range </span><span class="math"><span class="MathJax_Preview" style=""></span><span class="MathJax_SVG" id="MathJax-Element-56-Frame" tabindex="0" data-mathml="<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mrow is=&quot;true&quot;><mo is=&quot;true&quot;>[</mo><mo is=&quot;true&quot;>&amp;#x2212;</mo><msup is=&quot;true&quot;><mn is=&quot;true&quot;>90</mn><mo is=&quot;true&quot;>&amp;#x2218;</mo></msup><mo is=&quot;true&quot;>,</mo><msup is=&quot;true&quot;><mn is=&quot;true&quot;>90</mn><mo is=&quot;true&quot;>&amp;#x2218;</mo></msup><mo is=&quot;true&quot;>]</mo></mrow></math>" role="presentation" style="font-size: 90%; display: inline-block; position: relative;"><svg xmlns:xlink="http://www.w3.org/1999/xlink" width="10.894ex" height="2.779ex" viewBox="0 -846.5 4690.5 1196.3" role="img" focusable="false" style="vertical-align: -0.812ex;" aria-hidden="true"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><g is="true"><g is="true"><use xlink:href="#MJMAIN-5B"></use></g><g is="true" transform="translate(278,0)"><use xlink:href="#MJMAIN-2212"></use></g><g is="true" transform="translate(1057,0)"><g is="true"><use xlink:href="#MJMAIN-39"></use><use xlink:href="#MJMAIN-30" x="500" y="0"></use></g><g is="true" transform="translate(1001,393)"><use transform="scale(0.707)" xlink:href="#MJMAIN-2218"></use></g></g><g is="true" transform="translate(2511,0)"><use xlink:href="#MJMAIN-2C"></use></g><g is="true" transform="translate(2957,0)"><g is="true"><use xlink:href="#MJMAIN-39"></use><use xlink:href="#MJMAIN-30" x="500" y="0"></use></g><g is="true" transform="translate(1001,393)"><use transform="scale(0.707)" xlink:href="#MJMAIN-2218"></use></g></g><g is="true" transform="translate(4411,0)"><use xlink:href="#MJMAIN-5D"></use></g></g></g></svg><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow is="true"><mo is="true">[</mo><mo is="true">−</mo><msup is="true"><mn is="true">90</mn><mo is="true">∘</mo></msup><mo is="true">,</mo><msup is="true"><mn is="true">90</mn><mo is="true">∘</mo></msup><mo is="true">]</mo></mrow></math></span></span><script type="math/mml" id="MathJax-Element-56"><math><mrow is="true"><mo is="true">[</mo><mo is="true">−</mo><msup is="true"><mn is="true">90</mn><mo is="true">∘</mo></msup><mo is="true">,</mo><msup is="true"><mn is="true">90</mn><mo is="true">∘</mo></msup><mo is="true">]</mo></mrow></math></script></span> for a total of 93 discrete poses for each person (<a class="anchor anchor-primary" href="#fig0004" name="bfig0004" data-sd-ui-side-panel-opener="true" data-xocs-content-type="reference" data-xocs-content-id="fig0004"><span class="anchor-text-container"><span class="anchor-text">Fig.&nbsp;4</span></span></a>). Two series of pictures with different lighting conditions are provided increasing the total number of available pictures to 186 per person. The head pose is estimated by directional evaluation, as a result this dataset is extremely challenging because the predictor must deal with substantial errors and poor uniformity between subjects.</div><figure class="figure text-xs" id="fig0004"><span><img src="https://ars.els-cdn.com/content/image/1-s2.0-S0031320317302327-gr4.jpg" height="129" alt="Fig. 4" aria-describedby="cap0004"><ol class="u-margin-s-bottom"><li><a class="anchor download-link u-font-sans anchor-primary" href="https://ars.els-cdn.com/content/image/1-s2.0-S0031320317302327-gr4_lrg.jpg" target="_blank" download="" title="Download high-res image (204KB)"><span class="anchor-text-container"><span class="anchor-text">Download: <span class="download-link-title">Download high-res image (204KB)</span></span></span></a></li><li><a class="anchor download-link u-font-sans anchor-primary" href="https://ars.els-cdn.com/content/image/1-s2.0-S0031320317302327-gr4.jpg" target="_blank" download="" title="Download full-size image"><span class="anchor-text-container"><span class="anchor-text">Download: <span class="download-link-title">Download full-size image</span></span></span></a></li></ol></span><span class="captions text-s"><span id="cap0004"><p id="spara0011"><span class="label">Fig. 4</span>. This figure represents a collection of images taken from the Prima dataset as they appear after cropping and scaling.</p></span></span></figure></div><div class="u-margin-s-bottom" id="para0036">Many different methods have been tested on the Prima dataset. In <a class="anchor anchor-primary" href="#bib0014" name="bbib0014" data-sd-ui-side-panel-opener="true" data-xocs-content-type="reference" data-xocs-content-id="bib0014"><span class="anchor-text-container"><span class="anchor-text">[14]</span></span></a><span><span> a performance comparison is made between high-order <a href="/topics/engineering/singular-value-decomposition" title="Learn more about Singular Value Decomposition from ScienceDirect's AI-generated Topic Pages" class="topic-link">Singular Value Decomposition</a> (SVD), </span><a href="/topics/engineering/principal-components" title="Learn more about Principal Component from ScienceDirect's AI-generated Topic Pages" class="topic-link">Principal Component</a> Analysis (PCA) and locally embedded analysis. Neural networks-based methods have been tested in </span><a class="anchor anchor-primary" href="#bib0016" name="bbib0016" data-sd-ui-side-panel-opener="true" data-xocs-content-type="reference" data-xocs-content-id="bib0016"><span class="anchor-text-container"><span class="anchor-text">[16]</span></span></a>, <a class="anchor anchor-primary" href="#bib0036" name="bbib0036" data-sd-ui-side-panel-opener="true" data-xocs-content-type="reference" data-xocs-content-id="bib0036"><span class="anchor-text-container"><span class="anchor-text">[36]</span></span></a><span>. This dataset is the only one in which the <a href="/topics/engineering/human-performance" title="Learn more about human performance from ScienceDirect's AI-generated Topic Pages" class="topic-link">human performance</a> has been measured </span><a class="anchor anchor-primary" href="#bib0032" name="bbib0032" data-sd-ui-side-panel-opener="true" data-xocs-content-type="reference" data-xocs-content-id="bib0032"><span class="anchor-text-container"><span class="anchor-text">[32]</span></span></a>.</div><section id="sec0009"><h4 id="sectt0012" class="u-margin-m-top u-margin-xs-bottom">4.1.1. Methods</h4><div class="u-margin-s-bottom" id="para0037">This experiment investigated the influence of three factors (network type, optimiser, dropout) and it consisted of two phases:
<ul class="list"><li class="react-xocs-list-item"><span class="list-label">1.</span><span><div class="u-margin-s-bottom" id="para0038">Optimiser selection. In the first phase we used a standard network to select the best optimiser for this dataset. The standard network used is LeNet-5 <a class="anchor anchor-primary" href="#bib0035" name="bbib0035" data-sd-ui-side-panel-opener="true" data-xocs-content-type="reference" data-xocs-content-id="bib0035"><span class="anchor-text-container"><span class="anchor-text">[35]</span></span></a> shown in <a class="anchor anchor-primary" href="#fig0002" name="bfig0002" data-sd-ui-side-panel-opener="true" data-xocs-content-type="reference" data-xocs-content-id="fig0002"><span class="anchor-text-container"><span class="anchor-text">Fig.&nbsp;2</span></span></a>. The optimisers used were the four described in <a class="anchor anchor-primary" href="#sec0006" name="bsec0006" data-sd-ui-side-panel-opener="true" data-xocs-content-type="reference" data-xocs-content-id="sec0006"><span class="anchor-text-container"><span class="anchor-text">Section&nbsp;3.3</span></span></a><span> plus <a href="/topics/engineering/gradient-descent" title="Learn more about SGD from ScienceDirect's AI-generated Topic Pages" class="topic-link">SGD</a><span> and <a href="/topics/earth-and-planetary-sciences/stochastic-gradient-descent" title="Learn more about SGD from ScienceDirect's AI-generated Topic Pages" class="topic-link">SGD</a> with momentum.</span></span></div></span></li><li class="react-xocs-list-item"><span class="list-label">2.</span><span><div class="u-margin-s-bottom" id="para0039">Network selection. In the second phase we used the best optimiser selected previously for finding the best architecture for each degree of freedom.</div></span></li></ul></div><div class="u-margin-s-bottom" id="para0040"><span>In this experiment we used the sigmoid <a href="/topics/engineering/activation-function" title="Learn more about activation function from ScienceDirect's AI-generated Topic Pages" class="topic-link">activation function</a> which produced a continuous output in the range [0, 1]. As a loss function we used the sum of squares of the differences between the target value </span><em>y</em> and the estimated value <span class="math"><span class="MathJax_Preview" style=""></span><span class="MathJax_SVG" id="MathJax-Element-57-Frame" tabindex="0" data-mathml="<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mrow is=&quot;true&quot;><mover accent=&quot;true&quot; is=&quot;true&quot;><mi is=&quot;true&quot;>y</mi><mo is=&quot;true&quot;>^</mo></mover><mo is=&quot;true&quot;>,</mo></mrow></math>" role="presentation" style="font-size: 90%; display: inline-block; position: relative;"><svg xmlns:xlink="http://www.w3.org/1999/xlink" width="1.949ex" height="2.432ex" viewBox="0 -747.2 839.2 1047.3" role="img" focusable="false" style="vertical-align: -0.697ex;" aria-hidden="true"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><g is="true"><g is="true"><g is="true" transform="translate(1,0)"><use xlink:href="#MJMATHI-79"></use></g><use xlink:href="#MJMAIN-2C6" is="true" x="60" y="-12"></use></g><g is="true" transform="translate(560,0)"><use xlink:href="#MJMAIN-2C"></use></g></g></g></svg><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow is="true"><mover accent="true" is="true"><mi is="true">y</mi><mo is="true">^</mo></mover><mo is="true">,</mo></mrow></math></span></span><script type="math/mml" id="MathJax-Element-57"><math><mrow is="true"><mover accent="true" is="true"><mi is="true">y</mi><mo is="true">^</mo></mover><mo is="true">,</mo></mrow></math></script></span> reported in <a class="anchor anchor-primary" href="#eq0002" name="beq0002" data-sd-ui-side-panel-opener="true" data-xocs-content-type="reference" data-xocs-content-id="eq0002"><span class="anchor-text-container"><span class="anchor-text">Eq. (2)</span></span></a>, with <span class="math"><span class="MathJax_Preview" style=""></span><span class="MathJax_SVG" id="MathJax-Element-58-Frame" tabindex="0" data-mathml="<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mrow is=&quot;true&quot;><mi is=&quot;true&quot;>&amp;#x3BB;</mi><mo is=&quot;true&quot;>=</mo><mn is=&quot;true&quot;>5</mn><mo is=&quot;true&quot;>&amp;#xD7;</mo><msup is=&quot;true&quot;><mn is=&quot;true&quot;>10</mn><mrow is=&quot;true&quot;><mo is=&quot;true&quot;>&amp;#x2212;</mo><mn is=&quot;true&quot;>4</mn></mrow></msup></mrow></math>" role="presentation" style="font-size: 90%; display: inline-block; position: relative;"><svg xmlns:xlink="http://www.w3.org/1999/xlink" width="13.114ex" height="2.432ex" viewBox="0 -945.9 5646.4 1047.3" role="img" focusable="false" style="vertical-align: -0.235ex;" aria-hidden="true"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><g is="true"><g is="true"><use xlink:href="#MJMATHI-3BB"></use></g><g is="true" transform="translate(861,0)"><use xlink:href="#MJMAIN-3D"></use></g><g is="true" transform="translate(1917,0)"><use xlink:href="#MJMAIN-35"></use></g><g is="true" transform="translate(2640,0)"><use xlink:href="#MJMAIN-D7"></use></g><g is="true" transform="translate(3641,0)"><g is="true"><use xlink:href="#MJMAIN-31"></use><use xlink:href="#MJMAIN-30" x="500" y="0"></use></g><g is="true" transform="translate(1001,393)"><g is="true"><use transform="scale(0.707)" xlink:href="#MJMAIN-2212"></use></g><g is="true" transform="translate(550,0)"><use transform="scale(0.707)" xlink:href="#MJMAIN-34"></use></g></g></g></g></g></svg><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow is="true"><mi is="true">λ</mi><mo is="true">=</mo><mn is="true">5</mn><mo is="true">×</mo><msup is="true"><mn is="true">10</mn><mrow is="true"><mo is="true">−</mo><mn is="true">4</mn></mrow></msup></mrow></math></span></span><script type="math/mml" id="MathJax-Element-58"><math><mrow is="true"><mi is="true">λ</mi><mo is="true">=</mo><mn is="true">5</mn><mo is="true">×</mo><msup is="true"><mn is="true">10</mn><mrow is="true"><mo is="true">−</mo><mn is="true">4</mn></mrow></msup></mrow></math></script></span><span>. We trained the networks for 20, 000 epochs, using mini-batches of size 64. The network weights were sampled from a <a href="/topics/biochemistry-genetics-and-molecular-biology/gaussian-distribution" title="Learn more about Gaussian distribution from ScienceDirect's AI-generated Topic Pages" class="topic-link">Gaussian distribution</a> (</span><span class="math"><span class="MathJax_Preview" style=""></span><span class="MathJax_SVG" id="MathJax-Element-59-Frame" tabindex="0" data-mathml="<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mrow is=&quot;true&quot;><mi is=&quot;true&quot;>&amp;#x3BC;</mi><mo is=&quot;true&quot;>=</mo><mn is=&quot;true&quot;>0</mn><mo is=&quot;true&quot;>,</mo></mrow></math>" role="presentation" style="font-size: 90%; display: inline-block; position: relative;"><svg xmlns:xlink="http://www.w3.org/1999/xlink" width="6.309ex" height="2.432ex" viewBox="0 -747.2 2716.6 1047.3" role="img" focusable="false" style="vertical-align: -0.697ex;" aria-hidden="true"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><g is="true"><g is="true"><use xlink:href="#MJMATHI-3BC"></use></g><g is="true" transform="translate(881,0)"><use xlink:href="#MJMAIN-3D"></use></g><g is="true" transform="translate(1937,0)"><use xlink:href="#MJMAIN-30"></use></g><g is="true" transform="translate(2438,0)"><use xlink:href="#MJMAIN-2C"></use></g></g></g></svg><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow is="true"><mi is="true">μ</mi><mo is="true">=</mo><mn is="true">0</mn><mo is="true">,</mo></mrow></math></span></span><script type="math/mml" id="MathJax-Element-59"><math><mrow is="true"><mi is="true">μ</mi><mo is="true">=</mo><mn is="true">0</mn><mo is="true">,</mo></mrow></math></script></span><span class="math"><span class="MathJax_Preview" style=""></span><span class="MathJax_SVG" id="MathJax-Element-60-Frame" tabindex="0" data-mathml="<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mrow is=&quot;true&quot;><mi is=&quot;true&quot;>&amp;#x3C3;</mi><mo is=&quot;true&quot;>=</mo><mn is=&quot;true&quot;>0.1</mn></mrow></math>" role="presentation" style="font-size: 90%; display: inline-block; position: relative;"><svg xmlns:xlink="http://www.w3.org/1999/xlink" width="7.4ex" height="1.971ex" viewBox="0 -747.2 3186.1 848.5" role="img" focusable="false" style="vertical-align: -0.235ex;" aria-hidden="true"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><g is="true"><g is="true"><use xlink:href="#MJMATHI-3C3"></use></g><g is="true" transform="translate(850,0)"><use xlink:href="#MJMAIN-3D"></use></g><g is="true" transform="translate(1906,0)"><use xlink:href="#MJMAIN-30"></use><use xlink:href="#MJMAIN-2E" x="500" y="0"></use><use xlink:href="#MJMAIN-31" x="779" y="0"></use></g></g></g></svg><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow is="true"><mi is="true">σ</mi><mo is="true">=</mo><mn is="true">0.1</mn></mrow></math></span></span><script type="math/mml" id="MathJax-Element-60"><math><mrow is="true"><mi is="true">σ</mi><mo is="true">=</mo><mn is="true">0.1</mn></mrow></math></script></span>), and any values that had a magnitude more than two standard deviations from the mean were dropped and re-sampled. The weights were updated using <a class="anchor anchor-primary" href="#eq0001" name="beq0001" data-sd-ui-side-panel-opener="true" data-xocs-content-type="reference" data-xocs-content-id="eq0001"><span class="anchor-text-container"><span class="anchor-text">Eq. (1)</span></span></a>. For each optimiser we used the learning rate value recommended by the authors (see <a class="anchor anchor-primary" href="#sec0006" name="bsec0006" data-sd-ui-side-panel-opener="true" data-xocs-content-type="reference" data-xocs-content-id="sec0006"><span class="anchor-text-container"><span class="anchor-text">Section&nbsp;3.3</span></span></a>). When the authors did not suggest any standard value or when the recommended values did not lead to convergence we used a grid-search procedure. Starting from <span class="math"><span class="MathJax_Preview" style=""></span><span class="MathJax_SVG" id="MathJax-Element-61-Frame" tabindex="0" data-mathml="<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mrow is=&quot;true&quot;><mi is=&quot;true&quot;>&amp;#x3B1;</mi><mo is=&quot;true&quot;>=</mo><mn is=&quot;true&quot;>0.1</mn></mrow></math>" role="presentation" style="font-size: 90%; display: inline-block; position: relative;"><svg xmlns:xlink="http://www.w3.org/1999/xlink" width="7.558ex" height="1.971ex" viewBox="0 -747.2 3254.1 848.5" role="img" focusable="false" style="vertical-align: -0.235ex;" aria-hidden="true"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><g is="true"><g is="true"><use xlink:href="#MJMATHI-3B1"></use></g><g is="true" transform="translate(918,0)"><use xlink:href="#MJMAIN-3D"></use></g><g is="true" transform="translate(1974,0)"><use xlink:href="#MJMAIN-30"></use><use xlink:href="#MJMAIN-2E" x="500" y="0"></use><use xlink:href="#MJMAIN-31" x="779" y="0"></use></g></g></g></svg><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow is="true"><mi is="true">α</mi><mo is="true">=</mo><mn is="true">0.1</mn></mrow></math></span></span><script type="math/mml" id="MathJax-Element-61"><math><mrow is="true"><mi is="true">α</mi><mo is="true">=</mo><mn is="true">0.1</mn></mrow></math></script></span> we observed the loss function in the first 1000 epochs. In case of divergence the learning rate was divided by 2 and the procedure repeated. The value which permitted the fastest convergence was then selected and used for the training. Because we used dropout we set the value of the momentum to 0.95 as recommended in <a class="anchor anchor-primary" href="#bib0027" name="bbib0027" data-sd-ui-side-panel-opener="true" data-xocs-content-type="reference" data-xocs-content-id="bib0027"><span class="anchor-text-container"><span class="anchor-text">[27]</span></span></a><span>. The faces were isolated using the <a href="/topics/engineering/bounding-box" title="Learn more about bounding boxes from ScienceDirect's AI-generated Topic Pages" class="topic-link">bounding boxes</a> included in the dataset and then resized to 64 × 64 pixels.</span></div><div class="u-margin-s-bottom" id="para0041">Two kinds of cross-validation tests were applied to this dataset, in accordance with the procedures reported in <a class="anchor anchor-primary" href="#bib0037" name="bbib0037" data-sd-ui-side-panel-opener="true" data-xocs-content-type="reference" data-xocs-content-id="bib0037"><span class="anchor-text-container"><span class="anchor-text">[37]</span></span></a>. Testing on known faces was done by dividing the images per series into two separate folds. The two folds contained images of the same subjects taken under different lighting conditions. Testing on unknown faces is done using the Jack-Knife (leave-one-out) procedure, which consists of training the algorithm on all the subjects but one, which is used for testing. The procedure was repeated fifteen times, leaving out each subject. The mean value of all the measurements is considered to be the final score. We used the leave-one-out procedure to select the best optimiser and the best network. In a second moment the best configuration was tested with the known-subjects procedure. During the training we did not use any kind of early stopping technique. The use of the early stopping requires to monitor the error on a validation set taken from the test set, but the standard procedure reported in <a class="anchor anchor-primary" href="#bib0037" name="bbib0037" data-sd-ui-side-panel-opener="true" data-xocs-content-type="reference" data-xocs-content-id="bib0037"><span class="anchor-text-container"><span class="anchor-text">[37]</span></span></a><span> does not take it into account. Considering that the other methods used the standard procedure, we decided to keep the test set unchanged in order to have a fair comparison. However the observation of the error can be useful for understanding if there is overfitting. For this reason, in a separate phase, we generated a validation set randomly picking 50% of the images contained in the test set. We observed the <a href="/topics/earth-and-planetary-sciences/root-mean-square-error" title="Learn more about root mean square error from ScienceDirect's AI-generated Topic Pages" class="topic-link">root mean square error</a> (RMSE) for both training and validation set.</span></div><div class="u-margin-s-bottom" id="para0042">Training the architecture A for 20, 000 epochs on the two-fold dataset took 4.2&nbsp;h, while training it on the fifteen-fold dataset took 18.75&nbsp;h.</div></section><section id="sec0010"><h4 id="sectt0013" class="u-margin-m-top u-margin-xs-bottom">4.1.2. Results</h4><div class="u-margin-s-bottom"><div id="para0043">The results in term of MAE for the first phase (optimiser selection) are reported in <a class="anchor anchor-primary" href="#tbl0001" name="btbl0001" data-sd-ui-side-panel-opener="true" data-xocs-content-type="reference" data-xocs-content-id="tbl0001"><span class="anchor-text-container"><span class="anchor-text">Table&nbsp;1</span></span></a>. We analysed the convergence speed, observing the loss value during each of the 20, 000 epochs. For each optimiser we considered the loss values obtained from the mean of the 15 subject in the leave-one-out test, and we plotted the resulting graphs for both pitch (<a class="anchor anchor-primary" href="#fig0005" name="bfig0005" data-sd-ui-side-panel-opener="true" data-xocs-content-type="reference" data-xocs-content-id="fig0005"><span class="anchor-text-container"><span class="anchor-text">Fig.&nbsp;5</span></span></a>) and yaw (<a class="anchor anchor-primary" href="#fig0006" name="bfig0006" data-sd-ui-side-panel-opener="true" data-xocs-content-type="reference" data-xocs-content-id="fig0006"><span class="anchor-text-container"><span class="anchor-text">Fig.&nbsp;6</span></span></a>). The Adam optimiser had the lowest MAEs for both pitch and yaw (10.71 ± 11.04, 7.74 ± 8.03). A similar performance has been obtained with RMSProp (10.75 ± 10.51, 8.3 ± 8.17).</div><div class="tables rowsep-0 colsep-0 frame-topbot" id="tbl0001"><span class="captions text-s"><span id="cap0016"><p id="spara0023"><span class="label">Table 1</span>. In this table we report the results obtained on the Prima dataset for leave-one-out (unknown subjects) test using different optimisers. These results have been obtained training the architecture A for 20, 000 epochs (18.75&nbsp;h). The results are in terms of MAE (accuracy) with MAE expressed in degrees and Accuracy expressed in percentage. The best scores are in bold.</p></span></span><div class="groups"><table><thead><tr class="rowsep-1"><th scope="row" class="align-left valign-top">Optimiser</th><th scope="row" class="align-left valign-top">Pitch</th><th scope="row" class="align-left valign-top">Yaw</th></tr></thead><tbody><tr><th class="align-left valign-top" scope="row">Adadelta <a class="anchor anchor-primary" href="#bib0029" name="bbib0029" data-sd-ui-side-panel-opener="true" data-xocs-content-type="reference" data-xocs-content-id="bib0029"><span class="anchor-text-container"><span class="anchor-text">[29]</span></span></a></th><td class="align-left valign-top">20.71(35.3)</td><td class="align-left valign-top">13.7(35.23)</td></tr><tr><th class="align-left valign-top" scope="row">Adagrad <a class="anchor anchor-primary" href="#bib0028" name="bbib0028" data-sd-ui-side-panel-opener="true" data-xocs-content-type="reference" data-xocs-content-id="bib0028"><span class="anchor-text-container"><span class="anchor-text">[28]</span></span></a></th><td class="align-left valign-top">12.57(53.69)</td><td class="align-left valign-top">9.23(54.73)</td></tr><tr><th class="align-left valign-top" scope="row">Adam <a class="anchor anchor-primary" href="#bib0031" name="bbib0031" data-sd-ui-side-panel-opener="true" data-xocs-content-type="reference" data-xocs-content-id="bib0031"><span class="anchor-text-container"><span class="anchor-text">[31]</span></span></a></th><td class="align-left valign-top"><strong>10.71(60.93)</strong></td><td class="align-left valign-top"><strong>7.74(62.33)</strong></td></tr><tr><th class="align-left valign-top" scope="row">RMSProp <a class="anchor anchor-primary" href="#bib0030" name="bbib0030" data-sd-ui-side-panel-opener="true" data-xocs-content-type="reference" data-xocs-content-id="bib0030"><span class="anchor-text-container"><span class="anchor-text">[30]</span></span></a></th><td class="align-left valign-top">10.75(57.67)</td><td class="align-left valign-top">8.30(58.92)</td></tr><tr><th class="align-left valign-top" scope="row">SGD</th><td class="align-left valign-top">12.87(52.11)</td><td class="align-left valign-top">9.06(56.06)</td></tr><tr><th class="align-left valign-top" scope="row">SGD (Momentum)</th><td class="align-left valign-top">13.26(49.35)</td><td class="align-left valign-top">8.66(56.81)</td></tr></tbody></table></div></div><figure class="figure text-xs" id="fig0005"><span><img src="https://ars.els-cdn.com/content/image/1-s2.0-S0031320317302327-gr5.jpg" height="303" alt="Fig. 5" aria-describedby="cap0005"><ol class="u-margin-s-bottom"><li><a class="anchor download-link u-font-sans anchor-primary" href="https://ars.els-cdn.com/content/image/1-s2.0-S0031320317302327-gr5_lrg.jpg" target="_blank" download="" title="Download high-res image (187KB)"><span class="anchor-text-container"><span class="anchor-text">Download: <span class="download-link-title">Download high-res image (187KB)</span></span></span></a></li><li><a class="anchor download-link u-font-sans anchor-primary" href="https://ars.els-cdn.com/content/image/1-s2.0-S0031320317302327-gr5.jpg" target="_blank" download="" title="Download full-size image"><span class="anchor-text-container"><span class="anchor-text">Download: <span class="download-link-title">Download full-size image</span></span></span></a></li></ol></span><span class="captions text-s"><span id="cap0005"><p id="spara0012"><span class="label">Fig. 5</span>. Comparison of different optimisers (trained on network A) for the estimation of the <a href="/topics/biochemistry-genetics-and-molecular-biology/pitch" title="Learn more about pitch angle from ScienceDirect's AI-generated Topic Pages" class="topic-link">pitch angle</a> on the Prima dataset.</p></span></span></figure><figure class="figure text-xs" id="fig0006"><span><img src="https://ars.els-cdn.com/content/image/1-s2.0-S0031320317302327-gr6.jpg" height="303" alt="Fig. 6" aria-describedby="cap0006"><ol class="u-margin-s-bottom"><li><a class="anchor download-link u-font-sans anchor-primary" href="https://ars.els-cdn.com/content/image/1-s2.0-S0031320317302327-gr6_lrg.jpg" target="_blank" download="" title="Download high-res image (181KB)"><span class="anchor-text-container"><span class="anchor-text">Download: <span class="download-link-title">Download high-res image (181KB)</span></span></span></a></li><li><a class="anchor download-link u-font-sans anchor-primary" href="https://ars.els-cdn.com/content/image/1-s2.0-S0031320317302327-gr6.jpg" target="_blank" download="" title="Download full-size image"><span class="anchor-text-container"><span class="anchor-text">Download: <span class="download-link-title">Download full-size image</span></span></span></a></li></ol></span><span class="captions text-s"><span id="cap0006"><p id="spara0013"><span class="label">Fig. 6</span>. Comparison of different optimisers (trained on network A) for the estimation of the <a href="/topics/engineering/yaw-angle" title="Learn more about yaw angle from ScienceDirect's AI-generated Topic Pages" class="topic-link">yaw angle</a> on the Prima dataset.</p></span></span></figure></div><div class="u-margin-s-bottom"><div id="para0044">In the second phase (network selection) we used Adam to train the four architectures shown in <a class="anchor anchor-primary" href="#fig0003" name="bfig0003" data-sd-ui-side-panel-opener="true" data-xocs-content-type="reference" data-xocs-content-id="fig0003"><span class="anchor-text-container"><span class="anchor-text">Fig.&nbsp;3</span></span></a>. The best performances for both pitch and yaw are obtained with the architecture A (10.71 ± 11.04, 7.74 ± 8.03). A comparison of the four architectures is shown in <a class="anchor anchor-primary" href="#fig0007" name="bfig0007" data-sd-ui-side-panel-opener="true" data-xocs-content-type="reference" data-xocs-content-id="fig0007"><span class="anchor-text-container"><span class="anchor-text">Fig.&nbsp;7</span></span></a>. Mapping the continuous output in 9 discrete categories for pitch and 13 discrete categories for yaw, we were able to interpret the results in terms of classification. The best architecture (A) have an accuracy of 60.93% (pitch) and 62.33% (yaw) on unknown subjects. The accuracy is even higher on known subjects where it reaches 69.26% (pitch) and 67.61% (yaw). The normalised confusion tables for the best architecture are reported in form of heatmaps in <a class="anchor anchor-primary" href="#fig0008" name="bfig0008" data-sd-ui-side-panel-opener="true" data-xocs-content-type="reference" data-xocs-content-id="fig0008"><span class="anchor-text-container"><span class="anchor-text">Fig.&nbsp;8</span></span></a>.</div><figure class="figure text-xs" id="fig0007"><span><img src="https://ars.els-cdn.com/content/image/1-s2.0-S0031320317302327-gr7.jpg" height="294" alt="Fig. 7" aria-describedby="cap0007"><ol class="u-margin-s-bottom"><li><a class="anchor download-link u-font-sans anchor-primary" href="https://ars.els-cdn.com/content/image/1-s2.0-S0031320317302327-gr7_lrg.jpg" target="_blank" download="" title="Download high-res image (303KB)"><span class="anchor-text-container"><span class="anchor-text">Download: <span class="download-link-title">Download high-res image (303KB)</span></span></span></a></li><li><a class="anchor download-link u-font-sans anchor-primary" href="https://ars.els-cdn.com/content/image/1-s2.0-S0031320317302327-gr7.jpg" target="_blank" download="" title="Download full-size image"><span class="anchor-text-container"><span class="anchor-text">Download: <span class="download-link-title">Download full-size image</span></span></span></a></li></ol></span><span class="captions text-s"><span id="cap0007"><p id="spara0014"><span class="label">Fig. 7</span>. Comparison of the performances of the four networks trained with the Adam optimiser in pitch and yaw estimation of unknown subjects (Prima dataset). The STD has been shrunk by a factor of two for graphical reason.</p></span></span></figure><figure class="figure text-xs" id="fig0008"><span><img src="https://ars.els-cdn.com/content/image/1-s2.0-S0031320317302327-gr8.jpg" height="160" alt="Fig. 8" aria-describedby="cap0008"><ol class="u-margin-s-bottom"><li><a class="anchor download-link u-font-sans anchor-primary" href="https://ars.els-cdn.com/content/image/1-s2.0-S0031320317302327-gr8_lrg.jpg" target="_blank" download="" title="Download high-res image (92KB)"><span class="anchor-text-container"><span class="anchor-text">Download: <span class="download-link-title">Download high-res image (92KB)</span></span></span></a></li><li><a class="anchor download-link u-font-sans anchor-primary" href="https://ars.els-cdn.com/content/image/1-s2.0-S0031320317302327-gr8.jpg" target="_blank" download="" title="Download full-size image"><span class="anchor-text-container"><span class="anchor-text">Download: <span class="download-link-title">Download full-size image</span></span></span></a></li></ol></span><span class="captions text-s"><span id="cap0008"><p id="spara0015"><span class="label">Fig. 8</span>. Representation of the confusion tables for pitch (left) yaw angle (right) of the best architecture (A) on unknown subjects (Prima dataset). Each row of the tables represents the instances in a predicted class while each column represents the instances in an actual class.</p></span></span></figure></div><div class="u-margin-s-bottom" id="para0045">We used the best architecture also for the know-subjects test. We obtained a MAE of 8.06 ± 8.88 for the pitch estimation (accuracy 73.91%), and a MAE of 6.93 ± 7.32 for the yaw estimation (accuracy 66.6%).</div><div class="u-margin-s-bottom"><div id="para0046">To investigate the presence of overfitting, we trained the best architecture using the Adam optimiser on the unknown-subjects test and we generated a validation set randomly picking 50% of the images from the test set. We monitored the RMSE for both training and validation set. The results for the pitch and yaw estimation are reported in <a class="anchor anchor-primary" href="#fig0009" name="bfig0009" data-sd-ui-side-panel-opener="true" data-xocs-content-type="reference" data-xocs-content-id="fig0009"><span class="anchor-text-container"><span class="anchor-text">Figs.&nbsp;9</span></span></a> and <a class="anchor anchor-primary" href="#fig0010" name="bfig0010" data-sd-ui-side-panel-opener="true" data-xocs-content-type="reference" data-xocs-content-id="fig0010"><span class="anchor-text-container"><span class="anchor-text">10</span></span></a> and represent the mean RMSE for each one of the 15 subjects considered in the leave-one-out procedure.</div><figure class="figure text-xs" id="fig0009"><span><img src="https://ars.els-cdn.com/content/image/1-s2.0-S0031320317302327-gr9.jpg" height="308" alt="Fig. 9" aria-describedby="cap0009"><ol class="u-margin-s-bottom"><li><a class="anchor download-link u-font-sans anchor-primary" href="https://ars.els-cdn.com/content/image/1-s2.0-S0031320317302327-gr9_lrg.jpg" target="_blank" download="" title="Download high-res image (120KB)"><span class="anchor-text-container"><span class="anchor-text">Download: <span class="download-link-title">Download high-res image (120KB)</span></span></span></a></li><li><a class="anchor download-link u-font-sans anchor-primary" href="https://ars.els-cdn.com/content/image/1-s2.0-S0031320317302327-gr9.jpg" target="_blank" download="" title="Download full-size image"><span class="anchor-text-container"><span class="anchor-text">Download: <span class="download-link-title">Download full-size image</span></span></span></a></li></ol></span><span class="captions text-s"><span id="cap0009"><p id="spara0016"><span class="label">Fig. 9</span>. Performance of the best architecture (A) in terms of <a href="/topics/earth-and-planetary-sciences/root-mean-square-error" title="Learn more about RMSE from ScienceDirect's AI-generated Topic Pages" class="topic-link">RMSE</a><span> (degrees) on the training and validation set for the estimation of the <a href="/topics/biochemistry-genetics-and-molecular-biology/pitch" title="Learn more about pitch angle from ScienceDirect's AI-generated Topic Pages" class="topic-link">pitch angle</a> on the Prima dataset (unknown subjects test).</span></p></span></span></figure><figure class="figure text-xs" id="fig0010"><span><img src="https://ars.els-cdn.com/content/image/1-s2.0-S0031320317302327-gr10.jpg" height="308" alt="Fig. 10" aria-describedby="cap0010"><ol class="u-margin-s-bottom"><li><a class="anchor download-link u-font-sans anchor-primary" href="https://ars.els-cdn.com/content/image/1-s2.0-S0031320317302327-gr10_lrg.jpg" target="_blank" download="" title="Download high-res image (116KB)"><span class="anchor-text-container"><span class="anchor-text">Download: <span class="download-link-title">Download high-res image (116KB)</span></span></span></a></li><li><a class="anchor download-link u-font-sans anchor-primary" href="https://ars.els-cdn.com/content/image/1-s2.0-S0031320317302327-gr10.jpg" target="_blank" download="" title="Download full-size image"><span class="anchor-text-container"><span class="anchor-text">Download: <span class="download-link-title">Download full-size image</span></span></span></a></li></ol></span><span class="captions text-s"><span id="cap0010"><p id="spara0017"><span class="label">Fig. 10</span>. Performance of the best architecture (A) in terms of RMSE (degrees) on the training and validation set for the estimation of the yaw angle on the Prima dataset (unknown subjects test).</p></span></span></figure></div><div class="u-margin-s-bottom" id="para0047">We did some experiments to check if data augmentation of the images (horizontal flip) had an impact on the final score. We did not notice any significant improvement.</div><div class="u-margin-s-bottom" id="para0048">The best results on the Prima dataset have been obtained with the smallest network (A). However it is possible that networks with less parameters could perform better than our best architecture. This conclusion is reasonable since the Prima datasets contains a few thousands images and overfitting problems could deteriorate the performances of larger networks. To further investigate this hypothesis we used the Adam optimiser to train two networks. The networks were similar to LeNet-5 <a class="anchor anchor-primary" href="#bib0035" name="bbib0035" data-sd-ui-side-panel-opener="true" data-xocs-content-type="reference" data-xocs-content-id="bib0035"><span class="anchor-text-container"><span class="anchor-text">[35]</span></span></a> with six layers organised as in <a class="anchor anchor-primary" href="#fig0002" name="bfig0002" data-sd-ui-side-panel-opener="true" data-xocs-content-type="reference" data-xocs-content-id="fig0002"><span class="anchor-text-container"><span class="anchor-text">Fig.&nbsp;2</span></span></a>. The first network had 2.1 × 10<sup>6</sup> parameters and the following architecture: C1&nbsp;=&nbsp;32(64&nbsp;×&nbsp;64), P1&nbsp;=&nbsp;32(32&nbsp;×&nbsp;32), C2&nbsp;=&nbsp;64(32&nbsp;×&nbsp;32), P2&nbsp;=&nbsp;64(16&nbsp;×&nbsp;16), D1&nbsp;=&nbsp;128, D2&nbsp;=&nbsp;1. The second network had 0.5 × 10<sup>6</sup> parameters and the following architecture: C1&nbsp;=&nbsp;16(64&nbsp;×&nbsp;64), P1&nbsp;=&nbsp;16(32&nbsp;×&nbsp;32), C2&nbsp;=&nbsp;32(32&nbsp;×&nbsp;32), P2&nbsp;=&nbsp;32(16&nbsp;×&nbsp;16), D1&nbsp;=&nbsp;64, D2&nbsp;=&nbsp;1. The results did not show any major improvement except for the first architecture that got a slightly lower MAE (10.57 ± 10.78) and an higher accuracy (61.4%) for the pitch estimation on unknown subjects. The same network had a worse performance in yaw estimation with an MAE of 8.36 ± 8.42 and accuracy of 57.67%. The network with 0.5 × 10<sup>6</sup> parameters reported a score of 11.14 ± 11.24 (accuracy 58.02%) for pitch and 8.38 ± 8.57 (accuracy 57.53%) for yaw, which is significantly below the score obtained with architecture A. Also in the known-subjects test we did not observe any major improvement. The network with 2.1 × 10<sup>6</sup> parameters obtained an MAE of 8.24 ± 9.81 (accuracy 71.15%) for pitch and 7.23 ± 7.43 (accuracy 64.51%) for yaw. The network with 0.5 × 10<sup>6</sup> parameters obtained an MAE of 8.9 ± 10.35 (accuracy 70.82%) for pitch and 7.23 ± 7.42 (accuracy 64.19%) for yaw. We hypothesise that the use of dropout and L2 regularization helped to prevent overfitting in larger architectures leading to stabler solutions.</div><div class="u-margin-s-bottom"><div id="para0049">The comparison between our approach and other methods is reported in <a class="anchor anchor-primary" href="#tbl0002" name="btbl0002" data-sd-ui-side-panel-opener="true" data-xocs-content-type="reference" data-xocs-content-id="tbl0002"><span class="anchor-text-container"><span class="anchor-text">Table&nbsp;2</span></span></a>. CNNs perform better than any other methods on the two-fold test for known subjects and in the leave-one-out test for unknown subjects. The comparison in terms of MAE between human and our method shows how CNNs outperform naive humans in both pitch and yaw, and pre-trained humans only for the yaw estimation. The comparison in terms of accuracy (<a class="anchor anchor-primary" href="#tbl0002" name="btbl0002" data-sd-ui-side-panel-opener="true" data-xocs-content-type="reference" data-xocs-content-id="tbl0002"><span class="anchor-text-container"><span class="anchor-text">Table&nbsp;2</span></span></a>) shows that our method has the best reported scores for tests on known and unknown subjects. In this case the performance of pre-trained humans for pitch estimation on unknown subjects (59%) is lower than our score (60.93%).</div><div class="tables rowsep-0 colsep-0 frame-topbot" id="tbl0002"><span class="captions text-s"><span id="cap0017"><p id="spara0024"><span class="label">Table 2</span>. In this table we compare the results of our method with the result obtained by other authors on the Prima head pose dataset. These results have been obtained training architecture A for 20, 000 epochs on both unknown (18.75&nbsp;h) and know (4.2&nbsp;h) test with the Adam optimiser. The results are in term of MAE(accuracy), with MAE expressed in degrees and Accuracy expressed in percentage. The best scores are in bold.</p></span></span><div class="groups"><table><thead><tr><th scope="row" class="align-left valign-top">Method</th><th scope="row" class="align-left rowsep-1" colspan="2">Unknown Subjects</th><th scope="row" class="align-left rowsep-1" colspan="2">Known Subjects</th></tr><tr class="rowsep-1"><td scope="row" class="align-left" colspan="1"><span class="screen-reader-only">Empty Cell</span></td><th scope="row" class="align-left valign-top">Pitch</th><th scope="row" class="align-left valign-top">Yaw</th><th scope="row" class="align-left valign-top">Pitch</th><th scope="row" class="align-left valign-top">Yaw</th></tr></thead><tbody><tr><th class="align-left valign-top" scope="row">Human Performance <a class="anchor anchor-primary" href="#bib0037" name="bbib0037" data-sd-ui-side-panel-opener="true" data-xocs-content-type="reference" data-xocs-content-id="bib0037"><span class="anchor-text-container"><span class="anchor-text">[37]</span></span></a></th><td class="align-left valign-top">12.6(48)</td><td class="align-left valign-top">11.9(42.4)</td><td class="align-left valign-top">–</td><td class="align-left valign-top">–</td></tr><tr><th class="align-left valign-top" scope="row">Human Performance (training) <a class="anchor anchor-primary" href="#bib0037" name="bbib0037" data-sd-ui-side-panel-opener="true" data-xocs-content-type="reference" data-xocs-content-id="bib0037"><span class="anchor-text-container"><span class="anchor-text">[37]</span></span></a></th><td class="align-left valign-top">9.4(59)</td><td class="align-left valign-top">11.8(40.7)</td><td class="align-left valign-top">–</td><td class="align-left valign-top">–</td></tr><tr><th class="align-left valign-top" scope="row">Locally Embedded Analysis <a class="anchor anchor-primary" href="#bib0014" name="bbib0014" data-sd-ui-side-panel-opener="true" data-xocs-content-type="reference" data-xocs-content-id="bib0014"><span class="anchor-text-container"><span class="anchor-text">[14]</span></span></a></th><td class="align-left valign-top">–</td><td class="align-left valign-top">–</td><td class="align-left valign-top">17.44(50.61)</td><td class="align-left valign-top">15.88(45.16)</td></tr><tr><th class="align-left valign-top" scope="row">High-order SVD <a class="anchor anchor-primary" href="#bib0014" name="bbib0014" data-sd-ui-side-panel-opener="true" data-xocs-content-type="reference" data-xocs-content-id="bib0014"><span class="anchor-text-container"><span class="anchor-text">[14]</span></span></a></th><td class="align-left valign-top">–</td><td class="align-left valign-top">–</td><td class="align-left valign-top">17.97(54.84)</td><td class="align-left valign-top">12.9(49.25)</td></tr><tr><th class="align-left valign-top" scope="row">PCA <a class="anchor anchor-primary" href="#bib0014" name="bbib0014" data-sd-ui-side-panel-opener="true" data-xocs-content-type="reference" data-xocs-content-id="bib0014"><span class="anchor-text-container"><span class="anchor-text">[14]</span></span></a></th><td class="align-left valign-top">–</td><td class="align-left valign-top">–</td><td class="align-left valign-top">14.98(57.99)</td><td class="align-left valign-top">14.11(55.2)</td></tr><tr><th class="align-left valign-top" scope="row">Neural Network <a class="anchor anchor-primary" href="#bib0036" name="bbib0036" data-sd-ui-side-panel-opener="true" data-xocs-content-type="reference" data-xocs-content-id="bib0036"><span class="anchor-text-container"><span class="anchor-text">[36]</span></span></a></th><td class="align-left valign-top">–</td><td class="align-left valign-top">–</td><td class="align-left valign-top">12.77(52.1)</td><td class="align-left valign-top">12.3(41.8)</td></tr><tr><th class="align-left valign-top" scope="row">Large Margin Likelihoods <a class="anchor anchor-primary" href="#bib0046" name="bbib0046" data-sd-ui-side-panel-opener="true" data-xocs-content-type="reference" data-xocs-content-id="bib0046"><span class="anchor-text-container"><span class="anchor-text">[46]</span></span></a></th><td class="align-left valign-top">–</td><td class="align-left valign-top">–</td><td class="align-left valign-top">10.5</td><td class="align-left valign-top">9.1</td></tr><tr><th class="align-left valign-top" scope="row">Associative Memories <a class="anchor anchor-primary" href="#bib0037" name="bbib0037" data-sd-ui-side-panel-opener="true" data-xocs-content-type="reference" data-xocs-content-id="bib0037"><span class="anchor-text-container"><span class="anchor-text">[37]</span></span></a></th><td class="align-left valign-top">15.9(43.9)</td><td class="align-left valign-top">10.3(50.04)</td><td class="align-left valign-top">10.1(61.7)</td><td class="align-left valign-top">8.5(60.8)</td></tr><tr><th class="align-left valign-top" scope="row">Steerable Filters <a class="anchor anchor-primary" href="#bib0047" name="bbib0047" data-sd-ui-side-panel-opener="true" data-xocs-content-type="reference" data-xocs-content-id="bib0047"><span class="anchor-text-container"><span class="anchor-text">[47]</span></span></a></th><td class="align-left valign-top">13.8</td><td class="align-left valign-top">11.0</td><td class="align-left valign-top">12.4</td><td class="align-left valign-top">9.6</td></tr><tr><th class="align-left valign-top" scope="row">Steerable Filters (manual) <a class="anchor anchor-primary" href="#bib0047" name="bbib0047" data-sd-ui-side-panel-opener="true" data-xocs-content-type="reference" data-xocs-content-id="bib0047"><span class="anchor-text-container"><span class="anchor-text">[47]</span></span></a></th><td class="align-left valign-top">11.4</td><td class="align-left valign-top">9.97</td><td class="align-left valign-top">10.1</td><td class="align-left valign-top">8.7</td></tr><tr><th class="align-left valign-top" scope="row">CNNs [our]</th><td class="align-left valign-top"><strong>10.57(61.4)</strong></td><td class="align-left valign-top"><strong>7.74(62.33)</strong></td><td class="align-left valign-top"><strong>8.06(73.91)</strong></td><td class="align-left valign-top"><strong>6.93(66.6)</strong></td></tr></tbody></table></div></div></div></section></section><section id="sec0011"><h3 id="sectt0014" class="u-h4 u-margin-m-top u-margin-xs-bottom">4.2. Annotated facial landmarks in the wild</h3><div class="u-margin-s-bottom"><div id="para0050">The AFLW dataset <a class="anchor anchor-primary" href="#bib0033" name="bbib0033" data-sd-ui-side-panel-opener="true" data-xocs-content-type="reference" data-xocs-content-id="bib0033"><span class="anchor-text-container"><span class="anchor-text">[33]</span></span></a> provides a collection of 21,997 annotated images gathered from an image hosting website. The dataset contains a large variety of appearances (age, ethnicity, occlusions, expressions, etc.), lighting and environmental conditions for both genders (56% female, 44% male). Images compatible with the datasets are shown in <a class="anchor anchor-primary" href="#fig0011" name="bfig0011" data-sd-ui-side-panel-opener="true" data-xocs-content-type="reference" data-xocs-content-id="fig0011"><span class="anchor-text-container"><span class="anchor-text">Fig.&nbsp;11</span></span></a>. As reported by the authors the ratio of non-frontal faces (66%) is higher than in other databases. The head pose is estimated from 21 manually annotated landmarks using the POSIT algorithm <a class="anchor anchor-primary" href="#bib0038" name="bbib0038" data-sd-ui-side-panel-opener="true" data-xocs-content-type="reference" data-xocs-content-id="bib0038"><span class="anchor-text-container"><span class="anchor-text">[38]</span></span></a>.</div><figure class="figure text-xs" id="fig0011"><span><img src="https://ars.els-cdn.com/content/image/1-s2.0-S0031320317302327-gr11.jpg" height="161" alt="Fig. 11" aria-describedby="cap0011"><ol class="u-margin-s-bottom"><li><a class="anchor download-link u-font-sans anchor-primary" href="https://ars.els-cdn.com/content/image/1-s2.0-S0031320317302327-gr11_lrg.jpg" target="_blank" download="" title="Download high-res image (300KB)"><span class="anchor-text-container"><span class="anchor-text">Download: <span class="download-link-title">Download high-res image (300KB)</span></span></span></a></li><li><a class="anchor download-link u-font-sans anchor-primary" href="https://ars.els-cdn.com/content/image/1-s2.0-S0031320317302327-gr11.jpg" target="_blank" download="" title="Download full-size image"><span class="anchor-text-container"><span class="anchor-text">Download: <span class="download-link-title">Download full-size image</span></span></span></a></li></ol></span><span class="captions text-s"><span id="cap0011"><p id="spara0018"><span class="label">Fig. 11</span>. This figure represents a collection of images which are compatible with the AFLW and the AFW datasets (the licenses do not allow publishing the original images). The AFLW and the AFW datasets contain a large variety of appearances (age, ethnicity, occlusions, expressions, etc.), lighting and environmental conditions for both genders.</p></span></span></figure></div><div class="u-margin-s-bottom" id="para0051">Different methods have been tested on this dataset <a class="anchor anchor-primary" href="#bib0015" name="bbib0015" data-sd-ui-side-panel-opener="true" data-xocs-content-type="reference" data-xocs-content-id="bib0015"><span class="anchor-text-container"><span class="anchor-text">[15]</span></span></a>, <a class="anchor anchor-primary" href="#bib0034" name="bbib0034" data-sd-ui-side-panel-opener="true" data-xocs-content-type="reference" data-xocs-content-id="bib0034"><span class="anchor-text-container"><span class="anchor-text">[34]</span></span></a>, <a class="anchor anchor-primary" href="#bib0039" name="bbib0039" data-sd-ui-side-panel-opener="true" data-xocs-content-type="reference" data-xocs-content-id="bib0039"><span class="anchor-text-container"><span class="anchor-text">[39]</span></span></a>, <a class="anchor anchor-primary" href="#bib0040" name="bbib0040" data-sd-ui-side-panel-opener="true" data-xocs-content-type="reference" data-xocs-content-id="bib0040"><span class="anchor-text-container"><span class="anchor-text">[40]</span></span></a>, <a class="anchor anchor-primary" href="#bib0041" name="bbib0041" data-sd-ui-side-panel-opener="true" data-xocs-content-type="reference" data-xocs-content-id="bib0041"><span class="anchor-text-container"><span class="anchor-text">[41]</span></span></a>. To compare our work with the others we used the data reported in <a class="anchor anchor-primary" href="#bib0015" name="bbib0015" data-sd-ui-side-panel-opener="true" data-xocs-content-type="reference" data-xocs-content-id="bib0015"><span class="anchor-text-container"><span class="anchor-text">[15]</span></span></a>, where the authors describe the performance in terms of MAE for all of these methods, although limited to the yaw angle. The accuracy has been measured by dividing the range <span class="math"><span class="MathJax_Preview" style=""></span><span class="MathJax_SVG" id="MathJax-Element-62-Frame" tabindex="0" data-mathml="<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mrow is=&quot;true&quot;><mo is=&quot;true&quot;>[</mo><mo is=&quot;true&quot;>&amp;#x2212;</mo><msup is=&quot;true&quot;><mn is=&quot;true&quot;>90</mn><mo is=&quot;true&quot;>&amp;#x2218;</mo></msup><mo is=&quot;true&quot;>,</mo><msup is=&quot;true&quot;><mn is=&quot;true&quot;>90</mn><mo is=&quot;true&quot;>&amp;#x2218;</mo></msup><mo is=&quot;true&quot;>]</mo></mrow></math>" role="presentation" style="font-size: 90%; display: inline-block; position: relative;"><svg xmlns:xlink="http://www.w3.org/1999/xlink" width="10.894ex" height="2.779ex" viewBox="0 -846.5 4690.5 1196.3" role="img" focusable="false" style="vertical-align: -0.812ex;" aria-hidden="true"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><g is="true"><g is="true"><use xlink:href="#MJMAIN-5B"></use></g><g is="true" transform="translate(278,0)"><use xlink:href="#MJMAIN-2212"></use></g><g is="true" transform="translate(1057,0)"><g is="true"><use xlink:href="#MJMAIN-39"></use><use xlink:href="#MJMAIN-30" x="500" y="0"></use></g><g is="true" transform="translate(1001,393)"><use transform="scale(0.707)" xlink:href="#MJMAIN-2218"></use></g></g><g is="true" transform="translate(2511,0)"><use xlink:href="#MJMAIN-2C"></use></g><g is="true" transform="translate(2957,0)"><g is="true"><use xlink:href="#MJMAIN-39"></use><use xlink:href="#MJMAIN-30" x="500" y="0"></use></g><g is="true" transform="translate(1001,393)"><use transform="scale(0.707)" xlink:href="#MJMAIN-2218"></use></g></g><g is="true" transform="translate(4411,0)"><use xlink:href="#MJMAIN-5D"></use></g></g></g></svg><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow is="true"><mo is="true">[</mo><mo is="true">−</mo><msup is="true"><mn is="true">90</mn><mo is="true">∘</mo></msup><mo is="true">,</mo><msup is="true"><mn is="true">90</mn><mo is="true">∘</mo></msup><mo is="true">]</mo></mrow></math></span></span><script type="math/mml" id="MathJax-Element-62"><math><mrow is="true"><mo is="true">[</mo><mo is="true">−</mo><msup is="true"><mn is="true">90</mn><mo is="true">∘</mo></msup><mo is="true">,</mo><msup is="true"><mn is="true">90</mn><mo is="true">∘</mo></msup><mo is="true">]</mo></mrow></math></script></span> into steps of 15°, and it is intended as the percentage of images within ± 15 degrees of error. In our measurement of the yaw accuracy we used the same metric to enable a comparison with these works.</div><section id="sec0012"><h4 id="sectt0015" class="u-margin-m-top u-margin-xs-bottom">4.2.1. Methods</h4><div class="u-margin-s-bottom" id="para0052">In this experiment we manipulated two factors: network type and optimiser. The experiment was divided into two phases:
<ul class="list"><li class="react-xocs-list-item"><span class="list-label">1.</span><span><div class="u-margin-s-bottom" id="para0053">Optimiser selection. In the first phase we used a standard network to select the best optimiser for this dataset. We trained the LeNet-5 <a class="anchor anchor-primary" href="#bib0035" name="bbib0035" data-sd-ui-side-panel-opener="true" data-xocs-content-type="reference" data-xocs-content-id="bib0035"><span class="anchor-text-container"><span class="anchor-text">[35]</span></span></a> using the four optimisers described in <a class="anchor anchor-primary" href="#sec0006" name="bsec0006" data-sd-ui-side-panel-opener="true" data-xocs-content-type="reference" data-xocs-content-id="sec0006"><span class="anchor-text-container"><span class="anchor-text">Section&nbsp;3.3</span></span></a> plus SGD and SGD with momentum.</div></span></li><li class="react-xocs-list-item"><span class="list-label">2.</span><span><div class="u-margin-s-bottom" id="para0054">Network selection. In the second phase we used the optimiser selected previously for finding the best architecture among the four previously described (<a class="anchor anchor-primary" href="#fig0003" name="bfig0003" data-sd-ui-side-panel-opener="true" data-xocs-content-type="reference" data-xocs-content-id="fig0003"><span class="anchor-text-container"><span class="anchor-text">Fig.&nbsp;3</span></span></a>).</div></span></li></ul></div><div class="u-margin-s-bottom" id="para0055">The AFLW dataset is extremely challenging because the distribution of poses is not uniform. Roll has a mean and standard deviation of 1.07 ± 14.04°, pitch <span class="math"><span class="MathJax_Preview" style=""></span><span class="MathJax_SVG" id="MathJax-Element-63-Frame" tabindex="0" data-mathml="<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mrow is=&quot;true&quot;><mo is=&quot;true&quot;>&amp;#x2212;</mo><mn is=&quot;true&quot;>8.1</mn><mo is=&quot;true&quot;>&amp;#xB1;</mo><mn is=&quot;true&quot;>13</mn><mo is=&quot;true&quot;>.</mo><msup is=&quot;true&quot;><mn is=&quot;true&quot;>4</mn><mo is=&quot;true&quot;>&amp;#x2218;</mo></msup></mrow></math>" role="presentation" style="font-size: 90%; display: inline-block; position: relative;"><svg xmlns:xlink="http://www.w3.org/1999/xlink" width="13.196ex" height="2.202ex" viewBox="0 -796.9 5681.5 947.9" role="img" focusable="false" style="vertical-align: -0.351ex;" aria-hidden="true"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><g is="true"><g is="true"><use xlink:href="#MJMAIN-2212"></use></g><g is="true" transform="translate(778,0)"><use xlink:href="#MJMAIN-38"></use><use xlink:href="#MJMAIN-2E" x="500" y="0"></use><use xlink:href="#MJMAIN-31" x="779" y="0"></use></g><g is="true" transform="translate(2280,0)"><use xlink:href="#MJMAIN-B1"></use></g><g is="true" transform="translate(3280,0)"><use xlink:href="#MJMAIN-31"></use><use xlink:href="#MJMAIN-33" x="500" y="0"></use></g><g is="true" transform="translate(4281,0)"><use xlink:href="#MJMAIN-2E"></use></g><g is="true" transform="translate(4727,0)"><g is="true"><use xlink:href="#MJMAIN-34"></use></g><g is="true" transform="translate(500,404)"><use transform="scale(0.707)" xlink:href="#MJMAIN-2218"></use></g></g></g></g></svg><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow is="true"><mo is="true">−</mo><mn is="true">8.1</mn><mo is="true">±</mo><mn is="true">13</mn><mo is="true">.</mo><msup is="true"><mn is="true">4</mn><mo is="true">∘</mo></msup></mrow></math></span></span><script type="math/mml" id="MathJax-Element-63"><math><mrow is="true"><mo is="true">−</mo><mn is="true">8.1</mn><mo is="true">±</mo><mn is="true">13</mn><mo is="true">.</mo><msup is="true"><mn is="true">4</mn><mo is="true">∘</mo></msup></mrow></math></script></span>, and yaw 1.91 ± 41.8°. Because of this asymmetrical distribution it is difficult to uniformly map the angles in a continuous interval without losing precision. For this reason we decided to take only images above and below 2.698 standard deviations (1.5 the interquartile range of the lower and higher quartile). The final distribution contained poses in the following ranges: roll=<span class="math"><span class="MathJax_Preview" style=""></span><span class="MathJax_SVG" id="MathJax-Element-64-Frame" tabindex="0" data-mathml="<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mrow is=&quot;true&quot;><mo is=&quot;true&quot;>[</mo><mo is=&quot;true&quot;>&amp;#x2212;</mo><msup is=&quot;true&quot;><mn is=&quot;true&quot;>25</mn><mo is=&quot;true&quot;>&amp;#x2218;</mo></msup><mo is=&quot;true&quot;>,</mo><msup is=&quot;true&quot;><mn is=&quot;true&quot;>25</mn><mo is=&quot;true&quot;>&amp;#x2218;</mo></msup><mo is=&quot;true&quot;>]</mo><mo is=&quot;true&quot;>,</mo></mrow></math>" role="presentation" style="font-size: 90%; display: inline-block; position: relative;"><svg xmlns:xlink="http://www.w3.org/1999/xlink" width="11.541ex" height="2.779ex" viewBox="0 -846.5 4969 1196.3" role="img" focusable="false" style="vertical-align: -0.812ex;" aria-hidden="true"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><g is="true"><g is="true"><use xlink:href="#MJMAIN-5B"></use></g><g is="true" transform="translate(278,0)"><use xlink:href="#MJMAIN-2212"></use></g><g is="true" transform="translate(1057,0)"><g is="true"><use xlink:href="#MJMAIN-32"></use><use xlink:href="#MJMAIN-35" x="500" y="0"></use></g><g is="true" transform="translate(1001,393)"><use transform="scale(0.707)" xlink:href="#MJMAIN-2218"></use></g></g><g is="true" transform="translate(2511,0)"><use xlink:href="#MJMAIN-2C"></use></g><g is="true" transform="translate(2957,0)"><g is="true"><use xlink:href="#MJMAIN-32"></use><use xlink:href="#MJMAIN-35" x="500" y="0"></use></g><g is="true" transform="translate(1001,393)"><use transform="scale(0.707)" xlink:href="#MJMAIN-2218"></use></g></g><g is="true" transform="translate(4411,0)"><use xlink:href="#MJMAIN-5D"></use></g><g is="true" transform="translate(4690,0)"><use xlink:href="#MJMAIN-2C"></use></g></g></g></svg><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow is="true"><mo is="true">[</mo><mo is="true">−</mo><msup is="true"><mn is="true">25</mn><mo is="true">∘</mo></msup><mo is="true">,</mo><msup is="true"><mn is="true">25</mn><mo is="true">∘</mo></msup><mo is="true">]</mo><mo is="true">,</mo></mrow></math></span></span><script type="math/mml" id="MathJax-Element-64"><math><mrow is="true"><mo is="true">[</mo><mo is="true">−</mo><msup is="true"><mn is="true">25</mn><mo is="true">∘</mo></msup><mo is="true">,</mo><msup is="true"><mn is="true">25</mn><mo is="true">∘</mo></msup><mo is="true">]</mo><mo is="true">,</mo></mrow></math></script></span> pitch=<span class="math"><span class="MathJax_Preview" style=""></span><span class="MathJax_SVG" id="MathJax-Element-65-Frame" tabindex="0" data-mathml="<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mrow is=&quot;true&quot;><mo is=&quot;true&quot;>[</mo><mo is=&quot;true&quot;>&amp;#x2212;</mo><msup is=&quot;true&quot;><mn is=&quot;true&quot;>45</mn><mo is=&quot;true&quot;>&amp;#x2218;</mo></msup><mo is=&quot;true&quot;>,</mo><msup is=&quot;true&quot;><mn is=&quot;true&quot;>45</mn><mo is=&quot;true&quot;>&amp;#x2218;</mo></msup><mo is=&quot;true&quot;>]</mo><mo is=&quot;true&quot;>,</mo></mrow></math>" role="presentation" style="font-size: 90%; display: inline-block; position: relative;"><svg xmlns:xlink="http://www.w3.org/1999/xlink" width="11.541ex" height="2.779ex" viewBox="0 -846.5 4969 1196.3" role="img" focusable="false" style="vertical-align: -0.812ex;" aria-hidden="true"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><g is="true"><g is="true"><use xlink:href="#MJMAIN-5B"></use></g><g is="true" transform="translate(278,0)"><use xlink:href="#MJMAIN-2212"></use></g><g is="true" transform="translate(1057,0)"><g is="true"><use xlink:href="#MJMAIN-34"></use><use xlink:href="#MJMAIN-35" x="500" y="0"></use></g><g is="true" transform="translate(1001,404)"><use transform="scale(0.707)" xlink:href="#MJMAIN-2218"></use></g></g><g is="true" transform="translate(2511,0)"><use xlink:href="#MJMAIN-2C"></use></g><g is="true" transform="translate(2957,0)"><g is="true"><use xlink:href="#MJMAIN-34"></use><use xlink:href="#MJMAIN-35" x="500" y="0"></use></g><g is="true" transform="translate(1001,404)"><use transform="scale(0.707)" xlink:href="#MJMAIN-2218"></use></g></g><g is="true" transform="translate(4411,0)"><use xlink:href="#MJMAIN-5D"></use></g><g is="true" transform="translate(4690,0)"><use xlink:href="#MJMAIN-2C"></use></g></g></g></svg><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow is="true"><mo is="true">[</mo><mo is="true">−</mo><msup is="true"><mn is="true">45</mn><mo is="true">∘</mo></msup><mo is="true">,</mo><msup is="true"><mn is="true">45</mn><mo is="true">∘</mo></msup><mo is="true">]</mo><mo is="true">,</mo></mrow></math></span></span><script type="math/mml" id="MathJax-Element-65"><math><mrow is="true"><mo is="true">[</mo><mo is="true">−</mo><msup is="true"><mn is="true">45</mn><mo is="true">∘</mo></msup><mo is="true">,</mo><msup is="true"><mn is="true">45</mn><mo is="true">∘</mo></msup><mo is="true">]</mo><mo is="true">,</mo></mrow></math></script></span> yaw=<span class="math"><span class="MathJax_Preview" style=""></span><span class="MathJax_SVG" id="MathJax-Element-66-Frame" tabindex="0" data-mathml="<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mrow is=&quot;true&quot;><mo is=&quot;true&quot;>[</mo><mo is=&quot;true&quot;>&amp;#x2212;</mo><msup is=&quot;true&quot;><mn is=&quot;true&quot;>100</mn><mo is=&quot;true&quot;>&amp;#x2218;</mo></msup><mo is=&quot;true&quot;>,</mo><msup is=&quot;true&quot;><mn is=&quot;true&quot;>100</mn><mo is=&quot;true&quot;>&amp;#x2218;</mo></msup><mo is=&quot;true&quot;>]</mo></mrow></math>" role="presentation" style="font-size: 90%; display: inline-block; position: relative;"><svg xmlns:xlink="http://www.w3.org/1999/xlink" width="13.219ex" height="2.779ex" viewBox="0 -846.5 5691.5 1196.3" role="img" focusable="false" style="vertical-align: -0.812ex;" aria-hidden="true"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><g is="true"><g is="true"><use xlink:href="#MJMAIN-5B"></use></g><g is="true" transform="translate(278,0)"><use xlink:href="#MJMAIN-2212"></use></g><g is="true" transform="translate(1057,0)"><g is="true"><use xlink:href="#MJMAIN-31"></use><use xlink:href="#MJMAIN-30" x="500" y="0"></use><use xlink:href="#MJMAIN-30" x="1001" y="0"></use></g><g is="true" transform="translate(1501,393)"><use transform="scale(0.707)" xlink:href="#MJMAIN-2218"></use></g></g><g is="true" transform="translate(3012,0)"><use xlink:href="#MJMAIN-2C"></use></g><g is="true" transform="translate(3457,0)"><g is="true"><use xlink:href="#MJMAIN-31"></use><use xlink:href="#MJMAIN-30" x="500" y="0"></use><use xlink:href="#MJMAIN-30" x="1001" y="0"></use></g><g is="true" transform="translate(1501,393)"><use transform="scale(0.707)" xlink:href="#MJMAIN-2218"></use></g></g><g is="true" transform="translate(5412,0)"><use xlink:href="#MJMAIN-5D"></use></g></g></g></svg><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow is="true"><mo is="true">[</mo><mo is="true">−</mo><msup is="true"><mn is="true">100</mn><mo is="true">∘</mo></msup><mo is="true">,</mo><msup is="true"><mn is="true">100</mn><mo is="true">∘</mo></msup><mo is="true">]</mo></mrow></math></span></span><script type="math/mml" id="MathJax-Element-66"><math><mrow is="true"><mo is="true">[</mo><mo is="true">−</mo><msup is="true"><mn is="true">100</mn><mo is="true">∘</mo></msup><mo is="true">,</mo><msup is="true"><mn is="true">100</mn><mo is="true">∘</mo></msup><mo is="true">]</mo></mrow></math></script></span><span>. To further compensate for the high variability in the angle distribution, we decided to use the <a href="/topics/engineering/hyperbolic-tangent" title="Learn more about hyperbolic tangent from ScienceDirect's AI-generated Topic Pages" class="topic-link">hyperbolic tangent</a> activation function. Using the hyperbolic function the output of the networks was constrained to within the range </span><span class="math"><span class="MathJax_Preview" style=""></span><span class="MathJax_SVG" id="MathJax-Element-67-Frame" tabindex="0" data-mathml="<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mrow is=&quot;true&quot;><mo is=&quot;true&quot;>[</mo><mo is=&quot;true&quot;>&amp;#x2212;</mo><mn is=&quot;true&quot;>1</mn><mo is=&quot;true&quot;>,</mo><mn is=&quot;true&quot;>1</mn><mo is=&quot;true&quot;>]</mo></mrow></math>" role="presentation" style="font-size: 90%; display: inline-block; position: relative;"><svg xmlns:xlink="http://www.w3.org/1999/xlink" width="6.461ex" height="2.779ex" viewBox="0 -846.5 2781.7 1196.3" role="img" focusable="false" style="vertical-align: -0.812ex;" aria-hidden="true"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><g is="true"><g is="true"><use xlink:href="#MJMAIN-5B"></use></g><g is="true" transform="translate(278,0)"><use xlink:href="#MJMAIN-2212"></use></g><g is="true" transform="translate(1057,0)"><use xlink:href="#MJMAIN-31"></use></g><g is="true" transform="translate(1557,0)"><use xlink:href="#MJMAIN-2C"></use></g><g is="true" transform="translate(2002,0)"><use xlink:href="#MJMAIN-31"></use></g><g is="true" transform="translate(2503,0)"><use xlink:href="#MJMAIN-5D"></use></g></g></g></svg><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow is="true"><mo is="true">[</mo><mo is="true">−</mo><mn is="true">1</mn><mo is="true">,</mo><mn is="true">1</mn><mo is="true">]</mo></mrow></math></span></span><script type="math/mml" id="MathJax-Element-67"><math><mrow is="true"><mo is="true">[</mo><mo is="true">−</mo><mn is="true">1</mn><mo is="true">,</mo><mn is="true">1</mn><mo is="true">]</mo></mrow></math></script></span> instead of [0, 1]. We considered only faces with a bounding box greater or equal to 64 × 64 pixels. In total we discarded very few images (less than 5%) because the mean and standard deviation of the bounding boxes was 300 ± 343 pixels, with 84% of the samples distributed between 110 and 647 pixels. In the first phase we trained the networks for 20, 000 epochs and in the second phase for 30, 000 (mini-batches of size 64). In both phases we used dropout whit <span class="math"><span class="MathJax_Preview" style=""></span><span class="MathJax_SVG" id="MathJax-Element-68-Frame" tabindex="0" data-mathml="<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mrow is=&quot;true&quot;><mi is=&quot;true&quot;>p</mi><mo is=&quot;true&quot;>=</mo><mn is=&quot;true&quot;>0.5</mn></mrow></math>" role="presentation" style="font-size: 90%; display: inline-block; position: relative;"><svg xmlns:xlink="http://www.w3.org/1999/xlink" width="7.329ex" height="2.317ex" viewBox="-38.5 -747.2 3155.6 997.6" role="img" focusable="false" style="vertical-align: -0.582ex; margin-left: -0.089ex;" aria-hidden="true"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><g is="true"><g is="true"><use xlink:href="#MJMATHI-70"></use></g><g is="true" transform="translate(781,0)"><use xlink:href="#MJMAIN-3D"></use></g><g is="true" transform="translate(1837,0)"><use xlink:href="#MJMAIN-30"></use><use xlink:href="#MJMAIN-2E" x="500" y="0"></use><use xlink:href="#MJMAIN-35" x="779" y="0"></use></g></g></g></svg><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow is="true"><mi is="true">p</mi><mo is="true">=</mo><mn is="true">0.5</mn></mrow></math></span></span><script type="math/mml" id="MathJax-Element-68"><math><mrow is="true"><mi is="true">p</mi><mo is="true">=</mo><mn is="true">0.5</mn></mrow></math></script></span>. In the second phase we decided to extend the number of epochs to 30000 because the training was much faster compared to the Prima dataset (e.g. 8.0 vs. 18.75&nbsp;h for network A). Training the network for more epochs generally leads to stabler solutions and it is recommended when using dropout without time constraint <a class="anchor anchor-primary" href="#bib0022" name="bbib0022" data-sd-ui-side-panel-opener="true" data-xocs-content-type="reference" data-xocs-content-id="bib0022"><span class="anchor-text-container"><span class="anchor-text">[22]</span></span></a>.</div><div class="u-margin-s-bottom" id="para0056"><span>We applied a five-fold cross-validation procedure to test our networks on the dataset. After randomly dividing the dataset into five folds, we trained the models on four of the five folds and we tested them on the remaining one. The procedure was repeated five times, independently testing the model on each one of the five folds. The mean of the five tests was considered to be the final score. The total number of images included in each one of the five folds was 16, 696, whereas the number of images left for the test was 4173. To test the <a href="/topics/engineering/classification-accuracy" title="Learn more about classification accuracy from ScienceDirect's AI-generated Topic Pages" class="topic-link">classification accuracy</a> we split the yaw poses range </span><span class="math"><span class="MathJax_Preview" style=""></span><span class="MathJax_SVG" id="MathJax-Element-69-Frame" tabindex="0" data-mathml="<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mrow is=&quot;true&quot;><mo is=&quot;true&quot;>[</mo><mo is=&quot;true&quot;>&amp;#x2212;</mo><msup is=&quot;true&quot;><mn is=&quot;true&quot;>100</mn><mo is=&quot;true&quot;>&amp;#x2218;</mo></msup><mo is=&quot;true&quot;>,</mo><msup is=&quot;true&quot;><mn is=&quot;true&quot;>100</mn><mo is=&quot;true&quot;>&amp;#x2218;</mo></msup><mo is=&quot;true&quot;>]</mo></mrow></math>" role="presentation" style="font-size: 90%; display: inline-block; position: relative;"><svg xmlns:xlink="http://www.w3.org/1999/xlink" width="13.219ex" height="2.779ex" viewBox="0 -846.5 5691.5 1196.3" role="img" focusable="false" style="vertical-align: -0.812ex;" aria-hidden="true"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><g is="true"><g is="true"><use xlink:href="#MJMAIN-5B"></use></g><g is="true" transform="translate(278,0)"><use xlink:href="#MJMAIN-2212"></use></g><g is="true" transform="translate(1057,0)"><g is="true"><use xlink:href="#MJMAIN-31"></use><use xlink:href="#MJMAIN-30" x="500" y="0"></use><use xlink:href="#MJMAIN-30" x="1001" y="0"></use></g><g is="true" transform="translate(1501,393)"><use transform="scale(0.707)" xlink:href="#MJMAIN-2218"></use></g></g><g is="true" transform="translate(3012,0)"><use xlink:href="#MJMAIN-2C"></use></g><g is="true" transform="translate(3457,0)"><g is="true"><use xlink:href="#MJMAIN-31"></use><use xlink:href="#MJMAIN-30" x="500" y="0"></use><use xlink:href="#MJMAIN-30" x="1001" y="0"></use></g><g is="true" transform="translate(1501,393)"><use transform="scale(0.707)" xlink:href="#MJMAIN-2218"></use></g></g><g is="true" transform="translate(5412,0)"><use xlink:href="#MJMAIN-5D"></use></g></g></g></svg><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow is="true"><mo is="true">[</mo><mo is="true">−</mo><msup is="true"><mn is="true">100</mn><mo is="true">∘</mo></msup><mo is="true">,</mo><msup is="true"><mn is="true">100</mn><mo is="true">∘</mo></msup><mo is="true">]</mo></mrow></math></span></span><script type="math/mml" id="MathJax-Element-69"><math><mrow is="true"><mo is="true">[</mo><mo is="true">−</mo><msup is="true"><mn is="true">100</mn><mo is="true">∘</mo></msup><mo is="true">,</mo><msup is="true"><mn is="true">100</mn><mo is="true">∘</mo></msup><mo is="true">]</mo></mrow></math></script></span> into different categories using steps of 15°. The accuracy is intended as the percentage of images with ± 15° error. This measure is in line with the one used in <a class="anchor anchor-primary" href="#bib0015" name="bbib0015" data-sd-ui-side-panel-opener="true" data-xocs-content-type="reference" data-xocs-content-id="bib0015"><span class="anchor-text-container"><span class="anchor-text">[15]</span></span></a> and makes it possible to compare the results obtained with the different methods reported in that article. To have more reliable results we took the mean of the five folds.</div><div class="u-margin-s-bottom" id="para0057">The hyper-parameters selection followed the same methodology described in <a class="anchor anchor-primary" href="#sec0009" name="bsec0009" data-sd-ui-side-panel-opener="true" data-xocs-content-type="reference" data-xocs-content-id="sec0009"><span class="anchor-text-container"><span class="anchor-text">Section&nbsp;4.1.1</span></span></a>. The training of roll, pitch and yaw for a single experimental condition (20, 000 epochs) took 8.0&nbsp;h on the smallest architecture (A) and 9.8&nbsp;h on the largest architecture (D).</div></section><section id="sec0013"><h4 id="sectt0016" class="u-margin-m-top u-margin-xs-bottom">4.2.2. Results</h4><div class="u-margin-s-bottom"><div id="para0058">The results for the first phase (optimiser selection) are reported in <a class="anchor anchor-primary" href="#tbl0003" name="btbl0003" data-sd-ui-side-panel-opener="true" data-xocs-content-type="reference" data-xocs-content-id="tbl0003"><span class="anchor-text-container"><span class="anchor-text">Table&nbsp;3</span></span></a>. The results show that the RMSProp had the lowest reported MAE for roll, pitch and yaw (4.4 ± 4.35, 7.15 ± 6.0, 11.04 ± 10.86). As it is possible to see in <a class="anchor anchor-primary" href="#fig0012" name="bfig0012" data-sd-ui-side-panel-opener="true" data-xocs-content-type="reference" data-xocs-content-id="fig0012"><span class="anchor-text-container"><span class="anchor-text">Fig.&nbsp;12</span></span></a> the RMSProp had the fastest convergence rate and it reached the lowest loss values.</div><div class="tables rowsep-0 colsep-0 frame-topbot" id="tbl0003"><span class="captions text-s"><span id="cap0018"><p id="spara0025"><span class="label">Table 3</span>. In this table we report the results obtained on the AFLW dataset for the five-fold cross validation test. These results have been obtained training the architecture A for 30, 000 epochs (14.6&nbsp;h). The results are in terms of MAE(accuracy). MAE is expressed in degrees and Accuracy is expressed in percentage. The best scores are in bold.</p></span></span><div class="groups"><table><thead><tr class="rowsep-1"><th scope="row" class="align-left valign-top">Optimiser</th><th scope="row" class="align-left valign-top">Roll</th><th scope="row" class="align-left valign-top">Pitch</th><th scope="row" class="align-left valign-top">Yaw</th></tr></thead><tbody><tr><th class="align-left valign-top" scope="row">Adadelta <a class="anchor anchor-primary" href="#bib0029" name="bbib0029" data-sd-ui-side-panel-opener="true" data-xocs-content-type="reference" data-xocs-content-id="bib0029"><span class="anchor-text-container"><span class="anchor-text">[29]</span></span></a></th><td class="align-left valign-top">6.26(22.2)</td><td class="align-left valign-top">9.98(42.67)</td><td class="align-left valign-top">21.87(22.19)</td></tr><tr><th class="align-left valign-top" scope="row">Adagrad <a class="anchor anchor-primary" href="#bib0028" name="bbib0028" data-sd-ui-side-panel-opener="true" data-xocs-content-type="reference" data-xocs-content-id="bib0028"><span class="anchor-text-container"><span class="anchor-text">[28]</span></span></a></th><td class="align-left valign-top">5.27(69.23)</td><td class="align-left valign-top">8.24(51.29)</td><td class="align-left valign-top">17.83(28.8)</td></tr><tr><th class="align-left valign-top" scope="row">Adam <a class="anchor anchor-primary" href="#bib0031" name="bbib0031" data-sd-ui-side-panel-opener="true" data-xocs-content-type="reference" data-xocs-content-id="bib0031"><span class="anchor-text-container"><span class="anchor-text">[31]</span></span></a></th><td class="align-left valign-top">4.81(72.41)</td><td class="align-left valign-top">7.78(53.49)</td><td class="align-left valign-top">13.5(38.56)</td></tr><tr><th class="align-left valign-top" scope="row">RMSProp <a class="anchor anchor-primary" href="#bib0030" name="bbib0030" data-sd-ui-side-panel-opener="true" data-xocs-content-type="reference" data-xocs-content-id="bib0030"><span class="anchor-text-container"><span class="anchor-text">[30]</span></span></a></th><td class="align-left valign-top"><strong>4.4(75.14)</strong></td><td class="align-left valign-top"><strong>7.15(55.98)</strong></td><td class="align-left valign-top"><strong>11.04(44.54)</strong></td></tr><tr><th class="align-left valign-top" scope="row">SGD</th><td class="align-left valign-top">7.0(58.64)</td><td class="align-left valign-top">9.89(42.15)</td><td class="align-left valign-top">22.98(22.23)</td></tr><tr><th class="align-left valign-top" scope="row">SGD momentum</th><td class="align-left valign-top">6.17(63.19)</td><td class="align-left valign-top">10.3(42.37)</td><td class="align-left valign-top">21.31(22.52)</td></tr></tbody></table></div></div><figure class="figure text-xs" id="fig0012"><span><img src="https://ars.els-cdn.com/content/image/1-s2.0-S0031320317302327-gr12.jpg" height="302" alt="Fig. 12" aria-describedby="cap0012"><ol class="u-margin-s-bottom"><li><a class="anchor download-link u-font-sans anchor-primary" href="https://ars.els-cdn.com/content/image/1-s2.0-S0031320317302327-gr12_lrg.jpg" target="_blank" download="" title="Download high-res image (281KB)"><span class="anchor-text-container"><span class="anchor-text">Download: <span class="download-link-title">Download high-res image (281KB)</span></span></span></a></li><li><a class="anchor download-link u-font-sans anchor-primary" href="https://ars.els-cdn.com/content/image/1-s2.0-S0031320317302327-gr12.jpg" target="_blank" download="" title="Download full-size image"><span class="anchor-text-container"><span class="anchor-text">Download: <span class="download-link-title">Download full-size image</span></span></span></a></li></ol></span><span class="captions text-s"><span id="cap0012"><p id="spara0019"><span class="label">Fig. 12</span>. Comparison of the convergence speed between the six optimisers used to train architecture A for yaw estimation on the AFLW dataset. The loss values are the mean of the five fold.</p></span></span></figure></div><div class="u-margin-s-bottom"><div id="para0059">The results for the second phase (network selection) are reported in <a class="anchor anchor-primary" href="#fig0013" name="bfig0013" data-sd-ui-side-panel-opener="true" data-xocs-content-type="reference" data-xocs-content-id="fig0013"><span class="anchor-text-container"><span class="anchor-text">Fig.&nbsp;13</span></span></a>. The architecture B had the lowest MAE (4.15 ± 3.87, 6.8 ± 5.64, 9.51 ± 9.21). Mapping the continuous output in three discrete categories for roll, nine for pitch and 13 for yaw, we were able to interpret the results in terms of classification. The accuracy for roll, pitch and yaw was originally 76.55%, 57.68% and 48.55%. If we consider an error of ± 15° the accuracy drastically increases to 99.66%, 97.24% and 92.47%. To better visualise the accuracy we report in <a class="anchor anchor-primary" href="#fig0014" name="bfig0014" data-sd-ui-side-panel-opener="true" data-xocs-content-type="reference" data-xocs-content-id="fig0014"><span class="anchor-text-container"><span class="anchor-text">Fig.&nbsp;14</span></span></a> the confusion table of the best network (second architecture, RMSProp optimiser) for roll, pitch and yaw classification.</div><figure class="figure text-xs" id="fig0013"><span><img src="https://ars.els-cdn.com/content/image/1-s2.0-S0031320317302327-gr13.jpg" height="292" alt="Fig. 13" aria-describedby="cap0013"><ol class="u-margin-s-bottom"><li><a class="anchor download-link u-font-sans anchor-primary" href="https://ars.els-cdn.com/content/image/1-s2.0-S0031320317302327-gr13_lrg.jpg" target="_blank" download="" title="Download high-res image (347KB)"><span class="anchor-text-container"><span class="anchor-text">Download: <span class="download-link-title">Download high-res image (347KB)</span></span></span></a></li><li><a class="anchor download-link u-font-sans anchor-primary" href="https://ars.els-cdn.com/content/image/1-s2.0-S0031320317302327-gr13.jpg" target="_blank" download="" title="Download full-size image"><span class="anchor-text-container"><span class="anchor-text">Download: <span class="download-link-title">Download full-size image</span></span></span></a></li></ol></span><span class="captions text-s"><span id="cap0013"><p id="spara0020"><span class="label">Fig. 13</span>. Comparison in term of <a href="/topics/engineering/mean-absolute-error" title="Learn more about MAE from ScienceDirect's AI-generated Topic Pages" class="topic-link">MAE</a> between four architectures for roll pitch and yaw using the RMSProp optimiser on the AFLW dataset. The STD has been shrunk by a factor of two for graphical reason.</p></span></span></figure><figure class="figure text-xs" id="fig0014"><span><img src="https://ars.els-cdn.com/content/image/1-s2.0-S0031320317302327-gr14.jpg" height="154" alt="Fig. 14" aria-describedby="cap0014"><ol class="u-margin-s-bottom"><li><a class="anchor download-link u-font-sans anchor-primary" href="https://ars.els-cdn.com/content/image/1-s2.0-S0031320317302327-gr14_lrg.jpg" target="_blank" download="" title="Download high-res image (94KB)"><span class="anchor-text-container"><span class="anchor-text">Download: <span class="download-link-title">Download high-res image (94KB)</span></span></span></a></li><li><a class="anchor download-link u-font-sans anchor-primary" href="https://ars.els-cdn.com/content/image/1-s2.0-S0031320317302327-gr14.jpg" target="_blank" download="" title="Download full-size image"><span class="anchor-text-container"><span class="anchor-text">Download: <span class="download-link-title">Download full-size image</span></span></span></a></li></ol></span><span class="captions text-s"><span id="cap0014"><p id="spara0021"><span class="label">Fig. 14</span>. Representation of the confusion tables for roll (left), pitch (centre) and yaw (right) of the best architecture (B) trained with the RMSProp optimiser on the AFLW dataset. Each row of the tables represents the instances in a predicted class while each column represents the instances in an actual class.</p></span></span></figure></div><div class="u-margin-s-bottom"><div id="para0060">Similarly to what we did for the Prima dataset, we investigated the presence of overfitting in a separate phase. We trained the best architecture using RMSProp on the five-fold test and we generated a validation set randomly picking 50% of the images from the test fold. We monitored the RMSE for both training and validation set. The results for the yaw estimation are reported in <a class="anchor anchor-primary" href="#fig0015" name="bfig0015" data-sd-ui-side-panel-opener="true" data-xocs-content-type="reference" data-xocs-content-id="fig0015"><span class="anchor-text-container"><span class="anchor-text">Fig.&nbsp;15</span></span></a> and represent the mean RMSE for each one of the five folds in 20,000 epochs.</div><figure class="figure text-xs" id="fig0015"><span><img src="https://ars.els-cdn.com/content/image/1-s2.0-S0031320317302327-gr15.jpg" height="302" alt="Fig. 15" aria-describedby="cap0015"><ol class="u-margin-s-bottom"><li><a class="anchor download-link u-font-sans anchor-primary" href="https://ars.els-cdn.com/content/image/1-s2.0-S0031320317302327-gr15_lrg.jpg" target="_blank" download="" title="Download high-res image (145KB)"><span class="anchor-text-container"><span class="anchor-text">Download: <span class="download-link-title">Download high-res image (145KB)</span></span></span></a></li><li><a class="anchor download-link u-font-sans anchor-primary" href="https://ars.els-cdn.com/content/image/1-s2.0-S0031320317302327-gr15.jpg" target="_blank" download="" title="Download full-size image"><span class="anchor-text-container"><span class="anchor-text">Download: <span class="download-link-title">Download full-size image</span></span></span></a></li></ol></span><span class="captions text-s"><span id="cap0015"><p id="spara0022"><span class="label">Fig. 15</span>. Performance of the best architecture (A) in terms of RMSE (degrees) on the training and validation set for the estimation of the yaw angle on the AFLW dataset.</p></span></span></figure></div><div class="u-margin-s-bottom"><div id="para0061">The comparison with other methods (<a class="anchor anchor-primary" href="#tbl0004" name="btbl0004" data-sd-ui-side-panel-opener="true" data-xocs-content-type="reference" data-xocs-content-id="tbl0004"><span class="anchor-text-container"><span class="anchor-text">Table&nbsp;4</span></span></a>) shows that CNNs perform better than any other algorithm in terms of MAE and accuracy.</div><div class="tables rowsep-0 colsep-0 frame-topbot" id="tbl0004"><span class="captions text-s"><span id="cap0019"><p id="spara0026"><span class="label">Table 4</span>. In this table we report the results in term of MAE (degrees) and accuracy (percentage) obtained with different methods for the yaw estimation on the AFLW and the AFW datasets. Our results have been obtained training the architecture B for 30, 000 epochs (14.6&nbsp;h) with the RMSProp optimiser. MAE is expressed in degrees and Accuracy is expressed in percentage. The best scores are in bold.</p></span></span><div class="groups"><table><thead><tr class="rowsep-1"><th scope="row" class="align-left valign-top">Method</th><th scope="row" class="align-left valign-top">AFLW</th><th scope="row" class="align-left valign-top">AFW</th></tr></thead><tbody><tr><th class="align-left valign-top" scope="row">Mixture of trees <a class="anchor anchor-primary" href="#bib0034" name="bbib0034" data-sd-ui-side-panel-opener="true" data-xocs-content-type="reference" data-xocs-content-id="bib0034"><span class="anchor-text-container"><span class="anchor-text">[34]</span></span></a></th><td class="align-left valign-top">46.54(15.72)</td><td class="align-left valign-top">40.17(26.07)</td></tr><tr><th class="align-left valign-top" scope="row">Patch Based <a class="anchor anchor-primary" href="#bib0039" name="bbib0039" data-sd-ui-side-panel-opener="true" data-xocs-content-type="reference" data-xocs-content-id="bib0039"><span class="anchor-text-container"><span class="anchor-text">[39]</span></span></a></th><td class="align-left valign-top">38.39(23.87)</td><td class="align-left valign-top">41.67(21.36)</td></tr><tr><th class="align-left valign-top" scope="row">Feature Embedding <a class="anchor anchor-primary" href="#bib0041" name="bbib0041" data-sd-ui-side-panel-opener="true" data-xocs-content-type="reference" data-xocs-content-id="bib0041"><span class="anchor-text-container"><span class="anchor-text">[41]</span></span></a></th><td class="align-left valign-top">33.01(32.82)</td><td class="align-left valign-top">28.15(40.38)</td></tr><tr><th class="align-left valign-top" scope="row">Learning Manifold <a class="anchor anchor-primary" href="#bib0040" name="bbib0040" data-sd-ui-side-panel-opener="true" data-xocs-content-type="reference" data-xocs-content-id="bib0040"><span class="anchor-text-container"><span class="anchor-text">[40]</span></span></a></th><td class="align-left valign-top">16.31(63.13)</td><td class="align-left valign-top">18.26(58.33)</td></tr><tr><th class="align-left valign-top" scope="row">Approximate View Manifold <a class="anchor anchor-primary" href="#bib0015" name="bbib0015" data-sd-ui-side-panel-opener="true" data-xocs-content-type="reference" data-xocs-content-id="bib0015"><span class="anchor-text-container"><span class="anchor-text">[15]</span></span></a></th><td class="align-left valign-top">17.48(58.05)</td><td class="align-left valign-top">17.2(58.33)</td></tr><tr><th class="align-left valign-top" scope="row">CNNs [our]</th><td class="align-left valign-top"><strong>9.51(92.47)</strong></td><td class="align-left valign-top"><strong>16.73(75.29)</strong></td></tr></tbody></table></div></div></div></section></section><section id="sec0014"><h3 id="sectt0017" class="u-h4 u-margin-m-top u-margin-xs-bottom">4.3. Annotated face in the wild</h3><div class="u-margin-s-bottom" id="para0062">The AFW dataset is a benchmark proposed in <a class="anchor anchor-primary" href="#bib0034" name="bbib0034" data-sd-ui-side-panel-opener="true" data-xocs-content-type="reference" data-xocs-content-id="bib0034"><span class="anchor-text-container"><span class="anchor-text">[34]</span></span></a> to test the performance of face detection and head pose estimation methods. Similarly to the AFLW dataset, the AFW is composed of images sampled from social networks. It contains 205 images with 468 faces. Most of the images contain cluttered backgrounds with large variations in both face viewpoint and appearance (age, occlusion, expression, etc.). Each face is labeled with a bounding box, 13 discrete viewpoints (range <span class="math"><span class="MathJax_Preview" style=""></span><span class="MathJax_SVG" id="MathJax-Element-70-Frame" tabindex="0" data-mathml="<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mrow is=&quot;true&quot;><mo is=&quot;true&quot;>[</mo><mo is=&quot;true&quot;>&amp;#x2212;</mo><msup is=&quot;true&quot;><mn is=&quot;true&quot;>90</mn><mo is=&quot;true&quot;>&amp;#x2218;</mo></msup><mo is=&quot;true&quot;>,</mo><msup is=&quot;true&quot;><mn is=&quot;true&quot;>90</mn><mo is=&quot;true&quot;>&amp;#x2218;</mo></msup><mo is=&quot;true&quot;>]</mo></mrow></math>" role="presentation" style="font-size: 90%; display: inline-block; position: relative;"><svg xmlns:xlink="http://www.w3.org/1999/xlink" width="10.894ex" height="2.779ex" viewBox="0 -846.5 4690.5 1196.3" role="img" focusable="false" style="vertical-align: -0.812ex;" aria-hidden="true"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><g is="true"><g is="true"><use xlink:href="#MJMAIN-5B"></use></g><g is="true" transform="translate(278,0)"><use xlink:href="#MJMAIN-2212"></use></g><g is="true" transform="translate(1057,0)"><g is="true"><use xlink:href="#MJMAIN-39"></use><use xlink:href="#MJMAIN-30" x="500" y="0"></use></g><g is="true" transform="translate(1001,393)"><use transform="scale(0.707)" xlink:href="#MJMAIN-2218"></use></g></g><g is="true" transform="translate(2511,0)"><use xlink:href="#MJMAIN-2C"></use></g><g is="true" transform="translate(2957,0)"><g is="true"><use xlink:href="#MJMAIN-39"></use><use xlink:href="#MJMAIN-30" x="500" y="0"></use></g><g is="true" transform="translate(1001,393)"><use transform="scale(0.707)" xlink:href="#MJMAIN-2218"></use></g></g><g is="true" transform="translate(4411,0)"><use xlink:href="#MJMAIN-5D"></use></g></g></g></svg><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow is="true"><mo is="true">[</mo><mo is="true">−</mo><msup is="true"><mn is="true">90</mn><mo is="true">∘</mo></msup><mo is="true">,</mo><msup is="true"><mn is="true">90</mn><mo is="true">∘</mo></msup><mo is="true">]</mo></mrow></math></span></span><script type="math/mml" id="MathJax-Element-70"><math><mrow is="true"><mo is="true">[</mo><mo is="true">−</mo><msup is="true"><mn is="true">90</mn><mo is="true">∘</mo></msup><mo is="true">,</mo><msup is="true"><mn is="true">90</mn><mo is="true">∘</mo></msup><mo is="true">]</mo></mrow></math></script></span>) along pitch and yaw directions, and three discrete viewpoints along the roll direction (left, centre, right). This dataset differs from similar collections in its annotation of multiple, non-frontal faces in a single image. Pictures compatible with this dataset are shown in <a class="anchor anchor-primary" href="#fig0011" name="bfig0011" data-sd-ui-side-panel-opener="true" data-xocs-content-type="reference" data-xocs-content-id="fig0011"><span class="anchor-text-container"><span class="anchor-text">Fig.&nbsp;11</span></span></a>. Given the low number of images this dataset is generally used only for testing <a class="anchor anchor-primary" href="#bib0015" name="bbib0015" data-sd-ui-side-panel-opener="true" data-xocs-content-type="reference" data-xocs-content-id="bib0015"><span class="anchor-text-container"><span class="anchor-text">[15]</span></span></a>, <a class="anchor anchor-primary" href="#bib0034" name="bbib0034" data-sd-ui-side-panel-opener="true" data-xocs-content-type="reference" data-xocs-content-id="bib0034"><span class="anchor-text-container"><span class="anchor-text">[34]</span></span></a>. In our case we used the AFW dataset to test the best architectures trained on the AFLW dataset. In this way we have one more in-the-wild benchmark for comparing our work with other approaches.</div><section id="sec0015"><h4 id="sectt0018" class="u-margin-m-top u-margin-xs-bottom">4.3.1. Methods</h4><div class="u-margin-s-bottom" id="para0063">In this experiment we used the whole AFLW dataset (20, 869 faces) to train the architecture B. The network was trained for 30, 000 epochs. We used the RMSProp optimiser with the same hyper-parameters as used in the previous experiment: <span class="math"><span class="MathJax_Preview" style=""></span><span class="MathJax_SVG" id="MathJax-Element-71-Frame" tabindex="0" data-mathml="<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mrow is=&quot;true&quot;><mi is=&quot;true&quot;>&amp;#x3B1;</mi><mo is=&quot;true&quot;>=</mo><mn is=&quot;true&quot;>0.001</mn></mrow></math>" role="presentation" style="font-size: 90%; display: inline-block; position: relative;"><svg xmlns:xlink="http://www.w3.org/1999/xlink" width="9.883ex" height="1.971ex" viewBox="0 -747.2 4255.1 848.5" role="img" focusable="false" style="vertical-align: -0.235ex;" aria-hidden="true"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><g is="true"><g is="true"><use xlink:href="#MJMATHI-3B1"></use></g><g is="true" transform="translate(918,0)"><use xlink:href="#MJMAIN-3D"></use></g><g is="true" transform="translate(1974,0)"><use xlink:href="#MJMAIN-30"></use><use xlink:href="#MJMAIN-2E" x="500" y="0"></use><use xlink:href="#MJMAIN-30" x="779" y="0"></use><use xlink:href="#MJMAIN-30" x="1279" y="0"></use><use xlink:href="#MJMAIN-31" x="1780" y="0"></use></g></g></g></svg><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow is="true"><mi is="true">α</mi><mo is="true">=</mo><mn is="true">0.001</mn></mrow></math></span></span><script type="math/mml" id="MathJax-Element-71"><math><mrow is="true"><mi is="true">α</mi><mo is="true">=</mo><mn is="true">0.001</mn></mrow></math></script></span> and <span class="math"><span class="MathJax_Preview" style=""></span><span class="MathJax_SVG" id="MathJax-Element-72-Frame" tabindex="0" data-mathml="<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mrow is=&quot;true&quot;><mi is=&quot;true&quot;>&amp;#x3B3;</mi><mo is=&quot;true&quot;>=</mo><mn is=&quot;true&quot;>0.9</mn></mrow></math>" role="presentation" style="font-size: 90%; display: inline-block; position: relative;"><svg xmlns:xlink="http://www.w3.org/1999/xlink" width="7.333ex" height="2.432ex" viewBox="0 -747.2 3157.1 1047.3" role="img" focusable="false" style="vertical-align: -0.697ex;" aria-hidden="true"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><g is="true"><g is="true"><use xlink:href="#MJMATHI-3B3"></use></g><g is="true" transform="translate(821,0)"><use xlink:href="#MJMAIN-3D"></use></g><g is="true" transform="translate(1877,0)"><use xlink:href="#MJMAIN-30"></use><use xlink:href="#MJMAIN-2E" x="500" y="0"></use><use xlink:href="#MJMAIN-39" x="779" y="0"></use></g></g></g></svg><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow is="true"><mi is="true">γ</mi><mo is="true">=</mo><mn is="true">0.9</mn></mrow></math></span></span><script type="math/mml" id="MathJax-Element-72"><math><mrow is="true"><mi is="true">γ</mi><mo is="true">=</mo><mn is="true">0.9</mn></mrow></math></script></span>. Each face presented in the images was cropped and resized to 64 × 64 pixels. We removed smaller images (only five in total). The trained network was tested on the AFW dataset. To measure the network performance we used the average of five learning cycles. The CNN was initialised five times with random weights, trained on the AFLW dataset and tested on the AFW dataset. The average of the five MAEs has been used as the final score.</div></section><section id="sec0016"><h4 id="sectt0019" class="u-margin-m-top u-margin-xs-bottom">4.3.2. Results</h4><div class="u-margin-s-bottom" id="para0064">We obtained an MAE and STD of 16.73 ± 17.17 and an accuracy of 32.96% which reaches 75.29% when considering an error of ± 15°. This is the best score ever reported on this dataset. The comparison of CNNs with other methods is reported in <a class="anchor anchor-primary" href="#tbl0004" name="btbl0004" data-sd-ui-side-panel-opener="true" data-xocs-content-type="reference" data-xocs-content-id="tbl0004"><span class="anchor-text-container"><span class="anchor-text">Table&nbsp;4</span></span></a>. We did some additional tests augmenting the data in the AFLW dataset by horizontal flipping. These experiments did not lead to any major improvement in the final performance.</div></section></section><section id="sec0017"><h3 id="sectt0020" class="u-h4 u-margin-m-top u-margin-xs-bottom">4.4. Discussion</h3><div class="u-margin-s-bottom" id="para0065">We now detail the results achieved. The first phase of each experiment consisted of the optimiser selection. The results on the Prima dataset show the superiority of Adam on the other methods. The use of adaptive methods has been extremely important also for in-the-wild datasets where they significantly outperform SGD. In the AFLW dataset the RMSProp had the lowest reported MAE and the highest accuracy. It must be pointed out that in the last epochs the SGD with momentum reaches similar loss values of Adam and RMSProp, however the results in terms of MAE are higher. We hypothesise that the flexibility of Adam and RMSProp allowed exploring the space better than SGD with momentum, especially because of the high variability of the input features. Another advantage of the adaptive methods is the convergence speed. As it is possible to observe from <a class="anchor anchor-primary" href="#fig0005" name="bfig0005" data-sd-ui-side-panel-opener="true" data-xocs-content-type="reference" data-xocs-content-id="fig0005"><span class="anchor-text-container"><span class="anchor-text">Fig. 5</span></span></a>, <a class="anchor anchor-primary" href="#fig0006" name="bfig0006" data-sd-ui-side-panel-opener="true" data-xocs-content-type="reference" data-xocs-content-id="fig0006"><span class="anchor-text-container"><span class="anchor-text">Fig. 6</span></span></a> and <a class="anchor anchor-primary" href="#fig0012" name="bfig0012" data-sd-ui-side-panel-opener="true" data-xocs-content-type="reference" data-xocs-content-id="fig0012"><span class="anchor-text-container"><span class="anchor-text">12</span></span></a>, Adam and RMSProp converge to a very low loss value during the first epochs.</div><div class="u-margin-s-bottom" id="para0066">The second phase of the experiments consisted of the architecture selection. In the Prima dataset, comparing architecture A and its deeper counterpart (B) we see that the second architecture had an highest MAE for pitch (<span class="math"><span class="MathJax_Preview" style=""></span><span class="MathJax_SVG" id="MathJax-Element-73-Frame" tabindex="0" data-mathml="<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mrow is=&quot;true&quot;><mo is=&quot;true&quot;>+</mo><mn is=&quot;true&quot;>0</mn><mo is=&quot;true&quot;>.</mo><msup is=&quot;true&quot;><mn is=&quot;true&quot;>92</mn><mo is=&quot;true&quot;>&amp;#x2218;</mo></msup></mrow></math>" role="presentation" style="font-size: 90%; display: inline-block; position: relative;"><svg xmlns:xlink="http://www.w3.org/1999/xlink" width="7.384ex" height="2.202ex" viewBox="0 -796.9 3179.1 947.9" role="img" focusable="false" style="vertical-align: -0.351ex;" aria-hidden="true"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><g is="true"><g is="true"><use xlink:href="#MJMAIN-2B"></use></g><g is="true" transform="translate(778,0)"><use xlink:href="#MJMAIN-30"></use></g><g is="true" transform="translate(1279,0)"><use xlink:href="#MJMAIN-2E"></use></g><g is="true" transform="translate(1724,0)"><g is="true"><use xlink:href="#MJMAIN-39"></use><use xlink:href="#MJMAIN-32" x="500" y="0"></use></g><g is="true" transform="translate(1001,393)"><use transform="scale(0.707)" xlink:href="#MJMAIN-2218"></use></g></g></g></g></svg><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow is="true"><mo is="true">+</mo><mn is="true">0</mn><mo is="true">.</mo><msup is="true"><mn is="true">92</mn><mo is="true">∘</mo></msup></mrow></math></span></span><script type="math/mml" id="MathJax-Element-73"><math><mrow is="true"><mo is="true">+</mo><mn is="true">0</mn><mo is="true">.</mo><msup is="true"><mn is="true">92</mn><mo is="true">∘</mo></msup></mrow></math></script></span>) and yaw (<span class="math"><span class="MathJax_Preview" style=""></span><span class="MathJax_SVG" id="MathJax-Element-74-Frame" tabindex="0" data-mathml="<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mrow is=&quot;true&quot;><mo is=&quot;true&quot;>+</mo><mn is=&quot;true&quot;>0</mn><mo is=&quot;true&quot;>.</mo><msup is=&quot;true&quot;><mn is=&quot;true&quot;>66</mn><mo is=&quot;true&quot;>&amp;#x2218;</mo></msup></mrow></math>" role="presentation" style="font-size: 90%; display: inline-block; position: relative;"><svg xmlns:xlink="http://www.w3.org/1999/xlink" width="7.384ex" height="2.202ex" viewBox="0 -796.9 3179.1 947.9" role="img" focusable="false" style="vertical-align: -0.351ex;" aria-hidden="true"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><g is="true"><g is="true"><use xlink:href="#MJMAIN-2B"></use></g><g is="true" transform="translate(778,0)"><use xlink:href="#MJMAIN-30"></use></g><g is="true" transform="translate(1279,0)"><use xlink:href="#MJMAIN-2E"></use></g><g is="true" transform="translate(1724,0)"><g is="true"><use xlink:href="#MJMAIN-36"></use><use xlink:href="#MJMAIN-36" x="500" y="0"></use></g><g is="true" transform="translate(1001,393)"><use transform="scale(0.707)" xlink:href="#MJMAIN-2218"></use></g></g></g></g></svg><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow is="true"><mo is="true">+</mo><mn is="true">0</mn><mo is="true">.</mo><msup is="true"><mn is="true">66</mn><mo is="true">∘</mo></msup></mrow></math></span></span><script type="math/mml" id="MathJax-Element-74"><math><mrow is="true"><mo is="true">+</mo><mn is="true">0</mn><mo is="true">.</mo><msup is="true"><mn is="true">66</mn><mo is="true">∘</mo></msup></mrow></math></script></span>) estimation. The same effect has been observed between network C and D (<span class="math"><span class="MathJax_Preview" style=""></span><span class="MathJax_SVG" id="MathJax-Element-75-Frame" tabindex="0" data-mathml="<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mrow is=&quot;true&quot;><mo is=&quot;true&quot;>+</mo><mn is=&quot;true&quot;>2</mn><mo is=&quot;true&quot;>.</mo><msup is=&quot;true&quot;><mn is=&quot;true&quot;>54</mn><mo is=&quot;true&quot;>&amp;#x2218;</mo></msup><mo is=&quot;true&quot;>,</mo><mo is=&quot;true&quot;>+</mo><mn is=&quot;true&quot;>0</mn><mo is=&quot;true&quot;>.</mo><msup is=&quot;true&quot;><mn is=&quot;true&quot;>81</mn><mo is=&quot;true&quot;>&amp;#x2218;</mo></msup></mrow></math>" role="presentation" style="font-size: 90%; display: inline-block; position: relative;"><svg xmlns:xlink="http://www.w3.org/1999/xlink" width="15.801ex" height="2.432ex" viewBox="0 -796.9 6803.3 1047.3" role="img" focusable="false" style="vertical-align: -0.582ex;" aria-hidden="true"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><g is="true"><g is="true"><use xlink:href="#MJMAIN-2B"></use></g><g is="true" transform="translate(778,0)"><use xlink:href="#MJMAIN-32"></use></g><g is="true" transform="translate(1279,0)"><use xlink:href="#MJMAIN-2E"></use></g><g is="true" transform="translate(1724,0)"><g is="true"><use xlink:href="#MJMAIN-35"></use><use xlink:href="#MJMAIN-34" x="500" y="0"></use></g><g is="true" transform="translate(1001,404)"><use transform="scale(0.707)" xlink:href="#MJMAIN-2218"></use></g></g><g is="true" transform="translate(3179,0)"><use xlink:href="#MJMAIN-2C"></use></g><g is="true" transform="translate(3624,0)"><use xlink:href="#MJMAIN-2B"></use></g><g is="true" transform="translate(4402,0)"><use xlink:href="#MJMAIN-30"></use></g><g is="true" transform="translate(4903,0)"><use xlink:href="#MJMAIN-2E"></use></g><g is="true" transform="translate(5348,0)"><g is="true"><use xlink:href="#MJMAIN-38"></use><use xlink:href="#MJMAIN-31" x="500" y="0"></use></g><g is="true" transform="translate(1001,393)"><use transform="scale(0.707)" xlink:href="#MJMAIN-2218"></use></g></g></g></g></svg><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow is="true"><mo is="true">+</mo><mn is="true">2</mn><mo is="true">.</mo><msup is="true"><mn is="true">54</mn><mo is="true">∘</mo></msup><mo is="true">,</mo><mo is="true">+</mo><mn is="true">0</mn><mo is="true">.</mo><msup is="true"><mn is="true">81</mn><mo is="true">∘</mo></msup></mrow></math></span></span><script type="math/mml" id="MathJax-Element-75"><math><mrow is="true"><mo is="true">+</mo><mn is="true">2</mn><mo is="true">.</mo><msup is="true"><mn is="true">54</mn><mo is="true">∘</mo></msup><mo is="true">,</mo><mo is="true">+</mo><mn is="true">0</mn><mo is="true">.</mo><msup is="true"><mn is="true">81</mn><mo is="true">∘</mo></msup></mrow></math></script></span>). We can conclude that adding another convolutional layer or adding more parameters did not lead to any improvement. The reasons could be the small size of the Prima dataset and the controlled environment where the pictures have been taken. In the AFLW dataset, comparing architecture A with architecture B we can see that the second architecture had lowest MAEs for roll, pitch and yaw (<span class="math"><span class="MathJax_Preview" style=""></span><span class="MathJax_SVG" id="MathJax-Element-76-Frame" tabindex="0" data-mathml="<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mrow is=&quot;true&quot;><mo is=&quot;true&quot;>&amp;#x2212;</mo><mn is=&quot;true&quot;>0</mn><mo is=&quot;true&quot;>.</mo><msup is=&quot;true&quot;><mn is=&quot;true&quot;>15</mn><mo is=&quot;true&quot;>&amp;#x2218;</mo></msup><mo is=&quot;true&quot;>,</mo><mo is=&quot;true&quot;>&amp;#x2212;</mo><mn is=&quot;true&quot;>0</mn><mo is=&quot;true&quot;>.</mo><msup is=&quot;true&quot;><mn is=&quot;true&quot;>18</mn><mo is=&quot;true&quot;>&amp;#x2218;</mo></msup><mo is=&quot;true&quot;>,</mo><mo is=&quot;true&quot;>&amp;#x2212;</mo><mn is=&quot;true&quot;>1</mn><mo is=&quot;true&quot;>.</mo><msup is=&quot;true&quot;><mn is=&quot;true&quot;>38</mn><mo is=&quot;true&quot;>&amp;#x2218;</mo></msup></mrow></math>" role="presentation" style="font-size: 90%; display: inline-block; position: relative;"><svg xmlns:xlink="http://www.w3.org/1999/xlink" width="24.219ex" height="2.432ex" viewBox="0 -796.9 10427.6 1047.3" role="img" focusable="false" style="vertical-align: -0.582ex;" aria-hidden="true"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><g is="true"><g is="true"><use xlink:href="#MJMAIN-2212"></use></g><g is="true" transform="translate(778,0)"><use xlink:href="#MJMAIN-30"></use></g><g is="true" transform="translate(1279,0)"><use xlink:href="#MJMAIN-2E"></use></g><g is="true" transform="translate(1724,0)"><g is="true"><use xlink:href="#MJMAIN-31"></use><use xlink:href="#MJMAIN-35" x="500" y="0"></use></g><g is="true" transform="translate(1001,393)"><use transform="scale(0.707)" xlink:href="#MJMAIN-2218"></use></g></g><g is="true" transform="translate(3179,0)"><use xlink:href="#MJMAIN-2C"></use></g><g is="true" transform="translate(3624,0)"><use xlink:href="#MJMAIN-2212"></use></g><g is="true" transform="translate(4402,0)"><use xlink:href="#MJMAIN-30"></use></g><g is="true" transform="translate(4903,0)"><use xlink:href="#MJMAIN-2E"></use></g><g is="true" transform="translate(5348,0)"><g is="true"><use xlink:href="#MJMAIN-31"></use><use xlink:href="#MJMAIN-38" x="500" y="0"></use></g><g is="true" transform="translate(1001,393)"><use transform="scale(0.707)" xlink:href="#MJMAIN-2218"></use></g></g><g is="true" transform="translate(6803,0)"><use xlink:href="#MJMAIN-2C"></use></g><g is="true" transform="translate(7248,0)"><use xlink:href="#MJMAIN-2212"></use></g><g is="true" transform="translate(8026,0)"><use xlink:href="#MJMAIN-31"></use></g><g is="true" transform="translate(8527,0)"><use xlink:href="#MJMAIN-2E"></use></g><g is="true" transform="translate(8972,0)"><g is="true"><use xlink:href="#MJMAIN-33"></use><use xlink:href="#MJMAIN-38" x="500" y="0"></use></g><g is="true" transform="translate(1001,393)"><use transform="scale(0.707)" xlink:href="#MJMAIN-2218"></use></g></g></g></g></svg><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow is="true"><mo is="true">−</mo><mn is="true">0</mn><mo is="true">.</mo><msup is="true"><mn is="true">15</mn><mo is="true">∘</mo></msup><mo is="true">,</mo><mo is="true">−</mo><mn is="true">0</mn><mo is="true">.</mo><msup is="true"><mn is="true">18</mn><mo is="true">∘</mo></msup><mo is="true">,</mo><mo is="true">−</mo><mn is="true">1</mn><mo is="true">.</mo><msup is="true"><mn is="true">38</mn><mo is="true">∘</mo></msup></mrow></math></span></span><script type="math/mml" id="MathJax-Element-76"><math><mrow is="true"><mo is="true">−</mo><mn is="true">0</mn><mo is="true">.</mo><msup is="true"><mn is="true">15</mn><mo is="true">∘</mo></msup><mo is="true">,</mo><mo is="true">−</mo><mn is="true">0</mn><mo is="true">.</mo><msup is="true"><mn is="true">18</mn><mo is="true">∘</mo></msup><mo is="true">,</mo><mo is="true">−</mo><mn is="true">1</mn><mo is="true">.</mo><msup is="true"><mn is="true">38</mn><mo is="true">∘</mo></msup></mrow></math></script></span>). Augmenting the number of parameters did not lead to any improvement. In this case having an additional convolutional layer made a significant difference, and we can conclude that estimating the head pose in unconstrained datasets requires more complex architectures.</div><div class="u-margin-s-bottom" id="para0067">In a separate phase we investigated the presence of overfitting during the training. In the Prima dataset we monitored the RMSE of the best architecture trained with the Adam optimiser for pitch (<a class="anchor anchor-primary" href="#fig0009" name="bfig0009" data-sd-ui-side-panel-opener="true" data-xocs-content-type="reference" data-xocs-content-id="fig0009"><span class="anchor-text-container"><span class="anchor-text">Fig.&nbsp;9</span></span></a>) and yaw (<a class="anchor anchor-primary" href="#fig0010" name="bfig0010" data-sd-ui-side-panel-opener="true" data-xocs-content-type="reference" data-xocs-content-id="fig0010"><span class="anchor-text-container"><span class="anchor-text">Fig.&nbsp;10</span></span></a>). In both cases the RMSE on the validation set decreased stably without significantly diverging from the training error. This result seems to indicate that there is an extremely low overfitting and that the CNN has a good generalisation ability for unknown subjects. In the AFLW dataset we observed the RMSE of the best architecture for the yaw prediction (<a class="anchor anchor-primary" href="#fig0015" name="bfig0015" data-sd-ui-side-panel-opener="true" data-xocs-content-type="reference" data-xocs-content-id="fig0015"><span class="anchor-text-container"><span class="anchor-text">Fig.&nbsp;15</span></span></a>). Also in this case the validation error decreased stably in accordance with the training curve meaning that the network could effectively generalise to unseen data. Comparing the RMSE of the Prima and AFLW datasets it is possible to notice that in the AFLW the gap between training and validation is reduced thanks to the large amount of images available.</div><div class="u-margin-s-bottom" id="para0068"><span>We stated in the introduction that the use of <a href="/topics/engineering/nonlinear-regression" title="Learn more about nonlinear regression from ScienceDirect's AI-generated Topic Pages" class="topic-link">nonlinear regression</a> methods can tolerate systematic errors in the training set. Our experimental results confirm this statement. The accuracy of CNNs is higher than any other method meaning that the networks can grab the general rules and are not heavily affected by mislabelling. To visualise the accuracy we reported the confusion tables as heatmaps for both Prima (</span><a class="anchor anchor-primary" href="#fig0008" name="bfig0008" data-sd-ui-side-panel-opener="true" data-xocs-content-type="reference" data-xocs-content-id="fig0008"><span class="anchor-text-container"><span class="anchor-text">Fig.&nbsp;8</span></span></a>) and AFLW (<a class="anchor anchor-primary" href="#fig0014" name="bfig0014" data-sd-ui-side-panel-opener="true" data-xocs-content-type="reference" data-xocs-content-id="fig0014"><span class="anchor-text-container"><span class="anchor-text">Fig.&nbsp;14</span></span></a><span>) datasets. The darker cells are disposed along the <a href="/topics/engineering/main-diagonal" title="Learn more about main diagonal from ScienceDirect's AI-generated Topic Pages" class="topic-link">main diagonal</a>, meaning that the prediction has a high accuracy with false positives constrained to within the proximity of the correct category. The main difference between Prima and AFLW is in the prediction of values which are close to ± 90°. The reason for this difference is the AFLW dataset does not have a uniform distribution and values distant from the mean are very limited.</span></div></section></section><section id="sec0018"><h2 id="sectt0021" class="u-h4 u-margin-l-top u-margin-xs-bottom">5. Conclusions</h2><div class="u-margin-s-bottom" id="para0069">In this article we introduced the use of dropout and adaptive gradient methods for head pose estimation with CNNs. Our approach is significantly different from previous research <a class="anchor anchor-primary" href="#bib0017" name="bbib0017" data-sd-ui-side-panel-opener="true" data-xocs-content-type="reference" data-xocs-content-id="bib0017"><span class="anchor-text-container"><span class="anchor-text">[17]</span></span></a>, <a class="anchor anchor-primary" href="#bib0018" name="bbib0018" data-sd-ui-side-panel-opener="true" data-xocs-content-type="reference" data-xocs-content-id="bib0018"><span class="anchor-text-container"><span class="anchor-text">[18]</span></span></a>, <a class="anchor anchor-primary" href="#bib0020" name="bbib0020" data-sd-ui-side-panel-opener="true" data-xocs-content-type="reference" data-xocs-content-id="bib0020"><span class="anchor-text-container"><span class="anchor-text">[20]</span></span></a>, <a class="anchor anchor-primary" href="#bib0021" name="bbib0021" data-sd-ui-side-panel-opener="true" data-xocs-content-type="reference" data-xocs-content-id="bib0021"><span class="anchor-text-container"><span class="anchor-text">[21]</span></span></a>, and show how using the most recent deep learning techniques leads to the state-of-the-art in constrained and unconstrained datasets. Our method should be considered as part of a broader system, in particular it can be used in conjunction with a face detector. We implemented the system in Python using TenworFlow <a class="anchor anchor-primary" href="#bib0004" name="bbib0004" data-sd-ui-side-panel-opener="true" data-xocs-content-type="reference" data-xocs-content-id="bib0004"><span class="anchor-text-container"><span class="anchor-text">[4]</span></span></a> and OpenCV <a class="anchor anchor-primary" href="#bib0042" name="bbib0042" data-sd-ui-side-panel-opener="true" data-xocs-content-type="reference" data-xocs-content-id="bib0042"><span class="anchor-text-container"><span class="anchor-text">[42]</span></span></a>. We used the Viola-Jones object detection framework <a class="anchor anchor-primary" href="#bib0043" name="bbib0043" data-sd-ui-side-panel-opener="true" data-xocs-content-type="reference" data-xocs-content-id="bib0043"><span class="anchor-text-container"><span class="anchor-text">[43]</span></span></a> as a face detector and two CNNs of type B trained on the AFLW dataset as head pose estimator (pitch and yaw). We acquired camera frames with a resolution of 640 × 480 from a commercial webcam, and then we isolated the faces using the Viola-Jones algorithm. Finally we gave as input the isolated faces to the CNNs obtaining the head pose. The whole system runs at 15 frames per second on a standard laptop (intel core i5, 8GB RAM) without the use of a GPU. It must be pointed out that an inadequate face detector can be a significant bottleneck. In our case removing the face detector from the loop allows executing the head pose estimation at 20 frames per second. Going to the real-world is not straightforward and different problems can arise. The major problem we experienced during our tests was the increasing in pose estimation errors when the face detector returned a frame which was not well centred on the subjects face. In this case we found useful to train the networks on an augmented version of the AFLW dataset, where the centre of the frame was randomly shifted in one of four directions.</div><div class="u-margin-s-bottom" id="para0070">Although our approach is highly competitive, it can be further improved. Other factors can play an important role as pointed out by recent literature. In our opinion future research should particularly focus on the impact of weight initialization <a class="anchor anchor-primary" href="#bib0044" name="bbib0044" data-sd-ui-side-panel-opener="true" data-xocs-content-type="reference" data-xocs-content-id="bib0044"><span class="anchor-text-container"><span class="anchor-text">[44]</span></span></a> and sample selection <a class="anchor anchor-primary" href="#bib0045" name="bbib0045" data-sd-ui-side-panel-opener="true" data-xocs-content-type="reference" data-xocs-content-id="bib0045"><span class="anchor-text-container"><span class="anchor-text">[45]</span></span></a>. Moreover the results can be further improved once in-the-wild datasets with more images and an extended range of poses are available.</div></section></div><section id="ack0001"><h2 id="sectt0022" class="u-h4 u-margin-l-top u-margin-xs-bottom">Acknowledgment</h2><div class="u-margin-s-bottom" id="para0071">This material is based upon work supported by the <span id="GS100000181">Air Force Office of Scientific Research</span> grant number: <a class="anchor anchor-primary" href="#GS100000181"><span class="anchor-text-container"><span class="anchor-text">A9550-15-1-0025</span></span></a>, Air Force Materiel Command, USAF under Award No. FA9550-15-1-0025.</div><div class="u-margin-s-bottom" id="para0072">We gratefully acknowledge the support of <span id="GS100007065">NVIDIA</span> Corporation with the donation of the Tesla K40 GPU used for this research.</div></section></div><div class="related-content-links u-display-none-from-md"><button class="button-link button-link-primary button-link-small" type="button"><span class="button-link-text-container"><span class="button-link-text">Recommended articles</span></span></button></div><div class="Tail"></div><div><section class="bibliography u-font-serif text-s" id="bib001"><h2 class="section-title u-h4 u-margin-l-top u-margin-xs-bottom">References</h2><section class="bibliography-sec" id="bibsec002"><ol class="references" id="reference-links-bibsec002"><li><span class="label u-font-sans"><a class="anchor anchor-primary" href="#bbib0001" id="ref-id-bib0001" data-aa-button="sd:product:journal:article:location=references:type=anchor:name=citation-name"><span class="anchor-text-container"><span class="anchor-text">[1]</span></span></a></span><span class="reference" id="sbref0001"><div class="contribution"><div class="authors u-font-sans">D. Zanatto, M. Patacchiola, J. Goslin, A. Cangelosi</div><div id="ref-id-sbref0001" class="title text-m">Priming anthropomorphism: can the credibility of humanlike robots be transferred to non-humanlike robots?</div></div><div class="host u-font-sans">Proceedings of the Eleventh Annual ACM/IEEE International Conference on Human-Robot Interaction., IEEE Press, Christchurch, New Zealand (2016), pp. 543-544</div><div class="ReferenceLinks u-font-sans"><span class="link lazy-third-party-pdf-link"><span></span></span><a class="anchor link anchor-primary" href="https://doi.org/10.1109/HRI.2016.7451847" target="_blank" rel="noopener noreferrer" aria-describedby="ref-id-sbref0001"><span class="anchor-text-container"><span class="anchor-text">Crossref</span><svg focusable="false" viewBox="0 0 8 8" height="20" aria-label="Opens in new window" class="icon icon-arrow-up-right-tiny arrow-external-link"><path d="M1.12949 2.1072V1H7V6.85795H5.89111V2.90281L0.784057 8L0 7.21635L5.11902 2.1072H1.12949Z"></path></svg></span></a><a class="anchor link anchor-primary" href="https://www.scopus.com/inward/record.url?eid=2-s2.0-84964855135&amp;partnerID=10&amp;rel=R3.0.0" target="_blank" rel="noopener noreferrer" aria-describedby="ref-id-sbref0001"><span class="anchor-text-container"><span class="anchor-text">View in Scopus</span><svg focusable="false" viewBox="0 0 8 8" height="20" aria-label="Opens in new window" class="icon icon-arrow-up-right-tiny arrow-external-link"><path d="M1.12949 2.1072V1H7V6.85795H5.89111V2.90281L0.784057 8L0 7.21635L5.11902 2.1072H1.12949Z"></path></svg></span></a><a class="anchor link anchor-primary" href="https://scholar.google.com/scholar_lookup?title=Priming%20anthropomorphism%3A%20can%20the%20credibility%20of%20humanlike%20robots%20be%20transferred%20to%20non-humanlike%20robots&amp;publication_year=2016&amp;author=D.%20Zanatto&amp;author=M.%20Patacchiola&amp;author=J.%20Goslin&amp;author=A.%20Cangelosi" target="_blank" rel="noopener noreferrer" aria-describedby="ref-id-sbref0001"><span class="anchor-text-container"><span class="anchor-text">Google Scholar</span><svg focusable="false" viewBox="0 0 8 8" height="20" aria-label="Opens in new window" class="icon icon-arrow-up-right-tiny arrow-external-link"><path d="M1.12949 2.1072V1H7V6.85795H5.89111V2.90281L0.784057 8L0 7.21635L5.11902 2.1072H1.12949Z"></path></svg></span></a></div></span></li><li><span class="label u-font-sans"><a class="anchor anchor-primary" href="#bbib0002" id="ref-id-bib0002" data-aa-button="sd:product:journal:article:location=references:type=anchor:name=citation-name"><span class="anchor-text-container"><span class="anchor-text">[2]</span></span></a></span><span class="reference" id="sbref0002"><div class="contribution"><div class="authors u-font-sans">D. Geronimo, A.M. Lopez, A.D. Sappa, T. Graf</div><div id="ref-id-sbref0002" class="title text-m">Survey of pedestrian detection for advanced driver assistance systems</div></div><div class="host u-font-sans">IEEE Trans. Pattern Anal. Mach. Intell., 32 (2010), pp. 1239-1258</div><div class="ReferenceLinks u-font-sans"><a class="anchor link anchor-primary" href="https://www.scopus.com/inward/record.url?eid=2-s2.0-77952647953&amp;partnerID=10&amp;rel=R3.0.0" target="_blank" rel="noopener noreferrer" aria-describedby="ref-id-sbref0002"><span class="anchor-text-container"><span class="anchor-text">View in Scopus</span><svg focusable="false" viewBox="0 0 8 8" height="20" aria-label="Opens in new window" class="icon icon-arrow-up-right-tiny arrow-external-link"><path d="M1.12949 2.1072V1H7V6.85795H5.89111V2.90281L0.784057 8L0 7.21635L5.11902 2.1072H1.12949Z"></path></svg></span></a><a class="anchor link anchor-primary" href="https://scholar.google.com/scholar_lookup?title=Survey%20of%20pedestrian%20detection%20for%20advanced%20driver%20assistance%20systems&amp;publication_year=2010&amp;author=D.%20Geronimo&amp;author=A.M.%20Lopez&amp;author=A.D.%20Sappa&amp;author=T.%20Graf" target="_blank" rel="noopener noreferrer" aria-describedby="ref-id-sbref0002"><span class="anchor-text-container"><span class="anchor-text">Google Scholar</span><svg focusable="false" viewBox="0 0 8 8" height="20" aria-label="Opens in new window" class="icon icon-arrow-up-right-tiny arrow-external-link"><path d="M1.12949 2.1072V1H7V6.85795H5.89111V2.90281L0.784057 8L0 7.21635L5.11902 2.1072H1.12949Z"></path></svg></span></a></div></span></li><li><span class="label u-font-sans"><a class="anchor anchor-primary" href="#bbib0003" id="ref-id-bib0003" data-aa-button="sd:product:journal:article:location=references:type=anchor:name=citation-name"><span class="anchor-text-container"><span class="anchor-text">[3]</span></span></a></span><span class="reference" id="sbref0003"><div class="contribution"><div class="authors u-font-sans">R.H. Baxter, M.J.V. Leach, S.S. Mukherjee, N.M. Robertson</div><div id="ref-id-sbref0003" class="title text-m">An adaptive motion model for person tracking with instantaneous head-pose features</div></div><div class="host u-font-sans">IEEE Signal Process. Lett., 22 (2015), pp. 578-582</div><div class="ReferenceLinks u-font-sans"><a class="anchor link anchor-primary" href="https://www.scopus.com/inward/record.url?eid=2-s2.0-84910033544&amp;partnerID=10&amp;rel=R3.0.0" target="_blank" rel="noopener noreferrer" aria-describedby="ref-id-sbref0003"><span class="anchor-text-container"><span class="anchor-text">View in Scopus</span><svg focusable="false" viewBox="0 0 8 8" height="20" aria-label="Opens in new window" class="icon icon-arrow-up-right-tiny arrow-external-link"><path d="M1.12949 2.1072V1H7V6.85795H5.89111V2.90281L0.784057 8L0 7.21635L5.11902 2.1072H1.12949Z"></path></svg></span></a><a class="anchor link anchor-primary" href="https://scholar.google.com/scholar_lookup?title=An%20adaptive%20motion%20model%20for%20person%20tracking%20with%20instantaneous%20head-pose%20features&amp;publication_year=2015&amp;author=R.H.%20Baxter&amp;author=M.J.V.%20Leach&amp;author=S.S.%20Mukherjee&amp;author=N.M.%20Robertson" target="_blank" rel="noopener noreferrer" aria-describedby="ref-id-sbref0003"><span class="anchor-text-container"><span class="anchor-text">Google Scholar</span><svg focusable="false" viewBox="0 0 8 8" height="20" aria-label="Opens in new window" class="icon icon-arrow-up-right-tiny arrow-external-link"><path d="M1.12949 2.1072V1H7V6.85795H5.89111V2.90281L0.784057 8L0 7.21635L5.11902 2.1072H1.12949Z"></path></svg></span></a></div></span></li><li><span class="label u-font-sans"><a class="anchor anchor-primary" href="#bbib0004" id="ref-id-bib0004" data-aa-button="sd:product:journal:article:location=references:type=anchor:name=citation-name"><span class="anchor-text-container"><span class="anchor-text">[4]</span></span></a></span><span class="reference" id="othref0001"><div class="other-ref"><span>M. Abadi, A. Agarwal, P. Barham, E. Brevdo, Z. Chen, C. Citro, G.S. Corrado, A. Davis, J. Dean, M. Devin, S. Ghemawat, I. Goodfellow, A. Harp, G. Irving, M. Isard, Y. Jia, R. Jozefowicz, L. Kaiser, M. Kudlur, J. Levenberg, D. Mané, R. Monga, S. Moore, D. Murray, C. Olah, M. Schuster, J. Shlens, B. Steiner, I. Sutskever, K. Talwar, P. Tucker, V. Vanhoucke, V. Vasudevan, F. Viégas, O. Vinyals, P. Warden, M. Wattenberg, M. Wicke, Y. Yu, X. Zheng, TensorFlow: Large-scale machine learning on heterogeneous systems, 2015, Software available from tensorflow.org URL <a class="anchor anchor-primary" href="http://tensorflow.org/" target="_blank"><span class="anchor-text-container"><span class="anchor-text">http://tensorflow.org/</span><svg focusable="false" viewBox="0 0 8 8" height="20" aria-label="Opens in new window" class="icon icon-arrow-up-right-tiny arrow-external-link"><path d="M1.12949 2.1072V1H7V6.85795H5.89111V2.90281L0.784057 8L0 7.21635L5.11902 2.1072H1.12949Z"></path></svg></span></a>.</span></div><div class="ReferenceLinks u-font-sans"><a class="anchor link anchor-primary" href="https://scholar.google.com/scholar?q=M.%20Abadi%2C%20A.%20Agarwal%2C%20P.%20Barham%2C%20E.%20Brevdo%2C%20Z.%20Chen%2C%20C.%20Citro%2C%20G.S.%20Corrado%2C%20A.%20Davis%2C%20J.%20Dean%2C%20M.%20Devin%2C%20S.%20Ghemawat%2C%20I.%20Goodfellow%2C%20A.%20Harp%2C%20G.%20Irving%2C%20M.%20Isard%2C%20Y.%20Jia%2C%20R.%20Jozefowicz%2C%20L.%20Kaiser%2C%20M.%20Kudlur%2C%20J.%20Levenberg%2C%20D.%20Man%C3%A9%2C%20R.%20Monga%2C%20S.%20Moore%2C%20D.%20Murray%2C%20C.%20Olah%2C%20M.%20Schuster%2C%20J.%20Shlens%2C%20B.%20Steiner%2C%20I.%20Sutskever%2C%20K.%20Talwar%2C%20P.%20Tucker%2C%20V.%20Vanhoucke%2C%20V.%20Vasudevan%2C%20F.%20Vi%C3%A9gas%2C%20O.%20Vinyals%2C%20P.%20Warden%2C%20M.%20Wattenberg%2C%20M.%20Wicke%2C%20Y.%20Yu%2C%20X.%20Zheng%2C%20TensorFlow%3A%20Large-scale%20machine%20learning%20on%20heterogeneous%20systems%2C%202015%2C%20Software%20available%20from%20tensorflow.org%20URL%20http%3A%2F%2Ftensorflow.org%2F." target="_blank" rel="noopener noreferrer"><span class="anchor-text-container"><span class="anchor-text">Google Scholar</span><svg focusable="false" viewBox="0 0 8 8" height="20" aria-label="Opens in new window" class="icon icon-arrow-up-right-tiny arrow-external-link"><path d="M1.12949 2.1072V1H7V6.85795H5.89111V2.90281L0.784057 8L0 7.21635L5.11902 2.1072H1.12949Z"></path></svg></span></a></div></span></li><li><span class="label u-font-sans"><a class="anchor anchor-primary" href="#bbib0005" id="ref-id-bib0005" data-aa-button="sd:product:journal:article:location=references:type=anchor:name=citation-name"><span class="anchor-text-container"><span class="anchor-text">[5]</span></span></a></span><span class="reference" id="sbref0004"><div class="contribution"><div class="authors u-font-sans">E. Murphy-Chutorian, M.M. Trivedi</div><div id="ref-id-sbref0004" class="title text-m">Head pose estimation in computer vision: a survey</div></div><div class="host u-font-sans">IEEE Trans. Pattern Anal. Mach. Intell., 31 (2009), pp. 607-626</div><div class="ReferenceLinks u-font-sans"><a class="anchor link anchor-primary" href="https://www.scopus.com/inward/record.url?eid=2-s2.0-62249142056&amp;partnerID=10&amp;rel=R3.0.0" target="_blank" rel="noopener noreferrer" aria-describedby="ref-id-sbref0004"><span class="anchor-text-container"><span class="anchor-text">View in Scopus</span><svg focusable="false" viewBox="0 0 8 8" height="20" aria-label="Opens in new window" class="icon icon-arrow-up-right-tiny arrow-external-link"><path d="M1.12949 2.1072V1H7V6.85795H5.89111V2.90281L0.784057 8L0 7.21635L5.11902 2.1072H1.12949Z"></path></svg></span></a><a class="anchor link anchor-primary" href="https://scholar.google.com/scholar_lookup?title=Head%20pose%20estimation%20in%20computer%20vision%3A%20a%20survey&amp;publication_year=2009&amp;author=E.%20Murphy-Chutorian&amp;author=M.M.%20Trivedi" target="_blank" rel="noopener noreferrer" aria-describedby="ref-id-sbref0004"><span class="anchor-text-container"><span class="anchor-text">Google Scholar</span><svg focusable="false" viewBox="0 0 8 8" height="20" aria-label="Opens in new window" class="icon icon-arrow-up-right-tiny arrow-external-link"><path d="M1.12949 2.1072V1H7V6.85795H5.89111V2.90281L0.784057 8L0 7.21635L5.11902 2.1072H1.12949Z"></path></svg></span></a></div></span></li><li><span class="label u-font-sans"><a class="anchor anchor-primary" href="#bbib0006" id="ref-id-bib0006" data-aa-button="sd:product:journal:article:location=references:type=anchor:name=citation-name"><span class="anchor-text-container"><span class="anchor-text">[6]</span></span></a></span><span class="reference" id="sbref0005"><div class="contribution"><div class="authors u-font-sans">G. Fanelli, T. Weise, J. Gall, L.V. Gool</div><div id="ref-id-sbref0005" class="title text-m">Real time head pose estimation from consumer depth cameras</div></div><div class="host u-font-sans">Pattern Recognit., 6835 (2011), pp. 101-110</div><div class="ReferenceLinks u-font-sans"><span class="link lazy-third-party-pdf-link"><span></span></span><a class="anchor link anchor-primary" href="https://doi.org/10.1007/978-3-642-23123-0_11" target="_blank" rel="noopener noreferrer" aria-describedby="ref-id-sbref0005"><span class="anchor-text-container"><span class="anchor-text">Crossref</span><svg focusable="false" viewBox="0 0 8 8" height="20" aria-label="Opens in new window" class="icon icon-arrow-up-right-tiny arrow-external-link"><path d="M1.12949 2.1072V1H7V6.85795H5.89111V2.90281L0.784057 8L0 7.21635L5.11902 2.1072H1.12949Z"></path></svg></span></a><a class="anchor link anchor-primary" href="https://www.scopus.com/inward/record.url?eid=2-s2.0-80053039628&amp;partnerID=10&amp;rel=R3.0.0" target="_blank" rel="noopener noreferrer" aria-describedby="ref-id-sbref0005"><span class="anchor-text-container"><span class="anchor-text">View in Scopus</span><svg focusable="false" viewBox="0 0 8 8" height="20" aria-label="Opens in new window" class="icon icon-arrow-up-right-tiny arrow-external-link"><path d="M1.12949 2.1072V1H7V6.85795H5.89111V2.90281L0.784057 8L0 7.21635L5.11902 2.1072H1.12949Z"></path></svg></span></a><a class="anchor link anchor-primary" href="https://scholar.google.com/scholar_lookup?title=Real%20time%20head%20pose%20estimation%20from%20consumer%20depth%20cameras&amp;publication_year=2011&amp;author=G.%20Fanelli&amp;author=T.%20Weise&amp;author=J.%20Gall&amp;author=L.V.%20Gool" target="_blank" rel="noopener noreferrer" aria-describedby="ref-id-sbref0005"><span class="anchor-text-container"><span class="anchor-text">Google Scholar</span><svg focusable="false" viewBox="0 0 8 8" height="20" aria-label="Opens in new window" class="icon icon-arrow-up-right-tiny arrow-external-link"><path d="M1.12949 2.1072V1H7V6.85795H5.89111V2.90281L0.784057 8L0 7.21635L5.11902 2.1072H1.12949Z"></path></svg></span></a></div></span></li><li><span class="label u-font-sans"><a class="anchor anchor-primary" href="#bbib0007" id="ref-id-bib0007" data-aa-button="sd:product:journal:article:location=references:type=anchor:name=citation-name"><span class="anchor-text-container"><span class="anchor-text">[7]</span></span></a></span><span class="reference" id="sbref0006"><div class="contribution"><div class="authors u-font-sans">C. Wang, X. Song</div><div id="ref-id-sbref0006" class="title text-m">Robust head pose estimation via supervised manifold learning</div></div><div class="host u-font-sans">Neural Netw., 53 (2014), pp. 15-25</div><div class="ReferenceLinks u-font-sans"><a class="anchor pdf link anchor-primary anchor-icon-left anchor-with-icon" href="/science/article/pii/S0893608014000215/pdfft?md5=97397cd5803b9dfb08c9b48d3470418d&amp;pid=1-s2.0-S0893608014000215-main.pdf" target="_blank" rel="nofollow" aria-describedby="ref-id-sbref0006"><svg focusable="false" viewBox="0 0 35 32" height="20" class="icon icon-pdf-multicolor"><path d="M7 .362h17.875l6.763 6.1V31.64H6.948V16z" stroke="#000" stroke-width=".703" fill="#fff"></path><path d="M.167 2.592H22.39V9.72H.166z" fill="#da0000"></path><path fill="#fff9f9" d="M5.97 3.638h1.62c1.053 0 1.483.677 1.488 1.564.008.96-.6 1.564-1.492 1.564h-.644v1.66h-.977V3.64m.977.897v1.34h.542c.27 0 .596-.068.596-.673-.002-.6-.32-.667-.596-.667h-.542m3.8.036v2.92h.35c.933 0 1.223-.448 1.228-1.462.008-1.06-.316-1.45-1.23-1.45h-.347m-.977-.94h1.03c1.68 0 2.523.586 2.534 2.39.01 1.688-.607 2.4-2.534 2.4h-1.03V3.64m4.305 0h2.63v.934h-1.657v.894H16.6V6.4h-1.56v2.026h-.97V3.638"></path><path d="M19.462 13.46c.348 4.274-6.59 16.72-8.508 15.792-1.82-.85 1.53-3.317 2.92-4.366-2.864.894-5.394 3.252-3.837 3.93 2.113.895 7.048-9.25 9.41-15.394zM14.32 24.874c4.767-1.526 14.735-2.974 15.152-1.407.824-3.157-13.72-.37-15.153 1.407zm5.28-5.043c2.31 3.237 9.816 7.498 9.788 3.82-.306 2.046-6.66-1.097-8.925-4.164-4.087-5.534-2.39-8.772-1.682-8.732.917.047 1.074 1.307.67 2.442-.173-1.406-.58-2.44-1.224-2.415-1.835.067-1.905 4.46 1.37 9.065z" fill="#f91d0a"></path></svg><span class="anchor-text-container"><span class="anchor-text">View PDF</span></span></a><a class="anchor link anchor-primary" href="/science/article/pii/S0893608014000215" aria-describedby="ref-id-sbref0006"><span class="anchor-text-container"><span class="anchor-text">View article</span></span></a><a class="anchor link anchor-primary" href="https://doi.org/10.1186/1752-0509-8-15" target="_blank" rel="noopener noreferrer" aria-describedby="ref-id-sbref0006"><span class="anchor-text-container"><span class="anchor-text">Crossref</span><svg focusable="false" viewBox="0 0 8 8" height="20" aria-label="Opens in new window" class="icon icon-arrow-up-right-tiny arrow-external-link"><path d="M1.12949 2.1072V1H7V6.85795H5.89111V2.90281L0.784057 8L0 7.21635L5.11902 2.1072H1.12949Z"></path></svg></span></a><a class="anchor link anchor-primary" href="https://scholar.google.com/scholar_lookup?title=Robust%20head%20pose%20estimation%20via%20supervised%20manifold%20learning&amp;publication_year=2014&amp;author=C.%20Wang&amp;author=X.%20Song" target="_blank" rel="noopener noreferrer" aria-describedby="ref-id-sbref0006"><span class="anchor-text-container"><span class="anchor-text">Google Scholar</span><svg focusable="false" viewBox="0 0 8 8" height="20" aria-label="Opens in new window" class="icon icon-arrow-up-right-tiny arrow-external-link"><path d="M1.12949 2.1072V1H7V6.85795H5.89111V2.90281L0.784057 8L0 7.21635L5.11902 2.1072H1.12949Z"></path></svg></span></a></div></span></li><li><span class="label u-font-sans"><a class="anchor anchor-primary" href="#bbib0008" id="ref-id-bib0008" data-aa-button="sd:product:journal:article:location=references:type=anchor:name=citation-name"><span class="anchor-text-container"><span class="anchor-text">[8]</span></span></a></span><span class="reference" id="sbref0007"><div class="contribution"><div class="authors u-font-sans">J. Wu, M.M. Trivedi</div><div id="ref-id-sbref0007" class="title text-m">A two-stage head pose estimation framework and evaluation</div></div><div class="host u-font-sans">Pattern Recognit., 41 (2008), pp. 1138-1158</div><div class="ReferenceLinks u-font-sans"><a class="anchor pdf link anchor-primary anchor-icon-left anchor-with-icon" href="/science/article/pii/S0031320307003366/pdfft?md5=fecb991920e996a603a99745359dc62d&amp;pid=1-s2.0-S0031320307003366-main.pdf" target="_blank" rel="nofollow" aria-describedby="ref-id-sbref0007"><svg focusable="false" viewBox="0 0 35 32" height="20" class="icon icon-pdf-multicolor"><path d="M7 .362h17.875l6.763 6.1V31.64H6.948V16z" stroke="#000" stroke-width=".703" fill="#fff"></path><path d="M.167 2.592H22.39V9.72H.166z" fill="#da0000"></path><path fill="#fff9f9" d="M5.97 3.638h1.62c1.053 0 1.483.677 1.488 1.564.008.96-.6 1.564-1.492 1.564h-.644v1.66h-.977V3.64m.977.897v1.34h.542c.27 0 .596-.068.596-.673-.002-.6-.32-.667-.596-.667h-.542m3.8.036v2.92h.35c.933 0 1.223-.448 1.228-1.462.008-1.06-.316-1.45-1.23-1.45h-.347m-.977-.94h1.03c1.68 0 2.523.586 2.534 2.39.01 1.688-.607 2.4-2.534 2.4h-1.03V3.64m4.305 0h2.63v.934h-1.657v.894H16.6V6.4h-1.56v2.026h-.97V3.638"></path><path d="M19.462 13.46c.348 4.274-6.59 16.72-8.508 15.792-1.82-.85 1.53-3.317 2.92-4.366-2.864.894-5.394 3.252-3.837 3.93 2.113.895 7.048-9.25 9.41-15.394zM14.32 24.874c4.767-1.526 14.735-2.974 15.152-1.407.824-3.157-13.72-.37-15.153 1.407zm5.28-5.043c2.31 3.237 9.816 7.498 9.788 3.82-.306 2.046-6.66-1.097-8.925-4.164-4.087-5.534-2.39-8.772-1.682-8.732.917.047 1.074 1.307.67 2.442-.173-1.406-.58-2.44-1.224-2.415-1.835.067-1.905 4.46 1.37 9.065z" fill="#f91d0a"></path></svg><span class="anchor-text-container"><span class="anchor-text">View PDF</span></span></a><a class="anchor link anchor-primary" href="/science/article/pii/S0031320307003366" aria-describedby="ref-id-sbref0007"><span class="anchor-text-container"><span class="anchor-text">View article</span></span></a><a class="anchor link anchor-primary" href="https://www.scopus.com/inward/record.url?eid=2-s2.0-35448950932&amp;partnerID=10&amp;rel=R3.0.0" target="_blank" rel="noopener noreferrer" aria-describedby="ref-id-sbref0007"><span class="anchor-text-container"><span class="anchor-text">View in Scopus</span><svg focusable="false" viewBox="0 0 8 8" height="20" aria-label="Opens in new window" class="icon icon-arrow-up-right-tiny arrow-external-link"><path d="M1.12949 2.1072V1H7V6.85795H5.89111V2.90281L0.784057 8L0 7.21635L5.11902 2.1072H1.12949Z"></path></svg></span></a><a class="anchor link anchor-primary" href="https://scholar.google.com/scholar_lookup?title=A%20two-stage%20head%20pose%20estimation%20framework%20and%20evaluation&amp;publication_year=2008&amp;author=J.%20Wu&amp;author=M.M.%20Trivedi" target="_blank" rel="noopener noreferrer" aria-describedby="ref-id-sbref0007"><span class="anchor-text-container"><span class="anchor-text">Google Scholar</span><svg focusable="false" viewBox="0 0 8 8" height="20" aria-label="Opens in new window" class="icon icon-arrow-up-right-tiny arrow-external-link"><path d="M1.12949 2.1072V1H7V6.85795H5.89111V2.90281L0.784057 8L0 7.21635L5.11902 2.1072H1.12949Z"></path></svg></span></a></div></span></li><li><span class="label u-font-sans"><a class="anchor anchor-primary" href="#bbib0009" id="ref-id-bib0009" data-aa-button="sd:product:journal:article:location=references:type=anchor:name=citation-name"><span class="anchor-text-container"><span class="anchor-text">[9]</span></span></a></span><span class="reference" id="sbref0008"><div class="contribution"><div class="authors u-font-sans">J. Sherrah, S. Gong, E.-J. Ong</div><div id="ref-id-sbref0008" class="title text-m">Face distributions in similarity space under varying head pose</div></div><div class="host u-font-sans">Image Vision Comput., 19 (12) (2001), pp. 807-819</div><div class="ReferenceLinks u-font-sans"><a class="anchor pdf link anchor-primary anchor-icon-left anchor-with-icon" href="/science/article/pii/S0262885600000962/pdfft?md5=ec627931c74b83a3a4e41123dd91be77&amp;pid=1-s2.0-S0262885600000962-main.pdf" target="_blank" rel="nofollow" aria-describedby="ref-id-sbref0008"><svg focusable="false" viewBox="0 0 35 32" height="20" class="icon icon-pdf-multicolor"><path d="M7 .362h17.875l6.763 6.1V31.64H6.948V16z" stroke="#000" stroke-width=".703" fill="#fff"></path><path d="M.167 2.592H22.39V9.72H.166z" fill="#da0000"></path><path fill="#fff9f9" d="M5.97 3.638h1.62c1.053 0 1.483.677 1.488 1.564.008.96-.6 1.564-1.492 1.564h-.644v1.66h-.977V3.64m.977.897v1.34h.542c.27 0 .596-.068.596-.673-.002-.6-.32-.667-.596-.667h-.542m3.8.036v2.92h.35c.933 0 1.223-.448 1.228-1.462.008-1.06-.316-1.45-1.23-1.45h-.347m-.977-.94h1.03c1.68 0 2.523.586 2.534 2.39.01 1.688-.607 2.4-2.534 2.4h-1.03V3.64m4.305 0h2.63v.934h-1.657v.894H16.6V6.4h-1.56v2.026h-.97V3.638"></path><path d="M19.462 13.46c.348 4.274-6.59 16.72-8.508 15.792-1.82-.85 1.53-3.317 2.92-4.366-2.864.894-5.394 3.252-3.837 3.93 2.113.895 7.048-9.25 9.41-15.394zM14.32 24.874c4.767-1.526 14.735-2.974 15.152-1.407.824-3.157-13.72-.37-15.153 1.407zm5.28-5.043c2.31 3.237 9.816 7.498 9.788 3.82-.306 2.046-6.66-1.097-8.925-4.164-4.087-5.534-2.39-8.772-1.682-8.732.917.047 1.074 1.307.67 2.442-.173-1.406-.58-2.44-1.224-2.415-1.835.067-1.905 4.46 1.37 9.065z" fill="#f91d0a"></path></svg><span class="anchor-text-container"><span class="anchor-text">View PDF</span></span></a><a class="anchor link anchor-primary" href="/science/article/pii/S0262885600000962" aria-describedby="ref-id-sbref0008"><span class="anchor-text-container"><span class="anchor-text">View article</span></span></a><a class="anchor link anchor-primary" href="https://www.scopus.com/inward/record.url?eid=2-s2.0-0347868848&amp;partnerID=10&amp;rel=R3.0.0" target="_blank" rel="noopener noreferrer" aria-describedby="ref-id-sbref0008"><span class="anchor-text-container"><span class="anchor-text">View in Scopus</span><svg focusable="false" viewBox="0 0 8 8" height="20" aria-label="Opens in new window" class="icon icon-arrow-up-right-tiny arrow-external-link"><path d="M1.12949 2.1072V1H7V6.85795H5.89111V2.90281L0.784057 8L0 7.21635L5.11902 2.1072H1.12949Z"></path></svg></span></a><a class="anchor link anchor-primary" href="https://scholar.google.com/scholar_lookup?title=Face%20distributions%20in%20similarity%20space%20under%20varying%20head%20pose&amp;publication_year=2001&amp;author=J.%20Sherrah&amp;author=S.%20Gong&amp;author=E.-J.%20Ong" target="_blank" rel="noopener noreferrer" aria-describedby="ref-id-sbref0008"><span class="anchor-text-container"><span class="anchor-text">Google Scholar</span><svg focusable="false" viewBox="0 0 8 8" height="20" aria-label="Opens in new window" class="icon icon-arrow-up-right-tiny arrow-external-link"><path d="M1.12949 2.1072V1H7V6.85795H5.89111V2.90281L0.784057 8L0 7.21635L5.11902 2.1072H1.12949Z"></path></svg></span></a></div></span></li><li><span class="label u-font-sans"><a class="anchor anchor-primary" href="#bbib0010" id="ref-id-bib0010" data-aa-button="sd:product:journal:article:location=references:type=anchor:name=citation-name"><span class="anchor-text-container"><span class="anchor-text">[10]</span></span></a></span><span class="reference" id="sbref0009"><div class="contribution"><div class="authors u-font-sans">D. Lia, W. Pedrycz</div><div id="ref-id-sbref0009" class="title text-m">A central profile-based 3D face pose estimation</div></div><div class="host u-font-sans">Pattern Recognit., 47 (2014), pp. 525-534</div><div class="ReferenceLinks u-font-sans"><a class="anchor link anchor-primary" href="https://scholar.google.com/scholar_lookup?title=A%20central%20profile-based%203D%20face%20pose%20estimation&amp;publication_year=2014&amp;author=D.%20Lia&amp;author=W.%20Pedrycz" target="_blank" rel="noopener noreferrer" aria-describedby="ref-id-sbref0009"><span class="anchor-text-container"><span class="anchor-text">Google Scholar</span><svg focusable="false" viewBox="0 0 8 8" height="20" aria-label="Opens in new window" class="icon icon-arrow-up-right-tiny arrow-external-link"><path d="M1.12949 2.1072V1H7V6.85795H5.89111V2.90281L0.784057 8L0 7.21635L5.11902 2.1072H1.12949Z"></path></svg></span></a></div></span></li><li><span class="label u-font-sans"><a class="anchor anchor-primary" href="#bbib0011" id="ref-id-bib0011" data-aa-button="sd:product:journal:article:location=references:type=anchor:name=citation-name"><span class="anchor-text-container"><span class="anchor-text">[11]</span></span></a></span><span class="reference" id="sbref0010"><div class="contribution"><div class="authors u-font-sans">P. Martins, J. Batista</div><div id="ref-id-sbref0010" class="title text-m">Monocular head pose estimation</div></div><div class="host u-font-sans">International Conference Image Analysis and Recognition, Springer (2008), pp. 357-368</div><div class="ReferenceLinks u-font-sans"><span class="link lazy-third-party-pdf-link"><span></span></span><a class="anchor link anchor-primary" href="https://doi.org/10.1007/978-3-540-69812-8_35" target="_blank" rel="noopener noreferrer" aria-describedby="ref-id-sbref0010"><span class="anchor-text-container"><span class="anchor-text">Crossref</span><svg focusable="false" viewBox="0 0 8 8" height="20" aria-label="Opens in new window" class="icon icon-arrow-up-right-tiny arrow-external-link"><path d="M1.12949 2.1072V1H7V6.85795H5.89111V2.90281L0.784057 8L0 7.21635L5.11902 2.1072H1.12949Z"></path></svg></span></a><a class="anchor link anchor-primary" href="https://www.scopus.com/inward/record.url?eid=2-s2.0-47749092471&amp;partnerID=10&amp;rel=R3.0.0" target="_blank" rel="noopener noreferrer" aria-describedby="ref-id-sbref0010"><span class="anchor-text-container"><span class="anchor-text">View in Scopus</span><svg focusable="false" viewBox="0 0 8 8" height="20" aria-label="Opens in new window" class="icon icon-arrow-up-right-tiny arrow-external-link"><path d="M1.12949 2.1072V1H7V6.85795H5.89111V2.90281L0.784057 8L0 7.21635L5.11902 2.1072H1.12949Z"></path></svg></span></a><a class="anchor link anchor-primary" href="https://scholar.google.com/scholar_lookup?title=Monocular%20head%20pose%20estimation&amp;publication_year=2008&amp;author=P.%20Martins&amp;author=J.%20Batista" target="_blank" rel="noopener noreferrer" aria-describedby="ref-id-sbref0010"><span class="anchor-text-container"><span class="anchor-text">Google Scholar</span><svg focusable="false" viewBox="0 0 8 8" height="20" aria-label="Opens in new window" class="icon icon-arrow-up-right-tiny arrow-external-link"><path d="M1.12949 2.1072V1H7V6.85795H5.89111V2.90281L0.784057 8L0 7.21635L5.11902 2.1072H1.12949Z"></path></svg></span></a></div></span></li><li><span class="label u-font-sans"><a class="anchor anchor-primary" href="#bbib0012" id="ref-id-bib0012" data-aa-button="sd:product:journal:article:location=references:type=anchor:name=citation-name"><span class="anchor-text-container"><span class="anchor-text">[12]</span></span></a></span><span class="reference" id="sbref0011"><div class="contribution"><div class="authors u-font-sans">Q. Liu, J. Yang, J. Deng, K. Zhang</div><div id="ref-id-sbref0011" class="title text-m">Robust facial landmark tracking via cascade regression</div></div><div class="host u-font-sans">Pattern Recognit., 66 (2017), pp. 53-62</div><div class="ReferenceLinks u-font-sans"><a class="anchor pdf link anchor-primary anchor-icon-left anchor-with-icon" href="/science/article/pii/S0031320316304459/pdfft?md5=259c0404eacd0fff0f797aa7d51f0a04&amp;pid=1-s2.0-S0031320316304459-main.pdf" target="_blank" rel="nofollow" aria-describedby="ref-id-sbref0011"><svg focusable="false" viewBox="0 0 35 32" height="20" class="icon icon-pdf-multicolor"><path d="M7 .362h17.875l6.763 6.1V31.64H6.948V16z" stroke="#000" stroke-width=".703" fill="#fff"></path><path d="M.167 2.592H22.39V9.72H.166z" fill="#da0000"></path><path fill="#fff9f9" d="M5.97 3.638h1.62c1.053 0 1.483.677 1.488 1.564.008.96-.6 1.564-1.492 1.564h-.644v1.66h-.977V3.64m.977.897v1.34h.542c.27 0 .596-.068.596-.673-.002-.6-.32-.667-.596-.667h-.542m3.8.036v2.92h.35c.933 0 1.223-.448 1.228-1.462.008-1.06-.316-1.45-1.23-1.45h-.347m-.977-.94h1.03c1.68 0 2.523.586 2.534 2.39.01 1.688-.607 2.4-2.534 2.4h-1.03V3.64m4.305 0h2.63v.934h-1.657v.894H16.6V6.4h-1.56v2.026h-.97V3.638"></path><path d="M19.462 13.46c.348 4.274-6.59 16.72-8.508 15.792-1.82-.85 1.53-3.317 2.92-4.366-2.864.894-5.394 3.252-3.837 3.93 2.113.895 7.048-9.25 9.41-15.394zM14.32 24.874c4.767-1.526 14.735-2.974 15.152-1.407.824-3.157-13.72-.37-15.153 1.407zm5.28-5.043c2.31 3.237 9.816 7.498 9.788 3.82-.306 2.046-6.66-1.097-8.925-4.164-4.087-5.534-2.39-8.772-1.682-8.732.917.047 1.074 1.307.67 2.442-.173-1.406-.58-2.44-1.224-2.415-1.835.067-1.905 4.46 1.37 9.065z" fill="#f91d0a"></path></svg><span class="anchor-text-container"><span class="anchor-text">View PDF</span></span></a><a class="anchor link anchor-primary" href="/science/article/pii/S0031320316304459" aria-describedby="ref-id-sbref0011"><span class="anchor-text-container"><span class="anchor-text">View article</span></span></a><a class="anchor link anchor-primary" href="https://www.scopus.com/inward/record.url?eid=2-s2.0-85008429798&amp;partnerID=10&amp;rel=R3.0.0" target="_blank" rel="noopener noreferrer" aria-describedby="ref-id-sbref0011"><span class="anchor-text-container"><span class="anchor-text">View in Scopus</span><svg focusable="false" viewBox="0 0 8 8" height="20" aria-label="Opens in new window" class="icon icon-arrow-up-right-tiny arrow-external-link"><path d="M1.12949 2.1072V1H7V6.85795H5.89111V2.90281L0.784057 8L0 7.21635L5.11902 2.1072H1.12949Z"></path></svg></span></a><a class="anchor link anchor-primary" href="https://scholar.google.com/scholar_lookup?title=Robust%20facial%20landmark%20tracking%20via%20cascade%20regression&amp;publication_year=2017&amp;author=Q.%20Liu&amp;author=J.%20Yang&amp;author=J.%20Deng&amp;author=K.%20Zhang" target="_blank" rel="noopener noreferrer" aria-describedby="ref-id-sbref0011"><span class="anchor-text-container"><span class="anchor-text">Google Scholar</span><svg focusable="false" viewBox="0 0 8 8" height="20" aria-label="Opens in new window" class="icon icon-arrow-up-right-tiny arrow-external-link"><path d="M1.12949 2.1072V1H7V6.85795H5.89111V2.90281L0.784057 8L0 7.21635L5.11902 2.1072H1.12949Z"></path></svg></span></a></div></span></li><li><span class="label u-font-sans"><a class="anchor anchor-primary" href="#bbib0013" id="ref-id-bib0013" data-aa-button="sd:product:journal:article:location=references:type=anchor:name=citation-name"><span class="anchor-text-container"><span class="anchor-text">[13]</span></span></a></span><span class="reference" id="sbref0012"><div class="contribution"><div class="authors u-font-sans">X. Jin, X. Tan</div><div id="ref-id-sbref0012" class="title text-m">Face alignment by robust discriminative hough voting</div></div><div class="host u-font-sans">Pattern Recognit., 60 (2016), pp. 318-333</div><div class="ReferenceLinks u-font-sans"><a class="anchor pdf link anchor-primary anchor-icon-left anchor-with-icon" href="/science/article/pii/S0031320316301005/pdfft?md5=f5ec644f020e91618fc861abc0940c7d&amp;pid=1-s2.0-S0031320316301005-main.pdf" target="_blank" rel="nofollow" aria-describedby="ref-id-sbref0012"><svg focusable="false" viewBox="0 0 35 32" height="20" class="icon icon-pdf-multicolor"><path d="M7 .362h17.875l6.763 6.1V31.64H6.948V16z" stroke="#000" stroke-width=".703" fill="#fff"></path><path d="M.167 2.592H22.39V9.72H.166z" fill="#da0000"></path><path fill="#fff9f9" d="M5.97 3.638h1.62c1.053 0 1.483.677 1.488 1.564.008.96-.6 1.564-1.492 1.564h-.644v1.66h-.977V3.64m.977.897v1.34h.542c.27 0 .596-.068.596-.673-.002-.6-.32-.667-.596-.667h-.542m3.8.036v2.92h.35c.933 0 1.223-.448 1.228-1.462.008-1.06-.316-1.45-1.23-1.45h-.347m-.977-.94h1.03c1.68 0 2.523.586 2.534 2.39.01 1.688-.607 2.4-2.534 2.4h-1.03V3.64m4.305 0h2.63v.934h-1.657v.894H16.6V6.4h-1.56v2.026h-.97V3.638"></path><path d="M19.462 13.46c.348 4.274-6.59 16.72-8.508 15.792-1.82-.85 1.53-3.317 2.92-4.366-2.864.894-5.394 3.252-3.837 3.93 2.113.895 7.048-9.25 9.41-15.394zM14.32 24.874c4.767-1.526 14.735-2.974 15.152-1.407.824-3.157-13.72-.37-15.153 1.407zm5.28-5.043c2.31 3.237 9.816 7.498 9.788 3.82-.306 2.046-6.66-1.097-8.925-4.164-4.087-5.534-2.39-8.772-1.682-8.732.917.047 1.074 1.307.67 2.442-.173-1.406-.58-2.44-1.224-2.415-1.835.067-1.905 4.46 1.37 9.065z" fill="#f91d0a"></path></svg><span class="anchor-text-container"><span class="anchor-text">View PDF</span></span></a><a class="anchor link anchor-primary" href="/science/article/pii/S0031320316301005" aria-describedby="ref-id-sbref0012"><span class="anchor-text-container"><span class="anchor-text">View article</span></span></a><a class="anchor link anchor-primary" href="https://www.scopus.com/inward/record.url?eid=2-s2.0-84994807405&amp;partnerID=10&amp;rel=R3.0.0" target="_blank" rel="noopener noreferrer" aria-describedby="ref-id-sbref0012"><span class="anchor-text-container"><span class="anchor-text">View in Scopus</span><svg focusable="false" viewBox="0 0 8 8" height="20" aria-label="Opens in new window" class="icon icon-arrow-up-right-tiny arrow-external-link"><path d="M1.12949 2.1072V1H7V6.85795H5.89111V2.90281L0.784057 8L0 7.21635L5.11902 2.1072H1.12949Z"></path></svg></span></a><a class="anchor link anchor-primary" href="https://scholar.google.com/scholar_lookup?title=Face%20alignment%20by%20robust%20discriminative%20hough%20voting&amp;publication_year=2016&amp;author=X.%20Jin&amp;author=X.%20Tan" target="_blank" rel="noopener noreferrer" aria-describedby="ref-id-sbref0012"><span class="anchor-text-container"><span class="anchor-text">Google Scholar</span><svg focusable="false" viewBox="0 0 8 8" height="20" aria-label="Opens in new window" class="icon icon-arrow-up-right-tiny arrow-external-link"><path d="M1.12949 2.1072V1H7V6.85795H5.89111V2.90281L0.784057 8L0 7.21635L5.11902 2.1072H1.12949Z"></path></svg></span></a></div></span></li><li><span class="label u-font-sans"><a class="anchor anchor-primary" href="#bbib0014" id="ref-id-bib0014" data-aa-button="sd:product:journal:article:location=references:type=anchor:name=citation-name"><span class="anchor-text-container"><span class="anchor-text">[14]</span></span></a></span><span class="reference" id="sbref0013"><div class="contribution"><div class="authors u-font-sans">J. Tu, Y. Fu, Y. Hu, T. Huang</div><div id="ref-id-sbref0013" class="title text-m">Evaluation of head pose estimation for studio data</div></div><div class="host u-font-sans">Lect. Notes Comput. Sci., 4122 (2007), pp. 281-290</div><div class="ReferenceLinks u-font-sans"><span class="link lazy-third-party-pdf-link"><span></span></span><a class="anchor link anchor-primary" href="https://doi.org/10.1007/978-3-540-69568-4_25" target="_blank" rel="noopener noreferrer" aria-describedby="ref-id-sbref0013"><span class="anchor-text-container"><span class="anchor-text">Crossref</span><svg focusable="false" viewBox="0 0 8 8" height="20" aria-label="Opens in new window" class="icon icon-arrow-up-right-tiny arrow-external-link"><path d="M1.12949 2.1072V1H7V6.85795H5.89111V2.90281L0.784057 8L0 7.21635L5.11902 2.1072H1.12949Z"></path></svg></span></a><a class="anchor link anchor-primary" href="https://www.scopus.com/inward/record.url?eid=2-s2.0-38049172644&amp;partnerID=10&amp;rel=R3.0.0" target="_blank" rel="noopener noreferrer" aria-describedby="ref-id-sbref0013"><span class="anchor-text-container"><span class="anchor-text">View in Scopus</span><svg focusable="false" viewBox="0 0 8 8" height="20" aria-label="Opens in new window" class="icon icon-arrow-up-right-tiny arrow-external-link"><path d="M1.12949 2.1072V1H7V6.85795H5.89111V2.90281L0.784057 8L0 7.21635L5.11902 2.1072H1.12949Z"></path></svg></span></a><a class="anchor link anchor-primary" href="https://scholar.google.com/scholar_lookup?title=Evaluation%20of%20head%20pose%20estimation%20for%20studio%20data&amp;publication_year=2007&amp;author=J.%20Tu&amp;author=Y.%20Fu&amp;author=Y.%20Hu&amp;author=T.%20Huang" target="_blank" rel="noopener noreferrer" aria-describedby="ref-id-sbref0013"><span class="anchor-text-container"><span class="anchor-text">Google Scholar</span><svg focusable="false" viewBox="0 0 8 8" height="20" aria-label="Opens in new window" class="icon icon-arrow-up-right-tiny arrow-external-link"><path d="M1.12949 2.1072V1H7V6.85795H5.89111V2.90281L0.784057 8L0 7.21635L5.11902 2.1072H1.12949Z"></path></svg></span></a></div></span></li><li><span class="label u-font-sans"><a class="anchor anchor-primary" href="#bbib0015" id="ref-id-bib0015" data-aa-button="sd:product:journal:article:location=references:type=anchor:name=citation-name"><span class="anchor-text-container"><span class="anchor-text">[15]</span></span></a></span><span class="reference" id="sbref0014"><div class="contribution"><div class="authors u-font-sans">K. Sundararajan, D.L. Woodard</div><div id="ref-id-sbref0014" class="title text-m">Head pose estimation in the wild using approximate view manifolds</div></div><div class="host u-font-sans">The IEEE Conference on Computer Vision and Pattern Recognition (CVPR) Workshops, Boston, Massachusetts (2015), pp. 50-58</div><div class="ReferenceLinks u-font-sans"><span class="link lazy-third-party-pdf-link"><span></span></span><a class="anchor link anchor-primary" href="https://doi.org/10.1109/CVPRW.2015.7301354" target="_blank" rel="noopener noreferrer" aria-describedby="ref-id-sbref0014"><span class="anchor-text-container"><span class="anchor-text">Crossref</span><svg focusable="false" viewBox="0 0 8 8" height="20" aria-label="Opens in new window" class="icon icon-arrow-up-right-tiny arrow-external-link"><path d="M1.12949 2.1072V1H7V6.85795H5.89111V2.90281L0.784057 8L0 7.21635L5.11902 2.1072H1.12949Z"></path></svg></span></a><a class="anchor link anchor-primary" href="https://www.scopus.com/inward/record.url?eid=2-s2.0-84952022490&amp;partnerID=10&amp;rel=R3.0.0" target="_blank" rel="noopener noreferrer" aria-describedby="ref-id-sbref0014"><span class="anchor-text-container"><span class="anchor-text">View in Scopus</span><svg focusable="false" viewBox="0 0 8 8" height="20" aria-label="Opens in new window" class="icon icon-arrow-up-right-tiny arrow-external-link"><path d="M1.12949 2.1072V1H7V6.85795H5.89111V2.90281L0.784057 8L0 7.21635L5.11902 2.1072H1.12949Z"></path></svg></span></a><a class="anchor link anchor-primary" href="https://scholar.google.com/scholar_lookup?title=Head%20pose%20estimation%20in%20the%20wild%20using%20approximate%20view%20manifolds&amp;publication_year=2015&amp;author=K.%20Sundararajan&amp;author=D.L.%20Woodard" target="_blank" rel="noopener noreferrer" aria-describedby="ref-id-sbref0014"><span class="anchor-text-container"><span class="anchor-text">Google Scholar</span><svg focusable="false" viewBox="0 0 8 8" height="20" aria-label="Opens in new window" class="icon icon-arrow-up-right-tiny arrow-external-link"><path d="M1.12949 2.1072V1H7V6.85795H5.89111V2.90281L0.784057 8L0 7.21635L5.11902 2.1072H1.12949Z"></path></svg></span></a></div></span></li><li><span class="label u-font-sans"><a class="anchor anchor-primary" href="#bbib0016" id="ref-id-bib0016" data-aa-button="sd:product:journal:article:location=references:type=anchor:name=citation-name"><span class="anchor-text-container"><span class="anchor-text">[16]</span></span></a></span><span class="reference" id="sbref0015"><div class="contribution"><div class="authors u-font-sans">R. Stiefelhagen</div><div id="ref-id-sbref0015" class="title text-m">Estimating head pose with neural networks - results on the pointing04 icpr workshop evaluation data</div></div><div class="host u-font-sans">Proceedings of Pointing, ICPR, International Workshop on Visual Observation of Deictic Gestures, Cambridge, UK (2004)</div><div class="ReferenceLinks u-font-sans"><a class="anchor link anchor-primary" href="https://scholar.google.com/scholar_lookup?title=Estimating%20head%20pose%20with%20neural%20networks%20-%20results%20on%20the%20pointing04%20icpr%20workshop%20evaluation%20data&amp;publication_year=2004&amp;author=R.%20Stiefelhagen" target="_blank" rel="noopener noreferrer" aria-describedby="ref-id-sbref0015"><span class="anchor-text-container"><span class="anchor-text">Google Scholar</span><svg focusable="false" viewBox="0 0 8 8" height="20" aria-label="Opens in new window" class="icon icon-arrow-up-right-tiny arrow-external-link"><path d="M1.12949 2.1072V1H7V6.85795H5.89111V2.90281L0.784057 8L0 7.21635L5.11902 2.1072H1.12949Z"></path></svg></span></a></div></span><div class="reference note"><div class="u-margin-s-bottom" id="spara0006">pp. –</div></div></li><li><span class="label u-font-sans"><a class="anchor anchor-primary" href="#bbib0017" id="ref-id-bib0017" data-aa-button="sd:product:journal:article:location=references:type=anchor:name=citation-name"><span class="anchor-text-container"><span class="anchor-text">[17]</span></span></a></span><span class="reference" id="sbref0016"><div class="contribution"><div class="authors u-font-sans">M. Osadchy, Y.L. Cun, M.L. Miller</div><div id="ref-id-sbref0016" class="title text-m">Synergistic face detection and pose estimation with energy-based models</div></div><div class="host u-font-sans">J. Mach. Learn. Res., 8 (2007), pp. 1197-1215</div><div class="ReferenceLinks u-font-sans"><a class="anchor link anchor-primary" href="https://www.scopus.com/inward/record.url?eid=2-s2.0-34249661090&amp;partnerID=10&amp;rel=R3.0.0" target="_blank" rel="noopener noreferrer" aria-describedby="ref-id-sbref0016"><span class="anchor-text-container"><span class="anchor-text">View in Scopus</span><svg focusable="false" viewBox="0 0 8 8" height="20" aria-label="Opens in new window" class="icon icon-arrow-up-right-tiny arrow-external-link"><path d="M1.12949 2.1072V1H7V6.85795H5.89111V2.90281L0.784057 8L0 7.21635L5.11902 2.1072H1.12949Z"></path></svg></span></a><a class="anchor link anchor-primary" href="https://scholar.google.com/scholar_lookup?title=Synergistic%20face%20detection%20and%20pose%20estimation%20with%20energy-based%20models&amp;publication_year=2007&amp;author=M.%20Osadchy&amp;author=Y.L.%20Cun&amp;author=M.L.%20Miller" target="_blank" rel="noopener noreferrer" aria-describedby="ref-id-sbref0016"><span class="anchor-text-container"><span class="anchor-text">Google Scholar</span><svg focusable="false" viewBox="0 0 8 8" height="20" aria-label="Opens in new window" class="icon icon-arrow-up-right-tiny arrow-external-link"><path d="M1.12949 2.1072V1H7V6.85795H5.89111V2.90281L0.784057 8L0 7.21635L5.11902 2.1072H1.12949Z"></path></svg></span></a></div></span></li><li><span class="label u-font-sans"><a class="anchor anchor-primary" href="#bbib0018" id="ref-id-bib0018" data-aa-button="sd:product:journal:article:location=references:type=anchor:name=citation-name"><span class="anchor-text-container"><span class="anchor-text">[18]</span></span></a></span><span class="reference" id="sbref0017"><div class="contribution"><div class="authors u-font-sans">B. Ahn, J. Park, I.S. Kweon</div><div id="ref-id-sbref0017" class="title text-m">Real-time head orientation from a monocular camera using deep neural network</div></div><div class="host u-font-sans">12th Asian Conference on Computer Vision, Springer International Publishing, Singapore (2014), pp. 82-96</div><div class="ReferenceLinks u-font-sans"><a class="anchor link anchor-primary" href="https://scholar.google.com/scholar_lookup?title=Real-time%20head%20orientation%20from%20a%20monocular%20camera%20using%20deep%20neural%20network&amp;publication_year=2014&amp;author=B.%20Ahn&amp;author=J.%20Park&amp;author=I.S.%20Kweon" target="_blank" rel="noopener noreferrer" aria-describedby="ref-id-sbref0017"><span class="anchor-text-container"><span class="anchor-text">Google Scholar</span><svg focusable="false" viewBox="0 0 8 8" height="20" aria-label="Opens in new window" class="icon icon-arrow-up-right-tiny arrow-external-link"><path d="M1.12949 2.1072V1H7V6.85795H5.89111V2.90281L0.784057 8L0 7.21635L5.11902 2.1072H1.12949Z"></path></svg></span></a></div></span></li><li><span class="label u-font-sans"><a class="anchor anchor-primary" href="#bbib0019" id="ref-id-bib0019" data-aa-button="sd:product:journal:article:location=references:type=anchor:name=citation-name"><span class="anchor-text-container"><span class="anchor-text">[19]</span></span></a></span><span class="reference" id="sbref0018"><div class="contribution"><div class="authors u-font-sans">G. Fanelli, M. Dantone, J. Gall, A. Fossati, L.V. Gool</div><div id="ref-id-sbref0018" class="title text-m">Random forests for real time 3D face analysis</div></div><div class="host u-font-sans">Int. J. Comput. Vision, 101 (2012), pp. 437-458</div><div class="ReferenceLinks u-font-sans"><a class="anchor link anchor-primary" href="https://scholar.google.com/scholar_lookup?title=Random%20forests%20for%20real%20time%203D%20face%20analysis&amp;publication_year=2012&amp;author=G.%20Fanelli&amp;author=M.%20Dantone&amp;author=J.%20Gall&amp;author=A.%20Fossati&amp;author=L.V.%20Gool" target="_blank" rel="noopener noreferrer" aria-describedby="ref-id-sbref0018"><span class="anchor-text-container"><span class="anchor-text">Google Scholar</span><svg focusable="false" viewBox="0 0 8 8" height="20" aria-label="Opens in new window" class="icon icon-arrow-up-right-tiny arrow-external-link"><path d="M1.12949 2.1072V1H7V6.85795H5.89111V2.90281L0.784057 8L0 7.21635L5.11902 2.1072H1.12949Z"></path></svg></span></a></div></span></li><li><span class="label u-font-sans"><a class="anchor anchor-primary" href="#bbib0020" id="ref-id-bib0020" data-aa-button="sd:product:journal:article:location=references:type=anchor:name=citation-name"><span class="anchor-text-container"><span class="anchor-text">[20]</span></span></a></span><span class="reference" id="sbref0019"><div class="contribution"><div class="authors u-font-sans">N. Malagavi, V. Hemadri, U. Kulkarni</div><div id="ref-id-sbref0019" class="title text-m">Head pose estimation using convolutional neural networks</div></div><div class="host u-font-sans">Int. J. Innovative Sci. Eng. Technol., 1 (2014), pp. 470-475</div><div class="ReferenceLinks u-font-sans"><a class="anchor link anchor-primary" href="https://www.scopus.com/inward/record.url?eid=2-s2.0-85014396721&amp;partnerID=10&amp;rel=R3.0.0" target="_blank" rel="noopener noreferrer" aria-describedby="ref-id-sbref0019"><span class="anchor-text-container"><span class="anchor-text">View in Scopus</span><svg focusable="false" viewBox="0 0 8 8" height="20" aria-label="Opens in new window" class="icon icon-arrow-up-right-tiny arrow-external-link"><path d="M1.12949 2.1072V1H7V6.85795H5.89111V2.90281L0.784057 8L0 7.21635L5.11902 2.1072H1.12949Z"></path></svg></span></a><a class="anchor link anchor-primary" href="https://scholar.google.com/scholar_lookup?title=Head%20pose%20estimation%20using%20convolutional%20neural%20networks&amp;publication_year=2014&amp;author=N.%20Malagavi&amp;author=V.%20Hemadri&amp;author=U.%20Kulkarni" target="_blank" rel="noopener noreferrer" aria-describedby="ref-id-sbref0019"><span class="anchor-text-container"><span class="anchor-text">Google Scholar</span><svg focusable="false" viewBox="0 0 8 8" height="20" aria-label="Opens in new window" class="icon icon-arrow-up-right-tiny arrow-external-link"><path d="M1.12949 2.1072V1H7V6.85795H5.89111V2.90281L0.784057 8L0 7.21635L5.11902 2.1072H1.12949Z"></path></svg></span></a></div></span></li><li><span class="label u-font-sans"><a class="anchor anchor-primary" href="#bbib0021" id="ref-id-bib0021" data-aa-button="sd:product:journal:article:location=references:type=anchor:name=citation-name"><span class="anchor-text-container"><span class="anchor-text">[21]</span></span></a></span><span class="reference" id="sbref0020"><div class="contribution"><div class="authors u-font-sans">S.S. Mukherjee, N.M. Robertson</div><div id="ref-id-sbref0020" class="title text-m">Deep head pose: gaze-direction estimation in multimodal video</div></div><div class="host u-font-sans">IEEE Trans. Multimedia, 17 (2015), pp. 2094-2107</div><div class="ReferenceLinks u-font-sans"><a class="anchor link anchor-primary" href="https://www.scopus.com/inward/record.url?eid=2-s2.0-84946574616&amp;partnerID=10&amp;rel=R3.0.0" target="_blank" rel="noopener noreferrer" aria-describedby="ref-id-sbref0020"><span class="anchor-text-container"><span class="anchor-text">View in Scopus</span><svg focusable="false" viewBox="0 0 8 8" height="20" aria-label="Opens in new window" class="icon icon-arrow-up-right-tiny arrow-external-link"><path d="M1.12949 2.1072V1H7V6.85795H5.89111V2.90281L0.784057 8L0 7.21635L5.11902 2.1072H1.12949Z"></path></svg></span></a><a class="anchor link anchor-primary" href="https://scholar.google.com/scholar_lookup?title=Deep%20head%20pose%3A%20gaze-direction%20estimation%20in%20multimodal%20video&amp;publication_year=2015&amp;author=S.S.%20Mukherjee&amp;author=N.M.%20Robertson" target="_blank" rel="noopener noreferrer" aria-describedby="ref-id-sbref0020"><span class="anchor-text-container"><span class="anchor-text">Google Scholar</span><svg focusable="false" viewBox="0 0 8 8" height="20" aria-label="Opens in new window" class="icon icon-arrow-up-right-tiny arrow-external-link"><path d="M1.12949 2.1072V1H7V6.85795H5.89111V2.90281L0.784057 8L0 7.21635L5.11902 2.1072H1.12949Z"></path></svg></span></a></div></span></li><li><span class="label u-font-sans"><a class="anchor anchor-primary" href="#bbib0022" id="ref-id-bib0022" data-aa-button="sd:product:journal:article:location=references:type=anchor:name=citation-name"><span class="anchor-text-container"><span class="anchor-text">[22]</span></span></a></span><span class="reference" id="sbref0021"><div class="contribution"><div class="authors u-font-sans">A. Krizhevsky, I. Sutskever, G.E. Hinton</div><div id="ref-id-sbref0021" class="title text-m">Imagenet classification with deep convolutional neural networks</div></div><div class="host u-font-sans">F. Pereira, C.J.C. Burges, L. Bottou, K.Q. Weinberger (Eds.), Advances in Neural Information Processing Systems 25, Curran Associates, Inc. (2012), pp. 1097-1105</div><div class="ReferenceLinks u-font-sans"><a class="anchor link anchor-primary" href="https://scholar.google.com/scholar_lookup?title=Imagenet%20classification%20with%20deep%20convolutional%20neural%20networks&amp;publication_year=2012&amp;author=A.%20Krizhevsky&amp;author=I.%20Sutskever&amp;author=G.E.%20Hinton" target="_blank" rel="noopener noreferrer" aria-describedby="ref-id-sbref0021"><span class="anchor-text-container"><span class="anchor-text">Google Scholar</span><svg focusable="false" viewBox="0 0 8 8" height="20" aria-label="Opens in new window" class="icon icon-arrow-up-right-tiny arrow-external-link"><path d="M1.12949 2.1072V1H7V6.85795H5.89111V2.90281L0.784057 8L0 7.21635L5.11902 2.1072H1.12949Z"></path></svg></span></a></div></span></li><li><span class="label u-font-sans"><a class="anchor anchor-primary" href="#bbib0023" id="ref-id-bib0023" data-aa-button="sd:product:journal:article:location=references:type=anchor:name=citation-name"><span class="anchor-text-container"><span class="anchor-text">[23]</span></span></a></span><span class="reference" id="sbref0022"><div class="contribution"><div class="authors u-font-sans">A.T. Lopes, E. de Aguiar, A.F. De Souza, T. Oliveira-Santos</div><div id="ref-id-sbref0022" class="title text-m">Facial expression recognition with convolutional neural networks: coping with few data and the training sample order</div></div><div class="host u-font-sans">Pattern Recognit., 61 (2017), pp. 610-628</div><div class="ReferenceLinks u-font-sans"><a class="anchor pdf link anchor-primary anchor-icon-left anchor-with-icon" href="/science/article/pii/S0031320316301753/pdfft?md5=3652c422d2874205c7eb2b753a3aa71b&amp;pid=1-s2.0-S0031320316301753-main.pdf" target="_blank" rel="nofollow" aria-describedby="ref-id-sbref0022"><svg focusable="false" viewBox="0 0 35 32" height="20" class="icon icon-pdf-multicolor"><path d="M7 .362h17.875l6.763 6.1V31.64H6.948V16z" stroke="#000" stroke-width=".703" fill="#fff"></path><path d="M.167 2.592H22.39V9.72H.166z" fill="#da0000"></path><path fill="#fff9f9" d="M5.97 3.638h1.62c1.053 0 1.483.677 1.488 1.564.008.96-.6 1.564-1.492 1.564h-.644v1.66h-.977V3.64m.977.897v1.34h.542c.27 0 .596-.068.596-.673-.002-.6-.32-.667-.596-.667h-.542m3.8.036v2.92h.35c.933 0 1.223-.448 1.228-1.462.008-1.06-.316-1.45-1.23-1.45h-.347m-.977-.94h1.03c1.68 0 2.523.586 2.534 2.39.01 1.688-.607 2.4-2.534 2.4h-1.03V3.64m4.305 0h2.63v.934h-1.657v.894H16.6V6.4h-1.56v2.026h-.97V3.638"></path><path d="M19.462 13.46c.348 4.274-6.59 16.72-8.508 15.792-1.82-.85 1.53-3.317 2.92-4.366-2.864.894-5.394 3.252-3.837 3.93 2.113.895 7.048-9.25 9.41-15.394zM14.32 24.874c4.767-1.526 14.735-2.974 15.152-1.407.824-3.157-13.72-.37-15.153 1.407zm5.28-5.043c2.31 3.237 9.816 7.498 9.788 3.82-.306 2.046-6.66-1.097-8.925-4.164-4.087-5.534-2.39-8.772-1.682-8.732.917.047 1.074 1.307.67 2.442-.173-1.406-.58-2.44-1.224-2.415-1.835.067-1.905 4.46 1.37 9.065z" fill="#f91d0a"></path></svg><span class="anchor-text-container"><span class="anchor-text">View PDF</span></span></a><a class="anchor link anchor-primary" href="/science/article/pii/S0031320316301753" aria-describedby="ref-id-sbref0022"><span class="anchor-text-container"><span class="anchor-text">View article</span></span></a><a class="anchor link anchor-primary" href="https://www.scopus.com/inward/record.url?eid=2-s2.0-84991821737&amp;partnerID=10&amp;rel=R3.0.0" target="_blank" rel="noopener noreferrer" aria-describedby="ref-id-sbref0022"><span class="anchor-text-container"><span class="anchor-text">View in Scopus</span><svg focusable="false" viewBox="0 0 8 8" height="20" aria-label="Opens in new window" class="icon icon-arrow-up-right-tiny arrow-external-link"><path d="M1.12949 2.1072V1H7V6.85795H5.89111V2.90281L0.784057 8L0 7.21635L5.11902 2.1072H1.12949Z"></path></svg></span></a><a class="anchor link anchor-primary" href="https://scholar.google.com/scholar_lookup?title=Facial%20expression%20recognition%20with%20convolutional%20neural%20networks%3A%20coping%20with%20few%20data%20and%20the%20training%20sample%20order&amp;publication_year=2017&amp;author=A.T.%20Lopes&amp;author=E.%20de%20Aguiar&amp;author=A.F.%20De%20Souza&amp;author=T.%20Oliveira-Santos" target="_blank" rel="noopener noreferrer" aria-describedby="ref-id-sbref0022"><span class="anchor-text-container"><span class="anchor-text">Google Scholar</span><svg focusable="false" viewBox="0 0 8 8" height="20" aria-label="Opens in new window" class="icon icon-arrow-up-right-tiny arrow-external-link"><path d="M1.12949 2.1072V1H7V6.85795H5.89111V2.90281L0.784057 8L0 7.21635L5.11902 2.1072H1.12949Z"></path></svg></span></a></div></span></li><li><span class="label u-font-sans"><a class="anchor anchor-primary" href="#bbib0024" id="ref-id-bib0024" data-aa-button="sd:product:journal:article:location=references:type=anchor:name=citation-name"><span class="anchor-text-container"><span class="anchor-text">[24]</span></span></a></span><span class="reference" id="othref0002"><div class="other-ref"><span>K. Nogueira, O.A. Penatti, J.A.d. Santos, Towards better exploiting convolutional neural networks for remote sensing scene classification, arXiv preprint arXiv:<a class="anchor anchor-primary" href="http://arxiv.org/abs/1602.01517" target="_blank"><span class="anchor-text-container"><span class="anchor-text">1602.01517</span><svg focusable="false" viewBox="0 0 8 8" height="20" aria-label="Opens in new window" class="icon icon-arrow-up-right-tiny arrow-external-link"><path d="M1.12949 2.1072V1H7V6.85795H5.89111V2.90281L0.784057 8L0 7.21635L5.11902 2.1072H1.12949Z"></path></svg></span></a> (2016).</span></div><div class="ReferenceLinks u-font-sans"><a class="anchor link anchor-primary" href="https://scholar.google.com/scholar?q=K.%20Nogueira%2C%20O.A.%20Penatti%2C%20J.A.d.%20Santos%2C%20Towards%20better%20exploiting%20convolutional%20neural%20networks%20for%20remote%20sensing%20scene%20classification%2C%20arXiv%20preprint%20arXiv%3A1602.01517%20(2016)." target="_blank" rel="noopener noreferrer"><span class="anchor-text-container"><span class="anchor-text">Google Scholar</span><svg focusable="false" viewBox="0 0 8 8" height="20" aria-label="Opens in new window" class="icon icon-arrow-up-right-tiny arrow-external-link"><path d="M1.12949 2.1072V1H7V6.85795H5.89111V2.90281L0.784057 8L0 7.21635L5.11902 2.1072H1.12949Z"></path></svg></span></a></div></span></li><li><span class="label u-font-sans"><a class="anchor anchor-primary" href="#bbib0025" id="ref-id-bib0025" data-aa-button="sd:product:journal:article:location=references:type=anchor:name=citation-name"><span class="anchor-text-container"><span class="anchor-text">[25]</span></span></a></span><span class="reference" id="sbref0023"><div class="contribution"><div class="authors u-font-sans">J. Schmidhuber</div><div id="ref-id-sbref0023" class="title text-m">Deep learning in neural networks: an overview</div></div><div class="host u-font-sans">Neural Netw., 61 (2015), pp. 85-117</div><div class="ReferenceLinks u-font-sans"><a class="anchor pdf link anchor-primary anchor-icon-left anchor-with-icon" href="/science/article/pii/S0893608014002135/pdfft?md5=faa1dd773ca0a8371a71c3221dc8086d&amp;pid=1-s2.0-S0893608014002135-main.pdf" target="_blank" rel="nofollow" aria-describedby="ref-id-sbref0023"><svg focusable="false" viewBox="0 0 35 32" height="20" class="icon icon-pdf-multicolor"><path d="M7 .362h17.875l6.763 6.1V31.64H6.948V16z" stroke="#000" stroke-width=".703" fill="#fff"></path><path d="M.167 2.592H22.39V9.72H.166z" fill="#da0000"></path><path fill="#fff9f9" d="M5.97 3.638h1.62c1.053 0 1.483.677 1.488 1.564.008.96-.6 1.564-1.492 1.564h-.644v1.66h-.977V3.64m.977.897v1.34h.542c.27 0 .596-.068.596-.673-.002-.6-.32-.667-.596-.667h-.542m3.8.036v2.92h.35c.933 0 1.223-.448 1.228-1.462.008-1.06-.316-1.45-1.23-1.45h-.347m-.977-.94h1.03c1.68 0 2.523.586 2.534 2.39.01 1.688-.607 2.4-2.534 2.4h-1.03V3.64m4.305 0h2.63v.934h-1.657v.894H16.6V6.4h-1.56v2.026h-.97V3.638"></path><path d="M19.462 13.46c.348 4.274-6.59 16.72-8.508 15.792-1.82-.85 1.53-3.317 2.92-4.366-2.864.894-5.394 3.252-3.837 3.93 2.113.895 7.048-9.25 9.41-15.394zM14.32 24.874c4.767-1.526 14.735-2.974 15.152-1.407.824-3.157-13.72-.37-15.153 1.407zm5.28-5.043c2.31 3.237 9.816 7.498 9.788 3.82-.306 2.046-6.66-1.097-8.925-4.164-4.087-5.534-2.39-8.772-1.682-8.732.917.047 1.074 1.307.67 2.442-.173-1.406-.58-2.44-1.224-2.415-1.835.067-1.905 4.46 1.37 9.065z" fill="#f91d0a"></path></svg><span class="anchor-text-container"><span class="anchor-text">View PDF</span></span></a><a class="anchor link anchor-primary" href="/science/article/pii/S0893608014002135" aria-describedby="ref-id-sbref0023"><span class="anchor-text-container"><span class="anchor-text">View article</span></span></a><a class="anchor link anchor-primary" href="https://www.scopus.com/inward/record.url?eid=2-s2.0-84910651844&amp;partnerID=10&amp;rel=R3.0.0" target="_blank" rel="noopener noreferrer" aria-describedby="ref-id-sbref0023"><span class="anchor-text-container"><span class="anchor-text">View in Scopus</span><svg focusable="false" viewBox="0 0 8 8" height="20" aria-label="Opens in new window" class="icon icon-arrow-up-right-tiny arrow-external-link"><path d="M1.12949 2.1072V1H7V6.85795H5.89111V2.90281L0.784057 8L0 7.21635L5.11902 2.1072H1.12949Z"></path></svg></span></a><a class="anchor link anchor-primary" href="https://scholar.google.com/scholar_lookup?title=Deep%20learning%20in%20neural%20networks%3A%20an%20overview&amp;publication_year=2015&amp;author=J.%20Schmidhuber" target="_blank" rel="noopener noreferrer" aria-describedby="ref-id-sbref0023"><span class="anchor-text-container"><span class="anchor-text">Google Scholar</span><svg focusable="false" viewBox="0 0 8 8" height="20" aria-label="Opens in new window" class="icon icon-arrow-up-right-tiny arrow-external-link"><path d="M1.12949 2.1072V1H7V6.85795H5.89111V2.90281L0.784057 8L0 7.21635L5.11902 2.1072H1.12949Z"></path></svg></span></a></div></span></li><li><span class="label u-font-sans"><a class="anchor anchor-primary" href="#bbib0026" id="ref-id-bib0026" data-aa-button="sd:product:journal:article:location=references:type=anchor:name=citation-name"><span class="anchor-text-container"><span class="anchor-text">[26]</span></span></a></span><span class="reference" id="sbref0024"><div class="contribution"><div class="authors u-font-sans">D.E. Rumelhart, G.E. Hinton, R.J. Williams</div><div id="ref-id-sbref0024" class="title text-m">Learning internal representation by error propagation.</div></div><div class="host u-font-sans">Nature, 323 (1986), pp. 318-362</div><div class="ReferenceLinks u-font-sans"><a class="anchor link anchor-primary" href="https://scholar.google.com/scholar_lookup?title=Learning%20internal%20representation%20by%20error%20propagation.&amp;publication_year=1986&amp;author=D.E.%20Rumelhart&amp;author=G.E.%20Hinton&amp;author=R.J.%20Williams" target="_blank" rel="noopener noreferrer" aria-describedby="ref-id-sbref0024"><span class="anchor-text-container"><span class="anchor-text">Google Scholar</span><svg focusable="false" viewBox="0 0 8 8" height="20" aria-label="Opens in new window" class="icon icon-arrow-up-right-tiny arrow-external-link"><path d="M1.12949 2.1072V1H7V6.85795H5.89111V2.90281L0.784057 8L0 7.21635L5.11902 2.1072H1.12949Z"></path></svg></span></a></div></span></li><li><span class="label u-font-sans"><a class="anchor anchor-primary" href="#bbib0027" id="ref-id-bib0027" data-aa-button="sd:product:journal:article:location=references:type=anchor:name=citation-name"><span class="anchor-text-container"><span class="anchor-text">[27]</span></span></a></span><span class="reference" id="sbref0025"><div class="contribution"><div class="authors u-font-sans">N. Srivastava, G. Hinton, A. Krizhevsky, I. Sutskever, R. Salakhutdinov</div><div id="ref-id-sbref0025" class="title text-m">Dropout: a simple way to prevent neural networks from overfitting</div></div><div class="host u-font-sans">J. Mach. Learn. Res., 15 (2014), pp. 1929-1958</div><div class="ReferenceLinks u-font-sans"><a class="anchor link anchor-primary" href="https://www.scopus.com/inward/record.url?eid=2-s2.0-84904163933&amp;partnerID=10&amp;rel=R3.0.0" target="_blank" rel="noopener noreferrer" aria-describedby="ref-id-sbref0025"><span class="anchor-text-container"><span class="anchor-text">View in Scopus</span><svg focusable="false" viewBox="0 0 8 8" height="20" aria-label="Opens in new window" class="icon icon-arrow-up-right-tiny arrow-external-link"><path d="M1.12949 2.1072V1H7V6.85795H5.89111V2.90281L0.784057 8L0 7.21635L5.11902 2.1072H1.12949Z"></path></svg></span></a><a class="anchor link anchor-primary" href="https://scholar.google.com/scholar_lookup?title=Dropout%3A%20a%20simple%20way%20to%20prevent%20neural%20networks%20from%20overfitting&amp;publication_year=2014&amp;author=N.%20Srivastava&amp;author=G.%20Hinton&amp;author=A.%20Krizhevsky&amp;author=I.%20Sutskever&amp;author=R.%20Salakhutdinov" target="_blank" rel="noopener noreferrer" aria-describedby="ref-id-sbref0025"><span class="anchor-text-container"><span class="anchor-text">Google Scholar</span><svg focusable="false" viewBox="0 0 8 8" height="20" aria-label="Opens in new window" class="icon icon-arrow-up-right-tiny arrow-external-link"><path d="M1.12949 2.1072V1H7V6.85795H5.89111V2.90281L0.784057 8L0 7.21635L5.11902 2.1072H1.12949Z"></path></svg></span></a></div></span></li><li><span class="label u-font-sans"><a class="anchor anchor-primary" href="#bbib0028" id="ref-id-bib0028" data-aa-button="sd:product:journal:article:location=references:type=anchor:name=citation-name"><span class="anchor-text-container"><span class="anchor-text">[28]</span></span></a></span><span class="reference" id="sbref0026"><div class="contribution"><div class="authors u-font-sans">J. Duchi, E. Hazan, Y. Singer</div><div id="ref-id-sbref0026" class="title text-m">Adaptive subgradient methods for online learning and stochastic optimization</div></div><div class="host u-font-sans">J. Mach. Learn. Res., 12 (Jul) (2011), pp. 2121-2159</div><div class="ReferenceLinks u-font-sans"><a class="anchor link anchor-primary" href="https://www.scopus.com/inward/record.url?eid=2-s2.0-80052250414&amp;partnerID=10&amp;rel=R3.0.0" target="_blank" rel="noopener noreferrer" aria-describedby="ref-id-sbref0026"><span class="anchor-text-container"><span class="anchor-text">View in Scopus</span><svg focusable="false" viewBox="0 0 8 8" height="20" aria-label="Opens in new window" class="icon icon-arrow-up-right-tiny arrow-external-link"><path d="M1.12949 2.1072V1H7V6.85795H5.89111V2.90281L0.784057 8L0 7.21635L5.11902 2.1072H1.12949Z"></path></svg></span></a><a class="anchor link anchor-primary" href="https://scholar.google.com/scholar_lookup?title=Adaptive%20subgradient%20methods%20for%20online%20learning%20and%20stochastic%20optimization&amp;publication_year=2011&amp;author=J.%20Duchi&amp;author=E.%20Hazan&amp;author=Y.%20Singer" target="_blank" rel="noopener noreferrer" aria-describedby="ref-id-sbref0026"><span class="anchor-text-container"><span class="anchor-text">Google Scholar</span><svg focusable="false" viewBox="0 0 8 8" height="20" aria-label="Opens in new window" class="icon icon-arrow-up-right-tiny arrow-external-link"><path d="M1.12949 2.1072V1H7V6.85795H5.89111V2.90281L0.784057 8L0 7.21635L5.11902 2.1072H1.12949Z"></path></svg></span></a></div></span></li><li><span class="label u-font-sans"><a class="anchor anchor-primary" href="#bbib0029" id="ref-id-bib0029" data-aa-button="sd:product:journal:article:location=references:type=anchor:name=citation-name"><span class="anchor-text-container"><span class="anchor-text">[29]</span></span></a></span><span class="reference" id="othref0003"><div class="other-ref"><span>M.D. Zeiler, Adadelta: an adaptive learning rate method, arXiv preprint arXiv:<a class="anchor anchor-primary" href="http://arxiv.org/abs/1212.5701" target="_blank"><span class="anchor-text-container"><span class="anchor-text">1212.5701</span><svg focusable="false" viewBox="0 0 8 8" height="20" aria-label="Opens in new window" class="icon icon-arrow-up-right-tiny arrow-external-link"><path d="M1.12949 2.1072V1H7V6.85795H5.89111V2.90281L0.784057 8L0 7.21635L5.11902 2.1072H1.12949Z"></path></svg></span></a> (2012).</span></div><div class="ReferenceLinks u-font-sans"><a class="anchor link anchor-primary" href="https://scholar.google.com/scholar?q=M.D.%20Zeiler%2C%20Adadelta%3A%20an%20adaptive%20learning%20rate%20method%2C%20arXiv%20preprint%20arXiv%3A1212.5701%20(2012)." target="_blank" rel="noopener noreferrer"><span class="anchor-text-container"><span class="anchor-text">Google Scholar</span><svg focusable="false" viewBox="0 0 8 8" height="20" aria-label="Opens in new window" class="icon icon-arrow-up-right-tiny arrow-external-link"><path d="M1.12949 2.1072V1H7V6.85795H5.89111V2.90281L0.784057 8L0 7.21635L5.11902 2.1072H1.12949Z"></path></svg></span></a></div></span></li><li><span class="label u-font-sans"><a class="anchor anchor-primary" href="#bbib0030" id="ref-id-bib0030" data-aa-button="sd:product:journal:article:location=references:type=anchor:name=citation-name"><span class="anchor-text-container"><span class="anchor-text">[30]</span></span></a></span><span class="reference" id="sbref0027"><div class="contribution"><div class="authors u-font-sans">T. Tieleman, G. Hinton</div><div id="ref-id-sbref0027" class="title text-m">Lecture 6.5-rmsprop: divide the gradient by a running average of its recent magnitude</div></div><div class="host u-font-sans">COURSERA, 4 (2) (2012)</div><div class="ReferenceLinks u-font-sans"><a class="anchor link anchor-primary" href="https://scholar.google.com/scholar_lookup?title=Lecture%206.5-rmsprop%3A%20divide%20the%20gradient%20by%20a%20running%20average%20of%20its%20recent%20magnitude&amp;publication_year=2012&amp;author=T.%20Tieleman&amp;author=G.%20Hinton" target="_blank" rel="noopener noreferrer" aria-describedby="ref-id-sbref0027"><span class="anchor-text-container"><span class="anchor-text">Google Scholar</span><svg focusable="false" viewBox="0 0 8 8" height="20" aria-label="Opens in new window" class="icon icon-arrow-up-right-tiny arrow-external-link"><path d="M1.12949 2.1072V1H7V6.85795H5.89111V2.90281L0.784057 8L0 7.21635L5.11902 2.1072H1.12949Z"></path></svg></span></a></div></span></li><li><span class="label u-font-sans"><a class="anchor anchor-primary" href="#bbib0031" id="ref-id-bib0031" data-aa-button="sd:product:journal:article:location=references:type=anchor:name=citation-name"><span class="anchor-text-container"><span class="anchor-text">[31]</span></span></a></span><span class="reference" id="othref0004"><div class="other-ref"><span>D. Kingma, J. Ba, Adam: a method for stochastic optimization, arXiv preprint arXiv:<a class="anchor anchor-primary" href="http://arxiv.org/abs/1412.6980" target="_blank"><span class="anchor-text-container"><span class="anchor-text">1412.6980</span><svg focusable="false" viewBox="0 0 8 8" height="20" aria-label="Opens in new window" class="icon icon-arrow-up-right-tiny arrow-external-link"><path d="M1.12949 2.1072V1H7V6.85795H5.89111V2.90281L0.784057 8L0 7.21635L5.11902 2.1072H1.12949Z"></path></svg></span></a> (2014).</span></div><div class="ReferenceLinks u-font-sans"><a class="anchor link anchor-primary" href="https://scholar.google.com/scholar?q=D.%20Kingma%2C%20J.%20Ba%2C%20Adam%3A%20a%20method%20for%20stochastic%20optimization%2C%20arXiv%20preprint%20arXiv%3A1412.6980%20(2014)." target="_blank" rel="noopener noreferrer"><span class="anchor-text-container"><span class="anchor-text">Google Scholar</span><svg focusable="false" viewBox="0 0 8 8" height="20" aria-label="Opens in new window" class="icon icon-arrow-up-right-tiny arrow-external-link"><path d="M1.12949 2.1072V1H7V6.85795H5.89111V2.90281L0.784057 8L0 7.21635L5.11902 2.1072H1.12949Z"></path></svg></span></a></div></span></li><li><span class="label u-font-sans"><a class="anchor anchor-primary" href="#bbib0032" id="ref-id-bib0032" data-aa-button="sd:product:journal:article:location=references:type=anchor:name=citation-name"><span class="anchor-text-container"><span class="anchor-text">[32]</span></span></a></span><span class="reference" id="othref0004a"><div class="other-ref"><span>N. Gourier, D. Hall, J.L. Crowley, Estimating face orientation from robust detection of salient facial features, in: Proceedings of Pointing 2004, ICPR, International Workshop on Visual Observation of Deictic Gestures, Cambridge, UK, pp.– 2014.</span></div><div class="ReferenceLinks u-font-sans"><a class="anchor link anchor-primary" href="https://scholar.google.com/scholar?q=N.%20Gourier%2C%20D.%20Hall%2C%20J.L.%20Crowley%2C%20Estimating%20face%20orientation%20from%20robust%20detection%20of%20salient%20facial%20features%2C%20in%3A%20Proceedings%20of%20Pointing%202004%2C%20ICPR%2C%20International%20Workshop%20on%20Visual%20Observation%20of%20Deictic%20Gestures%2C%20Cambridge%2C%20UK%2C%20pp.%E2%80%93%202014." target="_blank" rel="noopener noreferrer"><span class="anchor-text-container"><span class="anchor-text">Google Scholar</span><svg focusable="false" viewBox="0 0 8 8" height="20" aria-label="Opens in new window" class="icon icon-arrow-up-right-tiny arrow-external-link"><path d="M1.12949 2.1072V1H7V6.85795H5.89111V2.90281L0.784057 8L0 7.21635L5.11902 2.1072H1.12949Z"></path></svg></span></a></div></span></li><li><span class="label u-font-sans"><a class="anchor anchor-primary" href="#bbib0033" id="ref-id-bib0033" data-aa-button="sd:product:journal:article:location=references:type=anchor:name=citation-name"><span class="anchor-text-container"><span class="anchor-text">[33]</span></span></a></span><span class="reference" id="sbref0029"><div class="contribution"><div class="authors u-font-sans">M. Koestinger, P. Wohlhart, P.M. Roth, H. Bischof</div><div id="ref-id-sbref0029" class="title text-m">Annotated facial landmarks in the wild: alarge-scale, real-world database for facial landmark localization</div></div><div class="host u-font-sans">First IEEE International Workshop on Benchmarking Facial Image Analysis Technologies (2011)</div><div class="ReferenceLinks u-font-sans"><a class="anchor link anchor-primary" href="https://scholar.google.com/scholar_lookup?title=Annotated%20facial%20landmarks%20in%20the%20wild%3A%20alarge-scale%2C%20real-world%20database%20for%20facial%20landmark%20localization&amp;publication_year=2011&amp;author=M.%20Koestinger&amp;author=P.%20Wohlhart&amp;author=P.M.%20Roth&amp;author=H.%20Bischof" target="_blank" rel="noopener noreferrer" aria-describedby="ref-id-sbref0029"><span class="anchor-text-container"><span class="anchor-text">Google Scholar</span><svg focusable="false" viewBox="0 0 8 8" height="20" aria-label="Opens in new window" class="icon icon-arrow-up-right-tiny arrow-external-link"><path d="M1.12949 2.1072V1H7V6.85795H5.89111V2.90281L0.784057 8L0 7.21635L5.11902 2.1072H1.12949Z"></path></svg></span></a></div></span></li><li><span class="label u-font-sans"><a class="anchor anchor-primary" href="#bbib0034" id="ref-id-bib0034" data-aa-button="sd:product:journal:article:location=references:type=anchor:name=citation-name"><span class="anchor-text-container"><span class="anchor-text">[34]</span></span></a></span><span class="reference" id="sbref0030"><div class="contribution"><div class="authors u-font-sans">X. Zhu, D. Ramanan</div><div id="ref-id-sbref0030" class="title text-m">Face detection, pose estimation, and landmark localization in the wild</div></div><div class="host u-font-sans">Computer Vision and Pattern Recognition (CVPR), 2012 IEEE Conference on, IEEE (2012), pp. 2879-2886</div><div class="ReferenceLinks u-font-sans"><a class="anchor link anchor-primary" href="https://www.scopus.com/inward/record.url?eid=2-s2.0-84866667680&amp;partnerID=10&amp;rel=R3.0.0" target="_blank" rel="noopener noreferrer" aria-describedby="ref-id-sbref0030"><span class="anchor-text-container"><span class="anchor-text">View in Scopus</span><svg focusable="false" viewBox="0 0 8 8" height="20" aria-label="Opens in new window" class="icon icon-arrow-up-right-tiny arrow-external-link"><path d="M1.12949 2.1072V1H7V6.85795H5.89111V2.90281L0.784057 8L0 7.21635L5.11902 2.1072H1.12949Z"></path></svg></span></a><a class="anchor link anchor-primary" href="https://scholar.google.com/scholar_lookup?title=Face%20detection%2C%20pose%20estimation%2C%20and%20landmark%20localization%20in%20the%20wild&amp;publication_year=2012&amp;author=X.%20Zhu&amp;author=D.%20Ramanan" target="_blank" rel="noopener noreferrer" aria-describedby="ref-id-sbref0030"><span class="anchor-text-container"><span class="anchor-text">Google Scholar</span><svg focusable="false" viewBox="0 0 8 8" height="20" aria-label="Opens in new window" class="icon icon-arrow-up-right-tiny arrow-external-link"><path d="M1.12949 2.1072V1H7V6.85795H5.89111V2.90281L0.784057 8L0 7.21635L5.11902 2.1072H1.12949Z"></path></svg></span></a></div></span></li><li><span class="label u-font-sans"><a class="anchor anchor-primary" href="#bbib0035" id="ref-id-bib0035" data-aa-button="sd:product:journal:article:location=references:type=anchor:name=citation-name"><span class="anchor-text-container"><span class="anchor-text">[35]</span></span></a></span><span class="reference" id="sbref0031"><div class="contribution"><div class="authors u-font-sans">Y. LeCun, L. Bottou, Y. Bengio, P. Haffner</div><div id="ref-id-sbref0031" class="title text-m">Gradient-based learning applied to document recognition</div></div><div class="host u-font-sans">Proceedings of the IEEE, IEEE (1998), pp. 2278-2324</div><div class="ReferenceLinks u-font-sans"><a class="anchor link anchor-primary" href="https://scholar.google.com/scholar_lookup?title=Gradient-based%20learning%20applied%20to%20document%20recognition&amp;publication_year=1998&amp;author=Y.%20LeCun&amp;author=L.%20Bottou&amp;author=Y.%20Bengio&amp;author=P.%20Haffner" target="_blank" rel="noopener noreferrer" aria-describedby="ref-id-sbref0031"><span class="anchor-text-container"><span class="anchor-text">Google Scholar</span><svg focusable="false" viewBox="0 0 8 8" height="20" aria-label="Opens in new window" class="icon icon-arrow-up-right-tiny arrow-external-link"><path d="M1.12949 2.1072V1H7V6.85795H5.89111V2.90281L0.784057 8L0 7.21635L5.11902 2.1072H1.12949Z"></path></svg></span></a></div></span></li><li><span class="label u-font-sans"><a class="anchor anchor-primary" href="#bbib0036" id="ref-id-bib0036" data-aa-button="sd:product:journal:article:location=references:type=anchor:name=citation-name"><span class="anchor-text-container"><span class="anchor-text">[36]</span></span></a></span><span class="reference" id="sbref0032"><div class="contribution"><div class="authors u-font-sans">M. Voit, K. Nickel, R. Stiefelhagen</div><div id="ref-id-sbref0032" class="title text-m">Neural network-based head pose estimation and multi-view fusion</div></div><div class="host u-font-sans">1st International Evaluation Conference on Classification of Events, Activities and Relationships (2007), pp. 291-298</div><div class="ReferenceLinks u-font-sans"><span class="link lazy-third-party-pdf-link"><span></span></span><a class="anchor link anchor-primary" href="https://doi.org/10.1007/978-3-540-69568-4_26" target="_blank" rel="noopener noreferrer" aria-describedby="ref-id-sbref0032"><span class="anchor-text-container"><span class="anchor-text">Crossref</span><svg focusable="false" viewBox="0 0 8 8" height="20" aria-label="Opens in new window" class="icon icon-arrow-up-right-tiny arrow-external-link"><path d="M1.12949 2.1072V1H7V6.85795H5.89111V2.90281L0.784057 8L0 7.21635L5.11902 2.1072H1.12949Z"></path></svg></span></a><a class="anchor link anchor-primary" href="https://www.scopus.com/inward/record.url?eid=2-s2.0-38049150178&amp;partnerID=10&amp;rel=R3.0.0" target="_blank" rel="noopener noreferrer" aria-describedby="ref-id-sbref0032"><span class="anchor-text-container"><span class="anchor-text">View in Scopus</span><svg focusable="false" viewBox="0 0 8 8" height="20" aria-label="Opens in new window" class="icon icon-arrow-up-right-tiny arrow-external-link"><path d="M1.12949 2.1072V1H7V6.85795H5.89111V2.90281L0.784057 8L0 7.21635L5.11902 2.1072H1.12949Z"></path></svg></span></a><a class="anchor link anchor-primary" href="https://scholar.google.com/scholar_lookup?title=Neural%20network-based%20head%20pose%20estimation%20and%20multi-view%20fusion&amp;publication_year=2007&amp;author=M.%20Voit&amp;author=K.%20Nickel&amp;author=R.%20Stiefelhagen" target="_blank" rel="noopener noreferrer" aria-describedby="ref-id-sbref0032"><span class="anchor-text-container"><span class="anchor-text">Google Scholar</span><svg focusable="false" viewBox="0 0 8 8" height="20" aria-label="Opens in new window" class="icon icon-arrow-up-right-tiny arrow-external-link"><path d="M1.12949 2.1072V1H7V6.85795H5.89111V2.90281L0.784057 8L0 7.21635L5.11902 2.1072H1.12949Z"></path></svg></span></a></div></span></li><li><span class="label u-font-sans"><a class="anchor anchor-primary" href="#bbib0037" id="ref-id-bib0037" data-aa-button="sd:product:journal:article:location=references:type=anchor:name=citation-name"><span class="anchor-text-container"><span class="anchor-text">[37]</span></span></a></span><span class="reference" id="sbref0033"><div class="contribution"><div class="authors u-font-sans">N. Gourier, J. Maisonnasse, D. Hall, J.L. Crowley</div><div id="ref-id-sbref0033" class="title text-m">Head pose estimation on low resolution images</div></div><div class="host u-font-sans">Lect. Notes Comput. Sci., 4122 (2006), pp. 270-280</div><div class="ReferenceLinks u-font-sans"><a class="anchor link anchor-primary" href="https://scholar.google.com/scholar_lookup?title=Head%20pose%20estimation%20on%20low%20resolution%20images&amp;publication_year=2006&amp;author=N.%20Gourier&amp;author=J.%20Maisonnasse&amp;author=D.%20Hall&amp;author=J.L.%20Crowley" target="_blank" rel="noopener noreferrer" aria-describedby="ref-id-sbref0033"><span class="anchor-text-container"><span class="anchor-text">Google Scholar</span><svg focusable="false" viewBox="0 0 8 8" height="20" aria-label="Opens in new window" class="icon icon-arrow-up-right-tiny arrow-external-link"><path d="M1.12949 2.1072V1H7V6.85795H5.89111V2.90281L0.784057 8L0 7.21635L5.11902 2.1072H1.12949Z"></path></svg></span></a></div></span></li><li><span class="label u-font-sans"><a class="anchor anchor-primary" href="#bbib0038" id="ref-id-bib0038" data-aa-button="sd:product:journal:article:location=references:type=anchor:name=citation-name"><span class="anchor-text-container"><span class="anchor-text">[38]</span></span></a></span><span class="reference" id="sbref0034"><div class="contribution"><div class="authors u-font-sans">D.F. Dementhon, L.S. Davis</div><div id="ref-id-sbref0034" class="title text-m">Model-based object pose in 25 lines of code</div></div><div class="host u-font-sans">Int. J. Comput. Vision, 15 (1995), pp. 123-141</div><div class="ReferenceLinks u-font-sans"><a class="anchor link anchor-primary" href="https://www.scopus.com/inward/record.url?eid=2-s2.0-0001210593&amp;partnerID=10&amp;rel=R3.0.0" target="_blank" rel="noopener noreferrer" aria-describedby="ref-id-sbref0034"><span class="anchor-text-container"><span class="anchor-text">View in Scopus</span><svg focusable="false" viewBox="0 0 8 8" height="20" aria-label="Opens in new window" class="icon icon-arrow-up-right-tiny arrow-external-link"><path d="M1.12949 2.1072V1H7V6.85795H5.89111V2.90281L0.784057 8L0 7.21635L5.11902 2.1072H1.12949Z"></path></svg></span></a><a class="anchor link anchor-primary" href="https://scholar.google.com/scholar_lookup?title=Model-based%20object%20pose%20in%2025%20lines%20of%20code&amp;publication_year=1995&amp;author=D.F.%20Dementhon&amp;author=L.S.%20Davis" target="_blank" rel="noopener noreferrer" aria-describedby="ref-id-sbref0034"><span class="anchor-text-container"><span class="anchor-text">Google Scholar</span><svg focusable="false" viewBox="0 0 8 8" height="20" aria-label="Opens in new window" class="icon icon-arrow-up-right-tiny arrow-external-link"><path d="M1.12949 2.1072V1H7V6.85795H5.89111V2.90281L0.784057 8L0 7.21635L5.11902 2.1072H1.12949Z"></path></svg></span></a></div></span></li><li><span class="label u-font-sans"><a class="anchor anchor-primary" href="#bbib0039" id="ref-id-bib0039" data-aa-button="sd:product:journal:article:location=references:type=anchor:name=citation-name"><span class="anchor-text-container"><span class="anchor-text">[39]</span></span></a></span><span class="reference" id="sbref0035"><div class="contribution"><div class="authors u-font-sans">J. Aghajanian, S. Prince</div><div id="ref-id-sbref0035" class="title text-m">Face pose estimation in uncontrolled environments.</div></div><div class="host u-font-sans">BMVC, 1 (2009), p. 3</div><div class="ReferenceLinks u-font-sans"><a class="anchor link anchor-primary" href="https://scholar.google.com/scholar_lookup?title=Face%20pose%20estimation%20in%20uncontrolled%20environments.&amp;publication_year=2009&amp;author=J.%20Aghajanian&amp;author=S.%20Prince" target="_blank" rel="noopener noreferrer" aria-describedby="ref-id-sbref0035"><span class="anchor-text-container"><span class="anchor-text">Google Scholar</span><svg focusable="false" viewBox="0 0 8 8" height="20" aria-label="Opens in new window" class="icon icon-arrow-up-right-tiny arrow-external-link"><path d="M1.12949 2.1072V1H7V6.85795H5.89111V2.90281L0.784057 8L0 7.21635L5.11902 2.1072H1.12949Z"></path></svg></span></a></div></span></li><li><span class="label u-font-sans"><a class="anchor anchor-primary" href="#bbib0040" id="ref-id-bib0040" data-aa-button="sd:product:journal:article:location=references:type=anchor:name=citation-name"><span class="anchor-text-container"><span class="anchor-text">[40]</span></span></a></span><span class="reference" id="sbref0038a"><div class="contribution"><div class="authors u-font-sans">C. Hegde, A.C. Sankaranarayanan, R.G. Baraniuk</div><div id="ref-id-sbref0038a" class="title text-m">Learning manifolds in the wild</div></div><div class="host u-font-sans">J. Mach. Learn. Res., 1 (2) (2012), p. 4</div><div class="ReferenceLinks u-font-sans"><a class="anchor link anchor-primary" href="https://scholar.google.com/scholar_lookup?title=Learning%20manifolds%20in%20the%20wild&amp;publication_year=2012&amp;author=C.%20Hegde&amp;author=A.C.%20Sankaranarayanan&amp;author=R.G.%20Baraniuk" target="_blank" rel="noopener noreferrer" aria-describedby="ref-id-sbref0038a"><span class="anchor-text-container"><span class="anchor-text">Google Scholar</span><svg focusable="false" viewBox="0 0 8 8" height="20" aria-label="Opens in new window" class="icon icon-arrow-up-right-tiny arrow-external-link"><path d="M1.12949 2.1072V1H7V6.85795H5.89111V2.90281L0.784057 8L0 7.21635L5.11902 2.1072H1.12949Z"></path></svg></span></a></div></span></li><li><span class="label u-font-sans"><a class="anchor anchor-primary" href="#bbib0041" id="ref-id-bib0041" data-aa-button="sd:product:journal:article:location=references:type=anchor:name=citation-name"><span class="anchor-text-container"><span class="anchor-text">[41]</span></span></a></span><span class="reference" id="sbref0036"><div class="contribution"><div class="authors u-font-sans">M. Torki, A. Elgammal</div><div id="ref-id-sbref0036" class="title text-m">Regression from local features for viewpoint and pose estimation</div></div><div class="host u-font-sans">2011 International Conference on Computer Vision, IEEE (2011), pp. 2603-2610</div><div class="ReferenceLinks u-font-sans"><span class="link lazy-third-party-pdf-link"><span></span></span><a class="anchor link anchor-primary" href="https://doi.org/10.1109/ICCV.2011.6126549" target="_blank" rel="noopener noreferrer" aria-describedby="ref-id-sbref0036"><span class="anchor-text-container"><span class="anchor-text">Crossref</span><svg focusable="false" viewBox="0 0 8 8" height="20" aria-label="Opens in new window" class="icon icon-arrow-up-right-tiny arrow-external-link"><path d="M1.12949 2.1072V1H7V6.85795H5.89111V2.90281L0.784057 8L0 7.21635L5.11902 2.1072H1.12949Z"></path></svg></span></a><a class="anchor link anchor-primary" href="https://www.scopus.com/inward/record.url?eid=2-s2.0-84856635908&amp;partnerID=10&amp;rel=R3.0.0" target="_blank" rel="noopener noreferrer" aria-describedby="ref-id-sbref0036"><span class="anchor-text-container"><span class="anchor-text">View in Scopus</span><svg focusable="false" viewBox="0 0 8 8" height="20" aria-label="Opens in new window" class="icon icon-arrow-up-right-tiny arrow-external-link"><path d="M1.12949 2.1072V1H7V6.85795H5.89111V2.90281L0.784057 8L0 7.21635L5.11902 2.1072H1.12949Z"></path></svg></span></a><a class="anchor link anchor-primary" href="https://scholar.google.com/scholar_lookup?title=Regression%20from%20local%20features%20for%20viewpoint%20and%20pose%20estimation&amp;publication_year=2011&amp;author=M.%20Torki&amp;author=A.%20Elgammal" target="_blank" rel="noopener noreferrer" aria-describedby="ref-id-sbref0036"><span class="anchor-text-container"><span class="anchor-text">Google Scholar</span><svg focusable="false" viewBox="0 0 8 8" height="20" aria-label="Opens in new window" class="icon icon-arrow-up-right-tiny arrow-external-link"><path d="M1.12949 2.1072V1H7V6.85795H5.89111V2.90281L0.784057 8L0 7.21635L5.11902 2.1072H1.12949Z"></path></svg></span></a></div></span></li><li><span class="label u-font-sans"><a class="anchor anchor-primary" href="#bbib0042" id="ref-id-bib0042" data-aa-button="sd:product:journal:article:location=references:type=anchor:name=citation-name"><span class="anchor-text-container"><span class="anchor-text">[42]</span></span></a></span><span class="reference" id="othref0006"><div class="other-ref"><span>Itseez, Open source computer vision library, 2015, (<a class="anchor anchor-primary" href="https://github.com/itseez/opencv" target="_blank"><span class="anchor-text-container"><span class="anchor-text">https://github.com/itseez/opencv</span><svg focusable="false" viewBox="0 0 8 8" height="20" aria-label="Opens in new window" class="icon icon-arrow-up-right-tiny arrow-external-link"><path d="M1.12949 2.1072V1H7V6.85795H5.89111V2.90281L0.784057 8L0 7.21635L5.11902 2.1072H1.12949Z"></path></svg></span></a>).</span></div><div class="ReferenceLinks u-font-sans"><a class="anchor link anchor-primary" href="https://scholar.google.com/scholar?q=Itseez%2C%20Open%20source%20computer%20vision%20library%2C%202015%2C%20(https%3A%2F%2Fgithub.com%2Fitseez%2Fopencv)." target="_blank" rel="noopener noreferrer"><span class="anchor-text-container"><span class="anchor-text">Google Scholar</span><svg focusable="false" viewBox="0 0 8 8" height="20" aria-label="Opens in new window" class="icon icon-arrow-up-right-tiny arrow-external-link"><path d="M1.12949 2.1072V1H7V6.85795H5.89111V2.90281L0.784057 8L0 7.21635L5.11902 2.1072H1.12949Z"></path></svg></span></a></div></span></li><li><span class="label u-font-sans"><a class="anchor anchor-primary" href="#bbib0043" id="ref-id-bib0043" data-aa-button="sd:product:journal:article:location=references:type=anchor:name=citation-name"><span class="anchor-text-container"><span class="anchor-text">[43]</span></span></a></span><span class="reference" id="sbref0037"><div class="contribution"><div class="authors u-font-sans">P. Viola, M. Jones</div><div id="ref-id-sbref0037" class="title text-m">Rapid object detection using a boosted cascade of simple features</div></div><div class="host u-font-sans">Computer Vision and Pattern Recognition, 2001. CVPR 2001. Proceedings of the 2001 IEEE Computer Society Conference on, 1, IEEE (2001), pp. I-511</div><div class="ReferenceLinks u-font-sans"><a class="anchor link anchor-primary" href="https://scholar.google.com/scholar_lookup?title=Rapid%20object%20detection%20using%20a%20boosted%20cascade%20of%20simple%20features&amp;publication_year=2001&amp;author=P.%20Viola&amp;author=M.%20Jones" target="_blank" rel="noopener noreferrer" aria-describedby="ref-id-sbref0037"><span class="anchor-text-container"><span class="anchor-text">Google Scholar</span><svg focusable="false" viewBox="0 0 8 8" height="20" aria-label="Opens in new window" class="icon icon-arrow-up-right-tiny arrow-external-link"><path d="M1.12949 2.1072V1H7V6.85795H5.89111V2.90281L0.784057 8L0 7.21635L5.11902 2.1072H1.12949Z"></path></svg></span></a></div></span></li><li><span class="label u-font-sans"><a class="anchor anchor-primary" href="#bbib0044" id="ref-id-bib0044" data-aa-button="sd:product:journal:article:location=references:type=anchor:name=citation-name"><span class="anchor-text-container"><span class="anchor-text">[44]</span></span></a></span><span class="reference" id="sbref0038"><div class="contribution"><div class="authors u-font-sans">D. Ribeiro, J.C. Nascimento, A. Bernardino, G. Carneiro</div><div id="ref-id-sbref0038" class="title text-m">Improving the performance of pedestrian detectors using convolutional learning</div></div><div class="host u-font-sans">Pattern Recognit., 61 (2017), pp. 641-649</div><div class="ReferenceLinks u-font-sans"><a class="anchor pdf link anchor-primary anchor-icon-left anchor-with-icon" href="/science/article/pii/S003132031630111X/pdfft?md5=362280e0892d04b4de6c1949c4137453&amp;pid=1-s2.0-S003132031630111X-main.pdf" target="_blank" rel="nofollow" aria-describedby="ref-id-sbref0038"><svg focusable="false" viewBox="0 0 35 32" height="20" class="icon icon-pdf-multicolor"><path d="M7 .362h17.875l6.763 6.1V31.64H6.948V16z" stroke="#000" stroke-width=".703" fill="#fff"></path><path d="M.167 2.592H22.39V9.72H.166z" fill="#da0000"></path><path fill="#fff9f9" d="M5.97 3.638h1.62c1.053 0 1.483.677 1.488 1.564.008.96-.6 1.564-1.492 1.564h-.644v1.66h-.977V3.64m.977.897v1.34h.542c.27 0 .596-.068.596-.673-.002-.6-.32-.667-.596-.667h-.542m3.8.036v2.92h.35c.933 0 1.223-.448 1.228-1.462.008-1.06-.316-1.45-1.23-1.45h-.347m-.977-.94h1.03c1.68 0 2.523.586 2.534 2.39.01 1.688-.607 2.4-2.534 2.4h-1.03V3.64m4.305 0h2.63v.934h-1.657v.894H16.6V6.4h-1.56v2.026h-.97V3.638"></path><path d="M19.462 13.46c.348 4.274-6.59 16.72-8.508 15.792-1.82-.85 1.53-3.317 2.92-4.366-2.864.894-5.394 3.252-3.837 3.93 2.113.895 7.048-9.25 9.41-15.394zM14.32 24.874c4.767-1.526 14.735-2.974 15.152-1.407.824-3.157-13.72-.37-15.153 1.407zm5.28-5.043c2.31 3.237 9.816 7.498 9.788 3.82-.306 2.046-6.66-1.097-8.925-4.164-4.087-5.534-2.39-8.772-1.682-8.732.917.047 1.074 1.307.67 2.442-.173-1.406-.58-2.44-1.224-2.415-1.835.067-1.905 4.46 1.37 9.065z" fill="#f91d0a"></path></svg><span class="anchor-text-container"><span class="anchor-text">View PDF</span></span></a><a class="anchor link anchor-primary" href="/science/article/pii/S003132031630111X" aria-describedby="ref-id-sbref0038"><span class="anchor-text-container"><span class="anchor-text">View article</span></span></a><a class="anchor link anchor-primary" href="https://www.scopus.com/inward/record.url?eid=2-s2.0-84992445409&amp;partnerID=10&amp;rel=R3.0.0" target="_blank" rel="noopener noreferrer" aria-describedby="ref-id-sbref0038"><span class="anchor-text-container"><span class="anchor-text">View in Scopus</span><svg focusable="false" viewBox="0 0 8 8" height="20" aria-label="Opens in new window" class="icon icon-arrow-up-right-tiny arrow-external-link"><path d="M1.12949 2.1072V1H7V6.85795H5.89111V2.90281L0.784057 8L0 7.21635L5.11902 2.1072H1.12949Z"></path></svg></span></a><a class="anchor link anchor-primary" href="https://scholar.google.com/scholar_lookup?title=Improving%20the%20performance%20of%20pedestrian%20detectors%20using%20convolutional%20learning&amp;publication_year=2017&amp;author=D.%20Ribeiro&amp;author=J.C.%20Nascimento&amp;author=A.%20Bernardino&amp;author=G.%20Carneiro" target="_blank" rel="noopener noreferrer" aria-describedby="ref-id-sbref0038"><span class="anchor-text-container"><span class="anchor-text">Google Scholar</span><svg focusable="false" viewBox="0 0 8 8" height="20" aria-label="Opens in new window" class="icon icon-arrow-up-right-tiny arrow-external-link"><path d="M1.12949 2.1072V1H7V6.85795H5.89111V2.90281L0.784057 8L0 7.21635L5.11902 2.1072H1.12949Z"></path></svg></span></a></div></span></li><li><span class="label u-font-sans"><a class="anchor anchor-primary" href="#bbib0045" id="ref-id-bib0045" data-aa-button="sd:product:journal:article:location=references:type=anchor:name=citation-name"><span class="anchor-text-container"><span class="anchor-text">[45]</span></span></a></span><span class="reference" id="sbref0039"><div class="contribution"><div class="authors u-font-sans">W. Yang, L. Jin, D. Tao, Z. Xie, Z. Feng</div><div id="ref-id-sbref0039" class="title text-m">Dropsample: a new training method to enhance deep convolutional neural networks for large-scale unconstrained handwritten chinese character recognition</div></div><div class="host u-font-sans">Pattern Recognit., 58 (2016), pp. 190-203</div><div class="ReferenceLinks u-font-sans"><a class="anchor pdf link anchor-primary anchor-icon-left anchor-with-icon" href="/science/article/pii/S0031320316300401/pdfft?md5=ea8af2fd429ce2f90636246e524b120a&amp;pid=1-s2.0-S0031320316300401-main.pdf" target="_blank" rel="nofollow" aria-describedby="ref-id-sbref0039"><svg focusable="false" viewBox="0 0 35 32" height="20" class="icon icon-pdf-multicolor"><path d="M7 .362h17.875l6.763 6.1V31.64H6.948V16z" stroke="#000" stroke-width=".703" fill="#fff"></path><path d="M.167 2.592H22.39V9.72H.166z" fill="#da0000"></path><path fill="#fff9f9" d="M5.97 3.638h1.62c1.053 0 1.483.677 1.488 1.564.008.96-.6 1.564-1.492 1.564h-.644v1.66h-.977V3.64m.977.897v1.34h.542c.27 0 .596-.068.596-.673-.002-.6-.32-.667-.596-.667h-.542m3.8.036v2.92h.35c.933 0 1.223-.448 1.228-1.462.008-1.06-.316-1.45-1.23-1.45h-.347m-.977-.94h1.03c1.68 0 2.523.586 2.534 2.39.01 1.688-.607 2.4-2.534 2.4h-1.03V3.64m4.305 0h2.63v.934h-1.657v.894H16.6V6.4h-1.56v2.026h-.97V3.638"></path><path d="M19.462 13.46c.348 4.274-6.59 16.72-8.508 15.792-1.82-.85 1.53-3.317 2.92-4.366-2.864.894-5.394 3.252-3.837 3.93 2.113.895 7.048-9.25 9.41-15.394zM14.32 24.874c4.767-1.526 14.735-2.974 15.152-1.407.824-3.157-13.72-.37-15.153 1.407zm5.28-5.043c2.31 3.237 9.816 7.498 9.788 3.82-.306 2.046-6.66-1.097-8.925-4.164-4.087-5.534-2.39-8.772-1.682-8.732.917.047 1.074 1.307.67 2.442-.173-1.406-.58-2.44-1.224-2.415-1.835.067-1.905 4.46 1.37 9.065z" fill="#f91d0a"></path></svg><span class="anchor-text-container"><span class="anchor-text">View PDF</span></span></a><a class="anchor link anchor-primary" href="/science/article/pii/S0031320316300401" aria-describedby="ref-id-sbref0039"><span class="anchor-text-container"><span class="anchor-text">View article</span></span></a><a class="anchor link anchor-primary" href="https://www.scopus.com/inward/record.url?eid=2-s2.0-84969940648&amp;partnerID=10&amp;rel=R3.0.0" target="_blank" rel="noopener noreferrer" aria-describedby="ref-id-sbref0039"><span class="anchor-text-container"><span class="anchor-text">View in Scopus</span><svg focusable="false" viewBox="0 0 8 8" height="20" aria-label="Opens in new window" class="icon icon-arrow-up-right-tiny arrow-external-link"><path d="M1.12949 2.1072V1H7V6.85795H5.89111V2.90281L0.784057 8L0 7.21635L5.11902 2.1072H1.12949Z"></path></svg></span></a><a class="anchor link anchor-primary" href="https://scholar.google.com/scholar_lookup?title=Dropsample%3A%20a%20new%20training%20method%20to%20enhance%20deep%20convolutional%20neural%20networks%20for%20large-scale%20unconstrained%20handwritten%20chinese%20character%20recognition&amp;publication_year=2016&amp;author=W.%20Yang&amp;author=L.%20Jin&amp;author=D.%20Tao&amp;author=Z.%20Xie&amp;author=Z.%20Feng" target="_blank" rel="noopener noreferrer" aria-describedby="ref-id-sbref0039"><span class="anchor-text-container"><span class="anchor-text">Google Scholar</span><svg focusable="false" viewBox="0 0 8 8" height="20" aria-label="Opens in new window" class="icon icon-arrow-up-right-tiny arrow-external-link"><path d="M1.12949 2.1072V1H7V6.85795H5.89111V2.90281L0.784057 8L0 7.21635L5.11902 2.1072H1.12949Z"></path></svg></span></a></div></span></li><li><span class="label u-font-sans"><a class="anchor anchor-primary" href="#bbib0046" id="ref-id-bib0046" data-aa-button="sd:product:journal:article:location=references:type=anchor:name=citation-name"><span class="anchor-text-container"><span class="anchor-text">[46]</span></span></a></span><span class="reference" id="sbref0040"><div class="contribution"><div class="authors u-font-sans">E. Ricci, J.-M. Odobez</div><div id="ref-id-sbref0040" class="title text-m">Learning large margin likelihoods for realtime head pose tracking</div></div><div class="host u-font-sans">16th IEEE International Conference on Image Processing (ICIP), IEEE, Cairo (2009), pp. 2593-2596</div><div class="ReferenceLinks u-font-sans"><span class="link lazy-third-party-pdf-link"><span></span></span><a class="anchor link anchor-primary" href="https://doi.org/10.1109/ICIP.2009.5413994" target="_blank" rel="noopener noreferrer" aria-describedby="ref-id-sbref0040"><span class="anchor-text-container"><span class="anchor-text">Crossref</span><svg focusable="false" viewBox="0 0 8 8" height="20" aria-label="Opens in new window" class="icon icon-arrow-up-right-tiny arrow-external-link"><path d="M1.12949 2.1072V1H7V6.85795H5.89111V2.90281L0.784057 8L0 7.21635L5.11902 2.1072H1.12949Z"></path></svg></span></a><a class="anchor link anchor-primary" href="https://www.scopus.com/inward/record.url?eid=2-s2.0-77951952922&amp;partnerID=10&amp;rel=R3.0.0" target="_blank" rel="noopener noreferrer" aria-describedby="ref-id-sbref0040"><span class="anchor-text-container"><span class="anchor-text">View in Scopus</span><svg focusable="false" viewBox="0 0 8 8" height="20" aria-label="Opens in new window" class="icon icon-arrow-up-right-tiny arrow-external-link"><path d="M1.12949 2.1072V1H7V6.85795H5.89111V2.90281L0.784057 8L0 7.21635L5.11902 2.1072H1.12949Z"></path></svg></span></a><a class="anchor link anchor-primary" href="https://scholar.google.com/scholar_lookup?title=Learning%20large%20margin%20likelihoods%20for%20realtime%20head%20pose%20tracking&amp;publication_year=2009&amp;author=E.%20Ricci&amp;author=J.-M.%20Odobez" target="_blank" rel="noopener noreferrer" aria-describedby="ref-id-sbref0040"><span class="anchor-text-container"><span class="anchor-text">Google Scholar</span><svg focusable="false" viewBox="0 0 8 8" height="20" aria-label="Opens in new window" class="icon icon-arrow-up-right-tiny arrow-external-link"><path d="M1.12949 2.1072V1H7V6.85795H5.89111V2.90281L0.784057 8L0 7.21635L5.11902 2.1072H1.12949Z"></path></svg></span></a></div></span></li><li><span class="label u-font-sans"><a class="anchor anchor-primary" href="#bbib0047" id="ref-id-bib0047" data-aa-button="sd:product:journal:article:location=references:type=anchor:name=citation-name"><span class="anchor-text-container"><span class="anchor-text">[47]</span></span></a></span><span class="reference" id="sbref0041"><div class="contribution"><div class="authors u-font-sans">N. Alioua, A. Amine, M. Rziza, A. Bensrhair, D. Aboutajdine1</div><div id="ref-id-sbref0041" class="title text-m">Head pose estimation based on steerable filters and likelihood parameterized function</div></div><div class="host u-font-sans">21st European Signal Processing Conference (EUSIPCO 2013), IEEE, Marrakech (2013), pp. 1-5</div><div class="ReferenceLinks u-font-sans"><a class="anchor link anchor-primary" href="https://scholar.google.com/scholar_lookup?title=Head%20pose%20estimation%20based%20on%20steerable%20filters%20and%20likelihood%20parameterized%20function&amp;publication_year=2013&amp;author=N.%20Alioua&amp;author=A.%20Amine&amp;author=M.%20Rziza&amp;author=A.%20Bensrhair&amp;author=D.%20Aboutajdine1" target="_blank" rel="noopener noreferrer" aria-describedby="ref-id-sbref0041"><span class="anchor-text-container"><span class="anchor-text">Google Scholar</span><svg focusable="false" viewBox="0 0 8 8" height="20" aria-label="Opens in new window" class="icon icon-arrow-up-right-tiny arrow-external-link"><path d="M1.12949 2.1072V1H7V6.85795H5.89111V2.90281L0.784057 8L0 7.21635L5.11902 2.1072H1.12949Z"></path></svg></span></a></div></span></li></ol></section></section></div><div id="section-cited-by"><section aria-label="Cited by" class="ListArticles preview"><div class="PageDivider"></div><header id="citing-articles-header"><h2 class="u-h4 u-margin-l-ver u-font-serif">Cited by (188)</h2></header><div aria-describedby="citing-articles-header"><div class="citing-articles u-margin-l-bottom"><ul><li class="ListArticleItem u-margin-l-bottom"><div class="sub-heading u-margin-xs-bottom"><h3 class="u-font-serif" id="citing-articles-article-0-title"><a class="anchor anchor-primary" href="/science/article/pii/S092523122031599X"><span class="anchor-text-container"><span class="anchor-text">Anisotropic angle distribution learning for head pose estimation and attention understanding in human-computer interaction</span></span></a></h3><div>2021, Neurocomputing</div></div><div class="buttons"><button class="button-link button-link-primary button-link-icon-right" data-aa-button="sd:product:journal:article:location=citing-articles:type=view-details" aria-describedby="citing-articles-article-0-title" aria-controls="citing-articles-article-0" aria-expanded="false" type="button"><span class="button-link-text-container"><span class="button-link-text">Show abstract</span></span><svg focusable="false" viewBox="0 0 92 128" height="20" class="icon icon-navigate-down"><path d="M1 51l7-7 38 38 38-38 7 7-45 45z"></path></svg></button></div><div class="u-display-none" aria-hidden="true"><div class="abstract u-margin-xs-top u-margin-m-bottom u-font-serif" id="reference-abstract"><div class="u-margin-ver-m"><div class="u-margin-s-bottom" id="sp0010">Head pose estimation is an important way to understand human attention in the human-computer interaction. In this paper, we propose a novel anisotropic angle distribution learning (AADL) network for head pose estimation task. Firstly, two key findings are revealed as following: 1) Head pose image variations are different at the yaw and pitch directions with the same pose angle increasing on a fixed central pose; 2) With the fixed angle interval increasing, the image variations increase firstly and then decrease in yaw angle direction. Then, the <em>maximum a posterior</em> technology is employed to construct the head pose estimation network, which includes three parts, such as convolutional layer, covariance pooling layer and output layer. In the output layer, the labels are constructed as the anisotropic angle distributions on the basis of two key findings. And the anisotropic angle distributions are fitted by the 2D Gaussian-like distributions (groundtruth labels). Furthermore, the Kullback-Leibler divergence is selected to measure the predication label and the groundtruth one. The features of head pose images are perceived at the AADL-based convolutional neural network in an end-to-end manner. Experimental results demonstrate that the developed AADL-based labels have several advantages, such as robustness for head pose image missing, insensitivity for the motion blur. Moreover, the proposed method has achieved good performance compared to several state-of-the-art methods on the Pointing’04 and CAS_PEAL_R1 databases.</div></div></div></div></li><li class="ListArticleItem u-margin-l-bottom"><div class="sub-heading u-margin-xs-bottom"><h3 class="u-font-serif" id="citing-articles-article-1-title"><a class="anchor anchor-primary" href="/science/article/pii/S0031320317304120"><span class="anchor-text-container"><span class="anchor-text">Recent advances in convolutional neural networks</span></span></a></h3><div>2018, Pattern Recognition</div></div><div class="buttons"><button class="button-link button-link-primary button-link-icon-right" data-aa-button="sd:product:journal:article:location=citing-articles:type=view-details" aria-describedby="citing-articles-article-1-title" aria-controls="citing-articles-article-1" aria-expanded="false" type="button"><span class="button-link-text-container"><span class="button-link-text">Show abstract</span></span><svg focusable="false" viewBox="0 0 92 128" height="20" class="icon icon-navigate-down"><path d="M1 51l7-7 38 38 38-38 7 7-45 45z"></path></svg></button></div><div class="u-display-none" aria-hidden="true"><div class="abstract u-margin-xs-top u-margin-m-bottom u-font-serif" id="reference-abstract"><div class="u-margin-ver-m"><div class="u-margin-s-bottom" id="spara0013">In the last few years, deep learning has led to very good performance on a variety of problems, such as visual recognition, speech recognition and natural language processing. Among different types of deep neural networks, convolutional neural networks have been most extensively studied. Leveraging on the rapid growth in the amount of the annotated data and the great improvements in the strengths of graphics processor units, the research on convolutional neural networks has been emerged swiftly and achieved state-of-the-art results on various tasks. In this paper, we provide a broad survey of the recent advances in convolutional neural networks. We detailize the improvements of CNN on different aspects, including layer design, activation function, loss function, regularization, optimization and fast computation. Besides, we also introduce various applications of convolutional neural networks in computer vision, speech and natural language processing.</div></div></div></div></li><li class="ListArticleItem u-margin-l-bottom"><div class="sub-heading u-margin-xs-bottom"><h3 class="u-font-serif" id="citing-articles-article-2-title"><a class="anchor anchor-primary" href="https://doi.org/10.1109/TII.2022.3143605" target="_blank"><span class="anchor-text-container"><span class="anchor-text">ARHPE: Asymmetric Relation-Aware Representation Learning for Head Pose Estimation in Industrial Human-Computer Interaction</span><svg focusable="false" viewBox="0 0 8 8" height="20" aria-label="Opens in new window" class="icon icon-arrow-up-right-tiny arrow-external-link"><path d="M1.12949 2.1072V1H7V6.85795H5.89111V2.90281L0.784057 8L0 7.21635L5.11902 2.1072H1.12949Z"></path></svg></span></a></h3><div>2022, IEEE Transactions on Industrial Informatics</div></div><div class="buttons"></div><div class="u-display-none" aria-hidden="true"><div class="abstract u-margin-xs-top u-margin-m-bottom u-font-serif" id="reference-abstract"></div></div></li><li class="ListArticleItem u-margin-l-bottom"><div class="sub-heading u-margin-xs-bottom"><h3 class="u-font-serif" id="citing-articles-article-3-title"><a class="anchor anchor-primary" href="https://doi.org/10.1109/TMM.2018.2866770" target="_blank"><span class="anchor-text-container"><span class="anchor-text">Quatnet: Quaternion-based head pose estimation with multiregression loss</span><svg focusable="false" viewBox="0 0 8 8" height="20" aria-label="Opens in new window" class="icon icon-arrow-up-right-tiny arrow-external-link"><path d="M1.12949 2.1072V1H7V6.85795H5.89111V2.90281L0.784057 8L0 7.21635L5.11902 2.1072H1.12949Z"></path></svg></span></a></h3><div>2019, IEEE Transactions on Multimedia</div></div><div class="buttons"></div><div class="u-display-none" aria-hidden="true"><div class="abstract u-margin-xs-top u-margin-m-bottom u-font-serif" id="reference-abstract"></div></div></li><li class="ListArticleItem u-margin-l-bottom"><div class="sub-heading u-margin-xs-bottom"><h3 class="u-font-serif" id="citing-articles-article-4-title"><a class="anchor anchor-primary" href="https://doi.org/10.1007/s11263-018-1097-z" target="_blank"><span class="anchor-text-container"><span class="anchor-text">Facial Landmark Detection: A Literature Survey</span><svg focusable="false" viewBox="0 0 8 8" height="20" aria-label="Opens in new window" class="icon icon-arrow-up-right-tiny arrow-external-link"><path d="M1.12949 2.1072V1H7V6.85795H5.89111V2.90281L0.784057 8L0 7.21635L5.11902 2.1072H1.12949Z"></path></svg></span></a></h3><div>2019, International Journal of Computer Vision</div></div><div class="buttons"></div><div class="u-display-none" aria-hidden="true"><div class="abstract u-margin-xs-top u-margin-m-bottom u-font-serif" id="reference-abstract"></div></div></li><li class="ListArticleItem u-margin-l-bottom"><div class="sub-heading u-margin-xs-bottom"><h3 class="u-font-serif" id="citing-articles-article-5-title"><a class="anchor anchor-primary" href="https://doi.org/10.1109/CVPRW.2018.00281" target="_blank"><span class="anchor-text-container"><span class="anchor-text">Fine-grained head pose estimation without keypoints</span><svg focusable="false" viewBox="0 0 8 8" height="20" aria-label="Opens in new window" class="icon icon-arrow-up-right-tiny arrow-external-link"><path d="M1.12949 2.1072V1H7V6.85795H5.89111V2.90281L0.784057 8L0 7.21635L5.11902 2.1072H1.12949Z"></path></svg></span></a></h3><div>2018, IEEE Computer Society Conference on Computer Vision and Pattern Recognition Workshops</div></div><div class="buttons"></div><div class="u-display-none" aria-hidden="true"><div class="abstract u-margin-xs-top u-margin-m-bottom u-font-serif" id="reference-abstract"></div></div></li></ul><a class="button-alternative button-alternative-secondary large-alternative button-alternative-icon-left" href="http://www.scopus.com/scopus/inward/citedby.url?partnerID=10&amp;rel=3.0.0&amp;eid=2-s2.0-85023196509&amp;md5=ee7b92606ef7ca8384f93a5ca435314" target="_blank" id="citing-articles-view-all-btn"><svg focusable="false" viewBox="0 0 54 128" height="20" class="icon icon-navigate-right"><path d="M1 99l38-38L1 23l7-7 45 45-45 45z"></path></svg><span class="button-alternative-text-container"><span class="button-alternative-text">View all citing articles on Scopus</span></span><svg focusable="false" viewBox="0 0 8 8" height="20" aria-label="Opens in new window" class="icon icon-arrow-up-right-tiny arrow-external-link"><path d="M1.12949 2.1072V1H7V6.85795H5.89111V2.90281L0.784057 8L0 7.21635L5.11902 2.1072H1.12949Z"></path></svg></a></div></div></section></div><div class="article-biography" id="b1"><div class="article-biography-text"><div class="u-margin-s-bottom" id="spara0001"><strong>Massimiliano Patacchiola</strong> attended his studies at La Sapienza University (Rome). After his internship at the Laboratory of Artificial Life and Robotics (Rome), in 2012 he started working as robotics engineer at Eurolink Systems group (Rome), where he spent more than two years creating algorithms and designing systems for the control of UGV (Unmanned Ground Vehicle) and UAV (Unmanned Aerial Vehicle). In 2015 he started a PhD program in robotics and computational modelling at Plymouth University. He is currently designing the social skills of different humanoid robots.</div></div></div><div class="article-biography" id="b2"><div class="article-biography-text"><div class="u-margin-s-bottom" id="spara0002"><strong>Angelo Cangelosi</strong> is professor of Artificial Intelligence and Cognition and the Director of the Centre for Robotics and Neural Systems at Plymouth University (UK). Cangelosi studied psychology and cognitive science at the Universities of Rome La Sapienza and at the University of Genoa, and was visiting scholar at the University of California San Diego and the University of Southampton. Cangelosi’s main research expertise is on language grounding and embodiment in humanoid robots, developmental robotics, human-robot interaction, and on the application of neuromorphic systems for robot learning.</div></div></div><div class="Footnotes text-xs"><dl class="footnote"><dt class="footnote-label"><a class="anchor u-padding-s-hor u-padding-xs u-display-inline-block anchor-primary" href="#bfn0001"><span class="anchor-text-container"><span class="anchor-text"><sup>1</sup></span></span></a></dt><dd class="footnote-detail u-padding-xs-top"><div class="u-margin-s-bottom" id="cenotep0001"><a class="anchor anchor-primary" href="https://github.com/mpatacchiola/deepgaze" target="_blank"><span class="anchor-text-container"><span class="anchor-text">https://github.com/mpatacchiola/deepgaze</span><svg focusable="false" viewBox="0 0 8 8" height="20" aria-label="Opens in new window" class="icon icon-arrow-up-right-tiny arrow-external-link"><path d="M1.12949 2.1072V1H7V6.85795H5.89111V2.90281L0.784057 8L0 7.21635L5.11902 2.1072H1.12949Z"></path></svg></span></a>.</div></dd></dl></div><a class="anchor abstract-link anchor-primary" href="/science/article/abs/pii/S0031320317302327"><span class="anchor-text-container"><span class="anchor-text">View Abstract</span></span></a><div class="Copyright"><span class="copyright-line">© 2017 Elsevier Ltd. All rights reserved.</span></div></article><div class="u-display-block-from-md col-lg-6 col-md-8 pad-right u-padding-s-top"><aside class="RelatedContent u-clr-grey8" aria-label="Related content"><section class="RelatedContentPanel u-margin-s-bottom"><header id="recommended-articles-header" class="related-content-panel-header u-margin-s-bottom"><button class="button-link button-link-secondary related-content-panel-toggle is-up button-link-icon-right button-link-has-colored-icon" aria-expanded="true" data-aa-button="sd:product:journal:article:location=recommended-articles:type=close" type="button"><span class="button-link-text-container"><span class="button-link-text"><h2 class="section-title u-h4"><span class="related-content-panel-title-text">Recommended articles</span></h2></span></span><svg focusable="false" viewBox="0 0 92 128" height="20" class="icon icon-navigate-down"><path d="M1 51l7-7 38 38 38-38 7 7-45 45z"></path></svg></button></header><div class="" aria-hidden="false" aria-describedby="recommended-articles-header"><div id="recommended-articles" class="text-xs"><ul><li class="RelatedContentPanelItem u-display-block"><div class="sub-heading u-padding-xs-bottom"><h3 class="related-content-panel-list-entry-outline-padding text-s u-font-serif" id="recommended-articles-article0-title"><a class="anchor u-clamp-2-lines anchor-primary" href="/science/article/pii/S2405896315027913" title="Flocking Analysis and Comparison in Simplex Multi-Agent Systems under Matrix-Weighting Hölder Norms"><span class="anchor-text-container"><span class="anchor-text"><span>Flocking Analysis and Comparison in Simplex Multi-Agent Systems under Matrix-Weighting Hölder Norms</span></span></span></a></h3><div class="article-source u-clr-grey6"><div class="source">IFAC-PapersOnLine, Volume 48, Issue 28, 2015, pp. 438-443</div></div><div class="authors"><span>J.</span> <span>Jhang</span>, …, <span>X.B.</span> <span>Lu</span></div></div><div class="buttons"><a class="anchor anchor-primary anchor-icon-left anchor-with-icon" href="/science/article/pii/S2405896315027913/pdf?md5=32b766f1e8a1ebda73031398eae152f2&amp;pid=1-s2.0-S2405896315027913-main.pdf" target="_blank" rel="nofollow" aria-describedby="recommended-articles-article0-title"><svg focusable="false" viewBox="0 0 35 32" height="20" class="icon icon-pdf-multicolor"><path d="M7 .362h17.875l6.763 6.1V31.64H6.948V16z" stroke="#000" stroke-width=".703" fill="#fff"></path><path d="M.167 2.592H22.39V9.72H.166z" fill="#da0000"></path><path fill="#fff9f9" d="M5.97 3.638h1.62c1.053 0 1.483.677 1.488 1.564.008.96-.6 1.564-1.492 1.564h-.644v1.66h-.977V3.64m.977.897v1.34h.542c.27 0 .596-.068.596-.673-.002-.6-.32-.667-.596-.667h-.542m3.8.036v2.92h.35c.933 0 1.223-.448 1.228-1.462.008-1.06-.316-1.45-1.23-1.45h-.347m-.977-.94h1.03c1.68 0 2.523.586 2.534 2.39.01 1.688-.607 2.4-2.534 2.4h-1.03V3.64m4.305 0h2.63v.934h-1.657v.894H16.6V6.4h-1.56v2.026h-.97V3.638"></path><path d="M19.462 13.46c.348 4.274-6.59 16.72-8.508 15.792-1.82-.85 1.53-3.317 2.92-4.366-2.864.894-5.394 3.252-3.837 3.93 2.113.895 7.048-9.25 9.41-15.394zM14.32 24.874c4.767-1.526 14.735-2.974 15.152-1.407.824-3.157-13.72-.37-15.153 1.407zm5.28-5.043c2.31 3.237 9.816 7.498 9.788 3.82-.306 2.046-6.66-1.097-8.925-4.164-4.087-5.534-2.39-8.772-1.682-8.732.917.047 1.074 1.307.67 2.442-.173-1.406-.58-2.44-1.224-2.415-1.835.067-1.905 4.46 1.37 9.065z" fill="#f91d0a"></path></svg><span class="anchor-text-container"><span class="anchor-text">View PDF</span></span></a></div></li><li class="RelatedContentPanelItem u-display-block"><div class="sub-heading u-padding-xs-bottom"><h3 class="related-content-panel-list-entry-outline-padding text-s u-font-serif" id="recommended-articles-article1-title"><a class="anchor u-clamp-2-lines anchor-primary" href="/science/article/pii/S2405896317300794" title="Controllable Graphs with Small Sums of Diameters and Maximum Vertex Degrees"><span class="anchor-text-container"><span class="anchor-text"><span>Controllable Graphs with Small Sums of Diameters and Maximum Vertex Degrees</span></span></span></a></h3><div class="article-source u-clr-grey6"><div class="source">IFAC-PapersOnLine, Volume 50, Issue 1, 2017, pp. 2517-2522</div></div><div class="authors"><span>Shun-Pin</span> <span>Hsu</span></div></div><div class="buttons"><a class="anchor anchor-primary anchor-icon-left anchor-with-icon" href="/science/article/pii/S2405896317300794/pdf?md5=6c71bdd7190495b97986d093f0ecbc95&amp;pid=1-s2.0-S2405896317300794-main.pdf" target="_blank" rel="nofollow" aria-describedby="recommended-articles-article1-title"><svg focusable="false" viewBox="0 0 35 32" height="20" class="icon icon-pdf-multicolor"><path d="M7 .362h17.875l6.763 6.1V31.64H6.948V16z" stroke="#000" stroke-width=".703" fill="#fff"></path><path d="M.167 2.592H22.39V9.72H.166z" fill="#da0000"></path><path fill="#fff9f9" d="M5.97 3.638h1.62c1.053 0 1.483.677 1.488 1.564.008.96-.6 1.564-1.492 1.564h-.644v1.66h-.977V3.64m.977.897v1.34h.542c.27 0 .596-.068.596-.673-.002-.6-.32-.667-.596-.667h-.542m3.8.036v2.92h.35c.933 0 1.223-.448 1.228-1.462.008-1.06-.316-1.45-1.23-1.45h-.347m-.977-.94h1.03c1.68 0 2.523.586 2.534 2.39.01 1.688-.607 2.4-2.534 2.4h-1.03V3.64m4.305 0h2.63v.934h-1.657v.894H16.6V6.4h-1.56v2.026h-.97V3.638"></path><path d="M19.462 13.46c.348 4.274-6.59 16.72-8.508 15.792-1.82-.85 1.53-3.317 2.92-4.366-2.864.894-5.394 3.252-3.837 3.93 2.113.895 7.048-9.25 9.41-15.394zM14.32 24.874c4.767-1.526 14.735-2.974 15.152-1.407.824-3.157-13.72-.37-15.153 1.407zm5.28-5.043c2.31 3.237 9.816 7.498 9.788 3.82-.306 2.046-6.66-1.097-8.925-4.164-4.087-5.534-2.39-8.772-1.682-8.732.917.047 1.074 1.307.67 2.442-.173-1.406-.58-2.44-1.224-2.415-1.835.067-1.905 4.46 1.37 9.065z" fill="#f91d0a"></path></svg><span class="anchor-text-container"><span class="anchor-text">View PDF</span></span></a></div></li><li class="RelatedContentPanelItem u-display-block"><div class="sub-heading u-padding-xs-bottom"><h3 class="related-content-panel-list-entry-outline-padding text-s u-font-serif" id="recommended-articles-article2-title"><a class="anchor u-clamp-2-lines anchor-primary" href="/science/article/pii/S2405896315029237" title="On estimation of approximate inverse models of block-oriented systems"><span class="anchor-text-container"><span class="anchor-text"><span>On estimation of approximate inverse models of block-oriented systems</span></span></span></a></h3><div class="article-source u-clr-grey6"><div class="source">IFAC-PapersOnLine, Volume 48, Issue 28, 2015, pp. 1226-1231</div></div><div class="authors"><span>Ylva</span> <span>Jung</span>, <span>Martin</span> <span>Enqvist</span></div></div><div class="buttons"><a class="anchor anchor-primary anchor-icon-left anchor-with-icon" href="/science/article/pii/S2405896315029237/pdf?md5=59f21d5d9d50bd145e45aa3a8183b2af&amp;pid=1-s2.0-S2405896315029237-main.pdf" target="_blank" rel="nofollow" aria-describedby="recommended-articles-article2-title"><svg focusable="false" viewBox="0 0 35 32" height="20" class="icon icon-pdf-multicolor"><path d="M7 .362h17.875l6.763 6.1V31.64H6.948V16z" stroke="#000" stroke-width=".703" fill="#fff"></path><path d="M.167 2.592H22.39V9.72H.166z" fill="#da0000"></path><path fill="#fff9f9" d="M5.97 3.638h1.62c1.053 0 1.483.677 1.488 1.564.008.96-.6 1.564-1.492 1.564h-.644v1.66h-.977V3.64m.977.897v1.34h.542c.27 0 .596-.068.596-.673-.002-.6-.32-.667-.596-.667h-.542m3.8.036v2.92h.35c.933 0 1.223-.448 1.228-1.462.008-1.06-.316-1.45-1.23-1.45h-.347m-.977-.94h1.03c1.68 0 2.523.586 2.534 2.39.01 1.688-.607 2.4-2.534 2.4h-1.03V3.64m4.305 0h2.63v.934h-1.657v.894H16.6V6.4h-1.56v2.026h-.97V3.638"></path><path d="M19.462 13.46c.348 4.274-6.59 16.72-8.508 15.792-1.82-.85 1.53-3.317 2.92-4.366-2.864.894-5.394 3.252-3.837 3.93 2.113.895 7.048-9.25 9.41-15.394zM14.32 24.874c4.767-1.526 14.735-2.974 15.152-1.407.824-3.157-13.72-.37-15.153 1.407zm5.28-5.043c2.31 3.237 9.816 7.498 9.788 3.82-.306 2.046-6.66-1.097-8.925-4.164-4.087-5.534-2.39-8.772-1.682-8.732.917.047 1.074 1.307.67 2.442-.173-1.406-.58-2.44-1.224-2.415-1.835.067-1.905 4.46 1.37 9.065z" fill="#f91d0a"></path></svg><span class="anchor-text-container"><span class="anchor-text">View PDF</span></span></a></div></li><li class="RelatedContentPanelItem u-display-none"><div class="sub-heading u-padding-xs-bottom"><h3 class="related-content-panel-list-entry-outline-padding text-s u-font-serif" id="recommended-articles-article3-title"><a class="anchor u-clamp-2-lines anchor-primary" href="/science/article/pii/S1875389217300068" title="The Magnification of Atomic Lines Intensity Originated by laser Breakdown in Ultrasound Field"><span class="anchor-text-container"><span class="anchor-text"><span>The Magnification of Atomic Lines Intensity Originated by laser Breakdown in Ultrasound Field</span></span></span></a></h3><div class="article-source u-clr-grey6"><div class="source">Physics Procedia, Volume 86, 2017, pp. 147-151</div></div><div class="authors"><span>A.V.</span> <span>Bulanov</span>, <span>I.G.</span> <span>Nagorny</span></div></div><div class="buttons"><a class="anchor anchor-primary anchor-icon-left anchor-with-icon" href="/science/article/pii/S1875389217300068/pdf?md5=10dd63cf46c39ce69a2edf5d3563f6ad&amp;pid=1-s2.0-S1875389217300068-main.pdf" target="_blank" rel="nofollow" aria-describedby="recommended-articles-article3-title"><svg focusable="false" viewBox="0 0 35 32" height="20" class="icon icon-pdf-multicolor"><path d="M7 .362h17.875l6.763 6.1V31.64H6.948V16z" stroke="#000" stroke-width=".703" fill="#fff"></path><path d="M.167 2.592H22.39V9.72H.166z" fill="#da0000"></path><path fill="#fff9f9" d="M5.97 3.638h1.62c1.053 0 1.483.677 1.488 1.564.008.96-.6 1.564-1.492 1.564h-.644v1.66h-.977V3.64m.977.897v1.34h.542c.27 0 .596-.068.596-.673-.002-.6-.32-.667-.596-.667h-.542m3.8.036v2.92h.35c.933 0 1.223-.448 1.228-1.462.008-1.06-.316-1.45-1.23-1.45h-.347m-.977-.94h1.03c1.68 0 2.523.586 2.534 2.39.01 1.688-.607 2.4-2.534 2.4h-1.03V3.64m4.305 0h2.63v.934h-1.657v.894H16.6V6.4h-1.56v2.026h-.97V3.638"></path><path d="M19.462 13.46c.348 4.274-6.59 16.72-8.508 15.792-1.82-.85 1.53-3.317 2.92-4.366-2.864.894-5.394 3.252-3.837 3.93 2.113.895 7.048-9.25 9.41-15.394zM14.32 24.874c4.767-1.526 14.735-2.974 15.152-1.407.824-3.157-13.72-.37-15.153 1.407zm5.28-5.043c2.31 3.237 9.816 7.498 9.788 3.82-.306 2.046-6.66-1.097-8.925-4.164-4.087-5.534-2.39-8.772-1.682-8.732.917.047 1.074 1.307.67 2.442-.173-1.406-.58-2.44-1.224-2.415-1.835.067-1.905 4.46 1.37 9.065z" fill="#f91d0a"></path></svg><span class="anchor-text-container"><span class="anchor-text">View PDF</span></span></a></div></li><li class="RelatedContentPanelItem u-display-none"><div class="sub-heading u-padding-xs-bottom"><h3 class="related-content-panel-list-entry-outline-padding text-s u-font-serif" id="recommended-articles-article4-title"><a class="anchor u-clamp-2-lines anchor-primary" href="/science/article/pii/B9780081022665000062" title="Knowledge Markets"><span class="anchor-text-container"><span class="anchor-text"><span>Knowledge Markets</span></span></span></a></h3><div class="article-source u-clr-grey6"><div class="source">Development of Creative Spaces in Academic Libraries, 2018, pp. 33-36</div></div><div class="authors"><span>Katy Kavanagh</span> <span>Webb</span></div></div><div class="buttons"><a class="anchor anchor-primary anchor-icon-left anchor-with-icon" href="/science/article/pii/B9780081022665000062/pdfft?md5=ca1e7d6f8319720827b439a8f0c4f92f&amp;pid=3-s2.0-B9780081022665000062-main.pdf" target="_blank" rel="nofollow" aria-describedby="recommended-articles-article4-title"><svg focusable="false" viewBox="0 0 35 32" height="20" class="icon icon-pdf-multicolor"><path d="M7 .362h17.875l6.763 6.1V31.64H6.948V16z" stroke="#000" stroke-width=".703" fill="#fff"></path><path d="M.167 2.592H22.39V9.72H.166z" fill="#da0000"></path><path fill="#fff9f9" d="M5.97 3.638h1.62c1.053 0 1.483.677 1.488 1.564.008.96-.6 1.564-1.492 1.564h-.644v1.66h-.977V3.64m.977.897v1.34h.542c.27 0 .596-.068.596-.673-.002-.6-.32-.667-.596-.667h-.542m3.8.036v2.92h.35c.933 0 1.223-.448 1.228-1.462.008-1.06-.316-1.45-1.23-1.45h-.347m-.977-.94h1.03c1.68 0 2.523.586 2.534 2.39.01 1.688-.607 2.4-2.534 2.4h-1.03V3.64m4.305 0h2.63v.934h-1.657v.894H16.6V6.4h-1.56v2.026h-.97V3.638"></path><path d="M19.462 13.46c.348 4.274-6.59 16.72-8.508 15.792-1.82-.85 1.53-3.317 2.92-4.366-2.864.894-5.394 3.252-3.837 3.93 2.113.895 7.048-9.25 9.41-15.394zM14.32 24.874c4.767-1.526 14.735-2.974 15.152-1.407.824-3.157-13.72-.37-15.153 1.407zm5.28-5.043c2.31 3.237 9.816 7.498 9.788 3.82-.306 2.046-6.66-1.097-8.925-4.164-4.087-5.534-2.39-8.772-1.682-8.732.917.047 1.074 1.307.67 2.442-.173-1.406-.58-2.44-1.224-2.415-1.835.067-1.905 4.46 1.37 9.065z" fill="#f91d0a"></path></svg><span class="anchor-text-container"><span class="anchor-text">View PDF</span></span></a></div></li><li class="RelatedContentPanelItem u-display-none"><div class="sub-heading u-padding-xs-bottom"><h3 class="related-content-panel-list-entry-outline-padding text-s u-font-serif" id="recommended-articles-article5-title"><a class="anchor u-clamp-2-lines anchor-primary" href="/science/article/pii/S1350449521001122" title="Precise head pose estimation on HPD5A database for attention recognition based on convolutional neural network in human-computer interaction"><span class="anchor-text-container"><span class="anchor-text"><span>Precise head pose estimation on HPD5A database for attention recognition based on convolutional neural network in human-computer interaction</span></span></span></a></h3><div class="article-source u-clr-grey6"><div class="source">Infrared Physics &amp; Technology, Volume 116, 2021, Article 103740</div></div><div class="authors"><span>Hai</span> <span>Liu</span>, …, <span>Sriram</span> <span>Subramanian</span></div></div><div class="buttons"><a class="anchor anchor-primary anchor-icon-left anchor-with-icon" href="/science/article/pii/S1350449521001122/pdfft?md5=847ff7edce8edd44adf729a55ec9a473&amp;pid=1-s2.0-S1350449521001122-main.pdf" target="_blank" rel="nofollow" aria-describedby="recommended-articles-article5-title"><svg focusable="false" viewBox="0 0 35 32" height="20" class="icon icon-pdf-multicolor"><path d="M7 .362h17.875l6.763 6.1V31.64H6.948V16z" stroke="#000" stroke-width=".703" fill="#fff"></path><path d="M.167 2.592H22.39V9.72H.166z" fill="#da0000"></path><path fill="#fff9f9" d="M5.97 3.638h1.62c1.053 0 1.483.677 1.488 1.564.008.96-.6 1.564-1.492 1.564h-.644v1.66h-.977V3.64m.977.897v1.34h.542c.27 0 .596-.068.596-.673-.002-.6-.32-.667-.596-.667h-.542m3.8.036v2.92h.35c.933 0 1.223-.448 1.228-1.462.008-1.06-.316-1.45-1.23-1.45h-.347m-.977-.94h1.03c1.68 0 2.523.586 2.534 2.39.01 1.688-.607 2.4-2.534 2.4h-1.03V3.64m4.305 0h2.63v.934h-1.657v.894H16.6V6.4h-1.56v2.026h-.97V3.638"></path><path d="M19.462 13.46c.348 4.274-6.59 16.72-8.508 15.792-1.82-.85 1.53-3.317 2.92-4.366-2.864.894-5.394 3.252-3.837 3.93 2.113.895 7.048-9.25 9.41-15.394zM14.32 24.874c4.767-1.526 14.735-2.974 15.152-1.407.824-3.157-13.72-.37-15.153 1.407zm5.28-5.043c2.31 3.237 9.816 7.498 9.788 3.82-.306 2.046-6.66-1.097-8.925-4.164-4.087-5.534-2.39-8.772-1.682-8.732.917.047 1.074 1.307.67 2.442-.173-1.406-.58-2.44-1.224-2.415-1.835.067-1.905 4.46 1.37 9.065z" fill="#f91d0a"></path></svg><span class="anchor-text-container"><span class="anchor-text">View PDF</span></span></a></div></li></ul></div><button class="button-link more-recommendations-button u-margin-s-bottom button-link-primary button-link-icon-right" type="button"><span class="button-link-text-container"><span class="button-link-text">Show 3 more articles</span></span><svg focusable="false" viewBox="0 0 92 128" height="20" class="icon icon-navigate-down"><path d="M1 51l7-7 38 38 38-38 7 7-45 45z"></path></svg></button></div></section><section class="RelatedContentPanel u-margin-s-bottom"><header id="metrics-header" class="related-content-panel-header u-margin-s-bottom"><button class="button-link button-link-secondary related-content-panel-toggle is-up button-link-icon-right button-link-has-colored-icon" aria-expanded="true" type="button"><span class="button-link-text-container"><span class="button-link-text"><h2 class="section-title u-h4"><span class="related-content-panel-title-text">Article Metrics</span></h2></span></span><svg focusable="false" viewBox="0 0 92 128" height="20" class="icon icon-navigate-down"><path d="M1 51l7-7 38 38 38-38 7 7-45 45z"></path></svg></button></header><div class="" aria-hidden="false" aria-describedby="metrics-header"><div class="plum-sciencedirect-theme"><div class="PlumX-Summary"><div class="pps-container pps-container-vertical plx-no-print"><div class="pps-branding pps-branding-top"><img alt="plumX logo" src="//cdn.plu.mx/3ba727faf225e19d2c759f6ebffc511d/plumx-inverse-logo.png" class="plx-logo"></div><div class="pps-cols"><div class="pps-col plx-citation"><div class="plx-citation"><div class="pps-title">Citations</div><ul><li class="plx-citation"><span class="pps-label">Citation Indexes: </span><span class="pps-count">187</span></li></ul></div></div><div class="pps-col plx-capture"><div class="plx-capture"><div class="pps-title">Captures</div><ul><li class="plx-capture"><span class="pps-label">Readers: </span><span class="pps-count">177</span></li></ul></div></div></div><div><div class="pps-branding pps-branding-bottom"><img alt="plumX logo" src="//cdn.plu.mx/3ba727faf225e19d2c759f6ebffc511d/plumx-logo.png" class="plx-logo"></div><a target="_blank" href="https://plu.mx/plum/a/?doi=10.1016/j.patcog.2017.06.009&amp;theme=plum-sciencedirect-theme&amp;hideUsage=true" class="pps-seemore" title="PlumX Metrics Detail Page">View details<svg fill="currentColor" tabindex="-1" focusable="false" width="16" height="16" viewBox="0 0 16 16" class="svg-arrow"><path d="M16 4.452l-1.26-1.26L8 9.932l-6.74-6.74L0 4.452l8 8 8-8z"></path></svg></a></div></div></div></div></div></section></aside></div></div></div></div><footer role="contentinfo" class="els-footer u-bg-white text-xs u-padding-s-hor u-padding-m-hor-from-sm u-padding-l-hor-from-md u-padding-l-ver u-margin-l-top u-margin-xl-top-from-sm u-margin-l-top-from-md"><div class="els-footer-elsevier u-margin-m-bottom u-margin-0-bottom-from-md u-margin-s-right u-margin-m-right-from-md u-margin-l-right-from-lg"><a class="anchor anchor-primary anchor-icon-left anchor-with-icon" href="https://www.elsevier.com/" target="_blank" aria-label="Elsevier home page (opens in a new tab)" rel="nofollow"><img class="footer-logo" src="https://sdfestaticassets-eu-west-1.sciencedirectassets.com/shared-assets/47/images/elsevier-non-solus-new-with-wordmark.svg" alt="Elsevier logo with wordmark" height="64" width="58" loading="lazy"></a></div><div class="els-footer-content"><div class="u-remove-if-print"><ul class="els-footer-links u-margin-xs-bottom" style="list-style:none"><li><a class="anchor u-display-flex u-clr-grey8 u-margin-s-bottom u-margin-0-bottom-from-sm u-margin-m-right-from-sm u-margin-l-right-from-md anchor-primary anchor-small" href="https://www.elsevier.com/solutions/sciencedirect" target="_blank" id="els-footer-about-science-direct" rel="nofollow"><span class="anchor-text-container"><span class="anchor-text">About ScienceDirect</span><svg focusable="false" viewBox="0 0 8 8" height="20" aria-label="Opens in new window" class="icon icon-arrow-up-right-tiny arrow-external-link"><path d="M1.12949 2.1072V1H7V6.85795H5.89111V2.90281L0.784057 8L0 7.21635L5.11902 2.1072H1.12949Z"></path></svg></span></a></li><li><a class="anchor u-display-flex u-clr-grey8 u-margin-s-bottom u-margin-0-bottom-from-sm u-margin-m-right-from-sm u-margin-l-right-from-md anchor-primary anchor-small" href="/user/institution/login?targetURL=%2Fscience%2Farticle%2Fpii%2FS0031320317302327" id="els-footer-remote-access" rel="nofollow"><span class="anchor-text-container"><span class="anchor-text">Remote access</span></span></a></li><li><a class="anchor u-display-flex u-clr-grey8 u-margin-s-bottom u-margin-0-bottom-from-sm u-margin-m-right-from-sm u-margin-l-right-from-md anchor-primary anchor-small" href="https://sd-cart.elsevier.com/?" target="_blank" id="els-footer-shopping-cart" rel="nofollow"><span class="anchor-text-container"><span class="anchor-text">Shopping cart</span><svg focusable="false" viewBox="0 0 8 8" height="20" aria-label="Opens in new window" class="icon icon-arrow-up-right-tiny arrow-external-link"><path d="M1.12949 2.1072V1H7V6.85795H5.89111V2.90281L0.784057 8L0 7.21635L5.11902 2.1072H1.12949Z"></path></svg></span></a></li><li><a class="anchor u-display-flex u-clr-grey8 u-margin-s-bottom u-margin-0-bottom-from-sm u-margin-m-right-from-sm u-margin-l-right-from-md anchor-primary anchor-small" href="https://www.elsmediakits.com" target="_blank" id="els-footer-advertise" rel="nofollow"><span class="anchor-text-container"><span class="anchor-text">Advertise</span><svg focusable="false" viewBox="0 0 8 8" height="20" aria-label="Opens in new window" class="icon icon-arrow-up-right-tiny arrow-external-link"><path d="M1.12949 2.1072V1H7V6.85795H5.89111V2.90281L0.784057 8L0 7.21635L5.11902 2.1072H1.12949Z"></path></svg></span></a></li><li><a class="anchor u-display-flex u-clr-grey8 u-margin-s-bottom u-margin-0-bottom-from-sm u-margin-m-right-from-sm u-margin-l-right-from-md anchor-primary anchor-small" href="https://service.elsevier.com/ci/pta/login/redirect/contact/supporthub/sciencedirect/p_li/xyhJEXWoHAMsz8VQOu3h2LHHIekBL3hT38urfpOCxeAty3TF61ibE7vsQPaZh4C6srqm9MNOxus2v65ykDkikA4MoWWax9xsxmy7qS6Jhq1MDk8fC~ZGE1crT~IU0fB88KgH29YS658ka3vhWTqW3QsF38M7JrWC3EPvnlMgTGg39gl1xRqh4DNloSU9hGNUBWmK_Teu~5LuRZ6Al86jUzFxO7CiLa3WIvaVAP5f3g900Gfh5TZfq33GuKqA9hfimBRbW0fFzY3a21RwOu4PLgTJkGu8dMJdwZTxXGeKI1g*" target="_blank" id="els-footer-contact-support" rel="nofollow"><span class="anchor-text-container"><span class="anchor-text">Contact and support</span><svg focusable="false" viewBox="0 0 8 8" height="20" aria-label="Opens in new window" class="icon icon-arrow-up-right-tiny arrow-external-link"><path d="M1.12949 2.1072V1H7V6.85795H5.89111V2.90281L0.784057 8L0 7.21635L5.11902 2.1072H1.12949Z"></path></svg></span></a></li><li><a class="anchor u-display-flex u-clr-grey8 u-margin-s-bottom u-margin-0-bottom-from-sm u-margin-m-right-from-sm u-margin-l-right-from-md anchor-primary anchor-small" href="https://www.elsevier.com/legal/elsevier-website-terms-and-conditions" target="_blank" id="els-footer-terms-condition" rel="nofollow"><span class="anchor-text-container"><span class="anchor-text">Terms and conditions</span><svg focusable="false" viewBox="0 0 8 8" height="20" aria-label="Opens in new window" class="icon icon-arrow-up-right-tiny arrow-external-link"><path d="M1.12949 2.1072V1H7V6.85795H5.89111V2.90281L0.784057 8L0 7.21635L5.11902 2.1072H1.12949Z"></path></svg></span></a></li><li><a class="anchor u-display-flex u-clr-grey8 u-margin-s-bottom u-margin-0-bottom-from-sm u-margin-m-right-from-sm u-margin-l-right-from-md anchor-primary anchor-small" href="https://www.elsevier.com/legal/privacy-policy" target="_blank" id="els-footer-privacy-policy" rel="nofollow"><span class="anchor-text-container"><span class="anchor-text">Privacy policy</span><svg focusable="false" viewBox="0 0 8 8" height="20" aria-label="Opens in new window" class="icon icon-arrow-up-right-tiny arrow-external-link"><path d="M1.12949 2.1072V1H7V6.85795H5.89111V2.90281L0.784057 8L0 7.21635L5.11902 2.1072H1.12949Z"></path></svg></span></a></li></ul></div><p id="els-footer-cookie-message" class="u-remove-if-print">Cookies are used by this site. <!-- --> <button class="button-link ot-sdk-show-settings cookie-btn button-link-primary button-link-small" id="ot-sdk-btn" type="button">Cookie Settings</button></p><p id="els-footer-copyright">All content on this site: Copyright © <!-- -->2024<!-- --> Elsevier B.V., its licensors, and contributors. All rights are reserved, including those for text and data mining, AI training, and similar technologies. For all open access content, the Creative Commons licensing terms apply.</p></div><div class="els-footer-relx u-margin-0-top u-margin-m-top-from-xs u-margin-0-top-from-md"><a class="anchor anchor-primary anchor-icon-left anchor-with-icon" href="https://www.relx.com/" target="_blank" aria-label="RELX home page (opens in a new tab)" id="els-footer-relx" rel="nofollow"><img loading="lazy" src="https://sdfestaticassets-eu-west-1.sciencedirectassets.com/shared-assets/60/images/logo-relx-tm.svg" width="93" height="20" alt="RELX group home page"></a></div></footer></div></div></div></div>
      <div id="floating-ui-node" class="floating-ui-node" data-sd-ui-floating-ui="true"></div>
      
      <script async="" src="https://assets.adobedtm.com/4a848ae9611a/032db4f73473/launch-a6263b31083f.min.js" type="text/javascript"></script>
      
<script type="text/javascript">
    window.pageData = {"content":[{"contentType":"JL","format":"MIME-XHTML","id":"sd:article:pii:S0031320317302327","type":"sd:article:JL:scope-full","detail":"sd:article:subtype:fla","publicationType":"journal","issn":"0031-3203","volumeNumber":"71","suppl":"C","provider":"elsevier","entitlementType":"package"}],"page":{"businessUnit":"ELS:RP:ST","language":"en","name":"product:journal:article","noTracking":"false","productAppVersion":"full-direct","productName":"SD","type":"CP-CA","environment":"prod","loadTimestamp":1730203906742,"loadTime":""},"visitor":{"accessType":"ae:REG_SHIBBOLETH","accountId":"ae:50401","accountName":"ae:IT University of Copenhagen","loginStatus":"logged in","userId":"ae:71970787","ipAddress":"130.225.244.206","appSessionId":"d803021f-cf0c-4303-a9ac-edd1111de6ef"}};
    window.pageData.page.loadTime = performance ? Math.round(performance.now()).toString() : '';

    try {
      appData.push({
      event: 'pageLoad',
      page: pageData.page,
      visitor: pageData.visitor,
      content: pageData.content
      })
    } catch(e) {
        console.warn("There was an error loading or running Adobe DTM: ", e);
    }
</script>
      <script nomodule="" src="https://sdfestaticassets-eu-west-1.sciencedirectassets.com/shared-assets/73/js/core-js/3.20.2/core-js.es.minified.js" type="text/javascript"></script>
      <script src="https://sdfestaticassets-eu-west-1.sciencedirectassets.com/shared-assets/108/js/react/18.3.1/react.production.min.js" type="text/javascript"></script>
      <script src="https://sdfestaticassets-eu-west-1.sciencedirectassets.com/shared-assets/108/js/react-dom/18.3.1/react-dom.production.min.js" type="text/javascript"></script>
      <script async="" src="https://sdfestaticassets-eu-west-1.sciencedirectassets.com/prod/562c52f0a29e84041e12a6c3286c1d8a5b89ba0b/arp.js" type="text/javascript"></script>
      <script type="text/javascript">
    const pendoData = {"visitor":{"pageName":"SD:product:journal:article","pageType":"CP-CA","pageProduct":"SD","pageLanguage":"en","pageEnvironment":"prod","accessType":"ae:REG_SHIBBOLETH","countryCode":"DK"},"account":{"id":"ae:50401","name":"ae:IT University of Copenhagen"},"events":{}};;
    pendoData.events = {
      ready: function () {
        pendo.addAltText();
      },
    };
    function runPendo(data, options) {
  const {
    firstDelay,
    maxRetries,
    urlPrefix,
    urlSuffix,
    apiKey
  } = options;
  (function (apiKey) {
    (function (p, e, n, d, o) {
      var v, w, x, y, z;
      o = p[d] = p[d] || {};
      o._q = [];
      v = ['initialize', 'identify', 'updateOptions', 'pageLoad'];
      for (w = 0, x = v.length; w < x; ++w) (function (m) {
        o[m] = o[m] || function () {
          o._q[m === v[0] ? 'unshift' : 'push']([m].concat([].slice.call(arguments, 0)));
        };
      })(v[w]);
      y = e.createElement(n);
      y.async = !0;
      y.src = urlPrefix + apiKey + urlSuffix;
      z = e.getElementsByTagName(n)[0];
      z.parentNode.insertBefore(y, z);
    })(window, document, 'script', 'pendo');
    pendo.addAltText = function () {
      var target = document.querySelector('body');
      var observer = new MutationObserver(function (mutations) {
        mutations.forEach(function (mutation) {
          if (mutation?.addedNodes?.length) {
            if (mutation.addedNodes[0]?.className?.includes("_pendo-badge")) {
              const badge = mutation.addedNodes[0];
              const altText = badge?.attributes['aria-label'].value ? badge?.attributes['aria-label'].value : 'Feedback';
              const pendoBadgeImage = pendo.dom(`#${badge?.attributes?.id.value} img`);
              if (pendoBadgeImage.length) {
                pendoBadgeImage[0]?.setAttribute('alt', altText);
              }
            }
          }
        });
      });
      var config = {
        attributeFilter: ['data-layout'],
        attributes: true,
        childList: true,
        characterData: true,
        subtree: false
      };
      observer.observe(target, config);
    };
  })(apiKey);
  (function watchAndSetPendo(nextDelay, retryAttempt) {
    if (typeof pageDataTracker === 'object' && typeof pageDataTracker.getVisitorId === 'function' && pageDataTracker.getVisitorId()) {
      data.visitor.id = pageDataTracker.getVisitorId();
      console.debug(`initializing pendo`);
      pendo.initialize(data);
    } else {
      if (retryAttempt > 0) {
        return setTimeout(function () {
          watchAndSetPendo(nextDelay * 2, retryAttempt - 1);
        }, nextDelay);
      }
      pendo.initialize(data);
      console.debug(`gave up ... pendo initialized`);
    }
  })(firstDelay, maxRetries);
}
    runPendo(pendoData, {
      firstDelay: 100,
      maxRetries: 5,
      urlPrefix: 'https://cdn.pendo.io/agent/static/',
      urlSuffix: '/pendo.js',
      apiKey: 'd6c1d995-bc7e-4e53-77f1-2ea4ecbb9565',
    });
  </script>
      <span id="pendo-answer-rating"></span>
      <script type="text/x-mathjax-config;executed=true">
        MathJax.Hub.Config({
          displayAlign: 'left',
          "fast-preview": {
            disabled: true
          },
          CommonHTML: { linebreaks: { automatic: true } },
          PreviewHTML: { linebreaks: { automatic: true } },
          'HTML-CSS': { linebreaks: { automatic: true } },
          SVG: {
            scale: 90,
            linebreaks: { automatic: true }
          }
        });
      </script>
      <script async="" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=MML_SVG" type="text/javascript"></script>
      <script async="" src="https://www.googletagservices.com/tag/js/gpt.js" type="text/javascript"></script>
      <script async="" src="https://scholar.google.com/scholar_js/casa.js" type="text/javascript"></script>
      <script data-cfasync="false">
      (function initOneTrust()  {
        const monitor = {
  init: () => {},
  loaded: () => {},
};
        function enableGroup(group) {
  document.querySelectorAll(`script[type*="ot-${group}"]`).forEach(script => {
    script.type = 'text/javascript';
    document.head.appendChild(script);
  });
}
        function runOneTrustCookies(doClear, monitor) {
  const oneTrustConsentSdkId = 'onetrust-consent-sdk';
  const emptyNodeSelectors = 'h3.ot-host-name, h4.ot-host-desc, button.ot-host-box';
  const ariaLabelledByButtonNodes = 'div.ot-accordion-layout > button';
  const ariaAttribute = 'aria-labelledby';
  function adjustOneTrustDOM() {
    const oneTrustRoot = document.getElementById('onetrust-consent-sdk');

    /* remove empty nodes */
    [...(oneTrustRoot?.querySelectorAll(emptyNodeSelectors) ?? [])].filter(e => e.textContent === '').forEach(e => e.remove());

    /* remove invalid aria-labelledby values */
    oneTrustRoot?.querySelectorAll(ariaLabelledByButtonNodes).forEach(e => {
      const presentIdValue = e.getAttribute(ariaAttribute)?.split(' ').filter(label => document.getElementById(label)).join(' ');
      if (presentIdValue) {
        e.setAttribute(ariaAttribute, presentIdValue);
      }
    });
  }
  function observeOneTrustLoaded(shouldSetOTDefaults, isConsentPresent) {
    const cb = (mutationList, observer) => {
      const oneTrustRoot = mutationList.filter(mutationRecord => mutationRecord.type === 'childList' && mutationRecord.addedNodes.length).map(mutationRecord => [...mutationRecord.addedNodes]).flat().find(e => e.id === oneTrustConsentSdkId);
      if (oneTrustRoot && typeof OneTrust !== 'undefined') {
        monitor.loaded(true);
        OneTrust.OnConsentChanged(() => {
          const perfAllowed = decodeURIComponent(document.cookie.match('(^| )OptanonConsent=([^;]+)')?.[2])?.match('groups=([0-9:0|1,?]+)&?')?.[1]?.match('2:([0|1])')[1] === '1';
          if (perfAllowed) {
            enableGroup('performance');
          }
        });
        if (!isConsentPresent && (shouldSetOTDefaults || OneTrust.GetDomainData().ConsentModel.Name === 'implied consent')) {
          OneTrust.AllowAll();
        }
        document.dispatchEvent(new CustomEvent('@sdtech/onetrust/loaded', {}));
        observer.disconnect();
        adjustOneTrustDOM();
      }
    };
    const observer = new MutationObserver(cb);
    observer.observe(document.querySelector('body'), {
      childList: true
    });
  }
  if (doClear) {
    document.cookie = 'OptanonAlertBoxClosed=; expires=Thu, 01 Jan 1970 00:00:00 UTC; samesite=lax; path=/';
  }
  const isConsentPresent = !!decodeURIComponent(document.cookie.match('(^| )OptanonConsent=([^;]+)')?.[2])?.match('groups=([0-9:0|1,?]+)&?')?.[1];
  const shouldSetOTDefaults = 'false' === 'false' && !document.cookie?.match('OptanonAlertBoxClosed=');
  if (shouldSetOTDefaults) {
    const date = new Date();
    date.setFullYear(date.getFullYear() + 1);
    document.cookie = `OptanonAlertBoxClosed=${new Date().toISOString()}; expires=${date.toUTCString()}; samesite=lax; path=/; domain=sciencedirect.com`;
  }
  observeOneTrustLoaded(shouldSetOTDefaults, isConsentPresent, monitor);
  window.addOTScript = () => {
    const otSDK = document.createElement('script');
    otSDK.setAttribute('data-cfasync', 'false');
    otSDK.setAttribute('src', 'https://cdn.cookielaw.org/scripttemplates/otSDKStub.js');
    otSDK.setAttribute('data-document-language', 'true');
    otSDK.setAttribute('data-domain-script', '865ea198-88cc-4e41-8952-1df75d554d02');
    window.addOTScript = () => {};
    document.head.appendChild(otSDK);
    monitor.init();
  };
  window.addEventListener('load', () => window.addOTScript());
}
        if (document.location.host.match(/.sciencedirect.com$/)) {
          runOneTrustCookies(true, monitor);
        }
        else {
          window.addEventListener('load', (event) => {
            enableGroup('performance');
          });
        }
      }());
    </script>
    
  <script>
var pageDataTracker = {
    eventCookieName: 'eventTrack',
    debugCookie: 'els-aa-debugmode',
    debugCounter: 1,
    warnings: [],
    measures: {},
    timeoffset: 0

    ,trackPageLoad: function(data) {
        if (window.pageData && ((pageData.page && pageData.page.noTracking == 'true') || window.pageData_isLoaded)) {
            return false;
        }

        this.updatePageData(data);

        this.initWarnings();
        if(!(window.pageData && pageData.page && pageData.page.name)) {
            console.error('pageDataTracker.trackPageLoad() called without pageData.page.name being defined!');
            return;
        }

        this.processIdPlusData(window.pageData);

        if(window.pageData && pageData.page && !pageData.page.loadTime) {
          pageData.page.loadTime = performance ? Math.round((performance.now())).toString() : '';
        }

        if(window.pageData && pageData.page) {
            var localTime = new Date().getTime();
            if(pageData.page.loadTimestamp) {
                // calculate timeoffset
                var serverTime = parseInt(pageData.page.loadTimestamp);
                if(!isNaN(serverTime)) {
                    this.timeoffset = pageData.page.loadTimestamp - localTime;
                }
            } else {
                pageData.page.loadTimestamp = localTime;
            }
        }

        this.validateData(window.pageData);

        try {
            var cookieTest = 'aa-cookie-test';
            this.setCookie(cookieTest, cookieTest);
            if(this.getCookie(cookieTest) != cookieTest) {
                this.warnings.push('dtm5');
            }
            this.deleteCookie(cookieTest);
        } catch(e){
            this.warnings.push('dtm5');
        }

        this.registerCallbacks();
        this.setAnalyticsData();

        // handle any cookied event data
        this.getEvents();

        window.pageData_isLoaded = true;

        this.debugMessage('Init - trackPageLoad()', window.pageData);

        _satellite.track('eventDispatcher', JSON.stringify({
          eventName: 'newPage',
          eventData: {eventName: 'newPage'},
          pageData: window.pageData
        }));
    }

    ,trackEvent: function(event, data, callback) {
        if (window.pageData && pageData.page && pageData.page.noTracking == 'true') {
            return false;
        }
        
        if(!window.pageData_isLoaded) {
            if(this.isDebugEnabled()) {
                console.log('[AA] pageDataTracker.trackEvent() called without calling trackPageLoad() first.');
            }
            return false;
        }

        if (event) {
            this.initWarnings();
            if(event === 'newPage') {
                // auto fillings
                if(data && data.page && !data.page.loadTimestamp) {
                    data.page.loadTimestamp = ''+(new Date().getTime() + this.timeoffset);
                }
                this.processIdPlusData(data);
            }

            window.eventData = data ? data : {};
            window.eventData.eventName = event;
            if(!_satellite.getVar('blacklisted')) {
                this.handleEventData(event, data);
    
                if(event === 'newPage') {
                    this.validateData(window.pageData);
                }
                this.debugMessage('Event: ' + event, data);
    
                _satellite.track('eventDispatcher', JSON.stringify({
                  eventName: event,
                  eventData: window.eventData,
                  pageData: window.pageData
                }));
            } else {
                this.debugMessage('!! Blocked Event: ' + event, data);
            }
        }

        if (typeof(callback) == 'function') {
            callback.call();
        }
    }

    ,processIdPlusData: function(data) {
        if(data && data.visitor && data.visitor.idPlusData) {
            var idPlusFields = ['userId', 'accessType', 'accountId', 'accountName'];
            for(var i=0; i < idPlusFields.length; i++) {
                if(typeof data.visitor.idPlusData[idPlusFields[i]] !== 'undefined') {
                    data.visitor[idPlusFields[i]] = data.visitor.idPlusData[idPlusFields[i]];
                }
            }
            data.visitor.idPlusData = undefined;
        }
    }

    ,validateData: function(data) {
        if(!data) {
            this.warnings.push('dv0');
            return;
        }

        // top 5
        if(!(data.visitor && data.visitor.accessType)) {
            this.warnings.push('dv1');
        }
        if(data.visitor && (data.visitor.accountId || data.visitor.accountName)) {
            if(!data.visitor.accountName) {
                this.warnings.push('dv2');
            }
            if(!data.visitor.accountId) {
                this.warnings.push('dv3');
            }
        }
        if(!(data.page && data.page.productName)) {
            this.warnings.push('dv4');
        }
        if(!(data.page && data.page.businessUnit)) {
            this.warnings.push('dv5');
        }
        if(!(data.page && data.page.name)) {
            this.warnings.push('dv6');
        }

        // rp mandatory
        if(data.page && data.page.businessUnit && (data.page.businessUnit.toLowerCase().indexOf('els:rp:') !== -1 || data.page.businessUnit.toLowerCase().indexOf('els:rap:') !== -1)) {
            if(!(data.page && data.page.loadTimestamp)) {
                this.warnings.push('dv7');
            }
            if(!(data.page && data.page.loadTime)) {
                this.warnings.push('dv8');
            }
            if(!(data.visitor && data.visitor.ipAddress)) {
                this.warnings.push('dv9');
            }
            if(!(data.page && data.page.type)) {
                this.warnings.push('dv10');
            }
            if(!(data.page && data.page.language)) {
                this.warnings.push('dv11');
            }
        }

        // other
        if(data.page && data.page.environment) {
            var env = data.page.environment.toLowerCase();
            if(!(env === 'dev' || env === 'cert' || env === 'prod')) {
                this.warnings.push('dv12');
            }
        }
        if(data.content && data.content.constructor !== Array) {
            this.warnings.push('dv13');
        }

        if(data.visitor && data.visitor.accountId && data.visitor.accountId.indexOf(':') == -1) {
            this.warnings.push('dv14');
            data.visitor.accountId = "data violation"
        }
    }

    ,initWarnings: function() {
        this.warnings = [];
        try {
            var hdn = document.head.childNodes;
            var libf = false;
            for(var i=0; i<hdn.length; i++) {
                if(hdn[i].src && (hdn[i].src.indexOf('satelliteLib') !== -1 || hdn[i].src.indexOf('launch') !== -1)) {
                    libf = true;
                    break;
                }
            }
            if(!libf) {
                this.warnings.push('dtm1');
            }
        } catch(e) {}

        try {
            for (let element of document.querySelectorAll('*')) {
                // Check if the element has a src attribute and if it meets the criteria
                if (element.src && element.src.includes('assets.adobedtm.com') && element.src.includes('launch')) {
                    if (element.tagName.toLowerCase() !== 'script') {
                        this.warnings.push('dtm5');
                    }
                    if (!element.hasAttribute('async')) {
                        this.warnings.push('dtm4');
                    }
                }
            }
        } catch (e) { }
    }

    ,getMessages: function() {
        return ['v1'].concat(this.warnings).join('|');
    }
    ,addMessage: function(message) {
        this.warnings.push(message);
    }

    ,getPerformance: function() {
        var copy = {};
        for (var attr in this.measures) {
            if(this.measures.hasOwnProperty(attr)) {
                copy[attr] = this.measures[attr];
            }
        }

        this.measures = {};
        return copy;
    }

    ,dtmCodeDesc: {
        dtm1: 'satellite-lib must be placed in the <head> section',
        dtm2: 'trackPageLoad() must be placed and called before the closing </body> tag',
        dtm3: 'trackEvent() must be called at a stage where Document.readyState=complete (e.g. on the load event or a user event)',
        dtm4: 'Embed codes need to be loaded in async mode',
        dtm5: 'Embed codes not in type script',
        dv1: 'visitor.accessType not set but mandatory',
        dv2: 'visitor.accountName not set but mandatory',
        dv3: 'visitor.accountId not set but mandatory',
        dv4: 'page.productName not set but mandatory',
        dv5: 'page.businessUnit not set but mandatory',
        dv6: 'page.name not set but mandatory',
        dv7: 'page.loadTimestamp not set but mandatory',
        dv8: 'page.loadTime not set but mandatory',
        dv9: 'visitor.ipAddress not set but mandatory',
        dv10: 'page.type not set but mandatory',
        dv11: 'page.language not set but mandatory',
        dv12: 'page.environment must be set to \'prod\', \'cert\' or \'dev\'',
        dv13: 'content must be of type array of objects',
        dv14: 'account number must contain at least one \':\', e.g. \'ae:12345\''
    }

    ,debugMessage: function(event, data) {
        if(this.isDebugEnabled()) {
            console.log('[AA] --------- [' + (this.debugCounter++) + '] Web Analytics Data ---------');
            console.log('[AA] ' + event);
            console.groupCollapsed("[AA] AA Data: ");
            if(window.eventData) {
                console.log("[AA] eventData:\n" + JSON.stringify(window.eventData, true, 2));
            }
            if(window.pageData) {
                console.log("[AA] pageData:\n" + JSON.stringify(window.pageData, true, 2));
            }
            console.groupEnd();
            if(this.warnings.length > 0) {
                console.groupCollapsed("[AA] Warnings ("+this.warnings.length+"): ");
                for(var i=0; i<this.warnings.length; i++) {
                    var error = this.dtmCodeDesc[this.warnings[i]] ? this.dtmCodeDesc[this.warnings[i]] : 'Error Code: ' + this.warnings[i];
                    console.log('[AA] ' + error);
                }
                console.log('[AA] More can be found here: https://confluence.cbsels.com/display/AA/AA+Error+Catalog');
                console.groupEnd();
            }
            console.log("This mode can be disabled by calling 'pageDataTracker.disableDebug()'");
        }
    }

    ,getTrackingCode: function() {
      var campaign = _satellite.getVar('Campaign - ID');
      if(!campaign) {
        campaign = window.sessionStorage ? sessionStorage.getItem('dgcid') : '';
      }
      return campaign;
    }

    ,isDebugEnabled: function() {
        if(typeof this.debug === 'undefined') {
            this.debug = (document.cookie.indexOf(this.debugCookie) !== -1) || (window.pageData && pageData.page && pageData.page.environment && pageData.page.environment.toLowerCase() === 'dev');
            //this.debug = (document.cookie.indexOf(this.debugCookie) !== -1);
        }
        return this.debug;
    }

    ,enableDebug: function(expire) {
        if (typeof expire === 'undefined') {
            expire = 86400;
        }
        console.log('You just enabled debug mode for Adobe Analytics tracking. This mode will persist for 24h.');
        console.log("This mode can be disabled by calling 'pageDataTracker.disableDebug()'");
        this.setCookie(this.debugCookie, 'true', expire, document.location.hostname);
        this.debug = true;
    }

    ,disableDebug: function() {
        console.log('Debug mode is now disabled.');
        this.deleteCookie(this.debugCookie);
        this.debug = false;
    }

    ,setAnalyticsData: function() {
        if(!(window.pageData && pageData.page && pageData.page.productName && pageData.page.name)) {
            return;
        }
        pageData.page.analyticsPagename = pageData.page.productName + ':' + pageData.page.name;

        var pageEls = pageData.page.name.indexOf(':') > -1 ? pageData.page.name.split(':') : [pageData.page.name];
        pageData.page.sectionName = pageData.page.productName + ':' + pageEls[0];
    }

    ,getEvents: function() {
        pageData.savedEvents = {};
        pageData.eventList = [];

        var val = this.getCookie(this.eventCookieName);
        if (val) {
            pageData.savedEvents = val;
        }

        this.deleteCookie(this.eventCookieName);
    }

    ,updatePageData(data) {
        window.pageData = window.pageData || {};
        if (data && typeof(data) === 'object') {
            for (var x in data) {
                if(data.hasOwnProperty(x) && data[x] instanceof Array) {
                    pageData[x] = data[x];
                } else if(data.hasOwnProperty(x) && typeof(data[x]) === 'object') {
                    if(!pageData[x]) {
                        pageData[x] = {};
                    }
                    for (var y in data[x]) {
                        if(data[x].hasOwnProperty(y)) {
                            pageData[x][y] = data[x][y];
                        }
                    }
                }
            }
        }
    }

    ,handleEventData: function(event, data) {
        var val;
        switch(event) {
            case 'newPage':
                this.updatePageData(data);
                this.setAnalyticsData();
            case 'saveSearch':
            case 'searchResultsUpdated':
                if (data) {
                    // overwrite page-load object
                    if (data.search && typeof(data.search) == 'object') {
                        window.eventData.search.resultsPosition = '';
                        pageData.search = pageData.search || {};
                        var fields = ['advancedCriteria', 'criteria', 'currentPage', 'dataFormCriteria', 'facets', 'resultsByType', 'resultsPerPage', 'sortType', 'totalResults', 'type', 'database',
                        'suggestedClickPosition','suggestedLetterCount','suggestedResultCount', 'autoSuggestCategory', 'autoSuggestDetails','typedTerm','selectedTerm', 'channel',
                        'facetOperation', 'details'];
                        for (var i=0; i<fields.length; i++) {
                            if (data.search[fields[i]]) {
                                pageData.search[fields[i]] = data.search[fields[i]];
                            }
                        }
                    }
                }
                this.setAnalyticsData();
                break;
            case 'navigationClick':
                if (data && data.link) {
                    window.eventData.navigationLink = {
                        name: ((data.link.location || 'no location') + ':' + (data.link.name || 'no name'))
                    };
                }
                break;
            case 'autoSuggestClick':
                if (data && data.search) {
                    val = {
                        autoSuggestSearchData: (
                            'letterct:' + (data.search.suggestedLetterCount || 'none') +
                            '|resultct:' + (data.search.suggestedResultCount || 'none') +
                            '|clickpos:' + (data.search.suggestedClickPosition || 'none')
                        ).toLowerCase(),
                        autoSuggestSearchTerm: (data.search.typedTerm || ''),
                        autoSuggestTypedTerm: (data.search.typedTerm || ''),
                        autoSuggestSelectedTerm: (data.search.selectedTerm || ''),
                        autoSuggestCategory: (data.search.autoSuggestCategory || ''),
                        autoSuggestDetails: (data.search.autoSuggestDetails || '')
                    };
                }
                break;
            case 'linkOut':
                if (data && data.content && data.content.length > 0) {
                    window.eventData.linkOut = data.content[0].linkOut;
                    window.eventData.referringProduct = _satellite.getVar('Page - Product Name') + ':' + data.content[0].id;
                }
                break;
            case 'socialShare':
                if (data && data.social) {
                    window.eventData.sharePlatform = data.social.sharePlatform || '';
                }
                break;
            case 'contentInteraction':
                if (data && data.action) {
                    window.eventData.action.name = pageData.page.productName + ':' + data.action.name;
                }
                break;
            case 'searchWithinContent':
                if (data && data.search) {
                    window.pageData.search = window.pageData.search || {};
                    pageData.search.withinContentCriteria = data.search.withinContentCriteria;
                }
                break;
            case 'contentShare':
                if (data && data.content) {
                    window.eventData.sharePlatform = data.content[0].sharePlatform;
                }
                break;
            case 'contentLinkClick':
                if (data && data.link) {
                    window.eventData.action = { name: pageData.page.productName + ':' + (data.link.type || 'no link type') + ':' + (data.link.name || 'no link name') };
                }
                break;
            case 'contentWindowLoad':
            case 'contentTabClick':
                if (data && data.content) {
                    window.eventData.tabName = data.content[0].tabName || '';
                    window.eventData.windowName = data.content[0].windowName || '';
                }
                break;
            case 'userProfileUpdate':
                if (data && data.user) {
                    if (Object.prototype.toString.call(data.user) === "[object Array]") {
                        window.eventData.user = data.user[0];
                    }
                }
                break;
            case 'videoStart':
                if (data.video) {
                    data.video.length = parseFloat(data.video.length || '0');
                    data.video.position = parseFloat(data.video.position || '0');
                    s.Media.open(data.video.id, data.video.length, s.Media.playerName);
                    s.Media.play(data.video.id, data.video.position);
                }
                break;
            case 'videoPlay':
                if (data.video) {
                    data.video.position = parseFloat(data.video.position || '0');
                    s.Media.play(data.video.id, data.video.position);
                }
                break;
            case 'videoStop':
                if (data.video) {
                    data.video.position = parseFloat(data.video.position || '0');
                    s.Media.stop(data.video.id, data.video.position);
                }
                break;
            case 'videoComplete':
                if (data.video) {
                    data.video.position = parseFloat(data.video.position || '0');
                    s.Media.stop(data.video.id, data.video.position);
                    s.Media.close(data.video.id);
                }
                break;
            case 'addWebsiteExtension':
                if(data && data.page) {
                    val = {
                        wx: data.page.websiteExtension
                    }
                }
                break;
        }

        if (val) {
            this.setCookie(this.eventCookieName, val);
        }
    }

    ,registerCallbacks: function() {
        var self = this;
        if(window.usabilla_live) {
            window.usabilla_live('setEventCallback', function(category, action, label, value) {
                if(action == 'Campaign:Open') {
                    self.trackEvent('ctaImpression', {
                        cta: {
                            ids: ['usabillaid:' + label]
                        }
                    });
                } else if(action == 'Campaign:Success') {
                    self.trackEvent('ctaClick', {
                        cta: {
                            ids: ['usabillaid:' + label]
                        }
                    });
                }
            });
        }
    }

    ,getConsortiumAccountId: function() {
        var id = '';
        if (window.pageData && pageData.visitor && (pageData.visitor.consortiumId || pageData.visitor.accountId)) {
            id = (pageData.visitor.consortiumId || 'no consortium ID') + '|' + (pageData.visitor.accountId || 'no account ID');
        }

        return id;
    }

    ,getSearchClickPosition: function() {
        if (window.eventData && eventData.search && eventData.search.resultsPosition) {
            var pos = parseInt(eventData.search.resultsPosition), clickPos;
            if (!isNaN(pos)) {
                var page = pageData.search.currentPage ? parseInt(pageData.search.currentPage) : '', perPage = pageData.search.resultsPerPage ? parseInt(pageData.search.resultsPerPage) : '';
                if (!isNaN(page) && !isNaN(perPage)) {
                    clickPos = pos + ((page - 1) * perPage);
                }
            }
            return clickPos ? clickPos.toString() : eventData.search.resultsPosition;
        }
        return '';
    }

    ,getSearchFacets: function() {
        var facetList = '';
        if (window.pageData && pageData.search && pageData.search.facets) {
            if (typeof(pageData.search.facets) == 'object') {
                for (var i=0; i<pageData.search.facets.length; i++) {
                    var f = pageData.search.facets[i];
                    facetList += (facetList ? '|' : '') + f.name + '=' + f.values.join('^');
                }
            }
        }
        return facetList;
    }

    ,getSearchResultsByType: function() {
        var resultTypes = '';
        if (window.pageData && pageData.search && pageData.search.resultsByType) {
            for (var i=0; i<pageData.search.resultsByType.length; i++) {
                var r = pageData.search.resultsByType[i];
                resultTypes += (resultTypes ? '|' : '') + r.name + (r.results || r.values ? '=' + (r.results || r.values) : '');
            }
        }
        return resultTypes;
    }

    ,getJournalInfo: function() {
        var info = '';
        if (window.pageData && pageData.journal && (pageData.journal.name || pageData.journal.specialty || pageData.journal.section || pageData.journal.issn || pageData.journal.issueNumber || pageData.journal.volumeNumber || pageData.journal.family || pageData.journal.publisher)) {
            var journal = pageData.journal;
            info = (journal.name || 'no name') 
            + '|' + (journal.specialty || 'no specialty') 
            + '|' + (journal.section || 'no section') 
            + '|' + (journal.issn || 'no issn') 
            + '|' + (journal.issueNumber || 'no issue #') 
            + '|' + (journal.volumeNumber || 'no volume #')
            + '|' + (journal.family || 'no family')
            + '|' + (journal.publisher || 'no publisher');

        }
        return info;
    }

    ,getBibliographicInfo: function(doc) {
        if (!doc || !(doc.publisher || doc.indexTerms || doc.publicationType || doc.publicationRights || doc.volumeNumber || doc.issueNumber || doc.subjectAreas || doc.isbn)) {
            return '';
        }

        var terms = doc.indexTerms ? doc.indexTerms.split('+') : '';
        if (terms) {
            terms = terms.slice(0, 5).join('+');
            terms = terms.length > 100 ? terms.substring(0, 100) : terms;
        }

        var areas = doc.subjectAreas ? doc.subjectAreas.split('>') : '';
        if (areas) {
            areas = areas.slice(0, 5).join('>');
            areas = areas.length > 100 ? areas.substring(0, 100) : areas;
        }

        var biblio	= (doc.publisher || 'none')
            + '^' + (doc.publicationType || 'none')
            + '^' + (doc.publicationRights || 'none')
            + '^' + (terms || 'none')
            + '^' + (doc.volumeNumber || 'none')
            + '^' + (doc.issueNumber || 'none')
            + '^' + (areas || 'none')
            + '^' + (doc.isbn || 'none');

        return this.stripProductDelimiters(biblio).toLowerCase();
    }

    ,getContentItem: function() {
        var docs = window.eventData && eventData.content ? eventData.content : pageData.content;
        if (docs && docs.length > 0) {
            return docs[0];
        }
    }

    ,getFormattedDate: function(ts) {
        if (!ts) {
            return '';
        }

        var d = new Date(parseInt(ts) * 1000);

        // now do formatting
        var year = d.getFullYear()
            ,month = ((d.getMonth() + 1) < 10 ? '0' : '') + (d.getMonth() + 1)
            ,date = (d.getDate() < 10 ? '0' : '') + d.getDate()
            ,hours = d.getHours() > 12 ? d.getHours() - 12 : d.getHours()
            ,mins = (d.getMinutes() < 10 ? '0' : '') + d.getMinutes()
            ,ampm = d.getHours() > 12 ? 'pm' : 'am';

        hours = (hours < 10 ? '0' : '') + hours;
        return year + '-' + month + '-' + date;
    }

    ,getVisitorId: function() {
        var orgId = '4D6368F454EC41940A4C98A6@AdobeOrg';
        if(Visitor && Visitor.getInstance(orgId)) {
            return Visitor.getInstance(orgId).getMarketingCloudVisitorID();
        } else {
            return ''
        }
    }

    ,setProductsVariable: function() {
        var prodList = window.eventData && eventData.content ? eventData.content : pageData.content
            ,prods = [];
        if (prodList) {
            for (var i=0; i<prodList.length; i++) {
                if (prodList[i].id || prodList[i].type || prodList[i].publishDate || prodList[i].onlineDate) {
                    if (!prodList[i].id) {
                        prodList[i].id = 'no id';
                    }
                    var prodName = (pageData.page.productName || 'xx').toLowerCase();
                    if (prodList[i].id.indexOf(prodName + ':') != 0) {
                        prodList[i].id = prodName + ':' + prodList[i].id;
                    }
                    prodList[i].id = this.stripProductDelimiters(prodList[i].id);
                    var merch = [];
                    if (prodList[i].format) {
                        merch.push('evar17=' + this.stripProductDelimiters(prodList[i].format.toLowerCase()));
                    }
                    if (prodList[i].type) {
                        var type = prodList[i].type;
                        if (prodList[i].accessType) {
                            type += ':' + prodList[i].accessType;
                        }
                        merch.push('evar20=' + this.stripProductDelimiters(type.toLowerCase()));

                        if(type.indexOf(':manuscript') > 0) {
                            /*
                            var regex = /[a-z]+:manuscript:id:([a-z]+-[a-z]-[0-9]+-[0-9]+)/gmi;
                            var m = regex.exec(prodList[i].id);
                            if(m) {
                                merch.push('evar200=' + m[1]);
                            }
                            merch.push('evar200=' + prodList[i].id);
                            */
                            a = prodList[i].id.lastIndexOf(':');
                            if(a>0) {
                                merch.push('evar200=' + prodList[i].id.substring(a+1).toUpperCase());
                            }
                        } else if(type.indexOf(':submission') > 0) {
                            merch.push('evar200=' + prodList[i].id);
                        }
                    }
                    if(!prodList[i].title) {
                        prodList[i].title = prodList[i].name;
                    }
                    if (prodList[i].title) {
                        merch.push('evar75=' + this.stripProductDelimiters(prodList[i].title.toLowerCase()));
                    }
                    if (prodList[i].breadcrumb) {
                        merch.push('evar63=' + this.stripProductDelimiters(prodList[i].breadcrumb).toLowerCase());
                    }
                    var nowTs = new Date().getTime()/1000;
                    if (prodList[i].onlineDate && !isNaN(prodList[i].onlineDate)) {
                        if(prodList[i].onlineDate > 32503680000) {
                            prodList[i].onlineDate = prodList[i].onlineDate/1000;
                        }
                        merch.push('evar122=' + this.stripProductDelimiters(pageDataTracker.getFormattedDate(prodList[i].onlineDate)));
                        var onlineAge = Math.floor((nowTs - prodList[i].onlineDate) / 86400);
                        onlineAge = (onlineAge === 0) ? 'zero' : onlineAge;
                        merch.push('evar128=' + onlineAge);
                    }
                    if (prodList[i].publishDate && !isNaN(prodList[i].publishDate)) {
                        if(prodList[i].publishDate > 32503680000) {
                            prodList[i].publishDate = prodList[i].publishDate/1000;
                        }
                        merch.push('evar123=' + this.stripProductDelimiters(pageDataTracker.getFormattedDate(prodList[i].publishDate)));
                        var publishAge = Math.floor((nowTs - prodList[i].publishDate) / 86400);
                        publishAge = (publishAge === 0) ? 'zero' : publishAge;
                        merch.push('evar127=' + publishAge);
                    }
                    if (prodList[i].onlineDate && prodList[i].publishDate) {
                        merch.push('evar38=' + this.stripProductDelimiters(pageDataTracker.getFormattedDate(prodList[i].onlineDate) + '^' + pageDataTracker.getFormattedDate(prodList[i].publishDate)));
                    }
                    if (prodList[i].mapId) {
                        merch.push('evar70=' + this.stripProductDelimiters(prodList[i].mapId));
                    }
					if (prodList[i].relevancyScore) {
						merch.push('evar71=' + this.stripProductDelimiters(prodList[i].relevancyScore));
					}
                    if (prodList[i].status) {
                        merch.push('evar73=' + this.stripProductDelimiters(prodList[i].status));
                    }
                    if (prodList[i].previousStatus) {
                        merch.push('evar111=' + this.stripProductDelimiters(prodList[i].previousStatus));
                    }
                    if (prodList[i].entitlementType) {
                        merch.push('evar80=' + this.stripProductDelimiters(prodList[i].entitlementType));
                    }
                    if (prodList[i].recordType) {
                        merch.push('evar93=' + this.stripProductDelimiters(prodList[i].recordType));
                    }
                    if (prodList[i].exportType) {
                        merch.push('evar99=' + this.stripProductDelimiters(prodList[i].exportType));
                    }
                    if (prodList[i].importType) {
                        merch.push('evar142=' + this.stripProductDelimiters(prodList[i].importType));
                    }
                    if (prodList[i].section) {
                        merch.push('evar100=' + this.stripProductDelimiters(prodList[i].section));
                    }
                    if (prodList[i].detail) {
                        merch.push('evar104=' + this.stripProductDelimiters(prodList[i].detail.toLowerCase()));
                    } else if(prodList[i].details) {
                        merch.push('evar104=' + this.stripProductDelimiters(prodList[i].details.toLowerCase()));
                    }
                    if (prodList[i].position) {
                        merch.push('evar116=' + this.stripProductDelimiters(prodList[i].position));
                    }
                    if (prodList[i].publicationTitle) {
                        merch.push('evar129=' + this.stripProductDelimiters(prodList[i].publicationTitle));
                    }
                    if (prodList[i].specialIssueTitle) {
                        merch.push('evar130=' + this.stripProductDelimiters(prodList[i].specialIssueTitle));
                    }
                    if (prodList[i].specialIssueNumber) {
                        merch.push('evar131=' + this.stripProductDelimiters(prodList[i].specialIssueNumber));
                    }
                    if (prodList[i].referenceModuleTitle) {
                        merch.push('evar139=' + this.stripProductDelimiters(prodList[i].referenceModuleTitle));
                    }
                    if (prodList[i].referenceModuleISBN) {
                        merch.push('evar140=' + this.stripProductDelimiters(prodList[i].referenceModuleISBN));
                    }
                    if (prodList[i].volumeTitle) {
                        merch.push('evar132=' + this.stripProductDelimiters(prodList[i].volumeTitle));
                    }
                    if (prodList[i].publicationSection) {
                        merch.push('evar133=' + this.stripProductDelimiters(prodList[i].publicationSection));
                    }
                    if (prodList[i].publicationSpecialty) {
                        merch.push('evar134=' + this.stripProductDelimiters(prodList[i].publicationSpecialty));
                    }
                    if (prodList[i].issn) {
                        merch.push('evar135=' + this.stripProductDelimiters(prodList[i].issn));
                    }
                    if (prodList[i].id2) {
                        merch.push('evar159=' + this.stripProductDelimiters(prodList[i].id2));
                    }
                    if (prodList[i].id3) {
                        merch.push('evar160=' + this.stripProductDelimiters(prodList[i].id3));
                    }
                    if (prodList[i].provider) {
                        merch.push('evar164=' + this.stripProductDelimiters(prodList[i].provider));
                    }
                    if (prodList[i].citationStyle) {
                        merch.push('evar170=' + this.stripProductDelimiters(prodList[i].citationStyle));
                    }

                    var biblio = this.getBibliographicInfo(prodList[i]);
                    if (biblio) {
                        merch.push('evar28=' + biblio);
                    }

                    if (prodList[i].turnawayId) {
                        pageData.eventList.push('product turnaway');
                    }

                    var price = prodList[i].price || '', qty = prodList[i].quantity || '', evts = [];
                    if (price && qty) {
                        qty = parseInt(qty || '1');
                        price = parseFloat(price || '0');
                        price = (price * qty).toFixed(2);

                        if (window.eventData && eventData.eventName && eventData.eventName == 'cartAdd') {
                            evts.push('event20=' + price);
                        }
                    }

                    var type = window.pageData && pageData.page && pageData.page.type ? pageData.page.type : '', evt = window.eventData && eventData.eventName ? eventData.eventName : '';
                    if (type.match(/^CP\-/gi) !== null && (!evt || evt == 'newPage' || evt == 'contentView')) {
                        evts.push('event181=1');
                    }
                    if (evt == 'contentDownload' || type.match(/^CP\-DL/gi) !== null) {
                        evts.push('event182=1');
                    }
                    if (evt == 'contentDownloadRequest') {
                        evts.push('event319=1');
                    }
                    if (evt == 'contentExport') {
                        evts.push('event184=1');
                    }
                    if (this.eventFires('recommendationViews')) {
                        evts.push('event264=1');
                    }

                    if(prodList[i].datapoints) {
                        evts.push('event239=' + prodList[i].datapoints);
                    }
                    if(prodList[i].documents) {
                        evts.push('event240=' + prodList[i].documents);
                    }
                    if(prodList[i].size) {
                        evts.push('event335=' + prodList[i].size);
                        evts.push('event336=1')
                    }

                    prods.push([
                        ''					// empty category
                        ,prodList[i].id		// id
                        ,qty				// qty
                        ,price				// price
                        ,evts.join('|')		// events
                        ,merch.join('|')	// merchandising eVars
                    ].join(';'));
                }
            }
        }

        return prods.join(',');
    }
    ,eventFires: function(eventName) {
      var evt = window.eventData && eventData.eventName ? eventData.eventName : '';
      if(evt == eventName) {
        return true;
      }
      // initial pageload and new pages
      if((!window.eventData || evt == 'newPage') && window.pageData && window.pageData.trackEvents) {
        var tEvents = window.pageData.trackEvents;
        for(var i=0; i<tEvents.length; i++) {
          if(tEvents[i] == eventName) {
            return true;
          }
        }
      }
      return false;
    }

    ,md5: function(s){function L(k,d){return(k<<d)|(k>>>(32-d))}function K(G,k){var I,d,F,H,x;F=(G&2147483648);H=(k&2147483648);I=(G&1073741824);d=(k&1073741824);x=(G&1073741823)+(k&1073741823);if(I&d){return(x^2147483648^F^H)}if(I|d){if(x&1073741824){return(x^3221225472^F^H)}else{return(x^1073741824^F^H)}}else{return(x^F^H)}}function r(d,F,k){return(d&F)|((~d)&k)}function q(d,F,k){return(d&k)|(F&(~k))}function p(d,F,k){return(d^F^k)}function n(d,F,k){return(F^(d|(~k)))}function u(G,F,aa,Z,k,H,I){G=K(G,K(K(r(F,aa,Z),k),I));return K(L(G,H),F)}function f(G,F,aa,Z,k,H,I){G=K(G,K(K(q(F,aa,Z),k),I));return K(L(G,H),F)}function D(G,F,aa,Z,k,H,I){G=K(G,K(K(p(F,aa,Z),k),I));return K(L(G,H),F)}function t(G,F,aa,Z,k,H,I){G=K(G,K(K(n(F,aa,Z),k),I));return K(L(G,H),F)}function e(G){var Z;var F=G.length;var x=F+8;var k=(x-(x%64))/64;var I=(k+1)*16;var aa=Array(I-1);var d=0;var H=0;while(H<F){Z=(H-(H%4))/4;d=(H%4)*8;aa[Z]=(aa[Z]| (G.charCodeAt(H)<<d));H++}Z=(H-(H%4))/4;d=(H%4)*8;aa[Z]=aa[Z]|(128<<d);aa[I-2]=F<<3;aa[I-1]=F>>>29;return aa}function B(x){var k="",F="",G,d;for(d=0;d<=3;d++){G=(x>>>(d*8))&255;F="0"+G.toString(16);k=k+F.substr(F.length-2,2)}return k}function J(k){k=k.replace(/rn/g,"n");var d="";for(var F=0;F<k.length;F++){var x=k.charCodeAt(F);if(x<128){d+=String.fromCharCode(x)}else{if((x>127)&&(x<2048)){d+=String.fromCharCode((x>>6)|192);d+=String.fromCharCode((x&63)|128)}else{d+=String.fromCharCode((x>>12)|224);d+=String.fromCharCode(((x>>6)&63)|128);d+=String.fromCharCode((x&63)|128)}}}return d}var C=Array();var P,h,E,v,g,Y,X,W,V;var S=7,Q=12,N=17,M=22;var A=5,z=9,y=14,w=20;var o=4,m=11,l=16,j=23;var U=6,T=10,R=15,O=21;s=J(s);C=e(s);Y=1732584193;X=4023233417;W=2562383102;V=271733878;for(P=0;P<C.length;P+=16){h=Y;E=X;v=W;g=V;Y=u(Y,X,W,V,C[P+0],S,3614090360);V=u(V,Y,X,W,C[P+1],Q,3905402710);W=u(W,V,Y,X,C[P+2],N,606105819);X=u(X,W,V,Y,C[P+3],M,3250441966);Y=u(Y,X,W,V,C[P+4],S,4118548399);V=u(V,Y,X,W,C[P+5],Q,1200080426);W=u(W,V,Y,X,C[P+6],N,2821735955);X=u(X,W,V,Y,C[P+7],M,4249261313);Y=u(Y,X,W,V,C[P+8],S,1770035416);V=u(V,Y,X,W,C[P+9],Q,2336552879);W=u(W,V,Y,X,C[P+10],N,4294925233);X=u(X,W,V,Y,C[P+11],M,2304563134);Y=u(Y,X,W,V,C[P+12],S,1804603682);V=u(V,Y,X,W,C[P+13],Q,4254626195);W=u(W,V,Y,X,C[P+14],N,2792965006);X=u(X,W,V,Y,C[P+15],M,1236535329);Y=f(Y,X,W,V,C[P+1],A,4129170786);V=f(V,Y,X,W,C[P+6],z,3225465664);W=f(W,V,Y,X,C[P+11],y,643717713);X=f(X,W,V,Y,C[P+0],w,3921069994);Y=f(Y,X,W,V,C[P+5],A,3593408605);V=f(V,Y,X,W,C[P+10],z,38016083);W=f(W,V,Y,X,C[P+15],y,3634488961);X=f(X,W,V,Y,C[P+4],w,3889429448);Y=f(Y,X,W,V,C[P+9],A,568446438);V=f(V,Y,X,W,C[P+14],z,3275163606);W=f(W,V,Y,X,C[P+3],y,4107603335);X=f(X,W,V,Y,C[P+8],w,1163531501);Y=f(Y,X,W,V,C[P+13],A,2850285829);V=f(V,Y,X,W,C[P+2],z,4243563512);W=f(W,V,Y,X,C[P+7],y,1735328473);X=f(X,W,V,Y,C[P+12],w,2368359562);Y=D(Y,X,W,V,C[P+5],o,4294588738);V=D(V,Y,X,W,C[P+8],m,2272392833);W=D(W,V,Y,X,C[P+11],l,1839030562);X=D(X,W,V,Y,C[P+14],j,4259657740);Y=D(Y,X,W,V,C[P+1],o,2763975236);V=D(V,Y,X,W,C[P+4],m,1272893353);W=D(W,V,Y,X,C[P+7],l,4139469664);X=D(X,W,V,Y,C[P+10],j,3200236656);Y=D(Y,X,W,V,C[P+13],o,681279174);V=D(V,Y,X,W,C[P+0],m,3936430074);W=D(W,V,Y,X,C[P+3],l,3572445317);X=D(X,W,V,Y,C[P+6],j,76029189);Y=D(Y,X,W,V,C[P+9],o,3654602809);V=D(V,Y,X,W,C[P+12],m,3873151461);W=D(W,V,Y,X,C[P+15],l,530742520);X=D(X,W,V,Y,C[P+2],j,3299628645);Y=t(Y,X,W,V,C[P+0],U,4096336452);V=t(V,Y,X,W,C[P+7],T,1126891415);W=t(W,V,Y,X,C[P+14],R,2878612391);X=t(X,W,V,Y,C[P+5],O,4237533241);Y=t(Y,X,W,V,C[P+12],U,1700485571);V=t(V,Y,X,W,C[P+3],T,2399980690);W=t(W,V,Y,X,C[P+10],R,4293915773);X=t(X,W,V,Y,C[P+1],O,2240044497);Y=t(Y,X,W,V,C[P+8],U,1873313359);V=t(V,Y,X,W,C[P+15],T,4264355552);W=t(W,V,Y,X,C[P+6],R,2734768916);X=t(X,W,V,Y,C[P+13],O,1309151649);Y=t(Y,X,W,V,C[P+4],U,4149444226);V=t(V,Y,X,W,C[P+11],T,3174756917);W=t(W,V,Y,X,C[P+2],R,718787259);X=t(X,W,V,Y,C[P+9],O,3951481745);Y=K(Y,h);X=K(X,E);W=K(W,v);V=K(V,g)}var i=B(Y)+B(X)+B(W)+B(V);return i.toLowerCase()}
    ,stripProductDelimiters: function(val) {
        if (val) {
            return val.replace(/\;|\||\,/gi, '-');
        }
    }

    ,setCookie: function(name, value, seconds, domain) {
        domain = document.location.hostname;
        var expires = '';
        var expiresNow = '';
        var date = new Date();
        date.setTime(date.getTime() + (-1 * 1000));
        expiresNow = "; expires=" + date.toGMTString();

        if (typeof(seconds) != 'undefined') {
            date.setTime(date.getTime() + (seconds * 1000));
            expires = '; expires=' + date.toGMTString();
        }

        var type = typeof(value);
        type = type.toLowerCase();
        if (type != 'undefined' && type != 'string') {
            value = JSON.stringify(value);
        }

        // fix scoping issues
        // keep writing the old cookie, but make it expire
        document.cookie = name + '=' + value + expiresNow + '; path=/';

        // now just set the right one
        document.cookie = name + '=' + value + expires + '; path=/; domain=' + domain;
    }

    ,getCookie: function(name) {
        name = name + '=';
        var carray = document.cookie.split(';'), value;

        for (var i=0; i<carray.length; i++) {
            var c = carray[i];
            while (c.charAt(0) == ' ') {
                c = c.substring(1, c.length);
            }
            if (c.indexOf(name) == 0) {
                value = c.substring(name.length, c.length);
                try {
                    value = JSON.parse(value);
                } catch(ex) {}

                return value;
            }
        }

        return null;
    }

    ,deleteCookie: function(name) {
        this.setCookie(name, '', -1);
        this.setCookie(name, '', -1, document.location.hostname);
    }

    ,mapAdobeVars: function(s) {
        var vars = {
            pageName		: 'Page - Analytics Pagename'
            ,channel		: 'Page - Section Name'
            ,campaign		: 'Campaign - ID'
            ,currencyCode	: 'Page - Currency Code'
            ,purchaseID		: 'Order - ID'
            ,prop1			: 'Visitor - Account ID'
            ,prop2			: 'Page - Product Name'
            ,prop4			: 'Page - Type'
            ,prop6			: 'Search - Type'
            ,prop7			: 'Search - Facet List'
            ,prop8			: 'Search - Feature Used'
            ,prop12			: 'Visitor - User ID'
            ,prop13			: 'Search - Sort Type'
            ,prop14			: 'Page - Load Time'
            ,prop15         : 'Support - Topic Name'
            ,prop16			: 'Page - Business Unit'
            ,prop21			: 'Search - Criteria'
            ,prop24			: 'Page - Language'
            ,prop25			: 'Page - Product Feature'
            ,prop28         : 'Support - Search Criteria'
            ,prop30			: 'Visitor - IP Address'
            ,prop33         : 'Page - Product Application Version'
            ,prop34         : 'Page - Website Extensions'
            ,prop60			: 'Search - Data Form Criteria'
            ,prop63			: 'Page - Extended Page Name'
            ,prop65         : 'Page - Online State'
            ,prop67         : 'Research Networks'
            ,prop40: 'Page - UX Properties'

            ,eVar3			: 'Search - Total Results'
            ,eVar7			: 'Visitor - Account Name'
            ,eVar15			: 'Event - Search Results Click Position'
            ,eVar19			: 'Search - Advanced Criteria'
            ,eVar21			: 'Promo - Clicked ID'
            ,eVar22			: 'Page - Test ID'
            ,eVar27			: 'Event - AutoSuggest Search Data'
            ,eVar157		: 'Event - AutoSuggest Search Typed Term'
            ,eVar156		: 'Event - AutoSuggest Search Selected Term'
            ,eVar162		: 'Event - AutoSuggest Search Category'
            ,eVar163		: 'Event - AutoSuggest Search Details'
            ,eVar33			: 'Visitor - Access Type'
            ,eVar34			: 'Order - Promo Code'
            ,eVar39			: 'Order - Payment Method'
            ,eVar41			: 'Visitor - Industry'
            ,eVar42			: 'Visitor - SIS ID'
            ,eVar43			: 'Page - Error Type'
            ,eVar44			: 'Event - Updated User Fields'
            ,eVar48			: 'Email - Recipient ID'
            ,eVar51			: 'Email - Message ID'
            ,eVar52			: 'Visitor - Department ID'
            ,eVar53			: 'Visitor - Department Name'
            ,eVar60			: 'Search - Within Content Criteria'
            ,eVar61			: 'Search - Within Results Criteria'
            ,eVar62			: 'Search - Result Types'
            ,eVar74			: 'Page - Journal Info'
            ,eVar59			: 'Page - Journal Publisher'
            ,eVar76			: 'Email - Broadlog ID'
            ,eVar78			: 'Visitor - Details'
            ,eVar80         : 'Visitor - Usage Path Info'
            ,eVar102		: 'Form - Name'
            ,eVar103        : 'Event - Conversion Driver'
            ,eVar105        : 'Search - Current Page'
            ,eVar106        : 'Visitor - App Session ID'
            ,eVar107        : 'Page - Secondary Product Name'
            ,eVar117        : 'Search - Database'
            ,eVar126        : 'Page - Environment'
            ,eVar141        : 'Search - Criteria Original'
            ,eVar143        : 'Page - Tabs'
            ,eVar161        : 'Search - Channel'
            ,eVar169        : 'Search - Facet Operation'
            ,eVar173        : 'Search - Details'
            ,eVar174        : 'Campaign - Spredfast ID'
            ,eVar175        : 'Visitor - TMX Device ID'
            ,eVar176        : 'Visitor - TMX Request ID'
            ,eVar148        : 'Visitor - Platform Name'
            ,eVar149        : 'Visitor - Platform ID'
            ,eVar152        : 'Visitor - Product ID'
            ,eVar153        : 'Visitor - Superaccount ID'
            ,eVar154        : 'Visitor - Superaccount Name'
            ,eVar177        : 'Page - Context Domain'
            ,eVar189    : 'Page - Experimentation User Id'
            ,eVar190    : 'Page - Identity User'
            ,eVar199    : 'Page - ID+ Parameters'

            ,list2			: 'Page - Widget Names'
            ,list3			: 'Promo - IDs'
        };

        for (var i in vars) {
            s[i] = s[i] ? s[i] : _satellite.getVar(vars[i]);
        }
    }
};

// async support fallback
(function(w) {
	var eventBuffer = [];
	if(w.appData) {
		if(Array.isArray(w.appData)) {
			eventBuffer = w.appData;
		} else {
			console.error('Elsevier DataLayer "window.appData" must be specified as array');
			return;
		}
    }

	w.appData = [];

	var oldPush = w.appData.push;

	var appDataPush = function() {
        oldPush.apply(w.appData, arguments);
        for(var i=0; i<arguments.length; i++) {
            var data = arguments[i];
            if(data.event) {
                if(data.event == 'pageLoad') {
                    w.pageDataTracker.trackPageLoad(data);
                } else {
                    w.pageDataTracker.trackEvent(data.event, data);
                }
            }
        }
	};

	w.appData.push = appDataPush;
	for(var i=0; i<eventBuffer.length; i++) {
	    var data = eventBuffer[i];
	    w.appData.push(data);
	}
})(window);

</script><script>_satellite["_runScript1"](function(event, target, Promise) {
_satellite.logger.log("eventDispatcher: clearing tracking state");try{s.events="",s.linkTrackVars="",s.linkTrackEvents=""}catch(e){_satellite.logger.log("eventDispatcher: s object - could not reset state.")}try{dispatcherData=JSON.parse(event.detail),window.ddqueue=window.ddqueue||[],window.ddqueue.push(dispatcherData),window.eventData=dispatcherData.eventData,window.pageData=dispatcherData.pageData,_satellite.track(dispatcherData.eventName)}catch(e){_satellite.logger.log("eventDispatcher: exception"),_satellite.logger.log(e)}
});</script><script src="https://cdn.plu.mx/widget-summary.js" async=""></script><script>_satellite["_runScript2"](function(event, target, Promise) {
_satellite.logger.log("eventDispatcher: clearing tracking state");try{s.events="",s.linkTrackVars="",s.linkTrackEvents=""}catch(e){_satellite.logger.log("eventDispatcher: s object - could not reset state.")}try{dispatcherData=JSON.parse(event.detail),window.ddqueue=window.ddqueue||[],window.ddqueue.push(dispatcherData),window.eventData=dispatcherData.eventData,window.pageData=dispatcherData.pageData,_satellite.track(dispatcherData.eventName)}catch(e){_satellite.logger.log("eventDispatcher: exception"),_satellite.logger.log(e)}
});</script><script>_satellite["_runScript3"](function(event, target, Promise) {
_satellite.logger.log("eventDispatcher: clearing tracking state");try{s.events="",s.linkTrackVars="",s.linkTrackEvents=""}catch(e){_satellite.logger.log("eventDispatcher: s object - could not reset state.")}try{dispatcherData=JSON.parse(event.detail),window.ddqueue=window.ddqueue||[],window.ddqueue.push(dispatcherData),window.eventData=dispatcherData.eventData,window.pageData=dispatcherData.pageData,_satellite.track(dispatcherData.eventName)}catch(e){_satellite.logger.log("eventDispatcher: exception"),_satellite.logger.log(e)}
});</script><div class="js-react-modal"></div><div class="js-react-modal"></div><div class="js-react-modal"></div><div class="js-react-modal"></div><div class="js-react-modal"></div><div class="js-react-modal"></div><div class="js-react-modal"></div><div id="onetrust-consent-sdk"><div class="onetrust-pc-dark-filter ot-hide ot-fade-in"></div><div id="onetrust-pc-sdk" class="otPcCenter ot-hide ot-fade-in" lang="en" aria-label="Preference center" role="region"><div role="alertdialog" aria-modal="true" aria-describedby="ot-pc-desc" style="height: 100%;" aria-label="Cookie Preference Center"><!-- Close Button --><div class="ot-pc-header"><!-- Logo Tag --><div class="ot-pc-logo" role="img" aria-label="Company Logo"><img alt="Company Logo" src="https://cdn.cookielaw.org/logos/static/ot_company_logo.png"></div></div><!-- Close Button --><div id="ot-pc-content" class="ot-pc-scrollbar"><div class="ot-optout-signal ot-hide"><div class="ot-optout-icon"><svg xmlns="http://www.w3.org/2000/svg"><path class="ot-floating-button__svg-fill" d="M14.588 0l.445.328c1.807 1.303 3.961 2.533 6.461 3.688 2.015.93 4.576 1.746 7.682 2.446 0 14.178-4.73 24.133-14.19 29.864l-.398.236C4.863 30.87 0 20.837 0 6.462c3.107-.7 5.668-1.516 7.682-2.446 2.709-1.251 5.01-2.59 6.906-4.016zm5.87 13.88a.75.75 0 00-.974.159l-5.475 6.625-3.005-2.997-.077-.067a.75.75 0 00-.983 1.13l4.172 4.16 6.525-7.895.06-.083a.75.75 0 00-.16-.973z" fill="#FFF" fill-rule="evenodd"></path></svg></div><span></span></div><h2 id="ot-pc-title">Cookie Preference Center</h2><div id="ot-pc-desc">We use cookies which are necessary to make our site work. We may also use additional cookies to analyse, improve and personalise our content and your digital experience. For more information, see our <a href="https://www.elsevier.com/legal/cookienotice/_nocache" target="_blank">Cookie Policy</a> and the list of <a href="https://support.google.com/admanager/answer/9012903" target="_blank">Google Ad-Tech Vendors</a>.
<br>
<br>
You may choose not to allow some types of cookies. However, blocking some types may impact your experience of our site and the services we are able to offer. See the different category headings below to find out more or change your settings.
<br>
</div><button id="accept-recommended-btn-handler">Allow all</button><section class="ot-sdk-row ot-cat-grp"><h3 id="ot-category-title"> Manage Consent Preferences</h3><div class="ot-accordion-layout ot-cat-item ot-vs-config" data-optanongroupid="1"><button aria-expanded="false" ot-accordion="true" aria-controls="ot-desc-id-1" aria-labelledby="ot-header-id-1 ot-status-id-1"></button><!-- Accordion header --><div class="ot-acc-hdr ot-always-active-group"><div class="ot-plus-minus"><span></span><span></span></div><h4 class="ot-cat-header" id="ot-header-id-1">Strictly Necessary Cookies</h4><div id="ot-status-id-1" class="ot-always-active">Always active</div></div><!-- accordion detail --><div class="ot-acc-grpcntr ot-acc-txt"><p class="ot-acc-grpdesc ot-category-desc" id="ot-desc-id-1">These cookies are necessary for the website to function and cannot be switched off in our systems. They are usually only set in response to actions made by you which amount to a request for services, such as setting your privacy preferences, logging in or filling in forms. You can set your browser to block or alert you about these cookies, but some parts of the site will not then work. These cookies do not store any personally identifiable information.
<br><br></p><div class="ot-hlst-cntr"><button class="ot-link-btn category-host-list-handler" aria-label="Cookie Details List" data-parent-id="1">Cookie Details List‎</button></div></div></div><div class="ot-accordion-layout ot-cat-item ot-vs-config" data-optanongroupid="3"><button aria-expanded="false" ot-accordion="true" aria-controls="ot-desc-id-3" aria-labelledby="ot-header-id-3"></button><!-- Accordion header --><div class="ot-acc-hdr"><div class="ot-plus-minus"><span></span><span></span></div><h4 class="ot-cat-header" id="ot-header-id-3">Functional Cookies</h4><div class="ot-tgl"><input type="checkbox" name="ot-group-id-3" id="ot-group-id-3" role="switch" class="category-switch-handler" data-optanongroupid="3" checked="" aria-labelledby="ot-header-id-3"> <label class="ot-switch" for="ot-group-id-3"><span class="ot-switch-nob" aria-checked="true" role="switch" aria-label="Functional Cookies"></span> <span class="ot-label-txt">Functional Cookies</span></label> </div></div><!-- accordion detail --><div class="ot-acc-grpcntr ot-acc-txt"><p class="ot-acc-grpdesc ot-category-desc" id="ot-desc-id-3">These cookies enable the website to provide enhanced functionality and personalisation. They may be set by us or by third party providers whose services we have added to our pages. If you do not allow these cookies then some or all of these services may not function properly.</p><div class="ot-hlst-cntr"><button class="ot-link-btn category-host-list-handler" aria-label="Cookie Details List" data-parent-id="3">Cookie Details List‎</button></div></div></div><div class="ot-accordion-layout ot-cat-item ot-vs-config" data-optanongroupid="2"><button aria-expanded="false" ot-accordion="true" aria-controls="ot-desc-id-2" aria-labelledby="ot-header-id-2"></button><!-- Accordion header --><div class="ot-acc-hdr"><div class="ot-plus-minus"><span></span><span></span></div><h4 class="ot-cat-header" id="ot-header-id-2">Performance Cookies</h4><div class="ot-tgl"><input type="checkbox" name="ot-group-id-2" id="ot-group-id-2" role="switch" class="category-switch-handler" data-optanongroupid="2" checked="" aria-labelledby="ot-header-id-2"> <label class="ot-switch" for="ot-group-id-2"><span class="ot-switch-nob" aria-checked="true" role="switch" aria-label="Performance Cookies"></span> <span class="ot-label-txt">Performance Cookies</span></label> </div></div><!-- accordion detail --><div class="ot-acc-grpcntr ot-acc-txt"><p class="ot-acc-grpdesc ot-category-desc" id="ot-desc-id-2">These cookies allow us to count visits and traffic sources so we can measure and improve the performance of our site. They help us to know which pages are the most and least popular and see how visitors move around the site.</p><div class="ot-hlst-cntr"><button class="ot-link-btn category-host-list-handler" aria-label="Cookie Details List" data-parent-id="2">Cookie Details List‎</button></div></div></div><div class="ot-accordion-layout ot-cat-item ot-vs-config" data-optanongroupid="4"><button aria-expanded="false" ot-accordion="true" aria-controls="ot-desc-id-4" aria-labelledby="ot-header-id-4"></button><!-- Accordion header --><div class="ot-acc-hdr"><div class="ot-plus-minus"><span></span><span></span></div><h4 class="ot-cat-header" id="ot-header-id-4">Targeting Cookies</h4><div class="ot-tgl"><input type="checkbox" name="ot-group-id-4" id="ot-group-id-4" role="switch" class="category-switch-handler" data-optanongroupid="4" checked="" aria-labelledby="ot-header-id-4"> <label class="ot-switch" for="ot-group-id-4"><span class="ot-switch-nob" aria-checked="true" role="switch" aria-label="Targeting Cookies"></span> <span class="ot-label-txt">Targeting Cookies</span></label> </div></div><!-- accordion detail --><div class="ot-acc-grpcntr ot-acc-txt"><p class="ot-acc-grpdesc ot-category-desc" id="ot-desc-id-4">These cookies may be set through our site by our advertising partners. They may be used by those companies to build a profile of your interests and show you relevant adverts on other sites. If you do not allow these cookies, you will experience less targeted advertising.</p><div class="ot-hlst-cntr"><button class="ot-link-btn category-host-list-handler" aria-label="Cookie Details List" data-parent-id="4">Cookie Details List‎</button></div></div></div><!-- Groups sections starts --><!-- Group section ends --><!-- Accordion Group section starts --><!-- Accordion Group section ends --></section></div><section id="ot-pc-lst" class="ot-hide ot-hosts-ui ot-pc-scrollbar"><div id="ot-pc-hdr"><div id="ot-lst-title"><button class="ot-link-btn back-btn-handler" aria-label="Back"><svg id="ot-back-arw" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" x="0px" y="0px" viewBox="0 0 444.531 444.531" xml:space="preserve"><title>Back Button</title><g><path fill="#656565" d="M213.13,222.409L351.88,83.653c7.05-7.043,10.567-15.657,10.567-25.841c0-10.183-3.518-18.793-10.567-25.835
                    l-21.409-21.416C323.432,3.521,314.817,0,304.637,0s-18.791,3.521-25.841,10.561L92.649,196.425
                    c-7.044,7.043-10.566,15.656-10.566,25.841s3.521,18.791,10.566,25.837l186.146,185.864c7.05,7.043,15.66,10.564,25.841,10.564
                    s18.795-3.521,25.834-10.564l21.409-21.412c7.05-7.039,10.567-15.604,10.567-25.697c0-10.085-3.518-18.746-10.567-25.978
                    L213.13,222.409z"></path></g></svg></button><h3>Cookie List</h3></div><div class="ot-lst-subhdr"><div class="ot-search-cntr"><p role="status" class="ot-scrn-rdr"></p><input id="vendor-search-handler" type="text" name="vendor-search-handler" placeholder="Search…" aria-label="Cookie list search"> <svg xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" x="0px" y="0px" viewBox="0 -30 110 110" aria-hidden="true"><title>Search Icon</title><path fill="#2e3644" d="M55.146,51.887L41.588,37.786c3.486-4.144,5.396-9.358,5.396-14.786c0-12.682-10.318-23-23-23s-23,10.318-23,23
            s10.318,23,23,23c4.761,0,9.298-1.436,13.177-4.162l13.661,14.208c0.571,0.593,1.339,0.92,2.162,0.92
            c0.779,0,1.518-0.297,2.079-0.837C56.255,54.982,56.293,53.08,55.146,51.887z M23.984,6c9.374,0,17,7.626,17,17s-7.626,17-17,17
            s-17-7.626-17-17S14.61,6,23.984,6z"></path></svg></div><div class="ot-fltr-cntr"><button id="filter-btn-handler" aria-label="Filter" aria-haspopup="true"><svg role="presentation" aria-hidden="true" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" x="0px" y="0px" viewBox="0 0 402.577 402.577" xml:space="preserve"><title>Filter Icon</title><g><path fill="#fff" d="M400.858,11.427c-3.241-7.421-8.85-11.132-16.854-11.136H18.564c-7.993,0-13.61,3.715-16.846,11.136
      c-3.234,7.801-1.903,14.467,3.999,19.985l140.757,140.753v138.755c0,4.955,1.809,9.232,5.424,12.854l73.085,73.083
      c3.429,3.614,7.71,5.428,12.851,5.428c2.282,0,4.66-0.479,7.135-1.43c7.426-3.238,11.14-8.851,11.14-16.845V172.166L396.861,31.413
      C402.765,25.895,404.093,19.231,400.858,11.427z"></path></g></svg></button></div><div id="ot-anchor"></div><section id="ot-fltr-modal"><div id="ot-fltr-cnt"><button id="clear-filters-handler">Clear</button><div class="ot-fltr-scrlcnt ot-pc-scrollbar"><div class="ot-fltr-opts"><div class="ot-fltr-opt"><div class="ot-chkbox"><input id="chkbox-id" type="checkbox" class="category-filter-handler"> <label for="chkbox-id"><span class="ot-label-txt">checkbox label</span></label> <span class="ot-label-status">label</span></div></div></div><div class="ot-fltr-btns"><button id="filter-apply-handler">Apply</button> <button id="filter-cancel-handler">Cancel</button></div></div></div></section></div></div><section id="ot-lst-cnt" class="ot-host-cnt ot-pc-scrollbar"><div id="ot-sel-blk"><div class="ot-sel-all"><div class="ot-sel-all-hdr"><span class="ot-consent-hdr">Consent</span> <span class="ot-li-hdr">Leg.Interest</span></div><div class="ot-sel-all-chkbox"><div class="ot-chkbox" id="ot-selall-hostcntr"><input id="select-all-hosts-groups-handler" type="checkbox"> <label for="select-all-hosts-groups-handler"><span class="ot-label-txt">checkbox label</span></label> <span class="ot-label-status">label</span></div><div class="ot-chkbox" id="ot-selall-vencntr"><input id="select-all-vendor-groups-handler" type="checkbox"> <label for="select-all-vendor-groups-handler"><span class="ot-label-txt">checkbox label</span></label> <span class="ot-label-status">label</span></div><div class="ot-chkbox" id="ot-selall-licntr"><input id="select-all-vendor-leg-handler" type="checkbox"> <label for="select-all-vendor-leg-handler"><span class="ot-label-txt">checkbox label</span></label> <span class="ot-label-status">label</span></div></div></div></div><div class="ot-sdk-row"><div class="ot-sdk-column"><ul id="ot-host-lst"></ul></div></div></section></section><div class="ot-pc-footer ot-pc-scrollbar"><div class="ot-btn-container"> <button class="save-preference-btn-handler onetrust-close-btn-handler">Confirm my choices</button></div><!-- Footer logo --><div class="ot-pc-footer-logo"><a href="https://www.onetrust.com/products/cookie-consent/" target="_blank" rel="noopener noreferrer" aria-label="Powered by OneTrust Opens in a new Tab"><img alt="Powered by Onetrust" src="https://cdn.cookielaw.org/logos/static/powered_by_logo.svg" title="Powered by OneTrust Opens in a new Tab"></a></div></div><!-- Cookie subgroup container --><!-- Vendor list link --><!-- Cookie lost link --><!-- Toggle HTML element --><!-- Checkbox HTML --><!-- plus minus--><!-- Arrow SVG element --><!-- Accordion basic element --><span class="ot-scrn-rdr" aria-atomic="true" aria-live="polite"></span><!-- Vendor Service container and item template --></div><iframe class="ot-text-resize" sandbox="allow-same-origin" title="onetrust-text-resize" style="position: absolute; top: -50000px; width: 100em;" aria-hidden="true"></iframe></div></div><button aria-label="Feedback" type="button" id="_pendo-badge_9BcFvkCLLiElWp6hocDK3ZG6Z4E" data-layout="badgeBlank" class="_pendo-badge _pendo-badge_" style="z-index: 19000; margin: 0px; height: 32px; width: 128px; font-size: 0px; background: rgba(255, 255, 255, 0); padding: 0px; line-height: 1; min-width: auto; box-shadow: rgb(136, 136, 136) 0px 0px 0px 0px; border: 0px; float: none; vertical-align: baseline; cursor: pointer; position: absolute; top: 39195px; left: 912px;"><img id="pendo-image-badge-19b66351" src="https://pendo-static-5661679399600128.storage.googleapis.com/D_T2uHq_M1r-XQq8htU6Z3GjHfE/guide-media-75af8ddc-3c43-49fd-8836-cfc7e2c3ea60" alt="Feedback" data-_pendo-image-1="" class="_pendo-image _pendo-badge-image" style="display: block; height: 32px; width: 128px; box-shadow: rgb(136, 136, 136) 0px 0px 0px 0px; float: none; vertical-align: baseline;"></button></body></html>