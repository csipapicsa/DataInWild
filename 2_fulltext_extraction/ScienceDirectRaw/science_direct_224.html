<html lang="en-US"><head>
      <meta name="citation_pii" content="S0925231219306137">
<meta name="citation_issn" content="0925-2312">
<meta name="citation_volume" content="355">
<meta name="citation_lastpage" content="92">
<meta name="citation_publisher" content="Elsevier">
<meta name="citation_firstpage" content="82">
<meta name="citation_journal_title" content="Neurocomputing">
<meta name="citation_type" content="JOUR">
<meta name="citation_doi" content="10.1016/j.neucom.2019.05.005">
<meta name="dc.identifier" content="10.1016/j.neucom.2019.05.005">
<meta name="citation_article_type" content="Full-length article">
<meta property="og:description" content="Facial expression recognition (FER) in the wild is a novel and challenging topic in the field of human emotion perception. Different kinds of convolutâ€¦">
<meta property="og:image" content="https://ars.els-cdn.com/content/image/1-s2.0-S0925231219X00259-cov150h.gif">
<meta name="citation_title" content="Three convolutional neural network models for facial expression recognition in the wild">
<meta property="og:title" content="Three convolutional neural network models for facial expression recognition in the wild">
<meta name="citation_publication_date" content="2019/08/25">
<meta name="citation_online_date" content="2019/05/10">
<meta name="robots" content="INDEX,FOLLOW,NOARCHIVE,NOCACHE,NOODP,NOYDIR">
      <title>Three convolutional neural network models for facial expression recognition in the wild - ScienceDirect</title>
      <link rel="canonical" href="https://www.sciencedirect.com/science/article/pii/S0925231219306137">
      <meta property="og:type" content="article">
      <meta name="viewport" content="initial-scale=1">
      <meta name="SDTech" content="Proudly brought to you by the SD Technology team">
      <script async="" src="https://cdn.pendo.io/agent/static/d6c1d995-bc7e-4e53-77f1-2ea4ecbb9565/pendo.js"></script><script type="text/javascript">(function newRelicBrowserProSPA() {
  ;
  window.NREUM || (NREUM = {});
  NREUM.init = {
    privacy: {
      cookies_enabled: true
    },
    ajax: {
      deny_list: ["bam-cell.nr-data.net"]
    }
  };
  ;
  NREUM.loader_config = {
    accountID: "2128461",
    trustKey: "2038175",
    agentID: "1118783207",
    licenseKey: "7ac4127487",
    applicationID: "814813181"
  };
  ;
  NREUM.info = {
    beacon: "bam.nr-data.net",
    errorBeacon: "bam.nr-data.net",
    licenseKey: "7ac4127487",
    applicationID: "814813181",
    sa: 1
  };
  ; /*! For license information please see nr-loader-spa-1.238.0.min.js.LICENSE.txt */
  (() => {
    "use strict";

    var e,
      t,
      r = {
        5763: (e, t, r) => {
          r.d(t, {
            P_: () => f,
            Mt: () => p,
            C5: () => s,
            DL: () => v,
            OP: () => T,
            lF: () => D,
            Yu: () => y,
            Dg: () => h,
            CX: () => c,
            GE: () => b,
            sU: () => _
          });
          var n = r(8632),
            i = r(9567);
          const o = {
              beacon: n.ce.beacon,
              errorBeacon: n.ce.errorBeacon,
              licenseKey: void 0,
              applicationID: void 0,
              sa: void 0,
              queueTime: void 0,
              applicationTime: void 0,
              ttGuid: void 0,
              user: void 0,
              account: void 0,
              product: void 0,
              extra: void 0,
              jsAttributes: {},
              userAttributes: void 0,
              atts: void 0,
              transactionName: void 0,
              tNamePlain: void 0
            },
            a = {};
          function s(e) {
            if (!e) throw new Error("All info objects require an agent identifier!");
            if (!a[e]) throw new Error("Info for ".concat(e, " was never set"));
            return a[e];
          }
          function c(e, t) {
            if (!e) throw new Error("All info objects require an agent identifier!");
            a[e] = (0, i.D)(t, o), (0, n.Qy)(e, a[e], "info");
          }
          var u = r(7056);
          const d = () => {
              const e = {
                blockSelector: "[data-nr-block]",
                maskInputOptions: {
                  password: !0
                }
              };
              return {
                allow_bfcache: !0,
                privacy: {
                  cookies_enabled: !0
                },
                ajax: {
                  deny_list: void 0,
                  block_internal: !0,
                  enabled: !0,
                  harvestTimeSeconds: 10
                },
                distributed_tracing: {
                  enabled: void 0,
                  exclude_newrelic_header: void 0,
                  cors_use_newrelic_header: void 0,
                  cors_use_tracecontext_headers: void 0,
                  allowed_origins: void 0
                },
                session: {
                  domain: void 0,
                  expiresMs: u.oD,
                  inactiveMs: u.Hb
                },
                ssl: void 0,
                obfuscate: void 0,
                jserrors: {
                  enabled: !0,
                  harvestTimeSeconds: 10
                },
                metrics: {
                  enabled: !0
                },
                page_action: {
                  enabled: !0,
                  harvestTimeSeconds: 30
                },
                page_view_event: {
                  enabled: !0
                },
                page_view_timing: {
                  enabled: !0,
                  harvestTimeSeconds: 30,
                  long_task: !1
                },
                session_trace: {
                  enabled: !0,
                  harvestTimeSeconds: 10
                },
                harvest: {
                  tooManyRequestsDelay: 60
                },
                session_replay: {
                  enabled: !1,
                  harvestTimeSeconds: 60,
                  sampleRate: .1,
                  errorSampleRate: .1,
                  maskTextSelector: "*",
                  maskAllInputs: !0,
                  get blockClass() {
                    return "nr-block";
                  },
                  get ignoreClass() {
                    return "nr-ignore";
                  },
                  get maskTextClass() {
                    return "nr-mask";
                  },
                  get blockSelector() {
                    return e.blockSelector;
                  },
                  set blockSelector(t) {
                    e.blockSelector += ",".concat(t);
                  },
                  get maskInputOptions() {
                    return e.maskInputOptions;
                  },
                  set maskInputOptions(t) {
                    e.maskInputOptions = {
                      ...t,
                      password: !0
                    };
                  }
                },
                spa: {
                  enabled: !0,
                  harvestTimeSeconds: 10
                }
              };
            },
            l = {};
          function f(e) {
            if (!e) throw new Error("All configuration objects require an agent identifier!");
            if (!l[e]) throw new Error("Configuration for ".concat(e, " was never set"));
            return l[e];
          }
          function h(e, t) {
            if (!e) throw new Error("All configuration objects require an agent identifier!");
            l[e] = (0, i.D)(t, d()), (0, n.Qy)(e, l[e], "config");
          }
          function p(e, t) {
            if (!e) throw new Error("All configuration objects require an agent identifier!");
            var r = f(e);
            if (r) {
              for (var n = t.split("."), i = 0; i < n.length - 1; i++) if ("object" != typeof (r = r[n[i]])) return;
              r = r[n[n.length - 1]];
            }
            return r;
          }
          const g = {
              accountID: void 0,
              trustKey: void 0,
              agentID: void 0,
              licenseKey: void 0,
              applicationID: void 0,
              xpid: void 0
            },
            m = {};
          function v(e) {
            if (!e) throw new Error("All loader-config objects require an agent identifier!");
            if (!m[e]) throw new Error("LoaderConfig for ".concat(e, " was never set"));
            return m[e];
          }
          function b(e, t) {
            if (!e) throw new Error("All loader-config objects require an agent identifier!");
            m[e] = (0, i.D)(t, g), (0, n.Qy)(e, m[e], "loader_config");
          }
          const y = (0, n.mF)().o;
          var w = r(385),
            A = r(6818);
          const x = {
              buildEnv: A.Re,
              bytesSent: {},
              queryBytesSent: {},
              customTransaction: void 0,
              disabled: !1,
              distMethod: A.gF,
              isolatedBacklog: !1,
              loaderType: void 0,
              maxBytes: 3e4,
              offset: Math.floor(w._A?.performance?.timeOrigin || w._A?.performance?.timing?.navigationStart || Date.now()),
              onerror: void 0,
              origin: "" + w._A.location,
              ptid: void 0,
              releaseIds: {},
              session: void 0,
              xhrWrappable: "function" == typeof w._A.XMLHttpRequest?.prototype?.addEventListener,
              version: A.q4,
              denyList: void 0
            },
            E = {};
          function T(e) {
            if (!e) throw new Error("All runtime objects require an agent identifier!");
            if (!E[e]) throw new Error("Runtime for ".concat(e, " was never set"));
            return E[e];
          }
          function _(e, t) {
            if (!e) throw new Error("All runtime objects require an agent identifier!");
            E[e] = (0, i.D)(t, x), (0, n.Qy)(e, E[e], "runtime");
          }
          function D(e) {
            return function (e) {
              try {
                const t = s(e);
                return !!t.licenseKey && !!t.errorBeacon && !!t.applicationID;
              } catch (e) {
                return !1;
              }
            }(e);
          }
        },
        9567: (e, t, r) => {
          r.d(t, {
            D: () => i
          });
          var n = r(50);
          function i(e, t) {
            try {
              if (!e || "object" != typeof e) return (0, n.Z)("Setting a Configurable requires an object as input");
              if (!t || "object" != typeof t) return (0, n.Z)("Setting a Configurable requires a model to set its initial properties");
              const r = Object.create(Object.getPrototypeOf(t), Object.getOwnPropertyDescriptors(t)),
                o = 0 === Object.keys(r).length ? e : r;
              for (let a in o) if (void 0 !== e[a]) try {
                "object" == typeof e[a] && "object" == typeof t[a] ? r[a] = i(e[a], t[a]) : r[a] = e[a];
              } catch (e) {
                (0, n.Z)("An error occurred while setting a property of a Configurable", e);
              }
              return r;
            } catch (e) {
              (0, n.Z)("An error occured while setting a Configurable", e);
            }
          }
        },
        6818: (e, t, r) => {
          r.d(t, {
            Re: () => i,
            gF: () => o,
            q4: () => n
          });
          const n = "1.238.0",
            i = "PROD",
            o = "CDN";
        },
        385: (e, t, r) => {
          r.d(t, {
            FN: () => a,
            IF: () => u,
            Nk: () => l,
            Tt: () => s,
            _A: () => o,
            il: () => n,
            pL: () => c,
            v6: () => i,
            w1: () => d
          });
          const n = "undefined" != typeof window && !!window.document,
            i = "undefined" != typeof WorkerGlobalScope && ("undefined" != typeof self && self instanceof WorkerGlobalScope && self.navigator instanceof WorkerNavigator || "undefined" != typeof globalThis && globalThis instanceof WorkerGlobalScope && globalThis.navigator instanceof WorkerNavigator),
            o = n ? window : "undefined" != typeof WorkerGlobalScope && ("undefined" != typeof self && self instanceof WorkerGlobalScope && self || "undefined" != typeof globalThis && globalThis instanceof WorkerGlobalScope && globalThis),
            a = "" + o?.location,
            s = /iPad|iPhone|iPod/.test(navigator.userAgent),
            c = s && "undefined" == typeof SharedWorker,
            u = (() => {
              const e = navigator.userAgent.match(/Firefox[/\s](\d+\.\d+)/);
              return Array.isArray(e) && e.length >= 2 ? +e[1] : 0;
            })(),
            d = Boolean(n && window.document.documentMode),
            l = !!navigator.sendBeacon;
        },
        1117: (e, t, r) => {
          r.d(t, {
            w: () => o
          });
          var n = r(50);
          const i = {
            agentIdentifier: "",
            ee: void 0
          };
          class o {
            constructor(e) {
              try {
                if ("object" != typeof e) return (0, n.Z)("shared context requires an object as input");
                this.sharedContext = {}, Object.assign(this.sharedContext, i), Object.entries(e).forEach(e => {
                  let [t, r] = e;
                  Object.keys(i).includes(t) && (this.sharedContext[t] = r);
                });
              } catch (e) {
                (0, n.Z)("An error occured while setting SharedContext", e);
              }
            }
          }
        },
        8e3: (e, t, r) => {
          r.d(t, {
            L: () => d,
            R: () => c
          });
          var n = r(8325),
            i = r(1284),
            o = r(4322),
            a = r(3325);
          const s = {};
          function c(e, t) {
            const r = {
              staged: !1,
              priority: a.p[t] || 0
            };
            u(e), s[e].get(t) || s[e].set(t, r);
          }
          function u(e) {
            e && (s[e] || (s[e] = new Map()));
          }
          function d() {
            let e = arguments.length > 0 && void 0 !== arguments[0] ? arguments[0] : "",
              t = arguments.length > 1 && void 0 !== arguments[1] ? arguments[1] : "feature";
            if (u(e), !e || !s[e].get(t)) return a(t);
            s[e].get(t).staged = !0;
            const r = [...s[e]];
            function a(t) {
              const r = e ? n.ee.get(e) : n.ee,
                a = o.X.handlers;
              if (r.backlog && a) {
                var s = r.backlog[t],
                  c = a[t];
                if (c) {
                  for (var u = 0; s && u < s.length; ++u) l(s[u], c);
                  (0, i.D)(c, function (e, t) {
                    (0, i.D)(t, function (t, r) {
                      r[0].on(e, r[1]);
                    });
                  });
                }
                delete a[t], r.backlog[t] = null, r.emit("drain-" + t, []);
              }
            }
            r.every(e => {
              let [t, r] = e;
              return r.staged;
            }) && (r.sort((e, t) => e[1].priority - t[1].priority), r.forEach(e => {
              let [t] = e;
              a(t);
            }));
          }
          function l(e, t) {
            var r = e[1];
            (0, i.D)(t[r], function (t, r) {
              var n = e[0];
              if (r[0] === n) {
                var i = r[1],
                  o = e[3],
                  a = e[2];
                i.apply(o, a);
              }
            });
          }
        },
        8325: (e, t, r) => {
          r.d(t, {
            A: () => c,
            ee: () => u
          });
          var n = r(8632),
            i = r(2210),
            o = r(5763);
          class a {
            constructor(e) {
              this.contextId = e;
            }
          }
          var s = r(3117);
          const c = "nr@context:".concat(s.a),
            u = function e(t, r) {
              var n = {},
                s = {},
                d = {},
                f = !1;
              try {
                f = 16 === r.length && (0, o.OP)(r).isolatedBacklog;
              } catch (e) {}
              var h = {
                on: g,
                addEventListener: g,
                removeEventListener: function (e, t) {
                  var r = n[e];
                  if (!r) return;
                  for (var i = 0; i < r.length; i++) r[i] === t && r.splice(i, 1);
                },
                emit: function (e, r, n, i, o) {
                  !1 !== o && (o = !0);
                  if (u.aborted && !i) return;
                  t && o && t.emit(e, r, n);
                  for (var a = p(n), c = m(e), d = c.length, l = 0; l < d; l++) c[l].apply(a, r);
                  var f = b()[s[e]];
                  f && f.push([h, e, r, a]);
                  return a;
                },
                get: v,
                listeners: m,
                context: p,
                buffer: function (e, t) {
                  const r = b();
                  if (t = t || "feature", h.aborted) return;
                  Object.entries(e || {}).forEach(e => {
                    let [n, i] = e;
                    s[i] = t, t in r || (r[t] = []);
                  });
                },
                abort: l,
                aborted: !1,
                isBuffering: function (e) {
                  return !!b()[s[e]];
                },
                debugId: r,
                backlog: f ? {} : t && "object" == typeof t.backlog ? t.backlog : {}
              };
              return h;
              function p(e) {
                return e && e instanceof a ? e : e ? (0, i.X)(e, c, () => new a(c)) : new a(c);
              }
              function g(e, t) {
                n[e] = m(e).concat(t);
              }
              function m(e) {
                return n[e] || [];
              }
              function v(t) {
                return d[t] = d[t] || e(h, t);
              }
              function b() {
                return h.backlog;
              }
            }(void 0, "globalEE"),
            d = (0, n.fP)();
          function l() {
            u.aborted = !0, u.backlog = {};
          }
          d.ee || (d.ee = u);
        },
        5546: (e, t, r) => {
          r.d(t, {
            E: () => n,
            p: () => i
          });
          var n = r(8325).ee.get("handle");
          function i(e, t, r, i, o) {
            o ? (o.buffer([e], i), o.emit(e, t, r)) : (n.buffer([e], i), n.emit(e, t, r));
          }
        },
        4322: (e, t, r) => {
          r.d(t, {
            X: () => o
          });
          var n = r(5546);
          o.on = a;
          var i = o.handlers = {};
          function o(e, t, r, o) {
            a(o || n.E, i, e, t, r);
          }
          function a(e, t, r, i, o) {
            o || (o = "feature"), e || (e = n.E);
            var a = t[o] = t[o] || {};
            (a[r] = a[r] || []).push([e, i]);
          }
        },
        3239: (e, t, r) => {
          r.d(t, {
            bP: () => s,
            iz: () => c,
            m$: () => a
          });
          var n = r(385);
          let i = !1,
            o = !1;
          try {
            const e = {
              get passive() {
                return i = !0, !1;
              },
              get signal() {
                return o = !0, !1;
              }
            };
            n._A.addEventListener("test", null, e), n._A.removeEventListener("test", null, e);
          } catch (e) {}
          function a(e, t) {
            return i || o ? {
              capture: !!e,
              passive: i,
              signal: t
            } : !!e;
          }
          function s(e, t) {
            let r = arguments.length > 2 && void 0 !== arguments[2] && arguments[2],
              n = arguments.length > 3 ? arguments[3] : void 0;
            window.addEventListener(e, t, a(r, n));
          }
          function c(e, t) {
            let r = arguments.length > 2 && void 0 !== arguments[2] && arguments[2],
              n = arguments.length > 3 ? arguments[3] : void 0;
            document.addEventListener(e, t, a(r, n));
          }
        },
        3117: (e, t, r) => {
          r.d(t, {
            a: () => n
          });
          const n = (0, r(4402).Rl)();
        },
        4402: (e, t, r) => {
          r.d(t, {
            Ht: () => u,
            M: () => c,
            Rl: () => a,
            ky: () => s
          });
          var n = r(385);
          const i = "xxxxxxxx-xxxx-4xxx-yxxx-xxxxxxxxxxxx";
          function o(e, t) {
            return e ? 15 & e[t] : 16 * Math.random() | 0;
          }
          function a() {
            const e = n._A?.crypto || n._A?.msCrypto;
            let t,
              r = 0;
            return e && e.getRandomValues && (t = e.getRandomValues(new Uint8Array(31))), i.split("").map(e => "x" === e ? o(t, ++r).toString(16) : "y" === e ? (3 & o() | 8).toString(16) : e).join("");
          }
          function s(e) {
            const t = n._A?.crypto || n._A?.msCrypto;
            let r,
              i = 0;
            t && t.getRandomValues && (r = t.getRandomValues(new Uint8Array(31)));
            const a = [];
            for (var s = 0; s < e; s++) a.push(o(r, ++i).toString(16));
            return a.join("");
          }
          function c() {
            return s(16);
          }
          function u() {
            return s(32);
          }
        },
        7056: (e, t, r) => {
          r.d(t, {
            Bq: () => n,
            Hb: () => o,
            oD: () => i
          });
          const n = "NRBA",
            i = 144e5,
            o = 18e5;
        },
        7894: (e, t, r) => {
          function n() {
            return Math.round(performance.now());
          }
          r.d(t, {
            z: () => n
          });
        },
        7243: (e, t, r) => {
          r.d(t, {
            e: () => o
          });
          var n = r(385),
            i = {};
          function o(e) {
            if (e in i) return i[e];
            if (0 === (e || "").indexOf("data:")) return {
              protocol: "data"
            };
            let t;
            var r = n._A?.location,
              o = {};
            if (n.il) t = document.createElement("a"), t.href = e;else try {
              t = new URL(e, r.href);
            } catch (e) {
              return o;
            }
            o.port = t.port;
            var a = t.href.split("://");
            !o.port && a[1] && (o.port = a[1].split("/")[0].split("@").pop().split(":")[1]), o.port && "0" !== o.port || (o.port = "https" === a[0] ? "443" : "80"), o.hostname = t.hostname || r.hostname, o.pathname = t.pathname, o.protocol = a[0], "/" !== o.pathname.charAt(0) && (o.pathname = "/" + o.pathname);
            var s = !t.protocol || ":" === t.protocol || t.protocol === r.protocol,
              c = t.hostname === r.hostname && t.port === r.port;
            return o.sameOrigin = s && (!t.hostname || c), "/" === o.pathname && (i[e] = o), o;
          }
        },
        50: (e, t, r) => {
          function n(e, t) {
            "function" == typeof console.warn && (console.warn("New Relic: ".concat(e)), t && console.warn(t));
          }
          r.d(t, {
            Z: () => n
          });
        },
        2587: (e, t, r) => {
          r.d(t, {
            N: () => c,
            T: () => u
          });
          var n = r(8325),
            i = r(5546),
            o = r(8e3),
            a = r(3325);
          const s = {
            stn: [a.D.sessionTrace],
            err: [a.D.jserrors, a.D.metrics],
            ins: [a.D.pageAction],
            spa: [a.D.spa],
            sr: [a.D.sessionReplay, a.D.sessionTrace]
          };
          function c(e, t) {
            const r = n.ee.get(t);
            e && "object" == typeof e && (Object.entries(e).forEach(e => {
              let [t, n] = e;
              void 0 === u[t] && (s[t] ? s[t].forEach(e => {
                n ? (0, i.p)("feat-" + t, [], void 0, e, r) : (0, i.p)("block-" + t, [], void 0, e, r), (0, i.p)("rumresp-" + t, [Boolean(n)], void 0, e, r);
              }) : n && (0, i.p)("feat-" + t, [], void 0, void 0, r), u[t] = Boolean(n));
            }), Object.keys(s).forEach(e => {
              void 0 === u[e] && (s[e]?.forEach(t => (0, i.p)("rumresp-" + e, [!1], void 0, t, r)), u[e] = !1);
            }), (0, o.L)(t, a.D.pageViewEvent));
          }
          const u = {};
        },
        2210: (e, t, r) => {
          r.d(t, {
            X: () => i
          });
          var n = Object.prototype.hasOwnProperty;
          function i(e, t, r) {
            if (n.call(e, t)) return e[t];
            var i = r();
            if (Object.defineProperty && Object.keys) try {
              return Object.defineProperty(e, t, {
                value: i,
                writable: !0,
                enumerable: !1
              }), i;
            } catch (e) {}
            return e[t] = i, i;
          }
        },
        1284: (e, t, r) => {
          r.d(t, {
            D: () => n
          });
          const n = (e, t) => Object.entries(e || {}).map(e => {
            let [r, n] = e;
            return t(r, n);
          });
        },
        4351: (e, t, r) => {
          r.d(t, {
            P: () => o
          });
          var n = r(8325);
          const i = () => {
            const e = new WeakSet();
            return (t, r) => {
              if ("object" == typeof r && null !== r) {
                if (e.has(r)) return;
                e.add(r);
              }
              return r;
            };
          };
          function o(e) {
            try {
              return JSON.stringify(e, i());
            } catch (e) {
              try {
                n.ee.emit("internal-error", [e]);
              } catch (e) {}
            }
          }
        },
        3960: (e, t, r) => {
          r.d(t, {
            K: () => a,
            b: () => o
          });
          var n = r(3239);
          function i() {
            return "undefined" == typeof document || "complete" === document.readyState;
          }
          function o(e, t) {
            if (i()) return e();
            (0, n.bP)("load", e, t);
          }
          function a(e) {
            if (i()) return e();
            (0, n.iz)("DOMContentLoaded", e);
          }
        },
        8632: (e, t, r) => {
          r.d(t, {
            EZ: () => u,
            Qy: () => c,
            ce: () => o,
            fP: () => a,
            gG: () => d,
            mF: () => s
          });
          var n = r(7894),
            i = r(385);
          const o = {
            beacon: "bam.nr-data.net",
            errorBeacon: "bam.nr-data.net"
          };
          function a() {
            return i._A.NREUM || (i._A.NREUM = {}), void 0 === i._A.newrelic && (i._A.newrelic = i._A.NREUM), i._A.NREUM;
          }
          function s() {
            let e = a();
            return e.o || (e.o = {
              ST: i._A.setTimeout,
              SI: i._A.setImmediate,
              CT: i._A.clearTimeout,
              XHR: i._A.XMLHttpRequest,
              REQ: i._A.Request,
              EV: i._A.Event,
              PR: i._A.Promise,
              MO: i._A.MutationObserver,
              FETCH: i._A.fetch
            }), e;
          }
          function c(e, t, r) {
            let i = a();
            const o = i.initializedAgents || {},
              s = o[e] || {};
            return Object.keys(s).length || (s.initializedAt = {
              ms: (0, n.z)(),
              date: new Date()
            }), i.initializedAgents = {
              ...o,
              [e]: {
                ...s,
                [r]: t
              }
            }, i;
          }
          function u(e, t) {
            a()[e] = t;
          }
          function d() {
            return function () {
              let e = a();
              const t = e.info || {};
              e.info = {
                beacon: o.beacon,
                errorBeacon: o.errorBeacon,
                ...t
              };
            }(), function () {
              let e = a();
              const t = e.init || {};
              e.init = {
                ...t
              };
            }(), s(), function () {
              let e = a();
              const t = e.loader_config || {};
              e.loader_config = {
                ...t
              };
            }(), a();
          }
        },
        7956: (e, t, r) => {
          r.d(t, {
            N: () => i
          });
          var n = r(3239);
          function i(e) {
            let t = arguments.length > 1 && void 0 !== arguments[1] && arguments[1],
              r = arguments.length > 2 ? arguments[2] : void 0,
              i = arguments.length > 3 ? arguments[3] : void 0;
            return void (0, n.iz)("visibilitychange", function () {
              if (t) return void ("hidden" == document.visibilityState && e());
              e(document.visibilityState);
            }, r, i);
          }
        },
        1214: (e, t, r) => {
          r.d(t, {
            em: () => b,
            u5: () => j,
            QU: () => O,
            _L: () => I,
            Gm: () => H,
            Lg: () => L,
            BV: () => G,
            Kf: () => K
          });
          var n = r(8325),
            i = r(3117);
          const o = "nr@original:".concat(i.a);
          var a = Object.prototype.hasOwnProperty,
            s = !1;
          function c(e, t) {
            return e || (e = n.ee), r.inPlace = function (e, t, n, i, o) {
              n || (n = "");
              const a = "-" === n.charAt(0);
              for (let s = 0; s < t.length; s++) {
                const c = t[s],
                  u = e[c];
                d(u) || (e[c] = r(u, a ? c + n : n, i, c, o));
              }
            }, r.flag = o, r;
            function r(t, r, n, s, c) {
              return d(t) ? t : (r || (r = ""), nrWrapper[o] = t, function (e, t, r) {
                if (Object.defineProperty && Object.keys) try {
                  return Object.keys(e).forEach(function (r) {
                    Object.defineProperty(t, r, {
                      get: function () {
                        return e[r];
                      },
                      set: function (t) {
                        return e[r] = t, t;
                      }
                    });
                  }), t;
                } catch (e) {
                  u([e], r);
                }
                for (var n in e) a.call(e, n) && (t[n] = e[n]);
              }(t, nrWrapper, e), nrWrapper);
              function nrWrapper() {
                var o, a, d, l;
                try {
                  a = this, o = [...arguments], d = "function" == typeof n ? n(o, a) : n || {};
                } catch (t) {
                  u([t, "", [o, a, s], d], e);
                }
                i(r + "start", [o, a, s], d, c);
                try {
                  return l = t.apply(a, o);
                } catch (e) {
                  throw i(r + "err", [o, a, e], d, c), e;
                } finally {
                  i(r + "end", [o, a, l], d, c);
                }
              }
            }
            function i(r, n, i, o) {
              if (!s || t) {
                var a = s;
                s = !0;
                try {
                  e.emit(r, n, i, t, o);
                } catch (t) {
                  u([t, r, n, i], e);
                }
                s = a;
              }
            }
          }
          function u(e, t) {
            t || (t = n.ee);
            try {
              t.emit("internal-error", e);
            } catch (e) {}
          }
          function d(e) {
            return !(e && e instanceof Function && e.apply && !e[o]);
          }
          var l = r(2210),
            f = r(385);
          const h = {},
            p = f._A.XMLHttpRequest,
            g = "addEventListener",
            m = "removeEventListener",
            v = "nr@wrapped:".concat(n.A);
          function b(e) {
            var t = function (e) {
              return (e || n.ee).get("events");
            }(e);
            if (h[t.debugId]++) return t;
            h[t.debugId] = 1;
            var r = c(t, !0);
            function i(e) {
              r.inPlace(e, [g, m], "-", o);
            }
            function o(e, t) {
              return e[1];
            }
            return "getPrototypeOf" in Object && (f.il && y(document, i), y(f._A, i), y(p.prototype, i)), t.on(g + "-start", function (e, t) {
              var n = e[1];
              if (null !== n && ("function" == typeof n || "object" == typeof n)) {
                var i = (0, l.X)(n, v, function () {
                  var e = {
                    object: function () {
                      if ("function" != typeof n.handleEvent) return;
                      return n.handleEvent.apply(n, arguments);
                    },
                    function: n
                  }[typeof n];
                  return e ? r(e, "fn-", null, e.name || "anonymous") : n;
                });
                this.wrapped = e[1] = i;
              }
            }), t.on(m + "-start", function (e) {
              e[1] = this.wrapped || e[1];
            }), t;
          }
          function y(e, t) {
            let r = e;
            for (; "object" == typeof r && !Object.prototype.hasOwnProperty.call(r, g);) r = Object.getPrototypeOf(r);
            for (var n = arguments.length, i = new Array(n > 2 ? n - 2 : 0), o = 2; o < n; o++) i[o - 2] = arguments[o];
            r && t(r, ...i);
          }
          var w = "fetch-",
            A = w + "body-",
            x = ["arrayBuffer", "blob", "json", "text", "formData"],
            E = f._A.Request,
            T = f._A.Response,
            _ = "prototype";
          const D = {};
          function j(e) {
            const t = function (e) {
              return (e || n.ee).get("fetch");
            }(e);
            if (!(E && T && f._A.fetch)) return t;
            if (D[t.debugId]++) return t;
            function r(e, r, i) {
              var o = e[r];
              "function" == typeof o && (e[r] = function () {
                var e,
                  r = [...arguments],
                  a = {};
                t.emit(i + "before-start", [r], a), a[n.A] && a[n.A].dt && (e = a[n.A].dt);
                var s = o.apply(this, r);
                return t.emit(i + "start", [r, e], s), s.then(function (e) {
                  return t.emit(i + "end", [null, e], s), e;
                }, function (e) {
                  throw t.emit(i + "end", [e], s), e;
                });
              });
            }
            return D[t.debugId] = 1, x.forEach(e => {
              r(E[_], e, A), r(T[_], e, A);
            }), r(f._A, "fetch", w), t.on(w + "end", function (e, r) {
              var n = this;
              if (r) {
                var i = r.headers.get("content-length");
                null !== i && (n.rxSize = i), t.emit(w + "done", [null, r], n);
              } else t.emit(w + "done", [e], n);
            }), t;
          }
          const C = {},
            N = ["pushState", "replaceState"];
          function O(e) {
            const t = function (e) {
              return (e || n.ee).get("history");
            }(e);
            return !f.il || C[t.debugId]++ || (C[t.debugId] = 1, c(t).inPlace(window.history, N, "-")), t;
          }
          var S = r(3239);
          const P = {},
            R = ["appendChild", "insertBefore", "replaceChild"];
          function I(e) {
            const t = function (e) {
              return (e || n.ee).get("jsonp");
            }(e);
            if (!f.il || P[t.debugId]) return t;
            P[t.debugId] = !0;
            var r = c(t),
              i = /[?&](?:callback|cb)=([^&#]+)/,
              o = /(.*)\.([^.]+)/,
              a = /^(\w+)(\.|$)(.*)$/;
            function s(e, t) {
              if (!e) return t;
              const r = e.match(a),
                n = r[1];
              return s(r[3], t[n]);
            }
            return r.inPlace(Node.prototype, R, "dom-"), t.on("dom-start", function (e) {
              !function (e) {
                if (!e || "string" != typeof e.nodeName || "script" !== e.nodeName.toLowerCase()) return;
                if ("function" != typeof e.addEventListener) return;
                var n = (a = e.src, c = a.match(i), c ? c[1] : null);
                var a, c;
                if (!n) return;
                var u = function (e) {
                  var t = e.match(o);
                  if (t && t.length >= 3) return {
                    key: t[2],
                    parent: s(t[1], window)
                  };
                  return {
                    key: e,
                    parent: window
                  };
                }(n);
                if ("function" != typeof u.parent[u.key]) return;
                var d = {};
                function l() {
                  t.emit("jsonp-end", [], d), e.removeEventListener("load", l, (0, S.m$)(!1)), e.removeEventListener("error", f, (0, S.m$)(!1));
                }
                function f() {
                  t.emit("jsonp-error", [], d), t.emit("jsonp-end", [], d), e.removeEventListener("load", l, (0, S.m$)(!1)), e.removeEventListener("error", f, (0, S.m$)(!1));
                }
                r.inPlace(u.parent, [u.key], "cb-", d), e.addEventListener("load", l, (0, S.m$)(!1)), e.addEventListener("error", f, (0, S.m$)(!1)), t.emit("new-jsonp", [e.src], d);
              }(e[0]);
            }), t;
          }
          const k = {};
          function H(e) {
            const t = function (e) {
              return (e || n.ee).get("mutation");
            }(e);
            if (!f.il || k[t.debugId]) return t;
            k[t.debugId] = !0;
            var r = c(t),
              i = f._A.MutationObserver;
            return i && (window.MutationObserver = function (e) {
              return this instanceof i ? new i(r(e, "fn-")) : i.apply(this, arguments);
            }, MutationObserver.prototype = i.prototype), t;
          }
          const z = {};
          function L(e) {
            const t = function (e) {
              return (e || n.ee).get("promise");
            }(e);
            if (z[t.debugId]) return t;
            z[t.debugId] = !0;
            var r = t.context,
              i = c(t),
              a = f._A.Promise;
            return a && function () {
              function e(r) {
                var n = t.context(),
                  o = i(r, "executor-", n, null, !1);
                const s = Reflect.construct(a, [o], e);
                return t.context(s).getCtx = function () {
                  return n;
                }, s;
              }
              f._A.Promise = e, Object.defineProperty(e, "name", {
                value: "Promise"
              }), e.toString = function () {
                return a.toString();
              }, Object.setPrototypeOf(e, a), ["all", "race"].forEach(function (r) {
                const n = a[r];
                e[r] = function (e) {
                  let i = !1;
                  [...(e || [])].forEach(e => {
                    this.resolve(e).then(a("all" === r), a(!1));
                  });
                  const o = n.apply(this, arguments);
                  return o;
                  function a(e) {
                    return function () {
                      t.emit("propagate", [null, !i], o, !1, !1), i = i || !e;
                    };
                  }
                };
              }), ["resolve", "reject"].forEach(function (r) {
                const n = a[r];
                e[r] = function (e) {
                  const r = n.apply(this, arguments);
                  return e !== r && t.emit("propagate", [e, !0], r, !1, !1), r;
                };
              }), e.prototype = a.prototype;
              const n = a.prototype.then;
              a.prototype.then = function () {
                var e = this,
                  o = r(e);
                o.promise = e;
                for (var a = arguments.length, s = new Array(a), c = 0; c < a; c++) s[c] = arguments[c];
                s[0] = i(s[0], "cb-", o, null, !1), s[1] = i(s[1], "cb-", o, null, !1);
                const u = n.apply(this, s);
                return o.nextPromise = u, t.emit("propagate", [e, !0], u, !1, !1), u;
              }, a.prototype.then[o] = n, t.on("executor-start", function (e) {
                e[0] = i(e[0], "resolve-", this, null, !1), e[1] = i(e[1], "resolve-", this, null, !1);
              }), t.on("executor-err", function (e, t, r) {
                e[1](r);
              }), t.on("cb-end", function (e, r, n) {
                t.emit("propagate", [n, !0], this.nextPromise, !1, !1);
              }), t.on("propagate", function (e, r, n) {
                this.getCtx && !r || (this.getCtx = function () {
                  if (e instanceof Promise) var r = t.context(e);
                  return r && r.getCtx ? r.getCtx() : this;
                });
              });
            }(), t;
          }
          const M = {},
            B = "setTimeout",
            F = "setInterval",
            U = "clearTimeout",
            q = "-start",
            Z = "-",
            V = [B, "setImmediate", F, U, "clearImmediate"];
          function G(e) {
            const t = function (e) {
              return (e || n.ee).get("timer");
            }(e);
            if (M[t.debugId]++) return t;
            M[t.debugId] = 1;
            var r = c(t);
            return r.inPlace(f._A, V.slice(0, 2), B + Z), r.inPlace(f._A, V.slice(2, 3), F + Z), r.inPlace(f._A, V.slice(3), U + Z), t.on(F + q, function (e, t, n) {
              e[0] = r(e[0], "fn-", null, n);
            }), t.on(B + q, function (e, t, n) {
              this.method = n, this.timerDuration = isNaN(e[1]) ? 0 : +e[1], e[0] = r(e[0], "fn-", this, n);
            }), t;
          }
          var W = r(50);
          const X = {},
            Q = ["open", "send"];
          function K(e) {
            var t = e || n.ee;
            const r = function (e) {
              return (e || n.ee).get("xhr");
            }(t);
            if (X[r.debugId]++) return r;
            X[r.debugId] = 1, b(t);
            var i = c(r),
              o = f._A.XMLHttpRequest,
              a = f._A.MutationObserver,
              s = f._A.Promise,
              u = f._A.setInterval,
              d = "readystatechange",
              l = ["onload", "onerror", "onabort", "onloadstart", "onloadend", "onprogress", "ontimeout"],
              h = [],
              p = f._A.XMLHttpRequest = function (e) {
                const t = new o(e),
                  n = r.context(t);
                try {
                  r.emit("new-xhr", [t], n), t.addEventListener(d, (a = n, function () {
                    var e = this;
                    e.readyState > 3 && !a.resolved && (a.resolved = !0, r.emit("xhr-resolved", [], e)), i.inPlace(e, l, "fn-", A);
                  }), (0, S.m$)(!1));
                } catch (e) {
                  (0, W.Z)("An error occurred while intercepting XHR", e);
                  try {
                    r.emit("internal-error", [e]);
                  } catch (e) {}
                }
                var a;
                return t;
              };
            function g(e, t) {
              i.inPlace(t, ["onreadystatechange"], "fn-", A);
            }
            if (function (e, t) {
              for (var r in e) t[r] = e[r];
            }(o, p), p.prototype = o.prototype, i.inPlace(p.prototype, Q, "-xhr-", A), r.on("send-xhr-start", function (e, t) {
              g(e, t), function (e) {
                h.push(e), a && (m ? m.then(w) : u ? u(w) : (v = -v, y.data = v));
              }(t);
            }), r.on("open-xhr-start", g), a) {
              var m = s && s.resolve();
              if (!u && !s) {
                var v = 1,
                  y = document.createTextNode(v);
                new a(w).observe(y, {
                  characterData: !0
                });
              }
            } else t.on("fn-end", function (e) {
              e[0] && e[0].type === d || w();
            });
            function w() {
              for (var e = 0; e < h.length; e++) g(0, h[e]);
              h.length && (h = []);
            }
            function A(e, t) {
              return t;
            }
            return r;
          }
        },
        7825: (e, t, r) => {
          r.d(t, {
            t: () => n
          });
          const n = r(3325).D.ajax;
        },
        6660: (e, t, r) => {
          r.d(t, {
            t: () => n
          });
          const n = r(3325).D.jserrors;
        },
        3081: (e, t, r) => {
          r.d(t, {
            gF: () => o,
            mY: () => i,
            t9: () => n,
            vz: () => s,
            xS: () => a
          });
          const n = r(3325).D.metrics,
            i = "sm",
            o = "cm",
            a = "storeSupportabilityMetrics",
            s = "storeEventMetrics";
        },
        4649: (e, t, r) => {
          r.d(t, {
            t: () => n
          });
          const n = r(3325).D.pageAction;
        },
        7633: (e, t, r) => {
          r.d(t, {
            Dz: () => i,
            OJ: () => a,
            qw: () => o,
            t9: () => n
          });
          const n = r(3325).D.pageViewEvent,
            i = "firstbyte",
            o = "domcontent",
            a = "windowload";
        },
        9251: (e, t, r) => {
          r.d(t, {
            t: () => n
          });
          const n = r(3325).D.pageViewTiming;
        },
        3614: (e, t, r) => {
          r.d(t, {
            BST_RESOURCE: () => i,
            END: () => s,
            FEATURE_NAME: () => n,
            FN_END: () => u,
            FN_START: () => c,
            PUSH_STATE: () => d,
            RESOURCE: () => o,
            START: () => a
          });
          const n = r(3325).D.sessionTrace,
            i = "bstResource",
            o = "resource",
            a = "-start",
            s = "-end",
            c = "fn" + a,
            u = "fn" + s,
            d = "pushState";
        },
        7836: (e, t, r) => {
          r.d(t, {
            BODY: () => x,
            CB_END: () => E,
            CB_START: () => u,
            END: () => A,
            FEATURE_NAME: () => i,
            FETCH: () => _,
            FETCH_BODY: () => v,
            FETCH_DONE: () => m,
            FETCH_START: () => g,
            FN_END: () => c,
            FN_START: () => s,
            INTERACTION: () => f,
            INTERACTION_API: () => d,
            INTERACTION_EVENTS: () => o,
            JSONP_END: () => b,
            JSONP_NODE: () => p,
            JS_TIME: () => T,
            MAX_TIMER_BUDGET: () => a,
            REMAINING: () => l,
            SPA_NODE: () => h,
            START: () => w,
            originalSetTimeout: () => y
          });
          var n = r(5763);
          const i = r(3325).D.spa,
            o = ["click", "submit", "keypress", "keydown", "keyup", "change"],
            a = 999,
            s = "fn-start",
            c = "fn-end",
            u = "cb-start",
            d = "api-ixn-",
            l = "remaining",
            f = "interaction",
            h = "spaNode",
            p = "jsonpNode",
            g = "fetch-start",
            m = "fetch-done",
            v = "fetch-body-",
            b = "jsonp-end",
            y = n.Yu.ST,
            w = "-start",
            A = "-end",
            x = "-body",
            E = "cb" + A,
            T = "jsTime",
            _ = "fetch";
        },
        5938: (e, t, r) => {
          r.d(t, {
            W: () => o
          });
          var n = r(5763),
            i = r(8325);
          class o {
            constructor(e, t, r) {
              this.agentIdentifier = e, this.aggregator = t, this.ee = i.ee.get(e, (0, n.OP)(this.agentIdentifier).isolatedBacklog), this.featureName = r, this.blocked = !1;
            }
          }
        },
        9144: (e, t, r) => {
          r.d(t, {
            j: () => m
          });
          var n = r(3325),
            i = r(5763),
            o = r(5546),
            a = r(8325),
            s = r(7894),
            c = r(8e3),
            u = r(3960),
            d = r(385),
            l = r(50),
            f = r(3081),
            h = r(8632);
          function p() {
            const e = (0, h.gG)();
            ["setErrorHandler", "finished", "addToTrace", "inlineHit", "addRelease", "addPageAction", "setCurrentRouteName", "setPageViewName", "setCustomAttribute", "interaction", "noticeError", "setUserId", "setApplicationVersion"].forEach(t => {
              e[t] = function () {
                for (var r = arguments.length, n = new Array(r), i = 0; i < r; i++) n[i] = arguments[i];
                return function (t) {
                  for (var r = arguments.length, n = new Array(r > 1 ? r - 1 : 0), i = 1; i < r; i++) n[i - 1] = arguments[i];
                  let o = [];
                  return Object.values(e.initializedAgents).forEach(e => {
                    e.exposed && e.api[t] && o.push(e.api[t](...n));
                  }), o.length > 1 ? o : o[0];
                }(t, ...n);
              };
            });
          }
          var g = r(2587);
          function m(e) {
            let t = arguments.length > 1 && void 0 !== arguments[1] ? arguments[1] : {},
              m = arguments.length > 2 ? arguments[2] : void 0,
              v = arguments.length > 3 ? arguments[3] : void 0,
              {
                init: b,
                info: y,
                loader_config: w,
                runtime: A = {
                  loaderType: m
                },
                exposed: x = !0
              } = t;
            const E = (0, h.gG)();
            y || (b = E.init, y = E.info, w = E.loader_config), (0, i.Dg)(e, b || {}), (0, i.GE)(e, w || {}), y.jsAttributes ??= {}, d.v6 && (y.jsAttributes.isWorker = !0), (0, i.CX)(e, y);
            const T = (0, i.P_)(e);
            A.denyList = [...(T.ajax?.deny_list || []), ...(T.ajax?.block_internal ? [y.beacon, y.errorBeacon] : [])], (0, i.sU)(e, A), p();
            const _ = function (e, t) {
              t || (0, c.R)(e, "api");
              const h = {};
              var p = a.ee.get(e),
                g = p.get("tracer"),
                m = "api-",
                v = m + "ixn-";
              function b(t, r, n, o) {
                const a = (0, i.C5)(e);
                return null === r ? delete a.jsAttributes[t] : (0, i.CX)(e, {
                  ...a,
                  jsAttributes: {
                    ...a.jsAttributes,
                    [t]: r
                  }
                }), A(m, n, !0, o || null === r ? "session" : void 0)(t, r);
              }
              function y() {}
              ["setErrorHandler", "finished", "addToTrace", "inlineHit", "addRelease"].forEach(e => h[e] = A(m, e, !0, "api")), h.addPageAction = A(m, "addPageAction", !0, n.D.pageAction), h.setCurrentRouteName = A(m, "routeName", !0, n.D.spa), h.setPageViewName = function (t, r) {
                if ("string" == typeof t) return "/" !== t.charAt(0) && (t = "/" + t), (0, i.OP)(e).customTransaction = (r || "http://custom.transaction") + t, A(m, "setPageViewName", !0)();
              }, h.setCustomAttribute = function (e, t) {
                let r = arguments.length > 2 && void 0 !== arguments[2] && arguments[2];
                if ("string" == typeof e) {
                  if (["string", "number"].includes(typeof t) || null === t) return b(e, t, "setCustomAttribute", r);
                  (0, l.Z)("Failed to execute setCustomAttribute.\nNon-null value must be a string or number type, but a type of <".concat(typeof t, "> was provided."));
                } else (0, l.Z)("Failed to execute setCustomAttribute.\nName must be a string type, but a type of <".concat(typeof e, "> was provided."));
              }, h.setUserId = function (e) {
                if ("string" == typeof e || null === e) return b("enduser.id", e, "setUserId", !0);
                (0, l.Z)("Failed to execute setUserId.\nNon-null value must be a string type, but a type of <".concat(typeof e, "> was provided."));
              }, h.setApplicationVersion = function (e) {
                if ("string" == typeof e || null === e) return b("application.version", e, "setApplicationVersion", !1);
                (0, l.Z)("Failed to execute setApplicationVersion. Expected <String | null>, but got <".concat(typeof e, ">."));
              }, h.interaction = function () {
                return new y().get();
              };
              var w = y.prototype = {
                createTracer: function (e, t) {
                  var r = {},
                    i = this,
                    a = "function" == typeof t;
                  return (0, o.p)(v + "tracer", [(0, s.z)(), e, r], i, n.D.spa, p), function () {
                    if (g.emit((a ? "" : "no-") + "fn-start", [(0, s.z)(), i, a], r), a) try {
                      return t.apply(this, arguments);
                    } catch (e) {
                      throw g.emit("fn-err", [arguments, this, e], r), e;
                    } finally {
                      g.emit("fn-end", [(0, s.z)()], r);
                    }
                  };
                }
              };
              function A(e, t, r, i) {
                return function () {
                  return (0, o.p)(f.xS, ["API/" + t + "/called"], void 0, n.D.metrics, p), i && (0, o.p)(e + t, [(0, s.z)(), ...arguments], r ? null : this, i, p), r ? void 0 : this;
                };
              }
              function x() {
                r.e(111).then(r.bind(r, 7438)).then(t => {
                  let {
                    setAPI: r
                  } = t;
                  r(e), (0, c.L)(e, "api");
                }).catch(() => (0, l.Z)("Downloading runtime APIs failed..."));
              }
              return ["actionText", "setName", "setAttribute", "save", "ignore", "onEnd", "getContext", "end", "get"].forEach(e => {
                w[e] = A(v, e, void 0, n.D.spa);
              }), h.noticeError = function (e, t) {
                "string" == typeof e && (e = new Error(e)), (0, o.p)(f.xS, ["API/noticeError/called"], void 0, n.D.metrics, p), (0, o.p)("err", [e, (0, s.z)(), !1, t], void 0, n.D.jserrors, p);
              }, d.il ? (0, u.b)(() => x(), !0) : x(), h;
            }(e, v);
            return (0, h.Qy)(e, _, "api"), (0, h.Qy)(e, x, "exposed"), (0, h.EZ)("activatedFeatures", g.T), _;
          }
        },
        3325: (e, t, r) => {
          r.d(t, {
            D: () => n,
            p: () => i
          });
          const n = {
              ajax: "ajax",
              jserrors: "jserrors",
              metrics: "metrics",
              pageAction: "page_action",
              pageViewEvent: "page_view_event",
              pageViewTiming: "page_view_timing",
              sessionReplay: "session_replay",
              sessionTrace: "session_trace",
              spa: "spa"
            },
            i = {
              [n.pageViewEvent]: 1,
              [n.pageViewTiming]: 2,
              [n.metrics]: 3,
              [n.jserrors]: 4,
              [n.ajax]: 5,
              [n.sessionTrace]: 6,
              [n.pageAction]: 7,
              [n.spa]: 8,
              [n.sessionReplay]: 9
            };
        }
      },
      n = {};
    function i(e) {
      var t = n[e];
      if (void 0 !== t) return t.exports;
      var o = n[e] = {
        exports: {}
      };
      return r[e](o, o.exports, i), o.exports;
    }
    i.m = r, i.d = (e, t) => {
      for (var r in t) i.o(t, r) && !i.o(e, r) && Object.defineProperty(e, r, {
        enumerable: !0,
        get: t[r]
      });
    }, i.f = {}, i.e = e => Promise.all(Object.keys(i.f).reduce((t, r) => (i.f[r](e, t), t), [])), i.u = e => "nr-spa.1097a448-1.238.0.min.js", i.o = (e, t) => Object.prototype.hasOwnProperty.call(e, t), e = {}, t = "NRBA-1.238.0.PROD:", i.l = (r, n, o, a) => {
      if (e[r]) e[r].push(n);else {
        var s, c;
        if (void 0 !== o) for (var u = document.getElementsByTagName("script"), d = 0; d < u.length; d++) {
          var l = u[d];
          if (l.getAttribute("src") == r || l.getAttribute("data-webpack") == t + o) {
            s = l;
            break;
          }
        }
        s || (c = !0, (s = document.createElement("script")).charset = "utf-8", s.timeout = 120, i.nc && s.setAttribute("nonce", i.nc), s.setAttribute("data-webpack", t + o), s.src = r), e[r] = [n];
        var f = (t, n) => {
            s.onerror = s.onload = null, clearTimeout(h);
            var i = e[r];
            if (delete e[r], s.parentNode && s.parentNode.removeChild(s), i && i.forEach(e => e(n)), t) return t(n);
          },
          h = setTimeout(f.bind(null, void 0, {
            type: "timeout",
            target: s
          }), 12e4);
        s.onerror = f.bind(null, s.onerror), s.onload = f.bind(null, s.onload), c && document.head.appendChild(s);
      }
    }, i.r = e => {
      "undefined" != typeof Symbol && Symbol.toStringTag && Object.defineProperty(e, Symbol.toStringTag, {
        value: "Module"
      }), Object.defineProperty(e, "__esModule", {
        value: !0
      });
    }, i.p = "https://js-agent.newrelic.com/", (() => {
      var e = {
        801: 0,
        92: 0
      };
      i.f.j = (t, r) => {
        var n = i.o(e, t) ? e[t] : void 0;
        if (0 !== n) if (n) r.push(n[2]);else {
          var o = new Promise((r, i) => n = e[t] = [r, i]);
          r.push(n[2] = o);
          var a = i.p + i.u(t),
            s = new Error();
          i.l(a, r => {
            if (i.o(e, t) && (0 !== (n = e[t]) && (e[t] = void 0), n)) {
              var o = r && ("load" === r.type ? "missing" : r.type),
                a = r && r.target && r.target.src;
              s.message = "Loading chunk " + t + " failed.\n(" + o + ": " + a + ")", s.name = "ChunkLoadError", s.type = o, s.request = a, n[1](s);
            }
          }, "chunk-" + t, t);
        }
      };
      var t = (t, r) => {
          var n,
            o,
            [a, s, c] = r,
            u = 0;
          if (a.some(t => 0 !== e[t])) {
            for (n in s) i.o(s, n) && (i.m[n] = s[n]);
            if (c) c(i);
          }
          for (t && t(r); u < a.length; u++) o = a[u], i.o(e, o) && e[o] && e[o][0](), e[o] = 0;
        },
        r = self["webpackChunk:NRBA-1.238.0.PROD"] = self["webpackChunk:NRBA-1.238.0.PROD"] || [];
      r.forEach(t.bind(null, 0)), r.push = t.bind(null, r.push.bind(r));
    })(), (() => {
      var e = i(50);
      class t {
        addPageAction(t, r) {
          (0, e.Z)("Call to agent api addPageAction failed. The session trace feature is not currently initialized.");
        }
        setPageViewName(t, r) {
          (0, e.Z)("Call to agent api setPageViewName failed. The page view feature is not currently initialized.");
        }
        setCustomAttribute(t, r, n) {
          (0, e.Z)("Call to agent api setCustomAttribute failed. The js errors feature is not currently initialized.");
        }
        noticeError(t, r) {
          (0, e.Z)("Call to agent api noticeError failed. The js errors feature is not currently initialized.");
        }
        setUserId(t) {
          (0, e.Z)("Call to agent api setUserId failed. The js errors feature is not currently initialized.");
        }
        setApplicationVersion(t) {
          (0, e.Z)("Call to agent api setApplicationVersion failed. The agent is not currently initialized.");
        }
        setErrorHandler(t) {
          (0, e.Z)("Call to agent api setErrorHandler failed. The js errors feature is not currently initialized.");
        }
        finished(t) {
          (0, e.Z)("Call to agent api finished failed. The page action feature is not currently initialized.");
        }
        addRelease(t, r) {
          (0, e.Z)("Call to agent api addRelease failed. The agent is not currently initialized.");
        }
      }
      var r = i(3325),
        n = i(5763);
      const o = Object.values(r.D);
      function a(e) {
        const t = {};
        return o.forEach(r => {
          t[r] = function (e, t) {
            return !1 !== (0, n.Mt)(t, "".concat(e, ".enabled"));
          }(r, e);
        }), t;
      }
      var s = i(9144);
      var c = i(5546),
        u = i(385),
        d = i(8e3),
        l = i(5938),
        f = i(3960);
      class h extends l.W {
        constructor(e, t, r) {
          let n = !(arguments.length > 3 && void 0 !== arguments[3]) || arguments[3];
          super(e, t, r), this.auto = n, this.abortHandler, this.featAggregate, this.onAggregateImported, n && (0, d.R)(e, r);
        }
        importAggregator() {
          let t = arguments.length > 0 && void 0 !== arguments[0] ? arguments[0] : {};
          if (this.featAggregate || !this.auto) return;
          const r = u.il && !0 === (0, n.Mt)(this.agentIdentifier, "privacy.cookies_enabled");
          let o;
          this.onAggregateImported = new Promise(e => {
            o = e;
          });
          const a = async () => {
            let n;
            try {
              if (r) {
                const {
                  setupAgentSession: e
                } = await i.e(111).then(i.bind(i, 3228));
                n = e(this.agentIdentifier);
              }
            } catch (t) {
              (0, e.Z)("A problem occurred when starting up session manager. This page will not start or extend any session.", t);
            }
            try {
              if (!this.shouldImportAgg(this.featureName, n)) return (0, d.L)(this.agentIdentifier, this.featureName), void o(!1);
              const {
                  lazyFeatureLoader: e
                } = await i.e(111).then(i.bind(i, 8582)),
                {
                  Aggregate: r
                } = await e(this.featureName, "aggregate");
              this.featAggregate = new r(this.agentIdentifier, this.aggregator, t), o(!0);
            } catch (t) {
              (0, e.Z)("Downloading and initializing ".concat(this.featureName, " failed..."), t), this.abortHandler?.(), o(!1);
            }
          };
          u.il ? (0, f.b)(() => a(), !0) : a();
        }
        shouldImportAgg(e, t) {
          return e !== r.D.sessionReplay || !!n.Yu.MO && !1 !== (0, n.Mt)(this.agentIdentifier, "session_trace.enabled") && (!!t?.isNew || !!t?.state.sessionReplay);
        }
      }
      var p = i(7633),
        g = i(7894);
      class m extends h {
        static featureName = p.t9;
        constructor(e, t) {
          let i = !(arguments.length > 2 && void 0 !== arguments[2]) || arguments[2];
          if (super(e, t, p.t9, i), ("undefined" == typeof PerformanceNavigationTiming || u.Tt) && "undefined" != typeof PerformanceTiming) {
            const t = (0, n.OP)(e);
            t[p.Dz] = Math.max(Date.now() - t.offset, 0), (0, f.K)(() => t[p.qw] = Math.max((0, g.z)() - t[p.Dz], 0)), (0, f.b)(() => {
              const e = (0, g.z)();
              t[p.OJ] = Math.max(e - t[p.Dz], 0), (0, c.p)("timing", ["load", e], void 0, r.D.pageViewTiming, this.ee);
            });
          }
          this.importAggregator();
        }
      }
      var v = i(1117),
        b = i(1284);
      class y extends v.w {
        constructor(e) {
          super(e), this.aggregatedData = {};
        }
        store(e, t, r, n, i) {
          var o = this.getBucket(e, t, r, i);
          return o.metrics = function (e, t) {
            t || (t = {
              count: 0
            });
            return t.count += 1, (0, b.D)(e, function (e, r) {
              t[e] = w(r, t[e]);
            }), t;
          }(n, o.metrics), o;
        }
        merge(e, t, r, n, i) {
          var o = this.getBucket(e, t, n, i);
          if (o.metrics) {
            var a = o.metrics;
            a.count += r.count, (0, b.D)(r, function (e, t) {
              if ("count" !== e) {
                var n = a[e],
                  i = r[e];
                i && !i.c ? a[e] = w(i.t, n) : a[e] = function (e, t) {
                  if (!t) return e;
                  t.c || (t = A(t.t));
                  return t.min = Math.min(e.min, t.min), t.max = Math.max(e.max, t.max), t.t += e.t, t.sos += e.sos, t.c += e.c, t;
                }(i, a[e]);
              }
            });
          } else o.metrics = r;
        }
        storeMetric(e, t, r, n) {
          var i = this.getBucket(e, t, r);
          return i.stats = w(n, i.stats), i;
        }
        getBucket(e, t, r, n) {
          this.aggregatedData[e] || (this.aggregatedData[e] = {});
          var i = this.aggregatedData[e][t];
          return i || (i = this.aggregatedData[e][t] = {
            params: r || {}
          }, n && (i.custom = n)), i;
        }
        get(e, t) {
          return t ? this.aggregatedData[e] && this.aggregatedData[e][t] : this.aggregatedData[e];
        }
        take(e) {
          for (var t = {}, r = "", n = !1, i = 0; i < e.length; i++) t[r = e[i]] = x(this.aggregatedData[r]), t[r].length && (n = !0), delete this.aggregatedData[r];
          return n ? t : null;
        }
      }
      function w(e, t) {
        return null == e ? function (e) {
          e ? e.c++ : e = {
            c: 1
          };
          return e;
        }(t) : t ? (t.c || (t = A(t.t)), t.c += 1, t.t += e, t.sos += e * e, e > t.max && (t.max = e), e < t.min && (t.min = e), t) : {
          t: e
        };
      }
      function A(e) {
        return {
          t: e,
          min: e,
          max: e,
          sos: e * e,
          c: 1
        };
      }
      function x(e) {
        return "object" != typeof e ? [] : (0, b.D)(e, E);
      }
      function E(e, t) {
        return t;
      }
      var T = i(8632),
        _ = i(4402),
        D = i(4351);
      var j = i(7956),
        C = i(3239),
        N = i(9251);
      class O extends h {
        static featureName = N.t;
        constructor(e, t) {
          let r = !(arguments.length > 2 && void 0 !== arguments[2]) || arguments[2];
          super(e, t, N.t, r), u.il && ((0, n.OP)(e).initHidden = Boolean("hidden" === document.visibilityState), (0, j.N)(() => (0, c.p)("docHidden", [(0, g.z)()], void 0, N.t, this.ee), !0), (0, C.bP)("pagehide", () => (0, c.p)("winPagehide", [(0, g.z)()], void 0, N.t, this.ee)), this.importAggregator());
        }
      }
      var S = i(3081);
      class P extends h {
        static featureName = S.t9;
        constructor(e, t) {
          let r = !(arguments.length > 2 && void 0 !== arguments[2]) || arguments[2];
          super(e, t, S.t9, r), this.importAggregator();
        }
      }
      var R = i(6660);
      class I {
        constructor(e, t, r, n) {
          this.name = "UncaughtError", this.message = e, this.sourceURL = t, this.line = r, this.column = n;
        }
      }
      class k extends h {
        static featureName = R.t;
        #e = new Set();
        constructor(e, t) {
          let n = !(arguments.length > 2 && void 0 !== arguments[2]) || arguments[2];
          super(e, t, R.t, n);
          try {
            this.removeOnAbort = new AbortController();
          } catch (e) {}
          this.ee.on("fn-err", (e, t, n) => {
            this.abortHandler && !this.#e.has(n) && (this.#e.add(n), (0, c.p)("err", [this.#t(n), (0, g.z)()], void 0, r.D.jserrors, this.ee));
          }), this.ee.on("internal-error", e => {
            this.abortHandler && (0, c.p)("ierr", [this.#t(e), (0, g.z)(), !0], void 0, r.D.jserrors, this.ee);
          }), u._A.addEventListener("unhandledrejection", e => {
            this.abortHandler && (0, c.p)("err", [this.#r(e), (0, g.z)(), !1, {
              unhandledPromiseRejection: 1
            }], void 0, r.D.jserrors, this.ee);
          }, (0, C.m$)(!1, this.removeOnAbort?.signal)), u._A.addEventListener("error", e => {
            this.abortHandler && (this.#e.has(e.error) ? this.#e.delete(e.error) : (0, c.p)("err", [this.#n(e), (0, g.z)()], void 0, r.D.jserrors, this.ee));
          }, (0, C.m$)(!1, this.removeOnAbort?.signal)), this.abortHandler = this.#i, this.importAggregator();
        }
        #i() {
          this.removeOnAbort?.abort(), this.#e.clear(), this.abortHandler = void 0;
        }
        #t(e) {
          return e instanceof Error ? e : void 0 !== e?.message ? new I(e.message, e.filename || e.sourceURL, e.lineno || e.line, e.colno || e.col) : new I("string" == typeof e ? e : (0, D.P)(e));
        }
        #r(e) {
          let t = "Unhandled Promise Rejection: ";
          if (e?.reason instanceof Error) try {
            return e.reason.message = t + e.reason.message, e.reason;
          } catch (t) {
            return e.reason;
          }
          if (void 0 === e.reason) return new I(t);
          const r = this.#t(e.reason);
          return r.message = t + r.message, r;
        }
        #n(e) {
          return e.error instanceof Error ? e.error : new I(e.message, e.filename, e.lineno, e.colno);
        }
      }
      var H = i(2210);
      let z = 1;
      const L = "nr@id";
      function M(e) {
        const t = typeof e;
        return !e || "object" !== t && "function" !== t ? -1 : e === u._A ? 0 : (0, H.X)(e, L, function () {
          return z++;
        });
      }
      function B(e) {
        if ("string" == typeof e && e.length) return e.length;
        if ("object" == typeof e) {
          if ("undefined" != typeof ArrayBuffer && e instanceof ArrayBuffer && e.byteLength) return e.byteLength;
          if ("undefined" != typeof Blob && e instanceof Blob && e.size) return e.size;
          if (!("undefined" != typeof FormData && e instanceof FormData)) try {
            return (0, D.P)(e).length;
          } catch (e) {
            return;
          }
        }
      }
      var F = i(1214),
        U = i(7243);
      class q {
        constructor(e) {
          this.agentIdentifier = e;
        }
        generateTracePayload(e) {
          if (!this.shouldGenerateTrace(e)) return null;
          var t = (0, n.DL)(this.agentIdentifier);
          if (!t) return null;
          var r = (t.accountID || "").toString() || null,
            i = (t.agentID || "").toString() || null,
            o = (t.trustKey || "").toString() || null;
          if (!r || !i) return null;
          var a = (0, _.M)(),
            s = (0, _.Ht)(),
            c = Date.now(),
            u = {
              spanId: a,
              traceId: s,
              timestamp: c
            };
          return (e.sameOrigin || this.isAllowedOrigin(e) && this.useTraceContextHeadersForCors()) && (u.traceContextParentHeader = this.generateTraceContextParentHeader(a, s), u.traceContextStateHeader = this.generateTraceContextStateHeader(a, c, r, i, o)), (e.sameOrigin && !this.excludeNewrelicHeader() || !e.sameOrigin && this.isAllowedOrigin(e) && this.useNewrelicHeaderForCors()) && (u.newrelicHeader = this.generateTraceHeader(a, s, c, r, i, o)), u;
        }
        generateTraceContextParentHeader(e, t) {
          return "00-" + t + "-" + e + "-01";
        }
        generateTraceContextStateHeader(e, t, r, n, i) {
          return i + "@nr=0-1-" + r + "-" + n + "-" + e + "----" + t;
        }
        generateTraceHeader(e, t, r, n, i, o) {
          if (!("function" == typeof u._A?.btoa)) return null;
          var a = {
            v: [0, 1],
            d: {
              ty: "Browser",
              ac: n,
              ap: i,
              id: e,
              tr: t,
              ti: r
            }
          };
          return o && n !== o && (a.d.tk = o), btoa((0, D.P)(a));
        }
        shouldGenerateTrace(e) {
          return this.isDtEnabled() && this.isAllowedOrigin(e);
        }
        isAllowedOrigin(e) {
          var t = !1,
            r = {};
          if ((0, n.Mt)(this.agentIdentifier, "distributed_tracing") && (r = (0, n.P_)(this.agentIdentifier).distributed_tracing), e.sameOrigin) t = !0;else if (r.allowed_origins instanceof Array) for (var i = 0; i < r.allowed_origins.length; i++) {
            var o = (0, U.e)(r.allowed_origins[i]);
            if (e.hostname === o.hostname && e.protocol === o.protocol && e.port === o.port) {
              t = !0;
              break;
            }
          }
          return t;
        }
        isDtEnabled() {
          var e = (0, n.Mt)(this.agentIdentifier, "distributed_tracing");
          return !!e && !!e.enabled;
        }
        excludeNewrelicHeader() {
          var e = (0, n.Mt)(this.agentIdentifier, "distributed_tracing");
          return !!e && !!e.exclude_newrelic_header;
        }
        useNewrelicHeaderForCors() {
          var e = (0, n.Mt)(this.agentIdentifier, "distributed_tracing");
          return !!e && !1 !== e.cors_use_newrelic_header;
        }
        useTraceContextHeadersForCors() {
          var e = (0, n.Mt)(this.agentIdentifier, "distributed_tracing");
          return !!e && !!e.cors_use_tracecontext_headers;
        }
      }
      var Z = i(7825),
        V = ["load", "error", "abort", "timeout"],
        G = V.length,
        W = n.Yu.REQ,
        X = n.Yu.XHR;
      class Q extends h {
        static featureName = Z.t;
        constructor(e, t) {
          let i = !(arguments.length > 2 && void 0 !== arguments[2]) || arguments[2];
          super(e, t, Z.t, i), (0, n.OP)(e).xhrWrappable && (this.dt = new q(e), this.handler = (e, t, r, n) => (0, c.p)(e, t, r, n, this.ee), (0, F.u5)(this.ee), (0, F.Kf)(this.ee), function (e, t, i, o) {
            function a(e) {
              var t = this;
              t.totalCbs = 0, t.called = 0, t.cbTime = 0, t.end = E, t.ended = !1, t.xhrGuids = {}, t.lastSize = null, t.loadCaptureCalled = !1, t.params = this.params || {}, t.metrics = this.metrics || {}, e.addEventListener("load", function (r) {
                _(t, e);
              }, (0, C.m$)(!1)), u.IF || e.addEventListener("progress", function (e) {
                t.lastSize = e.loaded;
              }, (0, C.m$)(!1));
            }
            function s(e) {
              this.params = {
                method: e[0]
              }, T(this, e[1]), this.metrics = {};
            }
            function c(t, r) {
              var i = (0, n.DL)(e);
              i.xpid && this.sameOrigin && r.setRequestHeader("X-NewRelic-ID", i.xpid);
              var a = o.generateTracePayload(this.parsedOrigin);
              if (a) {
                var s = !1;
                a.newrelicHeader && (r.setRequestHeader("newrelic", a.newrelicHeader), s = !0), a.traceContextParentHeader && (r.setRequestHeader("traceparent", a.traceContextParentHeader), a.traceContextStateHeader && r.setRequestHeader("tracestate", a.traceContextStateHeader), s = !0), s && (this.dt = a);
              }
            }
            function d(e, r) {
              var n = this.metrics,
                i = e[0],
                o = this;
              if (n && i) {
                var a = B(i);
                a && (n.txSize = a);
              }
              this.startTime = (0, g.z)(), this.listener = function (e) {
                try {
                  "abort" !== e.type || o.loadCaptureCalled || (o.params.aborted = !0), ("load" !== e.type || o.called === o.totalCbs && (o.onloadCalled || "function" != typeof r.onload) && "function" == typeof o.end) && o.end(r);
                } catch (e) {
                  try {
                    t.emit("internal-error", [e]);
                  } catch (e) {}
                }
              };
              for (var s = 0; s < G; s++) r.addEventListener(V[s], this.listener, (0, C.m$)(!1));
            }
            function l(e, t, r) {
              this.cbTime += e, t ? this.onloadCalled = !0 : this.called += 1, this.called !== this.totalCbs || !this.onloadCalled && "function" == typeof r.onload || "function" != typeof this.end || this.end(r);
            }
            function f(e, t) {
              var r = "" + M(e) + !!t;
              this.xhrGuids && !this.xhrGuids[r] && (this.xhrGuids[r] = !0, this.totalCbs += 1);
            }
            function h(e, t) {
              var r = "" + M(e) + !!t;
              this.xhrGuids && this.xhrGuids[r] && (delete this.xhrGuids[r], this.totalCbs -= 1);
            }
            function p() {
              this.endTime = (0, g.z)();
            }
            function m(e, r) {
              r instanceof X && "load" === e[0] && t.emit("xhr-load-added", [e[1], e[2]], r);
            }
            function v(e, r) {
              r instanceof X && "load" === e[0] && t.emit("xhr-load-removed", [e[1], e[2]], r);
            }
            function b(e, t, r) {
              t instanceof X && ("onload" === r && (this.onload = !0), ("load" === (e[0] && e[0].type) || this.onload) && (this.xhrCbStart = (0, g.z)()));
            }
            function y(e, r) {
              this.xhrCbStart && t.emit("xhr-cb-time", [(0, g.z)() - this.xhrCbStart, this.onload, r], r);
            }
            function w(e) {
              var t,
                r = e[1] || {};
              if ("string" == typeof e[0] ? 0 === (t = e[0]).length && u.il && (t = "" + u._A.location.href) : e[0] && e[0].url ? t = e[0].url : u._A?.URL && e[0] && e[0] instanceof URL ? t = e[0].href : "function" == typeof e[0].toString && (t = e[0].toString()), "string" == typeof t && 0 !== t.length) {
                t && (this.parsedOrigin = (0, U.e)(t), this.sameOrigin = this.parsedOrigin.sameOrigin);
                var n = o.generateTracePayload(this.parsedOrigin);
                if (n && (n.newrelicHeader || n.traceContextParentHeader)) if (e[0] && e[0].headers) s(e[0].headers, n) && (this.dt = n);else {
                  var i = {};
                  for (var a in r) i[a] = r[a];
                  i.headers = new Headers(r.headers || {}), s(i.headers, n) && (this.dt = n), e.length > 1 ? e[1] = i : e.push(i);
                }
              }
              function s(e, t) {
                var r = !1;
                return t.newrelicHeader && (e.set("newrelic", t.newrelicHeader), r = !0), t.traceContextParentHeader && (e.set("traceparent", t.traceContextParentHeader), t.traceContextStateHeader && e.set("tracestate", t.traceContextStateHeader), r = !0), r;
              }
            }
            function A(e, t) {
              this.params = {}, this.metrics = {}, this.startTime = (0, g.z)(), this.dt = t, e.length >= 1 && (this.target = e[0]), e.length >= 2 && (this.opts = e[1]);
              var r,
                n = this.opts || {},
                i = this.target;
              "string" == typeof i ? r = i : "object" == typeof i && i instanceof W ? r = i.url : u._A?.URL && "object" == typeof i && i instanceof URL && (r = i.href), T(this, r);
              var o = ("" + (i && i instanceof W && i.method || n.method || "GET")).toUpperCase();
              this.params.method = o, this.txSize = B(n.body) || 0;
            }
            function x(e, t) {
              var n;
              this.endTime = (0, g.z)(), this.params || (this.params = {}), this.params.status = t ? t.status : 0, "string" == typeof this.rxSize && this.rxSize.length > 0 && (n = +this.rxSize);
              var o = {
                txSize: this.txSize,
                rxSize: n,
                duration: (0, g.z)() - this.startTime
              };
              i("xhr", [this.params, o, this.startTime, this.endTime, "fetch"], this, r.D.ajax);
            }
            function E(e) {
              var t = this.params,
                n = this.metrics;
              if (!this.ended) {
                this.ended = !0;
                for (var o = 0; o < G; o++) e.removeEventListener(V[o], this.listener, !1);
                t.aborted || (n.duration = (0, g.z)() - this.startTime, this.loadCaptureCalled || 4 !== e.readyState ? null == t.status && (t.status = 0) : _(this, e), n.cbTime = this.cbTime, i("xhr", [t, n, this.startTime, this.endTime, "xhr"], this, r.D.ajax));
              }
            }
            function T(e, t) {
              var r = (0, U.e)(t),
                n = e.params;
              n.hostname = r.hostname, n.port = r.port, n.protocol = r.protocol, n.host = r.hostname + ":" + r.port, n.pathname = r.pathname, e.parsedOrigin = r, e.sameOrigin = r.sameOrigin;
            }
            function _(e, t) {
              e.params.status = t.status;
              var r = function (e, t) {
                var r = e.responseType;
                return "json" === r && null !== t ? t : "arraybuffer" === r || "blob" === r || "json" === r ? B(e.response) : "text" === r || "" === r || void 0 === r ? B(e.responseText) : void 0;
              }(t, e.lastSize);
              if (r && (e.metrics.rxSize = r), e.sameOrigin) {
                var n = t.getResponseHeader("X-NewRelic-App-Data");
                n && (e.params.cat = n.split(", ").pop());
              }
              e.loadCaptureCalled = !0;
            }
            t.on("new-xhr", a), t.on("open-xhr-start", s), t.on("open-xhr-end", c), t.on("send-xhr-start", d), t.on("xhr-cb-time", l), t.on("xhr-load-added", f), t.on("xhr-load-removed", h), t.on("xhr-resolved", p), t.on("addEventListener-end", m), t.on("removeEventListener-end", v), t.on("fn-end", y), t.on("fetch-before-start", w), t.on("fetch-start", A), t.on("fn-start", b), t.on("fetch-done", x);
          }(e, this.ee, this.handler, this.dt), this.importAggregator());
        }
      }
      var K = i(3614);
      const {
        BST_RESOURCE: Y,
        RESOURCE: J,
        START: ee,
        END: te,
        FEATURE_NAME: re,
        FN_END: ne,
        FN_START: ie,
        PUSH_STATE: oe
      } = K;
      var ae = i(7836);
      const {
        FEATURE_NAME: se,
        START: ce,
        END: ue,
        BODY: de,
        CB_END: le,
        JS_TIME: fe,
        FETCH: he,
        FN_START: pe,
        CB_START: ge,
        FN_END: me
      } = ae;
      var ve = i(4649);
      class be extends h {
        static featureName = ve.t;
        constructor(e, t) {
          let r = !(arguments.length > 2 && void 0 !== arguments[2]) || arguments[2];
          super(e, t, ve.t, r), this.importAggregator();
        }
      }
      new class extends t {
        constructor(t) {
          let r = arguments.length > 1 && void 0 !== arguments[1] ? arguments[1] : (0, _.ky)(16);
          super(), u._A ? (this.agentIdentifier = r, this.sharedAggregator = new y({
            agentIdentifier: this.agentIdentifier
          }), this.features = {}, this.desiredFeatures = new Set(t.features || []), this.desiredFeatures.add(m), Object.assign(this, (0, s.j)(this.agentIdentifier, t, t.loaderType || "agent")), this.start()) : (0, e.Z)("Failed to initial the agent. Could not determine the runtime environment.");
        }
        get config() {
          return {
            info: (0, n.C5)(this.agentIdentifier),
            init: (0, n.P_)(this.agentIdentifier),
            loader_config: (0, n.DL)(this.agentIdentifier),
            runtime: (0, n.OP)(this.agentIdentifier)
          };
        }
        start() {
          const t = "features";
          try {
            const n = a(this.agentIdentifier),
              i = [...this.desiredFeatures];
            i.sort((e, t) => r.p[e.featureName] - r.p[t.featureName]), i.forEach(t => {
              if (n[t.featureName] || t.featureName === r.D.pageViewEvent) {
                const i = function (e) {
                  switch (e) {
                    case r.D.ajax:
                      return [r.D.jserrors];
                    case r.D.sessionTrace:
                      return [r.D.ajax, r.D.pageViewEvent];
                    case r.D.sessionReplay:
                      return [r.D.sessionTrace];
                    case r.D.pageViewTiming:
                      return [r.D.pageViewEvent];
                    default:
                      return [];
                  }
                }(t.featureName);
                i.every(e => n[e]) || (0, e.Z)("".concat(t.featureName, " is enabled but one or more dependent features has been disabled (").concat((0, D.P)(i), "). This may cause unintended consequences or missing data...")), this.features[t.featureName] = new t(this.agentIdentifier, this.sharedAggregator);
              }
            }), (0, T.Qy)(this.agentIdentifier, this.features, t);
          } catch (r) {
            (0, e.Z)("Failed to initialize all enabled instrument classes (agent aborted) -", r);
            for (const e in this.features) this.features[e].abortHandler?.();
            const n = (0, T.fP)();
            return delete n.initializedAgents[this.agentIdentifier]?.api, delete n.initializedAgents[this.agentIdentifier]?.[t], delete this.sharedAggregator, n.ee?.abort(), delete n.ee?.get(this.agentIdentifier), !1;
          }
        }
        addToTrace(t) {
          (0, e.Z)("Call to agent api addToTrace failed. The page action feature is not currently initialized.");
        }
        setCurrentRouteName(t) {
          (0, e.Z)("Call to agent api setCurrentRouteName failed. The spa feature is not currently initialized.");
        }
        interaction() {
          (0, e.Z)("Call to agent api interaction failed. The spa feature is not currently initialized.");
        }
      }({
        features: [Q, m, O, class extends h {
          static featureName = re;
          constructor(e, t) {
            if (super(e, t, re, !(arguments.length > 2 && void 0 !== arguments[2]) || arguments[2]), !u.il) return;
            const n = this.ee;
            let i;
            (0, F.QU)(n), this.eventsEE = (0, F.em)(n), this.eventsEE.on(ie, function (e, t) {
              this.bstStart = (0, g.z)();
            }), this.eventsEE.on(ne, function (e, t) {
              (0, c.p)("bst", [e[0], t, this.bstStart, (0, g.z)()], void 0, r.D.sessionTrace, n);
            }), n.on(oe + ee, function (e) {
              this.time = (0, g.z)(), this.startPath = location.pathname + location.hash;
            }), n.on(oe + te, function (e) {
              (0, c.p)("bstHist", [location.pathname + location.hash, this.startPath, this.time], void 0, r.D.sessionTrace, n);
            });
            try {
              i = new PerformanceObserver(e => {
                const t = e.getEntries();
                (0, c.p)(Y, [t], void 0, r.D.sessionTrace, n);
              }), i.observe({
                type: J,
                buffered: !0
              });
            } catch (e) {}
            this.importAggregator({
              resourceObserver: i
            });
          }
        }, P, be, k, class extends h {
          static featureName = se;
          constructor(e, t) {
            if (super(e, t, se, !(arguments.length > 2 && void 0 !== arguments[2]) || arguments[2]), !u.il) return;
            if (!(0, n.OP)(e).xhrWrappable) return;
            try {
              this.removeOnAbort = new AbortController();
            } catch (e) {}
            let r,
              i = 0;
            const o = this.ee.get("tracer"),
              a = (0, F._L)(this.ee),
              s = (0, F.Lg)(this.ee),
              c = (0, F.BV)(this.ee),
              d = (0, F.Kf)(this.ee),
              l = this.ee.get("events"),
              f = (0, F.u5)(this.ee),
              h = (0, F.QU)(this.ee),
              p = (0, F.Gm)(this.ee);
            function m(e, t) {
              h.emit("newURL", ["" + window.location, t]);
            }
            function v() {
              i++, r = window.location.hash, this[pe] = (0, g.z)();
            }
            function b() {
              i--, window.location.hash !== r && m(0, !0);
              var e = (0, g.z)();
              this[fe] = ~~this[fe] + e - this[pe], this[me] = e;
            }
            function y(e, t) {
              e.on(t, function () {
                this[t] = (0, g.z)();
              });
            }
            this.ee.on(pe, v), s.on(ge, v), a.on(ge, v), this.ee.on(me, b), s.on(le, b), a.on(le, b), this.ee.buffer([pe, me, "xhr-resolved"], this.featureName), l.buffer([pe], this.featureName), c.buffer(["setTimeout" + ue, "clearTimeout" + ce, pe], this.featureName), d.buffer([pe, "new-xhr", "send-xhr" + ce], this.featureName), f.buffer([he + ce, he + "-done", he + de + ce, he + de + ue], this.featureName), h.buffer(["newURL"], this.featureName), p.buffer([pe], this.featureName), s.buffer(["propagate", ge, le, "executor-err", "resolve" + ce], this.featureName), o.buffer([pe, "no-" + pe], this.featureName), a.buffer(["new-jsonp", "cb-start", "jsonp-error", "jsonp-end"], this.featureName), y(f, he + ce), y(f, he + "-done"), y(a, "new-jsonp"), y(a, "jsonp-end"), y(a, "cb-start"), h.on("pushState-end", m), h.on("replaceState-end", m), window.addEventListener("hashchange", m, (0, C.m$)(!0, this.removeOnAbort?.signal)), window.addEventListener("load", m, (0, C.m$)(!0, this.removeOnAbort?.signal)), window.addEventListener("popstate", function () {
              m(0, i > 1);
            }, (0, C.m$)(!0, this.removeOnAbort?.signal)), this.abortHandler = this.#i, this.importAggregator();
          }
          #i() {
            this.removeOnAbort?.abort(), this.abortHandler = void 0;
          }
        }],
        loaderType: "spa"
      });
    })();
  })();
})()</script>
      <link rel="shortcut icon" href="https://sdfestaticassets-eu-west-1.sciencedirectassets.com/shared-assets/103/images/favSD.ico" type="image/x-icon">
      <link rel="icon" href="https://sdfestaticassets-eu-west-1.sciencedirectassets.com/shared-assets/103/images/favSD.ico" type="image/x-icon">
      <link rel="stylesheet" href="https://sdfestaticassets-eu-west-1.sciencedirectassets.com/prod/562c52f0a29e84041e12a6c3286c1d8a5b89ba0b/arp.css">
      <link href="//cdn.pendo.io" rel="dns-prefetch">
      <link href="https://cdn.pendo.io" rel="preconnect" crossorigin="anonymous">
      <link rel="dns-prefetch" href="https://smetrics.elsevier.com">
      <script async="" id="reading-assistant-script-tag" src="/feature/assets/ai-components/S0925231219306137?componentVersion=V11&amp;jwt=eyJ0eXAiOiJKV1QiLCJhbGciOiJIUzI1NiJ9.eyJhdWQiOiJnZW5BaUFwcHMiLCJzdWIiOiI1MDQwMSIsInBpaSI6IlMwOTI1MjMxMjE5MzA2MTM3IiwiaXNzIjoiYXJwIiwic2Vzc2lvbklkIjoiNWUwYThhMzI3ZjI3YTA0OGE4NWIyM2E2YTM3MTU2NmQ2OThkZ3hycWEiLCJleHAiOjE3MzAyMDU3MzksImlhdCI6MTczMDIwMzkzOSwidmVyc2lvbiI6MSwianRpIjoiN2U1YTU1ZTktNzhhOS00MjRkLWE0YzUtYTk2M2UzM2UzM2U1In0.xO4sB6bFm0Llrv0-TmPgYQWixtdewDjoTWvl5dZAC78" type="text/javascript"></script>
      <script type="text/javascript">
        var targetServerState = JSON.stringify({"4D6368F454EC41940A4C98A6@AdobeOrg":{"sdid":{"supplementalDataIDCurrent":"677919E2B928309D-184568A6D249D539","supplementalDataIDCurrentConsumed":{"payload:target-global-mbox":true},"supplementalDataIDLastConsumed":{}}}});
        window.appData = window.appData || [];
        window.pageTargeting = {"region":"eu-west-1","platform":"sdtech","entitled":true,"crawler":"","journal":"Neurocomputing","auth":"AE"};
        window.arp = {
          config: {"adobeSuite":"elsevier-sd-prod","arsUrl":"https://ars.els-cdn.com","recommendationsFeedback":{"enabled":true,"url":"https://feedback.recs.d.elsevier.com/raw/events","timeout":60000},"googleMapsApiKey":"AIzaSyCBYU6I6lrbEU6wQXUEIte3NwGtm3jwHQc","mediaBaseUrl":"https://ars.els-cdn.com/content/image/","strictMode":false,"seamlessAccess":{"enableSeamlessAccess":true,"scriptUrl":"https://unpkg.com/@theidentityselector/thiss-ds@1.0.13/dist/thiss-ds.js","persistenceUrl":"https://service.seamlessaccess.org/ps/","persistenceContext":"seamlessaccess.org","scienceDirectUrl":"https://www.sciencedirect.com","shibAuthUrl":"https://auth.elsevier.com/ShibAuth/institutionLogin"},"reaxys":{"apiUrl":"https://reaxys-sdlc.reaxys.com","origin":"sciencedirect","queryBuilderHostPath":"https://www.reaxys.com/reaxys/secured/hopinto.do","url":"https://www.reaxys.com"},"oneTrustCookie":{"enabled":true},"ssrn":{"url":"https://papers.ssrn.com","path":"/sol3/papers.cfm"},"assetRoute":"https://sdfestaticassets-eu-west-1.sciencedirectassets.com/prod/562c52f0a29e84041e12a6c3286c1d8a5b89ba0b"},
          subscriptions: [],
          subscribe: function(cb) {
            var self = this;
            var i = this.subscriptions.push(cb) - 1;
            return function unsubscribe() {
              self.subscriptions.splice(i, 1);
            }
          },
        };
        window.addEventListener('beforeprint', () => pendo.onGuideDismissed());
      </script>
    <script data-cfasync="false" src="https://cdn.cookielaw.org/scripttemplates/otSDKStub.js" data-document-language="true" data-domain-script="865ea198-88cc-4e41-8952-1df75d554d02"></script><script src="https://assets.adobedtm.com/extensions/EP8757b503532a44a68eee17773f6f10a0/AppMeasurement.min.js" async=""></script><script src="https://assets.adobedtm.com/extensions/EP8757b503532a44a68eee17773f6f10a0/AppMeasurement_Module_ActivityMap.min.js" async=""></script><script src="https://assets.adobedtm.com/4a848ae9611a/032db4f73473/6a62c1bc1779/RCa16d232f95a944c0aabdea6621a2ef94-source.min.js" async=""></script><script src="https://cdn.cookielaw.org/scripttemplates/202402.1.0/otBannerSdk.js" async="" type="text/javascript"></script><meta http-equiv="origin-trial" content="AlK2UR5SkAlj8jjdEc9p3F3xuFYlF6LYjAML3EOqw1g26eCwWPjdmecULvBH5MVPoqKYrOfPhYVL71xAXI1IBQoAAAB8eyJvcmlnaW4iOiJodHRwczovL2RvdWJsZWNsaWNrLm5ldDo0NDMiLCJmZWF0dXJlIjoiV2ViVmlld1hSZXF1ZXN0ZWRXaXRoRGVwcmVjYXRpb24iLCJleHBpcnkiOjE3NTgwNjcxOTksImlzU3ViZG9tYWluIjp0cnVlfQ=="><meta http-equiv="origin-trial" content="Amm8/NmvvQfhwCib6I7ZsmUxiSCfOxWxHayJwyU1r3gRIItzr7bNQid6O8ZYaE1GSQTa69WwhPC9flq/oYkRBwsAAACCeyJvcmlnaW4iOiJodHRwczovL2dvb2dsZXN5bmRpY2F0aW9uLmNvbTo0NDMiLCJmZWF0dXJlIjoiV2ViVmlld1hSZXF1ZXN0ZWRXaXRoRGVwcmVjYXRpb24iLCJleHBpcnkiOjE3NTgwNjcxOTksImlzU3ViZG9tYWluIjp0cnVlfQ=="><meta http-equiv="origin-trial" content="A9wSqI5i0iwGdf6L1CERNdmsTPgVu44ewj8QxTBYgsv1LCPUVF7YmWOvTappqB1139jAymxUW/RO8zmMqo4zlAAAAACNeyJvcmlnaW4iOiJodHRwczovL2RvdWJsZWNsaWNrLm5ldDo0NDMiLCJmZWF0dXJlIjoiRmxlZGdlQmlkZGluZ0FuZEF1Y3Rpb25TZXJ2ZXIiLCJleHBpcnkiOjE3MzY4MTI4MDAsImlzU3ViZG9tYWluIjp0cnVlLCJpc1RoaXJkUGFydHkiOnRydWV9"><meta http-equiv="origin-trial" content="A+d7vJfYtay4OUbdtRPZA3y7bKQLsxaMEPmxgfhBGqKXNrdkCQeJlUwqa6EBbSfjwFtJWTrWIioXeMW+y8bWAgQAAACTeyJvcmlnaW4iOiJodHRwczovL2dvb2dsZXN5bmRpY2F0aW9uLmNvbTo0NDMiLCJmZWF0dXJlIjoiRmxlZGdlQmlkZGluZ0FuZEF1Y3Rpb25TZXJ2ZXIiLCJleHBpcnkiOjE3MzY4MTI4MDAsImlzU3ViZG9tYWluIjp0cnVlLCJpc1RoaXJkUGFydHkiOnRydWV9"><script src="https://securepubads.g.doubleclick.net/pagead/managed/js/gpt/m202410240101/pubads_impl.js?cb=31088506" async=""></script><style type="text/css">.MathJax_Hover_Frame {border-radius: .25em; -webkit-border-radius: .25em; -moz-border-radius: .25em; -khtml-border-radius: .25em; box-shadow: 0px 0px 15px #83A; -webkit-box-shadow: 0px 0px 15px #83A; -moz-box-shadow: 0px 0px 15px #83A; -khtml-box-shadow: 0px 0px 15px #83A; border: 1px solid #A6D ! important; display: inline-block; position: absolute}
.MathJax_Menu_Button .MathJax_Hover_Arrow {position: absolute; cursor: pointer; display: inline-block; border: 2px solid #AAA; border-radius: 4px; -webkit-border-radius: 4px; -moz-border-radius: 4px; -khtml-border-radius: 4px; font-family: 'Courier New',Courier; font-size: 9px; color: #F0F0F0}
.MathJax_Menu_Button .MathJax_Hover_Arrow span {display: block; background-color: #AAA; border: 1px solid; border-radius: 3px; line-height: 0; padding: 4px}
.MathJax_Hover_Arrow:hover {color: white!important; border: 2px solid #CCC!important}
.MathJax_Hover_Arrow:hover span {background-color: #CCC!important}
</style><style type="text/css">#MathJax_About {position: fixed; left: 50%; width: auto; text-align: center; border: 3px outset; padding: 1em 2em; background-color: #DDDDDD; color: black; cursor: default; font-family: message-box; font-size: 120%; font-style: normal; text-indent: 0; text-transform: none; line-height: normal; letter-spacing: normal; word-spacing: normal; word-wrap: normal; white-space: nowrap; float: none; z-index: 201; border-radius: 15px; -webkit-border-radius: 15px; -moz-border-radius: 15px; -khtml-border-radius: 15px; box-shadow: 0px 10px 20px #808080; -webkit-box-shadow: 0px 10px 20px #808080; -moz-box-shadow: 0px 10px 20px #808080; -khtml-box-shadow: 0px 10px 20px #808080; filter: progid:DXImageTransform.Microsoft.dropshadow(OffX=2, OffY=2, Color='gray', Positive='true')}
#MathJax_About.MathJax_MousePost {outline: none}
.MathJax_Menu {position: absolute; background-color: white; color: black; width: auto; padding: 2px; border: 1px solid #CCCCCC; margin: 0; cursor: default; font: menu; text-align: left; text-indent: 0; text-transform: none; line-height: normal; letter-spacing: normal; word-spacing: normal; word-wrap: normal; white-space: nowrap; float: none; z-index: 201; box-shadow: 0px 10px 20px #808080; -webkit-box-shadow: 0px 10px 20px #808080; -moz-box-shadow: 0px 10px 20px #808080; -khtml-box-shadow: 0px 10px 20px #808080; filter: progid:DXImageTransform.Microsoft.dropshadow(OffX=2, OffY=2, Color='gray', Positive='true')}
.MathJax_MenuItem {padding: 2px 2em; background: transparent}
.MathJax_MenuArrow {position: absolute; right: .5em; padding-top: .25em; color: #666666; font-size: .75em}
.MathJax_MenuActive .MathJax_MenuArrow {color: white}
.MathJax_MenuArrow.RTL {left: .5em; right: auto}
.MathJax_MenuCheck {position: absolute; left: .7em}
.MathJax_MenuCheck.RTL {right: .7em; left: auto}
.MathJax_MenuRadioCheck {position: absolute; left: 1em}
.MathJax_MenuRadioCheck.RTL {right: 1em; left: auto}
.MathJax_MenuLabel {padding: 2px 2em 4px 1.33em; font-style: italic}
.MathJax_MenuRule {border-top: 1px solid #CCCCCC; margin: 4px 1px 0px}
.MathJax_MenuDisabled {color: GrayText}
.MathJax_MenuActive {background-color: Highlight; color: HighlightText}
.MathJax_MenuDisabled:focus, .MathJax_MenuLabel:focus {background-color: #E8E8E8}
.MathJax_ContextMenu:focus {outline: none}
.MathJax_ContextMenu .MathJax_MenuItem:focus {outline: none}
#MathJax_AboutClose {top: .2em; right: .2em}
.MathJax_Menu .MathJax_MenuClose {top: -10px; left: -10px}
.MathJax_MenuClose {position: absolute; cursor: pointer; display: inline-block; border: 2px solid #AAA; border-radius: 18px; -webkit-border-radius: 18px; -moz-border-radius: 18px; -khtml-border-radius: 18px; font-family: 'Courier New',Courier; font-size: 24px; color: #F0F0F0}
.MathJax_MenuClose span {display: block; background-color: #AAA; border: 1.5px solid; border-radius: 18px; -webkit-border-radius: 18px; -moz-border-radius: 18px; -khtml-border-radius: 18px; line-height: 0; padding: 8px 0 6px}
.MathJax_MenuClose:hover {color: white!important; border: 2px solid #CCC!important}
.MathJax_MenuClose:hover span {background-color: #CCC!important}
.MathJax_MenuClose:hover:focus {outline: none}
</style><style type="text/css">.MJX_Assistive_MathML {position: absolute!important; top: 0; left: 0; clip: rect(1px, 1px, 1px, 1px); padding: 1px 0 0 0!important; border: 0!important; height: 1px!important; width: 1px!important; overflow: hidden!important; display: block!important; -webkit-touch-callout: none; -webkit-user-select: none; -khtml-user-select: none; -moz-user-select: none; -ms-user-select: none; user-select: none}
.MJX_Assistive_MathML.MJX_Assistive_MathML_Block {width: 100%!important}
</style><style type="text/css">#MathJax_Zoom {position: absolute; background-color: #F0F0F0; overflow: auto; display: block; z-index: 301; padding: .5em; border: 1px solid black; margin: 0; font-weight: normal; font-style: normal; text-align: left; text-indent: 0; text-transform: none; line-height: normal; letter-spacing: normal; word-spacing: normal; word-wrap: normal; white-space: nowrap; float: none; -webkit-box-sizing: content-box; -moz-box-sizing: content-box; box-sizing: content-box; box-shadow: 5px 5px 15px #AAAAAA; -webkit-box-shadow: 5px 5px 15px #AAAAAA; -moz-box-shadow: 5px 5px 15px #AAAAAA; -khtml-box-shadow: 5px 5px 15px #AAAAAA; filter: progid:DXImageTransform.Microsoft.dropshadow(OffX=2, OffY=2, Color='gray', Positive='true')}
#MathJax_ZoomOverlay {position: absolute; left: 0; top: 0; z-index: 300; display: inline-block; width: 100%; height: 100%; border: 0; padding: 0; margin: 0; background-color: white; opacity: 0; filter: alpha(opacity=0)}
#MathJax_ZoomFrame {position: relative; display: inline-block; height: 0; width: 0}
#MathJax_ZoomEventTrap {position: absolute; left: 0; top: 0; z-index: 302; display: inline-block; border: 0; padding: 0; margin: 0; background-color: white; opacity: 0; filter: alpha(opacity=0)}
</style><style type="text/css">.MathJax_Preview {color: #888}
#MathJax_Message {position: fixed; left: 1em; bottom: 1.5em; background-color: #E6E6E6; border: 1px solid #959595; margin: 0px; padding: 2px 8px; z-index: 102; color: black; font-size: 80%; width: auto; white-space: nowrap}
#MathJax_MSIE_Frame {position: absolute; top: 0; left: 0; width: 0px; z-index: 101; border: 0px; margin: 0px; padding: 0px}
.MathJax_Error {color: #CC0000; font-style: italic}
</style><link id="plx-css-summary" type="text/css" rel="stylesheet" href="//cdn.plu.mx/summary.css"><script type="text/javascript" src="//ajax.googleapis.com/ajax/libs/jquery/1.10.2/jquery.min.js"></script><script type="text/javascript" src="//cdn.plu.mx/extjs/xss.js"></script><style type="text/css">.MJXp-script {font-size: .8em}
.MJXp-right {-webkit-transform-origin: right; -moz-transform-origin: right; -ms-transform-origin: right; -o-transform-origin: right; transform-origin: right}
.MJXp-bold {font-weight: bold}
.MJXp-italic {font-style: italic}
.MJXp-scr {font-family: MathJax_Script,'Times New Roman',Times,STIXGeneral,serif}
.MJXp-frak {font-family: MathJax_Fraktur,'Times New Roman',Times,STIXGeneral,serif}
.MJXp-sf {font-family: MathJax_SansSerif,'Times New Roman',Times,STIXGeneral,serif}
.MJXp-cal {font-family: MathJax_Caligraphic,'Times New Roman',Times,STIXGeneral,serif}
.MJXp-mono {font-family: MathJax_Typewriter,'Times New Roman',Times,STIXGeneral,serif}
.MJXp-largeop {font-size: 150%}
.MJXp-largeop.MJXp-int {vertical-align: -.2em}
.MJXp-math {display: inline-block; line-height: 1.2; text-indent: 0; font-family: 'Times New Roman',Times,STIXGeneral,serif; white-space: nowrap; border-collapse: collapse}
.MJXp-display {display: block; text-align: center; margin: 1em 0}
.MJXp-math span {display: inline-block}
.MJXp-box {display: block!important; text-align: center}
.MJXp-box:after {content: " "}
.MJXp-rule {display: block!important; margin-top: .1em}
.MJXp-char {display: block!important}
.MJXp-mo {margin: 0 .15em}
.MJXp-mfrac {margin: 0 .125em; vertical-align: .25em}
.MJXp-denom {display: inline-table!important; width: 100%}
.MJXp-denom > * {display: table-row!important}
.MJXp-surd {vertical-align: top}
.MJXp-surd > * {display: block!important}
.MJXp-script-box > *  {display: table!important; height: 50%}
.MJXp-script-box > * > * {display: table-cell!important; vertical-align: top}
.MJXp-script-box > *:last-child > * {vertical-align: bottom}
.MJXp-script-box > * > * > * {display: block!important}
.MJXp-mphantom {visibility: hidden}
.MJXp-munderover, .MJXp-munder {display: inline-table!important}
.MJXp-over {display: inline-block!important; text-align: center}
.MJXp-over > * {display: block!important}
.MJXp-munderover > *, .MJXp-munder > * {display: table-row!important}
.MJXp-mtable {vertical-align: .25em; margin: 0 .125em}
.MJXp-mtable > * {display: inline-table!important; vertical-align: middle}
.MJXp-mtr {display: table-row!important}
.MJXp-mtd {display: table-cell!important; text-align: center; padding: .5em 0 0 .5em}
.MJXp-mtr > .MJXp-mtd:first-child {padding-left: 0}
.MJXp-mtr:first-child > .MJXp-mtd {padding-top: 0}
.MJXp-mlabeledtr {display: table-row!important}
.MJXp-mlabeledtr > .MJXp-mtd:first-child {padding-left: 0}
.MJXp-mlabeledtr:first-child > .MJXp-mtd {padding-top: 0}
.MJXp-merror {background-color: #FFFF88; color: #CC0000; border: 1px solid #CC0000; padding: 1px 3px; font-style: normal; font-size: 90%}
.MJXp-scale0 {-webkit-transform: scaleX(.0); -moz-transform: scaleX(.0); -ms-transform: scaleX(.0); -o-transform: scaleX(.0); transform: scaleX(.0)}
.MJXp-scale1 {-webkit-transform: scaleX(.1); -moz-transform: scaleX(.1); -ms-transform: scaleX(.1); -o-transform: scaleX(.1); transform: scaleX(.1)}
.MJXp-scale2 {-webkit-transform: scaleX(.2); -moz-transform: scaleX(.2); -ms-transform: scaleX(.2); -o-transform: scaleX(.2); transform: scaleX(.2)}
.MJXp-scale3 {-webkit-transform: scaleX(.3); -moz-transform: scaleX(.3); -ms-transform: scaleX(.3); -o-transform: scaleX(.3); transform: scaleX(.3)}
.MJXp-scale4 {-webkit-transform: scaleX(.4); -moz-transform: scaleX(.4); -ms-transform: scaleX(.4); -o-transform: scaleX(.4); transform: scaleX(.4)}
.MJXp-scale5 {-webkit-transform: scaleX(.5); -moz-transform: scaleX(.5); -ms-transform: scaleX(.5); -o-transform: scaleX(.5); transform: scaleX(.5)}
.MJXp-scale6 {-webkit-transform: scaleX(.6); -moz-transform: scaleX(.6); -ms-transform: scaleX(.6); -o-transform: scaleX(.6); transform: scaleX(.6)}
.MJXp-scale7 {-webkit-transform: scaleX(.7); -moz-transform: scaleX(.7); -ms-transform: scaleX(.7); -o-transform: scaleX(.7); transform: scaleX(.7)}
.MJXp-scale8 {-webkit-transform: scaleX(.8); -moz-transform: scaleX(.8); -ms-transform: scaleX(.8); -o-transform: scaleX(.8); transform: scaleX(.8)}
.MJXp-scale9 {-webkit-transform: scaleX(.9); -moz-transform: scaleX(.9); -ms-transform: scaleX(.9); -o-transform: scaleX(.9); transform: scaleX(.9)}
</style><style data-styled="active" data-styled-version="6.1.13"></style><style id="onetrust-style">#onetrust-banner-sdk{-ms-text-size-adjust:100%;-webkit-text-size-adjust:100%}#onetrust-banner-sdk .onetrust-vendors-list-handler{cursor:pointer;color:#1f96db;font-size:inherit;font-weight:700;text-decoration:none;margin-left:5px}#onetrust-banner-sdk .onetrust-vendors-list-handler:hover{color:#1f96db}#onetrust-banner-sdk:focus{outline:2px solid #000;outline-offset:-2px}#onetrust-banner-sdk a:focus{outline:2px solid #000}#onetrust-banner-sdk #onetrust-accept-btn-handler,#onetrust-banner-sdk #onetrust-reject-all-handler,#onetrust-banner-sdk #onetrust-pc-btn-handler{outline-offset:1px}#onetrust-banner-sdk.ot-bnr-w-logo .ot-bnr-logo{height:64px;width:64px}#onetrust-banner-sdk .ot-tcf2-vendor-count.ot-text-bold{font-weight:700}#onetrust-banner-sdk .ot-close-icon,#onetrust-pc-sdk .ot-close-icon,#ot-sync-ntfy .ot-close-icon{background-size:contain;background-repeat:no-repeat;background-position:center;height:12px;width:12px}#onetrust-banner-sdk .powered-by-logo,#onetrust-banner-sdk .ot-pc-footer-logo a,#onetrust-pc-sdk .powered-by-logo,#onetrust-pc-sdk .ot-pc-footer-logo a,#ot-sync-ntfy .powered-by-logo,#ot-sync-ntfy .ot-pc-footer-logo a{background-size:contain;background-repeat:no-repeat;background-position:center;height:25px;width:152px;display:block;text-decoration:none;font-size:.75em}#onetrust-banner-sdk .powered-by-logo:hover,#onetrust-banner-sdk .ot-pc-footer-logo a:hover,#onetrust-pc-sdk .powered-by-logo:hover,#onetrust-pc-sdk .ot-pc-footer-logo a:hover,#ot-sync-ntfy .powered-by-logo:hover,#ot-sync-ntfy .ot-pc-footer-logo a:hover{color:#565656}#onetrust-banner-sdk h3 *,#onetrust-banner-sdk h4 *,#onetrust-banner-sdk h6 *,#onetrust-banner-sdk button *,#onetrust-banner-sdk a[data-parent-id] *,#onetrust-pc-sdk h3 *,#onetrust-pc-sdk h4 *,#onetrust-pc-sdk h6 *,#onetrust-pc-sdk button *,#onetrust-pc-sdk a[data-parent-id] *,#ot-sync-ntfy h3 *,#ot-sync-ntfy h4 *,#ot-sync-ntfy h6 *,#ot-sync-ntfy button *,#ot-sync-ntfy a[data-parent-id] *{font-size:inherit;font-weight:inherit;color:inherit}#onetrust-banner-sdk .ot-hide,#onetrust-pc-sdk .ot-hide,#ot-sync-ntfy .ot-hide{display:none!important}#onetrust-banner-sdk button.ot-link-btn:hover,#onetrust-pc-sdk button.ot-link-btn:hover,#ot-sync-ntfy button.ot-link-btn:hover{text-decoration:underline;opacity:1}#onetrust-pc-sdk .ot-sdk-row .ot-sdk-column{padding:0}#onetrust-pc-sdk .ot-sdk-container{padding-right:0}#onetrust-pc-sdk .ot-sdk-row{flex-direction:initial;width:100%}#onetrust-pc-sdk [type=checkbox]:checked,#onetrust-pc-sdk [type=checkbox]:not(:checked){pointer-events:initial}#onetrust-pc-sdk [type=checkbox]:disabled+label::before,#onetrust-pc-sdk [type=checkbox]:disabled+label:after,#onetrust-pc-sdk [type=checkbox]:disabled+label{pointer-events:none;opacity:.7}#onetrust-pc-sdk #vendor-list-content{transform:translate3d(0,0,0)}#onetrust-pc-sdk li input[type=checkbox]{z-index:1}#onetrust-pc-sdk li .ot-checkbox label{z-index:2}#onetrust-pc-sdk li .ot-checkbox input[type=checkbox]{height:auto;width:auto}#onetrust-pc-sdk li .host-title a,#onetrust-pc-sdk li .ot-host-name a,#onetrust-pc-sdk li .accordion-text,#onetrust-pc-sdk li .ot-acc-txt{z-index:2;position:relative}#onetrust-pc-sdk input{margin:3px .1ex}#onetrust-pc-sdk .pc-logo,#onetrust-pc-sdk .ot-pc-logo{height:60px;width:180px;background-position:center;background-size:contain;background-repeat:no-repeat;display:inline-flex;justify-content:center;align-items:center}#onetrust-pc-sdk .pc-logo img,#onetrust-pc-sdk .ot-pc-logo img{max-height:100%;max-width:100%}#onetrust-pc-sdk .screen-reader-only,#onetrust-pc-sdk .ot-scrn-rdr,.ot-sdk-cookie-policy .screen-reader-only,.ot-sdk-cookie-policy .ot-scrn-rdr{border:0;clip:rect(0 0 0 0);height:1px;margin:-1px;overflow:hidden;padding:0;position:absolute;width:1px}#onetrust-pc-sdk.ot-fade-in,.onetrust-pc-dark-filter.ot-fade-in,#onetrust-banner-sdk.ot-fade-in{animation-name:onetrust-fade-in;animation-duration:400ms;animation-timing-function:ease-in-out}#onetrust-pc-sdk.ot-hide{display:none!important}.onetrust-pc-dark-filter.ot-hide{display:none!important}#ot-sdk-btn.ot-sdk-show-settings,#ot-sdk-btn.optanon-show-settings{color:#68b631;border:1px solid #68b631;height:auto;white-space:normal;word-wrap:break-word;padding:.8em 2em;font-size:.8em;line-height:1.2;cursor:pointer;-moz-transition:.1s ease;-o-transition:.1s ease;-webkit-transition:1s ease;transition:.1s ease}#ot-sdk-btn.ot-sdk-show-settings:hover,#ot-sdk-btn.optanon-show-settings:hover{color:#fff;background-color:#68b631}.onetrust-pc-dark-filter{background:rgba(0,0,0,.5);z-index:2147483646;width:100%;height:100%;overflow:hidden;position:fixed;top:0;bottom:0;left:0}@keyframes onetrust-fade-in{0%{opacity:0}100%{opacity:1}}.ot-cookie-label{text-decoration:underline}@media only screen and (min-width:426px)and (max-width:896px)and (orientation:landscape){#onetrust-pc-sdk p{font-size:.75em}}#onetrust-banner-sdk .banner-option-input:focus+label{outline:1px solid #000;outline-style:auto}.category-vendors-list-handler+a:focus,.category-vendors-list-handler+a:focus-visible{outline:2px solid #000}#onetrust-pc-sdk .ot-userid-title{margin-top:10px}#onetrust-pc-sdk .ot-userid-title>span,#onetrust-pc-sdk .ot-userid-timestamp>span{font-weight:700}#onetrust-pc-sdk .ot-userid-desc{font-style:italic}#onetrust-pc-sdk .ot-host-desc a{pointer-events:initial}#onetrust-pc-sdk .ot-ven-hdr>p a{position:relative;z-index:2;pointer-events:initial}#onetrust-pc-sdk .ot-vnd-serv .ot-vnd-item .ot-vnd-info a,#onetrust-pc-sdk .ot-vs-list .ot-vnd-item .ot-vnd-info a{margin-right:auto}#onetrust-pc-sdk .ot-pc-footer-logo img{width:136px;height:16px}#onetrust-pc-sdk .ot-pur-vdr-count{font-weight:400;font-size:.7rem;padding-top:3px;display:block}#onetrust-banner-sdk .ot-optout-signal,#onetrust-pc-sdk .ot-optout-signal{border:1px solid #32ae88;border-radius:3px;padding:5px;margin-bottom:10px;background-color:#f9fffa;font-size:.85rem;line-height:2}#onetrust-banner-sdk .ot-optout-signal .ot-optout-icon,#onetrust-pc-sdk .ot-optout-signal .ot-optout-icon{display:inline;margin-right:5px}#onetrust-banner-sdk .ot-optout-signal svg,#onetrust-pc-sdk .ot-optout-signal svg{height:20px;width:30px;transform:scale(.5)}#onetrust-banner-sdk .ot-optout-signal svg path,#onetrust-pc-sdk .ot-optout-signal svg path{fill:#32ae88}#onetrust-banner-sdk,#onetrust-pc-sdk,#ot-sdk-cookie-policy,#ot-sync-ntfy{font-size:16px}#onetrust-banner-sdk *,#onetrust-banner-sdk ::after,#onetrust-banner-sdk ::before,#onetrust-pc-sdk *,#onetrust-pc-sdk ::after,#onetrust-pc-sdk ::before,#ot-sdk-cookie-policy *,#ot-sdk-cookie-policy ::after,#ot-sdk-cookie-policy ::before,#ot-sync-ntfy *,#ot-sync-ntfy ::after,#ot-sync-ntfy ::before{-webkit-box-sizing:content-box;-moz-box-sizing:content-box;box-sizing:content-box}#onetrust-banner-sdk div,#onetrust-banner-sdk span,#onetrust-banner-sdk h1,#onetrust-banner-sdk h2,#onetrust-banner-sdk h3,#onetrust-banner-sdk h4,#onetrust-banner-sdk h5,#onetrust-banner-sdk h6,#onetrust-banner-sdk p,#onetrust-banner-sdk img,#onetrust-banner-sdk svg,#onetrust-banner-sdk button,#onetrust-banner-sdk section,#onetrust-banner-sdk a,#onetrust-banner-sdk label,#onetrust-banner-sdk input,#onetrust-banner-sdk ul,#onetrust-banner-sdk li,#onetrust-banner-sdk nav,#onetrust-banner-sdk table,#onetrust-banner-sdk thead,#onetrust-banner-sdk tr,#onetrust-banner-sdk td,#onetrust-banner-sdk tbody,#onetrust-banner-sdk .ot-main-content,#onetrust-banner-sdk .ot-toggle,#onetrust-banner-sdk #ot-content,#onetrust-banner-sdk #ot-pc-content,#onetrust-banner-sdk .checkbox,#onetrust-pc-sdk div,#onetrust-pc-sdk span,#onetrust-pc-sdk h1,#onetrust-pc-sdk h2,#onetrust-pc-sdk h3,#onetrust-pc-sdk h4,#onetrust-pc-sdk h5,#onetrust-pc-sdk h6,#onetrust-pc-sdk p,#onetrust-pc-sdk img,#onetrust-pc-sdk svg,#onetrust-pc-sdk button,#onetrust-pc-sdk section,#onetrust-pc-sdk a,#onetrust-pc-sdk label,#onetrust-pc-sdk input,#onetrust-pc-sdk ul,#onetrust-pc-sdk li,#onetrust-pc-sdk nav,#onetrust-pc-sdk table,#onetrust-pc-sdk thead,#onetrust-pc-sdk tr,#onetrust-pc-sdk td,#onetrust-pc-sdk tbody,#onetrust-pc-sdk .ot-main-content,#onetrust-pc-sdk .ot-toggle,#onetrust-pc-sdk #ot-content,#onetrust-pc-sdk #ot-pc-content,#onetrust-pc-sdk .checkbox,#ot-sdk-cookie-policy div,#ot-sdk-cookie-policy span,#ot-sdk-cookie-policy h1,#ot-sdk-cookie-policy h2,#ot-sdk-cookie-policy h3,#ot-sdk-cookie-policy h4,#ot-sdk-cookie-policy h5,#ot-sdk-cookie-policy h6,#ot-sdk-cookie-policy p,#ot-sdk-cookie-policy img,#ot-sdk-cookie-policy svg,#ot-sdk-cookie-policy button,#ot-sdk-cookie-policy section,#ot-sdk-cookie-policy a,#ot-sdk-cookie-policy label,#ot-sdk-cookie-policy input,#ot-sdk-cookie-policy ul,#ot-sdk-cookie-policy li,#ot-sdk-cookie-policy nav,#ot-sdk-cookie-policy table,#ot-sdk-cookie-policy thead,#ot-sdk-cookie-policy tr,#ot-sdk-cookie-policy td,#ot-sdk-cookie-policy tbody,#ot-sdk-cookie-policy .ot-main-content,#ot-sdk-cookie-policy .ot-toggle,#ot-sdk-cookie-policy #ot-content,#ot-sdk-cookie-policy #ot-pc-content,#ot-sdk-cookie-policy .checkbox,#ot-sync-ntfy div,#ot-sync-ntfy span,#ot-sync-ntfy h1,#ot-sync-ntfy h2,#ot-sync-ntfy h3,#ot-sync-ntfy h4,#ot-sync-ntfy h5,#ot-sync-ntfy h6,#ot-sync-ntfy p,#ot-sync-ntfy img,#ot-sync-ntfy svg,#ot-sync-ntfy button,#ot-sync-ntfy section,#ot-sync-ntfy a,#ot-sync-ntfy label,#ot-sync-ntfy input,#ot-sync-ntfy ul,#ot-sync-ntfy li,#ot-sync-ntfy nav,#ot-sync-ntfy table,#ot-sync-ntfy thead,#ot-sync-ntfy tr,#ot-sync-ntfy td,#ot-sync-ntfy tbody,#ot-sync-ntfy .ot-main-content,#ot-sync-ntfy .ot-toggle,#ot-sync-ntfy #ot-content,#ot-sync-ntfy #ot-pc-content,#ot-sync-ntfy .checkbox{font-family:inherit;font-weight:400;-webkit-font-smoothing:auto;letter-spacing:normal;line-height:normal;padding:0;margin:0;height:auto;min-height:0;max-height:none;width:auto;min-width:0;max-width:none;border-radius:0;border:none;clear:none;float:none;position:static;bottom:auto;left:auto;right:auto;top:auto;text-align:left;text-decoration:none;text-indent:0;text-shadow:none;text-transform:none;white-space:normal;background:0 0;overflow:visible;vertical-align:baseline;visibility:visible;z-index:auto;box-shadow:none}#onetrust-banner-sdk label:before,#onetrust-banner-sdk label:after,#onetrust-banner-sdk .checkbox:after,#onetrust-banner-sdk .checkbox:before,#onetrust-pc-sdk label:before,#onetrust-pc-sdk label:after,#onetrust-pc-sdk .checkbox:after,#onetrust-pc-sdk .checkbox:before,#ot-sdk-cookie-policy label:before,#ot-sdk-cookie-policy label:after,#ot-sdk-cookie-policy .checkbox:after,#ot-sdk-cookie-policy .checkbox:before,#ot-sync-ntfy label:before,#ot-sync-ntfy label:after,#ot-sync-ntfy .checkbox:after,#ot-sync-ntfy .checkbox:before{content:"";content:none}#onetrust-banner-sdk .ot-sdk-container,#onetrust-pc-sdk .ot-sdk-container,#ot-sdk-cookie-policy .ot-sdk-container{position:relative;width:100%;max-width:100%;margin:0 auto;padding:0 20px;box-sizing:border-box}#onetrust-banner-sdk .ot-sdk-column,#onetrust-banner-sdk .ot-sdk-columns,#onetrust-pc-sdk .ot-sdk-column,#onetrust-pc-sdk .ot-sdk-columns,#ot-sdk-cookie-policy .ot-sdk-column,#ot-sdk-cookie-policy .ot-sdk-columns{width:100%;float:left;box-sizing:border-box;padding:0;display:initial}@media(min-width:400px){#onetrust-banner-sdk .ot-sdk-container,#onetrust-pc-sdk .ot-sdk-container,#ot-sdk-cookie-policy .ot-sdk-container{width:90%;padding:0}}@media(min-width:550px){#onetrust-banner-sdk .ot-sdk-container,#onetrust-pc-sdk .ot-sdk-container,#ot-sdk-cookie-policy .ot-sdk-container{width:100%}#onetrust-banner-sdk .ot-sdk-column,#onetrust-banner-sdk .ot-sdk-columns,#onetrust-pc-sdk .ot-sdk-column,#onetrust-pc-sdk .ot-sdk-columns,#ot-sdk-cookie-policy .ot-sdk-column,#ot-sdk-cookie-policy .ot-sdk-columns{margin-left:4%}#onetrust-banner-sdk .ot-sdk-column:first-child,#onetrust-banner-sdk .ot-sdk-columns:first-child,#onetrust-pc-sdk .ot-sdk-column:first-child,#onetrust-pc-sdk .ot-sdk-columns:first-child,#ot-sdk-cookie-policy .ot-sdk-column:first-child,#ot-sdk-cookie-policy .ot-sdk-columns:first-child{margin-left:0}#onetrust-banner-sdk .ot-sdk-two.ot-sdk-columns,#onetrust-pc-sdk .ot-sdk-two.ot-sdk-columns,#ot-sdk-cookie-policy .ot-sdk-two.ot-sdk-columns{width:13.3333333333%}#onetrust-banner-sdk .ot-sdk-three.ot-sdk-columns,#onetrust-pc-sdk .ot-sdk-three.ot-sdk-columns,#ot-sdk-cookie-policy .ot-sdk-three.ot-sdk-columns{width:22%}#onetrust-banner-sdk .ot-sdk-four.ot-sdk-columns,#onetrust-pc-sdk .ot-sdk-four.ot-sdk-columns,#ot-sdk-cookie-policy .ot-sdk-four.ot-sdk-columns{width:30.6666666667%}#onetrust-banner-sdk .ot-sdk-eight.ot-sdk-columns,#onetrust-pc-sdk .ot-sdk-eight.ot-sdk-columns,#ot-sdk-cookie-policy .ot-sdk-eight.ot-sdk-columns{width:65.3333333333%}#onetrust-banner-sdk .ot-sdk-nine.ot-sdk-columns,#onetrust-pc-sdk .ot-sdk-nine.ot-sdk-columns,#ot-sdk-cookie-policy .ot-sdk-nine.ot-sdk-columns{width:74%}#onetrust-banner-sdk .ot-sdk-ten.ot-sdk-columns,#onetrust-pc-sdk .ot-sdk-ten.ot-sdk-columns,#ot-sdk-cookie-policy .ot-sdk-ten.ot-sdk-columns{width:82.6666666667%}#onetrust-banner-sdk .ot-sdk-eleven.ot-sdk-columns,#onetrust-pc-sdk .ot-sdk-eleven.ot-sdk-columns,#ot-sdk-cookie-policy .ot-sdk-eleven.ot-sdk-columns{width:91.3333333333%}#onetrust-banner-sdk .ot-sdk-twelve.ot-sdk-columns,#onetrust-pc-sdk .ot-sdk-twelve.ot-sdk-columns,#ot-sdk-cookie-policy .ot-sdk-twelve.ot-sdk-columns{width:100%;margin-left:0}}#onetrust-banner-sdk h1,#onetrust-banner-sdk h2,#onetrust-banner-sdk h3,#onetrust-banner-sdk h4,#onetrust-banner-sdk h5,#onetrust-banner-sdk h6,#onetrust-pc-sdk h1,#onetrust-pc-sdk h2,#onetrust-pc-sdk h3,#onetrust-pc-sdk h4,#onetrust-pc-sdk h5,#onetrust-pc-sdk h6,#ot-sdk-cookie-policy h1,#ot-sdk-cookie-policy h2,#ot-sdk-cookie-policy h3,#ot-sdk-cookie-policy h4,#ot-sdk-cookie-policy h5,#ot-sdk-cookie-policy h6{margin-top:0;font-weight:600;font-family:inherit}#onetrust-banner-sdk h1,#onetrust-pc-sdk h1,#ot-sdk-cookie-policy h1{font-size:1.5rem;line-height:1.2}#onetrust-banner-sdk h2,#onetrust-pc-sdk h2,#ot-sdk-cookie-policy h2{font-size:1.5rem;line-height:1.25}#onetrust-banner-sdk h3,#onetrust-pc-sdk h3,#ot-sdk-cookie-policy h3{font-size:1.5rem;line-height:1.3}#onetrust-banner-sdk h4,#onetrust-pc-sdk h4,#ot-sdk-cookie-policy h4{font-size:1.5rem;line-height:1.35}#onetrust-banner-sdk h5,#onetrust-pc-sdk h5,#ot-sdk-cookie-policy h5{font-size:1.5rem;line-height:1.5}#onetrust-banner-sdk h6,#onetrust-pc-sdk h6,#ot-sdk-cookie-policy h6{font-size:1.5rem;line-height:1.6}@media(min-width:550px){#onetrust-banner-sdk h1,#onetrust-pc-sdk h1,#ot-sdk-cookie-policy h1{font-size:1.5rem}#onetrust-banner-sdk h2,#onetrust-pc-sdk h2,#ot-sdk-cookie-policy h2{font-size:1.5rem}#onetrust-banner-sdk h3,#onetrust-pc-sdk h3,#ot-sdk-cookie-policy h3{font-size:1.5rem}#onetrust-banner-sdk h4,#onetrust-pc-sdk h4,#ot-sdk-cookie-policy h4{font-size:1.5rem}#onetrust-banner-sdk h5,#onetrust-pc-sdk h5,#ot-sdk-cookie-policy h5{font-size:1.5rem}#onetrust-banner-sdk h6,#onetrust-pc-sdk h6,#ot-sdk-cookie-policy h6{font-size:1.5rem}}#onetrust-banner-sdk p,#onetrust-pc-sdk p,#ot-sdk-cookie-policy p{margin:0 0 1em;font-family:inherit;line-height:normal}#onetrust-banner-sdk a,#onetrust-pc-sdk a,#ot-sdk-cookie-policy a{color:#565656;text-decoration:underline}#onetrust-banner-sdk a:hover,#onetrust-pc-sdk a:hover,#ot-sdk-cookie-policy a:hover{color:#565656;text-decoration:none}#onetrust-banner-sdk .ot-sdk-button,#onetrust-banner-sdk button,#onetrust-pc-sdk .ot-sdk-button,#onetrust-pc-sdk button,#ot-sdk-cookie-policy .ot-sdk-button,#ot-sdk-cookie-policy button{margin-bottom:1rem;font-family:inherit}#onetrust-banner-sdk .ot-sdk-button,#onetrust-banner-sdk button,#onetrust-pc-sdk .ot-sdk-button,#onetrust-pc-sdk button,#ot-sdk-cookie-policy .ot-sdk-button,#ot-sdk-cookie-policy button{display:inline-block;height:38px;padding:0 30px;color:#555;text-align:center;font-size:.9em;font-weight:400;line-height:38px;letter-spacing:.01em;text-decoration:none;white-space:nowrap;background-color:transparent;border-radius:2px;border:1px solid #bbb;cursor:pointer;box-sizing:border-box}#onetrust-banner-sdk .ot-sdk-button:hover,#onetrust-banner-sdk :not(.ot-leg-btn-container)>button:not(.ot-link-btn):hover,#onetrust-banner-sdk :not(.ot-leg-btn-container)>button:not(.ot-link-btn):focus,#onetrust-pc-sdk .ot-sdk-button:hover,#onetrust-pc-sdk :not(.ot-leg-btn-container)>button:not(.ot-link-btn):hover,#onetrust-pc-sdk :not(.ot-leg-btn-container)>button:not(.ot-link-btn):focus,#ot-sdk-cookie-policy .ot-sdk-button:hover,#ot-sdk-cookie-policy :not(.ot-leg-btn-container)>button:not(.ot-link-btn):hover,#ot-sdk-cookie-policy :not(.ot-leg-btn-container)>button:not(.ot-link-btn):focus{color:#333;border-color:#888;opacity:.7}#onetrust-banner-sdk .ot-sdk-button:focus,#onetrust-banner-sdk :not(.ot-leg-btn-container)>button:focus,#onetrust-pc-sdk .ot-sdk-button:focus,#onetrust-pc-sdk :not(.ot-leg-btn-container)>button:focus,#ot-sdk-cookie-policy .ot-sdk-button:focus,#ot-sdk-cookie-policy :not(.ot-leg-btn-container)>button:focus{outline:2px solid #000}#onetrust-banner-sdk .ot-sdk-button.ot-sdk-button-primary,#onetrust-banner-sdk button.ot-sdk-button-primary,#onetrust-banner-sdk input[type=submit].ot-sdk-button-primary,#onetrust-banner-sdk input[type=reset].ot-sdk-button-primary,#onetrust-banner-sdk input[type=button].ot-sdk-button-primary,#onetrust-pc-sdk .ot-sdk-button.ot-sdk-button-primary,#onetrust-pc-sdk button.ot-sdk-button-primary,#onetrust-pc-sdk input[type=submit].ot-sdk-button-primary,#onetrust-pc-sdk input[type=reset].ot-sdk-button-primary,#onetrust-pc-sdk input[type=button].ot-sdk-button-primary,#ot-sdk-cookie-policy .ot-sdk-button.ot-sdk-button-primary,#ot-sdk-cookie-policy button.ot-sdk-button-primary,#ot-sdk-cookie-policy input[type=submit].ot-sdk-button-primary,#ot-sdk-cookie-policy input[type=reset].ot-sdk-button-primary,#ot-sdk-cookie-policy input[type=button].ot-sdk-button-primary{color:#fff;background-color:#33c3f0;border-color:#33c3f0}#onetrust-banner-sdk .ot-sdk-button.ot-sdk-button-primary:hover,#onetrust-banner-sdk button.ot-sdk-button-primary:hover,#onetrust-banner-sdk input[type=submit].ot-sdk-button-primary:hover,#onetrust-banner-sdk input[type=reset].ot-sdk-button-primary:hover,#onetrust-banner-sdk input[type=button].ot-sdk-button-primary:hover,#onetrust-banner-sdk .ot-sdk-button.ot-sdk-button-primary:focus,#onetrust-banner-sdk button.ot-sdk-button-primary:focus,#onetrust-banner-sdk input[type=submit].ot-sdk-button-primary:focus,#onetrust-banner-sdk input[type=reset].ot-sdk-button-primary:focus,#onetrust-banner-sdk input[type=button].ot-sdk-button-primary:focus,#onetrust-pc-sdk .ot-sdk-button.ot-sdk-button-primary:hover,#onetrust-pc-sdk button.ot-sdk-button-primary:hover,#onetrust-pc-sdk input[type=submit].ot-sdk-button-primary:hover,#onetrust-pc-sdk input[type=reset].ot-sdk-button-primary:hover,#onetrust-pc-sdk input[type=button].ot-sdk-button-primary:hover,#onetrust-pc-sdk .ot-sdk-button.ot-sdk-button-primary:focus,#onetrust-pc-sdk button.ot-sdk-button-primary:focus,#onetrust-pc-sdk input[type=submit].ot-sdk-button-primary:focus,#onetrust-pc-sdk input[type=reset].ot-sdk-button-primary:focus,#onetrust-pc-sdk input[type=button].ot-sdk-button-primary:focus,#ot-sdk-cookie-policy .ot-sdk-button.ot-sdk-button-primary:hover,#ot-sdk-cookie-policy button.ot-sdk-button-primary:hover,#ot-sdk-cookie-policy input[type=submit].ot-sdk-button-primary:hover,#ot-sdk-cookie-policy input[type=reset].ot-sdk-button-primary:hover,#ot-sdk-cookie-policy input[type=button].ot-sdk-button-primary:hover,#ot-sdk-cookie-policy .ot-sdk-button.ot-sdk-button-primary:focus,#ot-sdk-cookie-policy button.ot-sdk-button-primary:focus,#ot-sdk-cookie-policy input[type=submit].ot-sdk-button-primary:focus,#ot-sdk-cookie-policy input[type=reset].ot-sdk-button-primary:focus,#ot-sdk-cookie-policy input[type=button].ot-sdk-button-primary:focus{color:#fff;background-color:#1eaedb;border-color:#1eaedb}#onetrust-banner-sdk input[type=text],#onetrust-pc-sdk input[type=text],#ot-sdk-cookie-policy input[type=text]{height:38px;padding:6px 10px;background-color:#fff;border:1px solid #d1d1d1;border-radius:4px;box-shadow:none;box-sizing:border-box}#onetrust-banner-sdk input[type=text],#onetrust-pc-sdk input[type=text],#ot-sdk-cookie-policy input[type=text]{-webkit-appearance:none;-moz-appearance:none;appearance:none}#onetrust-banner-sdk input[type=text]:focus,#onetrust-pc-sdk input[type=text]:focus,#ot-sdk-cookie-policy input[type=text]:focus{border:1px solid #000;outline:0}#onetrust-banner-sdk label,#onetrust-pc-sdk label,#ot-sdk-cookie-policy label{display:block;margin-bottom:.5rem;font-weight:600}#onetrust-banner-sdk input[type=checkbox],#onetrust-pc-sdk input[type=checkbox],#ot-sdk-cookie-policy input[type=checkbox]{display:inline}#onetrust-banner-sdk ul,#onetrust-pc-sdk ul,#ot-sdk-cookie-policy ul{list-style:circle inside}#onetrust-banner-sdk ul,#onetrust-pc-sdk ul,#ot-sdk-cookie-policy ul{padding-left:0;margin-top:0}#onetrust-banner-sdk ul ul,#onetrust-pc-sdk ul ul,#ot-sdk-cookie-policy ul ul{margin:1.5rem 0 1.5rem 3rem;font-size:90%}#onetrust-banner-sdk li,#onetrust-pc-sdk li,#ot-sdk-cookie-policy li{margin-bottom:1rem}#onetrust-banner-sdk th,#onetrust-banner-sdk td,#onetrust-pc-sdk th,#onetrust-pc-sdk td,#ot-sdk-cookie-policy th,#ot-sdk-cookie-policy td{padding:12px 15px;text-align:left;border-bottom:1px solid #e1e1e1}#onetrust-banner-sdk button,#onetrust-pc-sdk button,#ot-sdk-cookie-policy button{margin-bottom:1rem;font-family:inherit}#onetrust-banner-sdk .ot-sdk-container:after,#onetrust-banner-sdk .ot-sdk-row:after,#onetrust-pc-sdk .ot-sdk-container:after,#onetrust-pc-sdk .ot-sdk-row:after,#ot-sdk-cookie-policy .ot-sdk-container:after,#ot-sdk-cookie-policy .ot-sdk-row:after{content:"";display:table;clear:both}#onetrust-banner-sdk .ot-sdk-row,#onetrust-pc-sdk .ot-sdk-row,#ot-sdk-cookie-policy .ot-sdk-row{margin:0;max-width:none;display:block}#onetrust-banner-sdk{box-shadow:0 0 18px rgba(0,0,0,.2)}#onetrust-banner-sdk.otFlat{position:fixed;z-index:2147483645;bottom:0;right:0;left:0;background-color:#fff;max-height:90%;overflow-x:hidden;overflow-y:auto}#onetrust-banner-sdk.otFlat.top{top:0px;bottom:auto}#onetrust-banner-sdk.otRelFont{font-size:1rem}#onetrust-banner-sdk>.ot-sdk-container{overflow:hidden}#onetrust-banner-sdk::-webkit-scrollbar{width:11px}#onetrust-banner-sdk::-webkit-scrollbar-thumb{border-radius:10px;background:#c1c1c1}#onetrust-banner-sdk{scrollbar-arrow-color:#c1c1c1;scrollbar-darkshadow-color:#c1c1c1;scrollbar-face-color:#c1c1c1;scrollbar-shadow-color:#c1c1c1}#onetrust-banner-sdk #onetrust-policy{margin:1.25em 0 .625em 2em;overflow:hidden}#onetrust-banner-sdk #onetrust-policy .ot-gv-list-handler{float:left;font-size:.82em;padding:0;margin-bottom:0;border:0;line-height:normal;height:auto;width:auto}#onetrust-banner-sdk #onetrust-policy-title{font-size:1.2em;line-height:1.3;margin-bottom:10px}#onetrust-banner-sdk #onetrust-policy-text{clear:both;text-align:left;font-size:.88em;line-height:1.4}#onetrust-banner-sdk #onetrust-policy-text *{font-size:inherit;line-height:inherit}#onetrust-banner-sdk #onetrust-policy-text a{font-weight:bold;margin-left:5px}#onetrust-banner-sdk #onetrust-policy-title,#onetrust-banner-sdk #onetrust-policy-text{color:dimgray;float:left}#onetrust-banner-sdk #onetrust-button-group-parent{min-height:1px;text-align:center}#onetrust-banner-sdk #onetrust-button-group{display:inline-block}#onetrust-banner-sdk #onetrust-accept-btn-handler,#onetrust-banner-sdk #onetrust-reject-all-handler,#onetrust-banner-sdk #onetrust-pc-btn-handler{background-color:#68b631;color:#fff;border-color:#68b631;margin-right:1em;min-width:125px;height:auto;white-space:normal;word-break:break-word;word-wrap:break-word;padding:12px 10px;line-height:1.2;font-size:.813em;font-weight:600}#onetrust-banner-sdk #onetrust-pc-btn-handler.cookie-setting-link{background-color:#fff;border:none;color:#68b631;text-decoration:underline;padding-left:0;padding-right:0}#onetrust-banner-sdk .onetrust-close-btn-ui{width:44px;height:44px;background-size:12px;border:none;position:relative;margin:auto;padding:0}#onetrust-banner-sdk .banner_logo{display:none}#onetrust-banner-sdk.ot-bnr-w-logo .ot-bnr-logo{position:absolute;top:50%;transform:translateY(-50%);left:0px}#onetrust-banner-sdk.ot-bnr-w-logo #onetrust-policy{margin-left:65px}#onetrust-banner-sdk .ot-b-addl-desc{clear:both;float:left;display:block}#onetrust-banner-sdk #banner-options{float:left;display:table;margin-right:0;margin-left:1em;width:calc(100% - 1em)}#onetrust-banner-sdk .banner-option-input{cursor:pointer;width:auto;height:auto;border:none;padding:0;padding-right:3px;margin:0 0 10px;font-size:.82em;line-height:1.4}#onetrust-banner-sdk .banner-option-input *{pointer-events:none;font-size:inherit;line-height:inherit}#onetrust-banner-sdk .banner-option-input[aria-expanded=true]~.banner-option-details{display:block;height:auto}#onetrust-banner-sdk .banner-option-input[aria-expanded=true] .ot-arrow-container{transform:rotate(90deg)}#onetrust-banner-sdk .banner-option{margin-bottom:12px;margin-left:0;border:none;float:left;padding:0}#onetrust-banner-sdk .banner-option:first-child{padding-left:2px}#onetrust-banner-sdk .banner-option:not(:first-child){padding:0;border:none}#onetrust-banner-sdk .banner-option-header{cursor:pointer;display:inline-block}#onetrust-banner-sdk .banner-option-header :first-child{color:dimgray;font-weight:bold;float:left}#onetrust-banner-sdk .banner-option-header .ot-arrow-container{display:inline-block;border-top:6px solid rgba(0,0,0,0);border-bottom:6px solid rgba(0,0,0,0);border-left:6px solid dimgray;margin-left:10px;vertical-align:middle}#onetrust-banner-sdk .banner-option-details{display:none;font-size:.83em;line-height:1.5;padding:10px 0px 5px 10px;margin-right:10px;height:0px}#onetrust-banner-sdk .banner-option-details *{font-size:inherit;line-height:inherit;color:dimgray}#onetrust-banner-sdk .ot-arrow-container,#onetrust-banner-sdk .banner-option-details{transition:all 300ms ease-in 0s;-webkit-transition:all 300ms ease-in 0s;-moz-transition:all 300ms ease-in 0s;-o-transition:all 300ms ease-in 0s}#onetrust-banner-sdk .ot-dpd-container{float:left}#onetrust-banner-sdk .ot-dpd-title{margin-bottom:10px}#onetrust-banner-sdk .ot-dpd-title,#onetrust-banner-sdk .ot-dpd-desc{font-size:.88em;line-height:1.4;color:dimgray}#onetrust-banner-sdk .ot-dpd-title *,#onetrust-banner-sdk .ot-dpd-desc *{font-size:inherit;line-height:inherit}#onetrust-banner-sdk.ot-iab-2 #onetrust-policy-text *{margin-bottom:0}#onetrust-banner-sdk.ot-iab-2 .onetrust-vendors-list-handler{display:block;margin-left:0;margin-top:5px;clear:both;margin-bottom:0;padding:0;border:0;height:auto;width:auto}#onetrust-banner-sdk.ot-iab-2 #onetrust-button-group button{display:block}#onetrust-banner-sdk.ot-close-btn-link{padding-top:25px}#onetrust-banner-sdk.ot-close-btn-link #onetrust-close-btn-container{top:15px;transform:none;right:15px}#onetrust-banner-sdk.ot-close-btn-link #onetrust-close-btn-container button{padding:0;white-space:pre-wrap;border:none;height:auto;line-height:1.5;text-decoration:underline;font-size:.69em}#onetrust-banner-sdk #onetrust-policy-text,#onetrust-banner-sdk .ot-dpd-desc,#onetrust-banner-sdk .ot-b-addl-desc{font-size:.813em;line-height:1.5}#onetrust-banner-sdk .ot-dpd-desc{margin-bottom:10px}#onetrust-banner-sdk .ot-dpd-desc>.ot-b-addl-desc{margin-top:10px;margin-bottom:10px;font-size:1em}@media only screen and (max-width: 425px){#onetrust-banner-sdk #onetrust-close-btn-container{position:absolute;top:6px;right:2px}#onetrust-banner-sdk #onetrust-policy{margin-left:0;margin-top:3em}#onetrust-banner-sdk #onetrust-button-group{display:block}#onetrust-banner-sdk #onetrust-accept-btn-handler,#onetrust-banner-sdk #onetrust-reject-all-handler,#onetrust-banner-sdk #onetrust-pc-btn-handler{width:100%}#onetrust-banner-sdk .onetrust-close-btn-ui{top:auto;transform:none}#onetrust-banner-sdk #onetrust-policy-title{display:inline;float:none}#onetrust-banner-sdk #banner-options{margin:0;padding:0;width:100%}}@media only screen and (min-width: 426px)and (max-width: 896px){#onetrust-banner-sdk #onetrust-close-btn-container{position:absolute;top:0;right:0}#onetrust-banner-sdk #onetrust-policy{margin-left:1em;margin-right:1em}#onetrust-banner-sdk .onetrust-close-btn-ui{top:10px;right:10px}#onetrust-banner-sdk:not(.ot-iab-2) #onetrust-group-container{width:95%}#onetrust-banner-sdk.ot-iab-2 #onetrust-group-container{width:100%}#onetrust-banner-sdk.ot-bnr-w-logo #onetrust-button-group-parent{padding-left:50px}#onetrust-banner-sdk #onetrust-button-group-parent{width:100%;position:relative;margin-left:0}#onetrust-banner-sdk #onetrust-button-group button{display:inline-block}#onetrust-banner-sdk #onetrust-button-group{margin-right:0;text-align:center}#onetrust-banner-sdk .has-reject-all-button #onetrust-pc-btn-handler{float:left}#onetrust-banner-sdk .has-reject-all-button #onetrust-reject-all-handler,#onetrust-banner-sdk .has-reject-all-button #onetrust-accept-btn-handler{float:right}#onetrust-banner-sdk .has-reject-all-button #onetrust-button-group{width:calc(100% - 2em);margin-right:0}#onetrust-banner-sdk .has-reject-all-button #onetrust-pc-btn-handler.cookie-setting-link{padding-left:0px;text-align:left}#onetrust-banner-sdk.ot-buttons-fw .ot-sdk-three button{width:100%;text-align:center}#onetrust-banner-sdk.ot-buttons-fw #onetrust-button-group-parent button{float:none}#onetrust-banner-sdk.ot-buttons-fw #onetrust-pc-btn-handler.cookie-setting-link{text-align:center}}@media only screen and (min-width: 550px){#onetrust-banner-sdk .banner-option:not(:first-child){border-left:1px solid #d8d8d8;padding-left:25px}}@media only screen and (min-width: 425px)and (max-width: 550px){#onetrust-banner-sdk.ot-iab-2 #onetrust-button-group,#onetrust-banner-sdk.ot-iab-2 #onetrust-policy,#onetrust-banner-sdk.ot-iab-2 .banner-option{width:100%}#onetrust-banner-sdk.ot-iab-2 #onetrust-button-group #onetrust-accept-btn-handler,#onetrust-banner-sdk.ot-iab-2 #onetrust-button-group #onetrust-reject-all-handler,#onetrust-banner-sdk.ot-iab-2 #onetrust-button-group #onetrust-pc-btn-handler{width:100%}#onetrust-banner-sdk.ot-iab-2 #onetrust-button-group #onetrust-accept-btn-handler,#onetrust-banner-sdk.ot-iab-2 #onetrust-button-group #onetrust-reject-all-handler{float:left}}@media only screen and (min-width: 769px){#onetrust-banner-sdk #onetrust-button-group{margin-right:30%}#onetrust-banner-sdk #banner-options{margin-left:2em;margin-right:5em;margin-bottom:1.25em;width:calc(100% - 7em)}}@media only screen and (min-width: 897px)and (max-width: 1023px){#onetrust-banner-sdk.vertical-align-content #onetrust-button-group-parent{position:absolute;top:50%;left:75%;transform:translateY(-50%)}#onetrust-banner-sdk #onetrust-close-btn-container{top:50%;margin:auto;transform:translate(-50%, -50%);position:absolute;padding:0;right:0}#onetrust-banner-sdk #onetrust-close-btn-container button{position:relative;margin:0;right:-22px;top:2px}}@media only screen and (min-width: 1024px){#onetrust-banner-sdk #onetrust-close-btn-container{top:50%;margin:auto;transform:translate(-50%, -50%);position:absolute;right:0}#onetrust-banner-sdk #onetrust-close-btn-container button{right:-12px}#onetrust-banner-sdk #onetrust-policy{margin-left:2em}#onetrust-banner-sdk.vertical-align-content #onetrust-button-group-parent{position:absolute;top:50%;left:60%;transform:translateY(-50%)}#onetrust-banner-sdk .ot-optout-signal{width:50%}#onetrust-banner-sdk.ot-iab-2 #onetrust-policy-title{width:50%}#onetrust-banner-sdk.ot-iab-2 #onetrust-policy-text,#onetrust-banner-sdk.ot-iab-2 :not(.ot-dpd-desc)>.ot-b-addl-desc{margin-bottom:1em;width:50%;border-right:1px solid #d8d8d8;padding-right:1rem}#onetrust-banner-sdk.ot-iab-2 #onetrust-policy-text{margin-bottom:0;padding-bottom:1em}#onetrust-banner-sdk.ot-iab-2 :not(.ot-dpd-desc)>.ot-b-addl-desc{margin-bottom:0;padding-bottom:1em}#onetrust-banner-sdk.ot-iab-2 .ot-dpd-container{width:45%;padding-left:1rem;display:inline-block;float:none}#onetrust-banner-sdk.ot-iab-2 .ot-dpd-title{line-height:1.7}#onetrust-banner-sdk.ot-iab-2 #onetrust-button-group-parent{left:auto;right:4%;margin-left:0}#onetrust-banner-sdk.ot-iab-2 #onetrust-button-group button{display:block}#onetrust-banner-sdk:not(.ot-iab-2) #onetrust-button-group-parent{margin:auto;width:30%}#onetrust-banner-sdk:not(.ot-iab-2) #onetrust-group-container{width:60%}#onetrust-banner-sdk #onetrust-button-group{margin-right:auto}#onetrust-banner-sdk #onetrust-accept-btn-handler,#onetrust-banner-sdk #onetrust-reject-all-handler,#onetrust-banner-sdk #onetrust-pc-btn-handler{margin-top:1em}}@media only screen and (min-width: 890px){#onetrust-banner-sdk.ot-buttons-fw:not(.ot-iab-2) #onetrust-button-group-parent{padding-left:3%;padding-right:4%;margin-left:0}#onetrust-banner-sdk.ot-buttons-fw:not(.ot-iab-2) #onetrust-button-group{margin-right:0;margin-top:1.25em;width:100%}#onetrust-banner-sdk.ot-buttons-fw:not(.ot-iab-2) #onetrust-button-group button{width:100%;margin-bottom:5px;margin-top:5px}#onetrust-banner-sdk.ot-buttons-fw:not(.ot-iab-2) #onetrust-button-group button:last-of-type{margin-bottom:20px}}@media only screen and (min-width: 1280px){#onetrust-banner-sdk:not(.ot-iab-2) #onetrust-group-container{width:55%}#onetrust-banner-sdk:not(.ot-iab-2) #onetrust-button-group-parent{width:44%;padding-left:2%;padding-right:2%}#onetrust-banner-sdk:not(.ot-iab-2).vertical-align-content #onetrust-button-group-parent{position:absolute;left:55%}}
        #onetrust-consent-sdk #onetrust-banner-sdk {background-color: #FFF;}
            #onetrust-consent-sdk #onetrust-policy-title,
                    #onetrust-consent-sdk #onetrust-policy-text,
                    #onetrust-consent-sdk .ot-b-addl-desc,
                    #onetrust-consent-sdk .ot-dpd-desc,
                    #onetrust-consent-sdk .ot-dpd-title,
                    #onetrust-consent-sdk #onetrust-policy-text *:not(.onetrust-vendors-list-handler),
                    #onetrust-consent-sdk .ot-dpd-desc *:not(.onetrust-vendors-list-handler),
                    #onetrust-consent-sdk #onetrust-banner-sdk #banner-options *,
                    #onetrust-banner-sdk .ot-cat-header,
                    #onetrust-banner-sdk .ot-optout-signal
                    {
                        color: #2E2E2E;
                    }
            #onetrust-consent-sdk #onetrust-banner-sdk .banner-option-details {
                    background-color: #E9E9E9;}
             #onetrust-consent-sdk #onetrust-banner-sdk a[href],
                    #onetrust-consent-sdk #onetrust-banner-sdk a[href] font,
                    #onetrust-consent-sdk #onetrust-banner-sdk .ot-link-btn
                        {
                            color: #007398;
                        }#onetrust-consent-sdk #onetrust-accept-btn-handler,
                         #onetrust-banner-sdk #onetrust-reject-all-handler {
                            background-color: #007398;border-color: #007398;
                color: #FFF;
            }
            #onetrust-consent-sdk #onetrust-banner-sdk *:focus,
            #onetrust-consent-sdk #onetrust-banner-sdk:focus {
               outline-color: #000000;
               outline-width: 1px;
            }
            #onetrust-consent-sdk #onetrust-pc-btn-handler,
            #onetrust-consent-sdk #onetrust-pc-btn-handler.cookie-setting-link {
                color: #6CC04A; border-color: #6CC04A;
                background-color:
                #FFF;
            }/*! Extra code to blur out background */
.onetrust-pc-dark-filter{
background:rgba(0,0,0,.5);
z-index:2147483646;
width:100%;
height:100%;
overflow:hidden;
position:fixed;
top:0;
bottom:0;
left:0;
backdrop-filter: initial
}

/*! v6.12.0 2021-01-19 */
div#onetrust-consent-sdk #onetrust-banner-sdk{border-top:2px solid #eb6500!important;outline:1px solid transparent;box-shadow:none;padding:24px}div#onetrust-consent-sdk button{border-radius:0!important;box-shadow:none!important;box-sizing:border-box!important;font-size:20px!important;font-weight:400!important;letter-spacing:0!important;max-width:none!important;white-space:nowrap!important}div#onetrust-consent-sdk button:not(.ot-link-btn){background-color:#007398!important;border:2px solid #007398!important;color:#fff!important;height:48px!important;padding:0 1em!important;width:auto!important}div#onetrust-consent-sdk button:hover{background-color:#fff!important;border-color:#eb6500!important;color:#2e2e2e!important}div#onetrust-consent-sdk button.ot-link-btn{color:#007398!important;font-size:16px!important;text-decoration:underline}div#onetrust-consent-sdk button.ot-link-btn:hover{color:inherit!important;text-decoration-color:#eb6500!important}div#onetrust-consent-sdk a,div#onetrust-pc-sdk a{color:#007398!important;text-decoration:underline!important}div#onetrust-consent-sdk a,div#onetrust-consent-sdk button,div#onetrust-consent-sdk p:hover{opacity:1!important}div#onetrust-consent-sdk a:focus,div#onetrust-consent-sdk button:focus,div#onetrust-consent-sdk input:focus{outline:2px solid #eb6500!important;outline-offset:1px!important}div#onetrust-banner-sdk .ot-sdk-container{padding:0;width:auto}div#onetrust-banner-sdk .ot-sdk-row{align-items:flex-start;box-sizing:border-box;display:flex;flex-direction:column;justify-content:space-between;margin:auto;max-width:1152px}div#onetrust-banner-sdk .ot-sdk-row:after{display:none}div#onetrust-banner-sdk #onetrust-group-container,div#onetrust-banner-sdk.ot-bnr-flift:not(.ot-iab-2) #onetrust-group-container,div#onetrust-banner-sdk:not(.ot-iab-2) #onetrust-group-container{flex-grow:1;width:auto}div#onetrust-banner-sdk #onetrust-policy,div#onetrust-banner-sdk.ot-bnr-flift #onetrust-policy{margin:0;overflow:visible}div#onetrust-banner-sdk.ot-bnr-flift #onetrust-policy-text,div#onetrust-consent-sdk #onetrust-policy-text{font-size:16px;line-height:24px;max-width:44em;margin:0}div#onetrust-consent-sdk #onetrust-policy-text a[href]{font-weight:400;margin-left:8px}div#onetrust-banner-sdk #onetrust-button-group-parent{flex:0 0 auto;margin:32px 0 0;width:100%}div#onetrust-banner-sdk #onetrust-button-group{display:flex;flex-direction:row;flex-wrap:wrap;justify-content:flex-end;margin:-8px}div#onetrust-banner-sdk .banner-actions-container{display:flex;flex:1 0 auto}div#onetrust-banner-sdk.ot-buttons-fw:not(.ot-iab-2) #onetrust-button-group button:last-of-type,div#onetrust-consent-sdk #onetrust-accept-btn-handler,div#onetrust-consent-sdk #onetrust-pc-btn-handler{flex:1 0 auto;margin:8px;width:auto}div#onetrust-consent-sdk #onetrust-pc-btn-handler{background-color:#fff!important;color:inherit!important}div#onetrust-banner-sdk #onetrust-close-btn-container{display:none}@media only screen and (min-width:556px){div#onetrust-consent-sdk #onetrust-banner-sdk{padding:40px}div#onetrust-banner-sdk #onetrust-policy{margin:0 40px 0 0}div#onetrust-banner-sdk .ot-sdk-row{align-items:center;flex-direction:row}div#onetrust-banner-sdk #onetrust-button-group-parent,div#onetrust-banner-sdk.ot-bnr-flift:not(.ot-iab-2) #onetrust-button-group-parent,div#onetrust-banner-sdk:not(.ot-iab-2) #onetrust-button-group-parent{margin:0;padding:0;width:auto}div#onetrust-banner-sdk #onetrust-button-group,div#onetrust-banner-sdk.ot-buttons-fw:not(.ot-iab-2) #onetrust-button-group{align-items:stretch;flex-direction:column-reverse;margin:0}div#onetrust-consent-sdk #onetrust-accept-btn-handler,div#onetrust-consent-sdk #onetrust-pc-btn-handler{flex:1 0 auto}}@media only screen and (min-width:768px){div#onetrust-banner-sdk #onetrust-policy{margin:0 48px 0 0}div#onetrust-consent-sdk #onetrust-banner-sdk{padding:48px}}div#onetrust-consent-sdk #onetrust-pc-sdk h5{font-size:16px;line-height:24px}div#onetrust-consent-sdk #onetrust-pc-sdk p,div#onetrust-pc-sdk #ot-pc-desc,div#onetrust-pc-sdk .category-host-list-handler,div#onetrust-pc-sdk .ot-accordion-layout .ot-cat-header{font-size:16px;font-weight:400;line-height:24px}div#onetrust-consent-sdk a:hover,div#onetrust-pc-sdk a:hover{color:inherit!important;text-decoration-color:#eb6500!important}div#onetrust-pc-sdk{border-radius:0;bottom:0;height:auto;left:0;margin:auto;max-width:100%;overflow:hidden;right:0;top:0;width:512px;max-height:800px}div#onetrust-pc-sdk .ot-pc-header{display:none}div#onetrust-pc-sdk #ot-pc-content{overscroll-behavior:contain;padding:0 12px 0 24px;margin:16px 4px 0 0;top:0;right:16px;left:0;width:auto}div#onetrust-pc-sdk #ot-category-title,div#onetrust-pc-sdk #ot-pc-title{font-size:24px;font-weight:400;line-height:32px;margin:0 0 16px}div#onetrust-pc-sdk #ot-pc-desc{padding:0}div#onetrust-pc-sdk #ot-pc-desc a{display:inline}div#onetrust-pc-sdk #accept-recommended-btn-handler{display:none!important}div#onetrust-pc-sdk input[type=checkbox]:focus+.ot-acc-hdr{outline:2px solid #eb6500;outline-offset:-1px;transition:none}div#onetrust-pc-sdk .ot-accordion-layout.ot-cat-item{border-width:0 0 2px}div#onetrust-pc-sdk .ot-accordion-layout.ot-cat-item:first-of-type{border-width:2px 0}div#onetrust-pc-sdk .ot-accordion-layout .ot-acc-hdr{padding:8px 0;width:100%}div#onetrust-pc-sdk .ot-plus-minus{transform:translateY(2px)}div#onetrust-pc-sdk .ot-accordion-layout.ot-cat-item>button{background:0 0!important;border:0!important;height:44px!important;max-width:none!important;width:calc(100% - 48px)!important}div#onetrust-consent-sdk #onetrust-pc-sdk h5{font-weight:700}div#onetrust-pc-sdk .ot-accordion-layout .ot-hlst-cntr{padding:0}div#onetrust-pc-sdk .ot-accordion-layout.ot-cat-item .ot-acc-grpdesc{padding:0;width:100%}div#onetrust-pc-sdk .ot-acc-grpcntr .ot-subgrp-cntr{border:0;padding:0}div#onetrust-pc-sdk .ot-subgrp-cntr ul.ot-subgrps li.ot-subgrp{margin:0}div#onetrust-pc-sdk .ot-always-active-group .ot-cat-header{width:calc(100% - 160px)}#onetrust-pc-sdk .ot-accordion-layout .ot-cat-header{width:calc(100% - 88px)}div#onetrust-pc-sdk .ot-accordion-layout h4~.ot-always-active{color:inherit;font-size:12px;font-weight:400;line-height:1.5;padding-right:48px}div#onetrust-pc-sdk .ot-accordion-layout h4~.ot-always-active:before{border-radius:12px;position:absolute;right:0;top:0;content:'';background:#fff;border:2px solid #939393;box-sizing:border-box;height:20px;width:40px}div#onetrust-pc-sdk .ot-accordion-layout h4~.ot-always-active:after{border-radius:50%;position:absolute;right:5px;top:4px;content:'';background-color:#eb6500;height:12px;width:12px}div#onetrust-pc-sdk .ot-accordion-layout h4~.ot-always-active,div#onetrust-pc-sdk .ot-accordion-layout h4~.ot-tgl{right:2px}div#onetrust-pc-sdk .ot-switch{display:block;height:20px;width:40px}div#onetrust-pc-sdk .ot-tgl input+.ot-switch .ot-switch-nob,div#onetrust-pc-sdk .ot-tgl input:checked+.ot-switch .ot-switch-nob{background:#fff;border:2px solid #939393;box-sizing:border-box;height:20px;width:40px}div#onetrust-pc-sdk .ot-tgl input+.ot-switch .ot-switch-nob:before{background-color:#737373;height:8px;left:4px;top:4px;width:8px}div#onetrust-pc-sdk .ot-tgl input:checked+.ot-switch .ot-switch-nob:before{background-color:#eb6500;height:12px;left:0;top:2px;width:12px}div#onetrust-pc-sdk .ot-tgl input:focus+.ot-switch .ot-switch-nob{box-shadow:0 0;outline:2px solid #eb6500!important;outline-offset:1px;transition:none}div#onetrust-consent-sdk #onetrust-pc-sdk .ot-acc-grpcntr.ot-acc-txt{background-color:transparent;padding-left:3px}div#onetrust-pc-sdk .ot-accordion-layout .ot-hlst-cntr,div#onetrust-pc-sdk .ot-accordion-layout .ot-vlst-cntr{overflow:visible;width:100%}div#onetrust-pc-sdk .ot-pc-footer{border-top:0 solid}div#onetrust-pc-sdk .ot-btn-container{padding-top:24px;text-align:center}div#onetrust-pc-sdk .ot-pc-footer button{margin:8px 0;background-color:#fff}div#onetrust-pc-sdk .ot-pc-footer-logo{background-color:#fff}div#onetrust-pc-sdk #ot-lst-title span{font-size:24px;font-weight:400;line-height:32px}div#onetrust-pc-sdk #ot-host-lst .ot-host-desc,div#onetrust-pc-sdk #ot-host-lst .ot-host-expand,div#onetrust-pc-sdk #ot-host-lst .ot-host-name,div#onetrust-pc-sdk #ot-host-lst .ot-host-name a,div#onetrust-pc-sdk .back-btn-handler,div#onetrust-pc-sdk .ot-host-opt li>div div{font-size:16px;font-weight:400;line-height:24px}div#onetrust-pc-sdk #ot-host-lst .ot-acc-txt{width:100%}div#onetrust-pc-sdk #ot-pc-lst{top:0}div#onetrust-pc-sdk .back-btn-handler{text-decoration:none!important}div#onetrust-pc-sdk #filter-btn-handler:hover svg{filter:invert(1)}div#onetrust-pc-sdk .back-btn-handler svg{width:16px;height:16px}div#onetrust-pc-sdk .ot-host-item>button{background:0 0!important;border:0!important;height:66px!important;max-width:none!important;width:calc(100% - 5px)!important;transform:translate(2px,2px)}div#onetrust-pc-sdk .ot-host-item{border-bottom:2px solid #b9b9b9;padding:0}div#onetrust-pc-sdk .ot-host-item .ot-acc-hdr{margin:0 0 -6px;padding:8px 0}div#onetrust-pc-sdk ul li:first-child{border-top:2px solid #b9b9b9}div#onetrust-pc-sdk .ot-host-item .ot-plus-minus{margin:0 8px 0 0}div#onetrust-pc-sdk .ot-search-cntr{width:calc(100% - 48px)}div#onetrust-pc-sdk .ot-host-opt .ot-host-info{background-color:transparent}div#onetrust-pc-sdk .ot-host-opt li>div div{padding:0}div#onetrust-pc-sdk #vendor-search-handler{border-radius:0;border-color:#939393;border-style:solid;border-width:2px 0 2px 2px;font-size:20px;height:48px;margin:0}div#onetrust-pc-sdk #ot-pc-hdr{margin-left:24px}div#onetrust-pc-sdk .ot-lst-subhdr{width:calc(100% - 24px)}div#onetrust-pc-sdk .ot-lst-subhdr svg{right:0;top:8px}div#onetrust-pc-sdk .ot-fltr-cntr{box-sizing:border-box;right:0;width:48px}div#onetrust-pc-sdk #filter-btn-handler{width:48px!important;padding:8px!important}div#onetrust-consent-sdk #onetrust-pc-sdk #clear-filters-handler,div#onetrust-pc-sdk button#filter-apply-handler,div#onetrust-pc-sdk button#filter-cancel-handler{height:2em!important;padding-left:14px!important;padding-right:14px!important}div#onetrust-pc-sdk #ot-fltr-cnt{box-shadow:0 0;border:1px solid #8e8e8e;border-radius:0}div#onetrust-pc-sdk .ot-fltr-scrlcnt{max-height:calc(100% - 80px)}div#onetrust-pc-sdk #ot-fltr-modal{max-height:400px}div#onetrust-pc-sdk .ot-fltr-opt{margin-bottom:16px}div#onetrust-pc-sdk #ot-lst-cnt{margin-left:24px;width:calc(100% - 48px)}div#onetrust-pc-sdk #ot-anchor{display:none!important}
/* 2023-12-04  Fix for button order in mobile view*/
@media (max-width: 550px) {
  #onetrust-accept-btn-handler {order: 1;  }
  #onetrust-reject-all-handler { order: 2;  }
  #onetrust-pc-btn-handler { order: 3;  }
}
#onetrust-pc-sdk.otPcCenter{overflow:hidden;position:fixed;margin:0 auto;top:5%;right:0;left:0;width:40%;max-width:575px;min-width:575px;border-radius:2.5px;z-index:2147483647;background-color:#fff;-webkit-box-shadow:0px 2px 10px -3px #999;-moz-box-shadow:0px 2px 10px -3px #999;box-shadow:0px 2px 10px -3px #999}#onetrust-pc-sdk.otPcCenter[dir=rtl]{right:0;left:0}#onetrust-pc-sdk.otRelFont{font-size:1rem}#onetrust-pc-sdk .ot-optout-signal{margin-top:.625rem}#onetrust-pc-sdk #ot-addtl-venlst .ot-arw-cntr,#onetrust-pc-sdk #ot-addtl-venlst .ot-plus-minus,#onetrust-pc-sdk .ot-hide-tgl{visibility:hidden}#onetrust-pc-sdk #ot-addtl-venlst .ot-arw-cntr *,#onetrust-pc-sdk #ot-addtl-venlst .ot-plus-minus *,#onetrust-pc-sdk .ot-hide-tgl *{visibility:hidden}#onetrust-pc-sdk #ot-gn-venlst .ot-ven-item .ot-acc-hdr{min-height:40px}#onetrust-pc-sdk .ot-pc-header{height:39px;padding:10px 0 10px 30px;border-bottom:1px solid #e9e9e9}#onetrust-pc-sdk #ot-pc-title,#onetrust-pc-sdk #ot-category-title,#onetrust-pc-sdk .ot-cat-header,#onetrust-pc-sdk #ot-lst-title,#onetrust-pc-sdk .ot-ven-hdr .ot-ven-name,#onetrust-pc-sdk .ot-always-active{font-weight:bold;color:dimgray}#onetrust-pc-sdk .ot-always-active-group .ot-cat-header{width:55%;font-weight:700}#onetrust-pc-sdk .ot-cat-item p{clear:both;float:left;margin-top:10px;margin-bottom:5px;line-height:1.5;font-size:.812em;color:dimgray}#onetrust-pc-sdk .ot-close-icon{height:44px;width:44px;background-size:10px}#onetrust-pc-sdk #ot-pc-title{float:left;font-size:1em;line-height:1.5;margin-bottom:10px;margin-top:10px;width:100%}#onetrust-pc-sdk #accept-recommended-btn-handler{margin-right:10px;margin-bottom:25px;outline-offset:-1px}#onetrust-pc-sdk #ot-pc-desc{clear:both;width:100%;font-size:.812em;line-height:1.5;margin-bottom:25px}#onetrust-pc-sdk #ot-pc-desc a{margin-left:5px}#onetrust-pc-sdk #ot-pc-desc *{font-size:inherit;line-height:inherit}#onetrust-pc-sdk #ot-pc-desc ul li{padding:10px 0px}#onetrust-pc-sdk a{color:#656565;cursor:pointer}#onetrust-pc-sdk a:hover{color:#3860be}#onetrust-pc-sdk label{margin-bottom:0}#onetrust-pc-sdk #vdr-lst-dsc{font-size:.812em;line-height:1.5;padding:10px 15px 5px 15px}#onetrust-pc-sdk button{max-width:394px;padding:12px 30px;line-height:1;word-break:break-word;word-wrap:break-word;white-space:normal;font-weight:bold;height:auto}#onetrust-pc-sdk .ot-link-btn{padding:0;margin-bottom:0;border:0;font-weight:normal;line-height:normal;width:auto;height:auto}#onetrust-pc-sdk #ot-pc-content{position:absolute;overflow-y:scroll;padding-left:0px;padding-right:30px;top:60px;bottom:110px;margin:1px 3px 0 30px;width:calc(100% - 63px)}#onetrust-pc-sdk .ot-vs-list .ot-always-active,#onetrust-pc-sdk .ot-cat-grp .ot-always-active{float:right;clear:none;color:#3860be;margin:0;font-size:.813em;line-height:1.3}#onetrust-pc-sdk .ot-pc-scrollbar::-webkit-scrollbar-track{margin-right:20px}#onetrust-pc-sdk .ot-pc-scrollbar::-webkit-scrollbar{width:11px}#onetrust-pc-sdk .ot-pc-scrollbar::-webkit-scrollbar-thumb{border-radius:10px;background:#d8d8d8}#onetrust-pc-sdk input[type=checkbox]:focus+.ot-acc-hdr{outline:#000 1px solid}#onetrust-pc-sdk .ot-pc-scrollbar{scrollbar-arrow-color:#d8d8d8;scrollbar-darkshadow-color:#d8d8d8;scrollbar-face-color:#d8d8d8;scrollbar-shadow-color:#d8d8d8}#onetrust-pc-sdk .save-preference-btn-handler{margin-right:20px}#onetrust-pc-sdk .ot-pc-refuse-all-handler{margin-right:10px}#onetrust-pc-sdk #ot-pc-desc .privacy-notice-link{margin-left:0;margin-right:8px}#onetrust-pc-sdk #ot-pc-desc .ot-imprint-handler{margin-left:0;margin-right:8px}#onetrust-pc-sdk .ot-subgrp-cntr{display:inline-block;clear:both;width:100%;padding-top:15px}#onetrust-pc-sdk .ot-switch+.ot-subgrp-cntr{padding-top:10px}#onetrust-pc-sdk ul.ot-subgrps{margin:0;font-size:initial}#onetrust-pc-sdk ul.ot-subgrps li p,#onetrust-pc-sdk ul.ot-subgrps li h5{font-size:.813em;line-height:1.4;color:dimgray}#onetrust-pc-sdk ul.ot-subgrps .ot-switch{min-height:auto}#onetrust-pc-sdk ul.ot-subgrps .ot-switch-nob{top:0}#onetrust-pc-sdk ul.ot-subgrps .ot-acc-hdr{display:inline-block;width:100%}#onetrust-pc-sdk ul.ot-subgrps .ot-acc-txt{margin:0}#onetrust-pc-sdk ul.ot-subgrps li{padding:0;border:none}#onetrust-pc-sdk ul.ot-subgrps li h5{position:relative;top:5px;font-weight:bold;margin-bottom:0;float:left}#onetrust-pc-sdk li.ot-subgrp{margin-left:20px;overflow:auto}#onetrust-pc-sdk li.ot-subgrp>h5{width:calc(100% - 100px)}#onetrust-pc-sdk .ot-cat-item p>ul,#onetrust-pc-sdk li.ot-subgrp p>ul{margin:0px;list-style:disc;margin-left:15px;font-size:inherit}#onetrust-pc-sdk .ot-cat-item p>ul li,#onetrust-pc-sdk li.ot-subgrp p>ul li{font-size:inherit;padding-top:10px;padding-left:0px;padding-right:0px;border:none}#onetrust-pc-sdk .ot-cat-item p>ul li:last-child,#onetrust-pc-sdk li.ot-subgrp p>ul li:last-child{padding-bottom:10px}#onetrust-pc-sdk .ot-pc-logo{height:40px;width:120px}#onetrust-pc-sdk .ot-pc-footer{position:absolute;bottom:0px;width:100%;max-height:160px;border-top:1px solid #d8d8d8}#onetrust-pc-sdk.ot-ftr-stacked .ot-pc-refuse-all-handler{margin-bottom:0px}#onetrust-pc-sdk.ot-ftr-stacked #ot-pc-content{bottom:160px}#onetrust-pc-sdk.ot-ftr-stacked .ot-pc-footer button{width:100%;max-width:none}#onetrust-pc-sdk.ot-ftr-stacked .ot-btn-container{margin:0 30px;width:calc(100% - 60px);padding-right:0}#onetrust-pc-sdk .ot-pc-footer-logo{height:30px;width:100%;text-align:right;background:#f4f4f4}#onetrust-pc-sdk .ot-pc-footer-logo a{display:inline-block;margin-top:5px;margin-right:10px}#onetrust-pc-sdk[dir=rtl] .ot-pc-footer-logo{direction:rtl}#onetrust-pc-sdk[dir=rtl] .ot-pc-footer-logo a{margin-right:25px}#onetrust-pc-sdk .ot-tgl{float:right;position:relative;z-index:1}#onetrust-pc-sdk .ot-tgl input:checked+.ot-switch .ot-switch-nob{background-color:#468254;border:1px solid #fff}#onetrust-pc-sdk .ot-tgl input:checked+.ot-switch .ot-switch-nob:before{-webkit-transform:translateX(20px);-ms-transform:translateX(20px);transform:translateX(20px);background-color:#fff;border-color:#fff}#onetrust-pc-sdk .ot-tgl input:focus+.ot-switch{outline:#000 solid 1px}#onetrust-pc-sdk .ot-switch{position:relative;display:inline-block;width:45px;height:25px}#onetrust-pc-sdk .ot-switch-nob{position:absolute;cursor:pointer;top:0;left:0;right:0;bottom:0;background-color:#767676;border:1px solid #ddd;transition:all .2s ease-in 0s;-moz-transition:all .2s ease-in 0s;-o-transition:all .2s ease-in 0s;-webkit-transition:all .2s ease-in 0s;border-radius:20px}#onetrust-pc-sdk .ot-switch-nob:before{position:absolute;content:"";height:18px;width:18px;bottom:3px;left:3px;background-color:#fff;-webkit-transition:.4s;transition:.4s;border-radius:20px}#onetrust-pc-sdk .ot-chkbox input:checked~label::before{background-color:#3860be}#onetrust-pc-sdk .ot-chkbox input+label::after{content:none;color:#fff}#onetrust-pc-sdk .ot-chkbox input:checked+label::after{content:""}#onetrust-pc-sdk .ot-chkbox input:focus+label::before{outline-style:solid;outline-width:2px;outline-style:auto}#onetrust-pc-sdk .ot-chkbox label{position:relative;display:inline-block;padding-left:30px;cursor:pointer;font-weight:500}#onetrust-pc-sdk .ot-chkbox label::before,#onetrust-pc-sdk .ot-chkbox label::after{position:absolute;content:"";display:inline-block;border-radius:3px}#onetrust-pc-sdk .ot-chkbox label::before{height:18px;width:18px;border:1px solid #3860be;left:0px;top:auto}#onetrust-pc-sdk .ot-chkbox label::after{height:5px;width:9px;border-left:3px solid;border-bottom:3px solid;transform:rotate(-45deg);-o-transform:rotate(-45deg);-ms-transform:rotate(-45deg);-webkit-transform:rotate(-45deg);left:4px;top:5px}#onetrust-pc-sdk .ot-label-txt{display:none}#onetrust-pc-sdk .ot-chkbox input,#onetrust-pc-sdk .ot-tgl input{position:absolute;opacity:0;width:0;height:0}#onetrust-pc-sdk .ot-arw-cntr{float:right;position:relative;pointer-events:none}#onetrust-pc-sdk .ot-arw-cntr .ot-arw{width:16px;height:16px;margin-left:5px;color:dimgray;display:inline-block;vertical-align:middle;-webkit-transition:all 150ms ease-in 0s;-moz-transition:all 150ms ease-in 0s;-o-transition:all 150ms ease-in 0s;transition:all 150ms ease-in 0s}#onetrust-pc-sdk input:checked~.ot-acc-hdr .ot-arw,#onetrust-pc-sdk button[aria-expanded=true]~.ot-acc-hdr .ot-arw-cntr svg{transform:rotate(90deg);-o-transform:rotate(90deg);-ms-transform:rotate(90deg);-webkit-transform:rotate(90deg)}#onetrust-pc-sdk input[type=checkbox]:focus+.ot-acc-hdr{outline:#000 1px solid}#onetrust-pc-sdk .ot-tgl-cntr,#onetrust-pc-sdk .ot-arw-cntr{display:inline-block}#onetrust-pc-sdk .ot-tgl-cntr{width:45px;float:right;margin-top:2px}#onetrust-pc-sdk #ot-lst-cnt .ot-tgl-cntr{margin-top:10px}#onetrust-pc-sdk .ot-always-active-subgroup{width:auto;padding-left:0px !important;top:3px;position:relative}#onetrust-pc-sdk .ot-label-status{padding-left:5px;font-size:.75em;display:none}#onetrust-pc-sdk .ot-arw-cntr{margin-top:-1px}#onetrust-pc-sdk .ot-arw-cntr svg{-webkit-transition:all 300ms ease-in 0s;-moz-transition:all 300ms ease-in 0s;-o-transition:all 300ms ease-in 0s;transition:all 300ms ease-in 0s;height:10px;width:10px}#onetrust-pc-sdk input:checked~.ot-acc-hdr .ot-arw{transform:rotate(90deg);-o-transform:rotate(90deg);-ms-transform:rotate(90deg);-webkit-transform:rotate(90deg)}#onetrust-pc-sdk .ot-arw{width:10px;margin-left:15px;transition:all 300ms ease-in 0s;-webkit-transition:all 300ms ease-in 0s;-moz-transition:all 300ms ease-in 0s;-o-transition:all 300ms ease-in 0s}#onetrust-pc-sdk .ot-vlst-cntr{margin-bottom:0}#onetrust-pc-sdk .ot-hlst-cntr{margin-top:5px;display:inline-block;width:100%}#onetrust-pc-sdk .category-vendors-list-handler,#onetrust-pc-sdk .category-vendors-list-handler+a,#onetrust-pc-sdk .category-host-list-handler{clear:both;color:#3860be;margin-left:0;font-size:.813em;text-decoration:none;float:left;overflow:hidden}#onetrust-pc-sdk .category-vendors-list-handler:hover,#onetrust-pc-sdk .category-vendors-list-handler+a:hover,#onetrust-pc-sdk .category-host-list-handler:hover{text-decoration-line:underline}#onetrust-pc-sdk .category-vendors-list-handler+a{clear:none}#onetrust-pc-sdk .ot-vlst-cntr .ot-ext-lnk,#onetrust-pc-sdk .ot-ven-hdr .ot-ext-lnk{display:inline-block;height:13px;width:13px;background-repeat:no-repeat;margin-left:1px;margin-top:6px;cursor:pointer}#onetrust-pc-sdk .ot-ven-hdr .ot-ext-lnk{margin-bottom:-1px}#onetrust-pc-sdk .back-btn-handler{font-size:1em;text-decoration:none}#onetrust-pc-sdk .back-btn-handler:hover{opacity:.6}#onetrust-pc-sdk #ot-lst-title h3{display:inline-block;word-break:break-word;word-wrap:break-word;margin-bottom:0;color:#656565;font-size:1em;font-weight:bold;margin-left:15px}#onetrust-pc-sdk #ot-lst-title{margin:10px 0 10px 0px;font-size:1em;text-align:left}#onetrust-pc-sdk #ot-pc-hdr{margin:0 0 0 30px;height:auto;width:auto}#onetrust-pc-sdk #ot-pc-hdr input::placeholder{color:#d4d4d4;font-style:italic}#onetrust-pc-sdk #vendor-search-handler{height:31px;width:100%;border-radius:50px;font-size:.8em;padding-right:35px;padding-left:15px;float:left;margin-left:15px}#onetrust-pc-sdk .ot-ven-name{display:block;width:auto;padding-right:5px}#onetrust-pc-sdk #ot-lst-cnt{overflow-y:auto;margin-left:20px;margin-right:7px;width:calc(100% - 27px);max-height:calc(100% - 80px);height:100%;transform:translate3d(0, 0, 0)}#onetrust-pc-sdk #ot-pc-lst{width:100%;bottom:100px;position:absolute;top:60px}#onetrust-pc-sdk #ot-pc-lst:not(.ot-enbl-chr) .ot-tgl-cntr .ot-arw-cntr,#onetrust-pc-sdk #ot-pc-lst:not(.ot-enbl-chr) .ot-tgl-cntr .ot-arw-cntr *{visibility:hidden}#onetrust-pc-sdk #ot-pc-lst .ot-tgl-cntr{right:12px;position:absolute}#onetrust-pc-sdk #ot-pc-lst .ot-arw-cntr{float:right;position:relative}#onetrust-pc-sdk #ot-pc-lst .ot-arw{margin-left:10px}#onetrust-pc-sdk #ot-pc-lst .ot-acc-hdr{overflow:hidden;cursor:pointer}#onetrust-pc-sdk .ot-vlst-cntr{overflow:hidden}#onetrust-pc-sdk #ot-sel-blk{overflow:hidden;width:100%;position:sticky;position:-webkit-sticky;top:0;z-index:3}#onetrust-pc-sdk #ot-back-arw{height:12px;width:12px}#onetrust-pc-sdk .ot-lst-subhdr{width:100%;display:inline-block}#onetrust-pc-sdk .ot-search-cntr{float:left;width:78%;position:relative}#onetrust-pc-sdk .ot-search-cntr>svg{width:30px;height:30px;position:absolute;float:left;right:-15px}#onetrust-pc-sdk .ot-fltr-cntr{float:right;right:50px;position:relative}#onetrust-pc-sdk #filter-btn-handler{background-color:#3860be;border-radius:17px;display:inline-block;position:relative;width:32px;height:32px;-moz-transition:.1s ease;-o-transition:.1s ease;-webkit-transition:1s ease;transition:.1s ease;padding:0;margin:0}#onetrust-pc-sdk #filter-btn-handler:hover{background-color:#3860be}#onetrust-pc-sdk #filter-btn-handler svg{width:12px;height:12px;margin:3px 10px 0 10px;display:block;position:static;right:auto;top:auto}#onetrust-pc-sdk .ot-ven-link,#onetrust-pc-sdk .ot-ven-legclaim-link{color:#3860be;text-decoration:none;font-weight:100;display:inline-block;padding-top:10px;transform:translate(0, 1%);-o-transform:translate(0, 1%);-ms-transform:translate(0, 1%);-webkit-transform:translate(0, 1%);position:relative;z-index:2}#onetrust-pc-sdk .ot-ven-link *,#onetrust-pc-sdk .ot-ven-legclaim-link *{font-size:inherit}#onetrust-pc-sdk .ot-ven-link:hover,#onetrust-pc-sdk .ot-ven-legclaim-link:hover{text-decoration:underline}#onetrust-pc-sdk .ot-ven-hdr{width:calc(100% - 160px);height:auto;float:left;word-break:break-word;word-wrap:break-word;vertical-align:middle;padding-bottom:3px}#onetrust-pc-sdk .ot-ven-link,#onetrust-pc-sdk .ot-ven-legclaim-link{letter-spacing:.03em;font-size:.75em;font-weight:400}#onetrust-pc-sdk .ot-ven-dets{border-radius:2px;background-color:#f8f8f8}#onetrust-pc-sdk .ot-ven-dets li:first-child p:first-child{border-top:none}#onetrust-pc-sdk .ot-ven-dets .ot-ven-disc:not(:first-child){border-top:1px solid #ddd !important}#onetrust-pc-sdk .ot-ven-dets .ot-ven-disc:nth-child(n+3) p{display:inline-block}#onetrust-pc-sdk .ot-ven-dets .ot-ven-disc:nth-child(n+3) p:nth-of-type(odd){width:30%}#onetrust-pc-sdk .ot-ven-dets .ot-ven-disc:nth-child(n+3) p:nth-of-type(even){width:50%;word-break:break-word;word-wrap:break-word}#onetrust-pc-sdk .ot-ven-dets .ot-ven-disc p,#onetrust-pc-sdk .ot-ven-dets .ot-ven-disc h4{padding-top:5px;padding-bottom:5px;display:block}#onetrust-pc-sdk .ot-ven-dets .ot-ven-disc h4{display:inline-block}#onetrust-pc-sdk .ot-ven-dets .ot-ven-disc p:nth-last-child(-n+1){padding-bottom:10px}#onetrust-pc-sdk .ot-ven-dets .ot-ven-disc p:nth-child(-n+2):not(.disc-pur){padding-top:10px}#onetrust-pc-sdk .ot-ven-dets .ot-ven-disc .disc-pur-cont{display:inline}#onetrust-pc-sdk .ot-ven-dets .ot-ven-disc .disc-pur{position:relative;width:50% !important;word-break:break-word;word-wrap:break-word;left:calc(30% + 17px)}#onetrust-pc-sdk .ot-ven-dets .ot-ven-disc .disc-pur:nth-child(-n+1){position:static}#onetrust-pc-sdk .ot-ven-dets p,#onetrust-pc-sdk .ot-ven-dets h4,#onetrust-pc-sdk .ot-ven-dets span{font-size:.69em;text-align:left;vertical-align:middle;word-break:break-word;word-wrap:break-word;margin:0;padding-bottom:10px;padding-left:15px;color:#2e3644}#onetrust-pc-sdk .ot-ven-dets h4{padding-top:5px}#onetrust-pc-sdk .ot-ven-dets span{color:dimgray;padding:0;vertical-align:baseline}#onetrust-pc-sdk .ot-ven-dets .ot-ven-pur h4{border-top:1px solid #e9e9e9;border-bottom:1px solid #e9e9e9;padding-bottom:5px;margin-bottom:5px;font-weight:bold}#onetrust-pc-sdk #ot-host-lst .ot-sel-all{float:right;position:relative;margin-right:42px;top:10px}#onetrust-pc-sdk #ot-host-lst .ot-sel-all input[type=checkbox]{width:auto;height:auto}#onetrust-pc-sdk #ot-host-lst .ot-sel-all label{height:20px;width:20px;padding-left:0px}#onetrust-pc-sdk #ot-host-lst .ot-acc-txt{overflow:hidden;width:95%}#onetrust-pc-sdk .ot-host-hdr{position:relative;z-index:1;pointer-events:none;width:calc(100% - 125px);float:left}#onetrust-pc-sdk .ot-host-name,#onetrust-pc-sdk .ot-host-desc{display:inline-block;width:90%}#onetrust-pc-sdk .ot-host-name{pointer-events:none}#onetrust-pc-sdk .ot-host-hdr>a{text-decoration:underline;font-size:.82em;position:relative;z-index:2;float:left;margin-bottom:5px;pointer-events:initial}#onetrust-pc-sdk .ot-host-name+a{margin-top:5px}#onetrust-pc-sdk .ot-host-name,#onetrust-pc-sdk .ot-host-name a,#onetrust-pc-sdk .ot-host-desc,#onetrust-pc-sdk .ot-host-info{color:dimgray;word-break:break-word;word-wrap:break-word}#onetrust-pc-sdk .ot-host-name,#onetrust-pc-sdk .ot-host-name a{font-weight:bold;font-size:.82em;line-height:1.3}#onetrust-pc-sdk .ot-host-name a{font-size:1em}#onetrust-pc-sdk .ot-host-expand{margin-top:3px;margin-bottom:3px;clear:both;display:block;color:#3860be;font-size:.72em;font-weight:normal}#onetrust-pc-sdk .ot-host-expand *{font-size:inherit}#onetrust-pc-sdk .ot-host-desc,#onetrust-pc-sdk .ot-host-info{font-size:.688em;line-height:1.4;font-weight:normal}#onetrust-pc-sdk .ot-host-desc{margin-top:10px}#onetrust-pc-sdk .ot-host-opt{margin:0;font-size:inherit;display:inline-block;width:100%}#onetrust-pc-sdk .ot-host-opt li>div div{font-size:.8em;padding:5px 0}#onetrust-pc-sdk .ot-host-opt li>div div:nth-child(1){width:30%;float:left}#onetrust-pc-sdk .ot-host-opt li>div div:nth-child(2){width:70%;float:left;word-break:break-word;word-wrap:break-word}#onetrust-pc-sdk .ot-host-info{border:none;display:inline-block;width:calc(100% - 10px);padding:10px;margin-bottom:10px;background-color:#f8f8f8}#onetrust-pc-sdk .ot-host-info>div{overflow:auto}#onetrust-pc-sdk #no-results{text-align:center;margin-top:30px}#onetrust-pc-sdk #no-results p{font-size:1em;color:#2e3644;word-break:break-word;word-wrap:break-word}#onetrust-pc-sdk #no-results p span{font-weight:bold}#onetrust-pc-sdk #ot-fltr-modal{width:100%;height:auto;display:none;-moz-transition:.2s ease;-o-transition:.2s ease;-webkit-transition:2s ease;transition:.2s ease;overflow:hidden;opacity:1;right:0}#onetrust-pc-sdk #ot-fltr-modal .ot-label-txt{display:inline-block;font-size:.85em;color:dimgray}#onetrust-pc-sdk #ot-fltr-cnt{z-index:2147483646;background-color:#fff;position:absolute;height:90%;max-height:300px;width:325px;left:210px;margin-top:10px;margin-bottom:20px;padding-right:10px;border-radius:3px;-webkit-box-shadow:0px 0px 12px 2px #c7c5c7;-moz-box-shadow:0px 0px 12px 2px #c7c5c7;box-shadow:0px 0px 12px 2px #c7c5c7}#onetrust-pc-sdk .ot-fltr-scrlcnt{overflow-y:auto;overflow-x:hidden;clear:both;max-height:calc(100% - 60px)}#onetrust-pc-sdk #ot-anchor{border:12px solid rgba(0,0,0,0);display:none;position:absolute;z-index:2147483647;right:55px;top:75px;transform:rotate(45deg);-o-transform:rotate(45deg);-ms-transform:rotate(45deg);-webkit-transform:rotate(45deg);background-color:#fff;-webkit-box-shadow:-3px -3px 5px -2px #c7c5c7;-moz-box-shadow:-3px -3px 5px -2px #c7c5c7;box-shadow:-3px -3px 5px -2px #c7c5c7}#onetrust-pc-sdk .ot-fltr-btns{margin-left:15px}#onetrust-pc-sdk #filter-apply-handler{margin-right:15px}#onetrust-pc-sdk .ot-fltr-opt{margin-bottom:25px;margin-left:15px;width:75%;position:relative}#onetrust-pc-sdk .ot-fltr-opt p{display:inline-block;margin:0;font-size:.9em;color:#2e3644}#onetrust-pc-sdk .ot-chkbox label span{font-size:.85em;color:dimgray}#onetrust-pc-sdk .ot-chkbox input[type=checkbox]+label::after{content:none;color:#fff}#onetrust-pc-sdk .ot-chkbox input[type=checkbox]:checked+label::after{content:""}#onetrust-pc-sdk .ot-chkbox input[type=checkbox]:focus+label::before{outline-style:solid;outline-width:2px;outline-style:auto}#onetrust-pc-sdk #ot-selall-vencntr,#onetrust-pc-sdk #ot-selall-adtlvencntr,#onetrust-pc-sdk #ot-selall-hostcntr,#onetrust-pc-sdk #ot-selall-licntr,#onetrust-pc-sdk #ot-selall-gnvencntr{right:15px;position:relative;width:20px;height:20px;float:right}#onetrust-pc-sdk #ot-selall-vencntr label,#onetrust-pc-sdk #ot-selall-adtlvencntr label,#onetrust-pc-sdk #ot-selall-hostcntr label,#onetrust-pc-sdk #ot-selall-licntr label,#onetrust-pc-sdk #ot-selall-gnvencntr label{float:left;padding-left:0}#onetrust-pc-sdk #ot-ven-lst:first-child{border-top:1px solid #e2e2e2}#onetrust-pc-sdk ul{list-style:none;padding:0}#onetrust-pc-sdk ul li{position:relative;margin:0;padding:15px 15px 15px 10px;border-bottom:1px solid #e2e2e2}#onetrust-pc-sdk ul li h3{font-size:.75em;color:#656565;margin:0;display:inline-block;width:70%;height:auto;word-break:break-word;word-wrap:break-word}#onetrust-pc-sdk ul li p{margin:0;font-size:.7em}#onetrust-pc-sdk ul li input[type=checkbox]{position:absolute;cursor:pointer;width:100%;height:100%;opacity:0;margin:0;top:0;left:0}#onetrust-pc-sdk .ot-cat-item>button:focus,#onetrust-pc-sdk .ot-acc-cntr>button:focus,#onetrust-pc-sdk li>button:focus{outline:#000 solid 2px}#onetrust-pc-sdk .ot-cat-item>button,#onetrust-pc-sdk .ot-acc-cntr>button,#onetrust-pc-sdk li>button{position:absolute;cursor:pointer;width:100%;height:100%;margin:0;top:0;left:0;z-index:1;max-width:none;border:none}#onetrust-pc-sdk .ot-cat-item>button[aria-expanded=false]~.ot-acc-txt,#onetrust-pc-sdk .ot-acc-cntr>button[aria-expanded=false]~.ot-acc-txt,#onetrust-pc-sdk li>button[aria-expanded=false]~.ot-acc-txt{margin-top:0;max-height:0;opacity:0;overflow:hidden;width:100%;transition:.25s ease-out;display:none}#onetrust-pc-sdk .ot-cat-item>button[aria-expanded=true]~.ot-acc-txt,#onetrust-pc-sdk .ot-acc-cntr>button[aria-expanded=true]~.ot-acc-txt,#onetrust-pc-sdk li>button[aria-expanded=true]~.ot-acc-txt{transition:.1s ease-in;margin-top:10px;width:100%;overflow:auto;display:block}#onetrust-pc-sdk .ot-cat-item>button[aria-expanded=true]~.ot-acc-grpcntr,#onetrust-pc-sdk .ot-acc-cntr>button[aria-expanded=true]~.ot-acc-grpcntr,#onetrust-pc-sdk li>button[aria-expanded=true]~.ot-acc-grpcntr{width:auto;margin-top:0px;padding-bottom:10px}#onetrust-pc-sdk .ot-host-item>button:focus,#onetrust-pc-sdk .ot-ven-item>button:focus{outline:0;border:2px solid #000}#onetrust-pc-sdk .ot-hide-acc>button{pointer-events:none}#onetrust-pc-sdk .ot-hide-acc .ot-plus-minus>*,#onetrust-pc-sdk .ot-hide-acc .ot-arw-cntr>*{visibility:hidden}#onetrust-pc-sdk .ot-hide-acc .ot-acc-hdr{min-height:30px}#onetrust-pc-sdk.ot-addtl-vendors #ot-lst-cnt:not(.ot-host-cnt){padding-right:10px;width:calc(100% - 37px);margin-top:10px;max-height:calc(100% - 90px)}#onetrust-pc-sdk.ot-addtl-vendors #ot-lst-cnt:not(.ot-host-cnt) #ot-sel-blk{background-color:#f9f9fc;border:1px solid #e2e2e2;width:calc(100% - 2px);padding-bottom:5px;padding-top:5px}#onetrust-pc-sdk.ot-addtl-vendors #ot-lst-cnt:not(.ot-host-cnt) #ot-sel-blk.ot-vnd-list-cnt{border:unset;background-color:unset}#onetrust-pc-sdk.ot-addtl-vendors #ot-lst-cnt:not(.ot-host-cnt) #ot-sel-blk.ot-vnd-list-cnt .ot-sel-all-hdr{display:none}#onetrust-pc-sdk.ot-addtl-vendors #ot-lst-cnt:not(.ot-host-cnt) #ot-sel-blk.ot-vnd-list-cnt .ot-sel-all{padding-right:.5rem}#onetrust-pc-sdk.ot-addtl-vendors #ot-lst-cnt:not(.ot-host-cnt) #ot-sel-blk.ot-vnd-list-cnt .ot-sel-all .ot-chkbox{right:0}#onetrust-pc-sdk.ot-addtl-vendors #ot-lst-cnt:not(.ot-host-cnt) .ot-sel-all{padding-right:34px}#onetrust-pc-sdk.ot-addtl-vendors #ot-lst-cnt:not(.ot-host-cnt) .ot-sel-all-chkbox{width:auto}#onetrust-pc-sdk.ot-addtl-vendors #ot-lst-cnt:not(.ot-host-cnt) ul li{border:1px solid #e2e2e2;margin-bottom:10px}#onetrust-pc-sdk.ot-addtl-vendors #ot-lst-cnt:not(.ot-host-cnt) .ot-acc-cntr>.ot-acc-hdr{padding:10px 0 10px 15px}#onetrust-pc-sdk.ot-addtl-vendors .ot-sel-all-chkbox{float:right}#onetrust-pc-sdk.ot-addtl-vendors .ot-plus-minus~.ot-sel-all-chkbox{right:34px}#onetrust-pc-sdk.ot-addtl-vendors #ot-ven-lst:first-child{border-top:none}#onetrust-pc-sdk .ot-acc-cntr{position:relative;border-left:1px solid #e2e2e2;border-right:1px solid #e2e2e2;border-bottom:1px solid #e2e2e2}#onetrust-pc-sdk .ot-acc-cntr input{z-index:1}#onetrust-pc-sdk .ot-acc-cntr>.ot-acc-hdr{background-color:#f9f9fc;padding:5px 0 5px 15px;width:auto}#onetrust-pc-sdk .ot-acc-cntr>.ot-acc-hdr .ot-plus-minus{vertical-align:middle;top:auto}#onetrust-pc-sdk .ot-acc-cntr>.ot-acc-hdr .ot-arw-cntr{right:10px}#onetrust-pc-sdk .ot-acc-cntr>.ot-acc-hdr input{z-index:2}#onetrust-pc-sdk .ot-acc-cntr.ot-add-tech .ot-acc-hdr{padding:10px 0 10px 15px}#onetrust-pc-sdk .ot-acc-cntr>input[type=checkbox]:checked~.ot-acc-hdr{border-bottom:1px solid #e2e2e2}#onetrust-pc-sdk .ot-acc-cntr>.ot-acc-txt{padding-left:10px;padding-right:10px}#onetrust-pc-sdk .ot-acc-cntr button[aria-expanded=true]~.ot-acc-txt{width:auto}#onetrust-pc-sdk .ot-acc-cntr .ot-addtl-venbox{display:none}#onetrust-pc-sdk .ot-vlst-cntr{margin-bottom:0;width:100%}#onetrust-pc-sdk .ot-vensec-title{font-size:.813em;vertical-align:middle;display:inline-block}#onetrust-pc-sdk .category-vendors-list-handler,#onetrust-pc-sdk .category-vendors-list-handler+a{margin-left:0;margin-top:10px}#onetrust-pc-sdk #ot-selall-vencntr.line-through label::after,#onetrust-pc-sdk #ot-selall-adtlvencntr.line-through label::after,#onetrust-pc-sdk #ot-selall-licntr.line-through label::after,#onetrust-pc-sdk #ot-selall-hostcntr.line-through label::after,#onetrust-pc-sdk #ot-selall-gnvencntr.line-through label::after{height:auto;border-left:0;transform:none;-o-transform:none;-ms-transform:none;-webkit-transform:none;left:5px;top:9px}#onetrust-pc-sdk #ot-category-title{float:left;padding-bottom:10px;font-size:1em;width:100%}#onetrust-pc-sdk .ot-cat-grp{margin-top:10px}#onetrust-pc-sdk .ot-cat-item{line-height:1.1;margin-top:10px;display:inline-block;width:100%}#onetrust-pc-sdk .ot-btn-container{text-align:right}#onetrust-pc-sdk .ot-btn-container button{display:inline-block;font-size:.75em;letter-spacing:.08em;margin-top:19px}#onetrust-pc-sdk #close-pc-btn-handler.ot-close-icon{position:absolute;top:10px;right:0;z-index:1;padding:0;background-color:rgba(0,0,0,0);border:none}#onetrust-pc-sdk #close-pc-btn-handler.ot-close-icon svg{display:block;height:10px;width:10px}#onetrust-pc-sdk #clear-filters-handler{margin-top:20px;margin-bottom:10px;float:right;max-width:200px;text-decoration:none;color:#3860be;font-size:.9em;font-weight:bold;background-color:rgba(0,0,0,0);border-color:rgba(0,0,0,0);padding:1px}#onetrust-pc-sdk #clear-filters-handler:hover{color:#2285f7}#onetrust-pc-sdk #clear-filters-handler:focus{outline:#000 solid 1px}#onetrust-pc-sdk .ot-enbl-chr h4~.ot-tgl,#onetrust-pc-sdk .ot-enbl-chr h4~.ot-always-active{right:45px}#onetrust-pc-sdk .ot-enbl-chr h4~.ot-tgl+.ot-tgl{right:120px}#onetrust-pc-sdk .ot-enbl-chr .ot-pli-hdr.ot-leg-border-color span:first-child{width:90px}#onetrust-pc-sdk .ot-enbl-chr li.ot-subgrp>h5+.ot-tgl-cntr{padding-right:25px}#onetrust-pc-sdk .ot-plus-minus{width:20px;height:20px;font-size:1.5em;position:relative;display:inline-block;margin-right:5px;top:3px}#onetrust-pc-sdk .ot-plus-minus span{position:absolute;background:#27455c;border-radius:1px}#onetrust-pc-sdk .ot-plus-minus span:first-of-type{top:25%;bottom:25%;width:10%;left:45%}#onetrust-pc-sdk .ot-plus-minus span:last-of-type{left:25%;right:25%;height:10%;top:45%}#onetrust-pc-sdk button[aria-expanded=true]~.ot-acc-hdr .ot-arw,#onetrust-pc-sdk button[aria-expanded=true]~.ot-acc-hdr .ot-plus-minus span:first-of-type,#onetrust-pc-sdk button[aria-expanded=true]~.ot-acc-hdr .ot-plus-minus span:last-of-type{transform:rotate(90deg)}#onetrust-pc-sdk button[aria-expanded=true]~.ot-acc-hdr .ot-plus-minus span:last-of-type{left:50%;right:50%}#onetrust-pc-sdk #ot-selall-vencntr label,#onetrust-pc-sdk #ot-selall-adtlvencntr label,#onetrust-pc-sdk #ot-selall-hostcntr label,#onetrust-pc-sdk #ot-selall-licntr label{position:relative;display:inline-block;width:20px;height:20px}#onetrust-pc-sdk .ot-host-item .ot-plus-minus,#onetrust-pc-sdk .ot-ven-item .ot-plus-minus{float:left;margin-right:8px;top:10px}#onetrust-pc-sdk .ot-ven-item ul{list-style:none inside;font-size:100%;margin:0}#onetrust-pc-sdk .ot-ven-item ul li{margin:0 !important;padding:0;border:none !important}#onetrust-pc-sdk .ot-pli-hdr{color:#77808e;overflow:hidden;padding-top:7.5px;padding-bottom:7.5px;width:calc(100% - 2px);border-top-left-radius:3px;border-top-right-radius:3px}#onetrust-pc-sdk .ot-pli-hdr span:first-child{top:50%;transform:translateY(50%);max-width:90px}#onetrust-pc-sdk .ot-pli-hdr span:last-child{padding-right:10px;max-width:95px;text-align:center}#onetrust-pc-sdk .ot-li-title{float:right;font-size:.813em}#onetrust-pc-sdk .ot-pli-hdr.ot-leg-border-color{background-color:#f4f4f4;border:1px solid #d8d8d8}#onetrust-pc-sdk .ot-pli-hdr.ot-leg-border-color span:first-child{text-align:left;width:70px}#onetrust-pc-sdk li.ot-subgrp>h5,#onetrust-pc-sdk .ot-cat-header{width:calc(100% - 130px)}#onetrust-pc-sdk li.ot-subgrp>h5+.ot-tgl-cntr{padding-left:13px}#onetrust-pc-sdk .ot-acc-grpcntr .ot-acc-grpdesc{margin-bottom:5px}#onetrust-pc-sdk .ot-acc-grpcntr .ot-subgrp-cntr{border-top:1px solid #d8d8d8}#onetrust-pc-sdk .ot-acc-grpcntr .ot-vlst-cntr+.ot-subgrp-cntr{border-top:none}#onetrust-pc-sdk .ot-acc-hdr .ot-arw-cntr+.ot-tgl-cntr,#onetrust-pc-sdk .ot-acc-txt h4+.ot-tgl-cntr{padding-left:13px}#onetrust-pc-sdk .ot-pli-hdr~.ot-cat-item .ot-subgrp>h5,#onetrust-pc-sdk .ot-pli-hdr~.ot-cat-item .ot-cat-header{width:calc(100% - 145px)}#onetrust-pc-sdk .ot-pli-hdr~.ot-cat-item h5+.ot-tgl-cntr,#onetrust-pc-sdk .ot-pli-hdr~.ot-cat-item .ot-cat-header+.ot-tgl{padding-left:28px}#onetrust-pc-sdk .ot-sel-all-hdr,#onetrust-pc-sdk .ot-sel-all-chkbox{display:inline-block;width:100%;position:relative}#onetrust-pc-sdk .ot-sel-all-chkbox{z-index:1}#onetrust-pc-sdk .ot-sel-all{margin:0;position:relative;padding-right:23px;float:right}#onetrust-pc-sdk .ot-consent-hdr,#onetrust-pc-sdk .ot-li-hdr{float:right;font-size:.812em;line-height:normal;text-align:center;word-break:break-word;word-wrap:break-word}#onetrust-pc-sdk .ot-li-hdr{max-width:100px;padding-right:10px}#onetrust-pc-sdk .ot-consent-hdr{max-width:55px}#onetrust-pc-sdk #ot-selall-licntr{display:block;width:21px;height:auto;float:right;position:relative;right:80px}#onetrust-pc-sdk #ot-selall-licntr label{position:absolute}#onetrust-pc-sdk .ot-ven-ctgl{margin-left:66px}#onetrust-pc-sdk .ot-ven-litgl+.ot-arw-cntr{margin-left:81px}#onetrust-pc-sdk .ot-enbl-chr .ot-host-cnt .ot-tgl-cntr{width:auto}#onetrust-pc-sdk #ot-lst-cnt:not(.ot-host-cnt) .ot-tgl-cntr{width:auto;top:auto;height:20px}#onetrust-pc-sdk #ot-lst-cnt .ot-chkbox{position:relative;display:inline-block;width:20px;height:20px}#onetrust-pc-sdk #ot-lst-cnt .ot-chkbox label{position:absolute;padding:0;width:20px;height:20px}#onetrust-pc-sdk #ot-lst-cnt .ot-vnd-info-cntr{border:1px solid #d8d8d8;padding:.75rem 2rem;padding-bottom:0;width:auto;margin-top:.5rem}#onetrust-pc-sdk .ot-acc-grpdesc+.ot-leg-btn-container{padding-left:20px;padding-right:20px;width:calc(100% - 40px);margin-bottom:5px}#onetrust-pc-sdk .ot-subgrp .ot-leg-btn-container{margin-bottom:5px}#onetrust-pc-sdk #ot-ven-lst .ot-leg-btn-container{margin-top:10px}#onetrust-pc-sdk .ot-leg-btn-container{display:inline-block;width:100%;margin-bottom:10px}#onetrust-pc-sdk .ot-leg-btn-container button{height:auto;padding:6.5px 8px;margin-bottom:0;letter-spacing:0;font-size:.75em;line-height:normal}#onetrust-pc-sdk .ot-leg-btn-container svg{display:none;height:14px;width:14px;padding-right:5px;vertical-align:sub}#onetrust-pc-sdk .ot-active-leg-btn{cursor:default;pointer-events:none}#onetrust-pc-sdk .ot-active-leg-btn svg{display:inline-block}#onetrust-pc-sdk .ot-remove-objection-handler{text-decoration:underline;padding:0;font-size:.75em;font-weight:600;line-height:1;padding-left:10px}#onetrust-pc-sdk .ot-obj-leg-btn-handler span{font-weight:bold;text-align:center;font-size:inherit;line-height:1.5}#onetrust-pc-sdk.ot-close-btn-link #close-pc-btn-handler{border:none;height:auto;line-height:1.5;text-decoration:underline;font-size:.69em;background:none;right:15px;top:15px;width:auto;font-weight:normal}#onetrust-pc-sdk .ot-pgph-link{font-size:.813em !important;margin-top:5px;position:relative}#onetrust-pc-sdk .ot-pgph-link.ot-pgph-link-subgroup{margin-bottom:1rem}#onetrust-pc-sdk .ot-pgph-contr{margin:0 2.5rem}#onetrust-pc-sdk .ot-pgph-title{font-size:1.18rem;margin-bottom:2rem}#onetrust-pc-sdk .ot-pgph-desc{font-size:1rem;font-weight:400;margin-bottom:2rem;line-height:1.5rem}#onetrust-pc-sdk .ot-pgph-desc:not(:last-child):after{content:"";width:96%;display:block;margin:0 auto;padding-bottom:2rem;border-bottom:1px solid #e9e9e9}#onetrust-pc-sdk .ot-cat-header{float:left;font-weight:600;font-size:.875em;line-height:1.5;max-width:90%;vertical-align:middle}#onetrust-pc-sdk .ot-vnd-item>button:focus{outline:#000 solid 2px}#onetrust-pc-sdk .ot-vnd-item>button{position:absolute;cursor:pointer;width:100%;height:100%;margin:0;top:0;left:0;z-index:1;max-width:none;border:none}#onetrust-pc-sdk .ot-vnd-item>button[aria-expanded=false]~.ot-acc-txt{margin-top:0;max-height:0;opacity:0;overflow:hidden;width:100%;transition:.25s ease-out;display:none}#onetrust-pc-sdk .ot-vnd-item>button[aria-expanded=true]~.ot-acc-txt{transition:.1s ease-in;margin-top:10px;width:100%;overflow:auto;display:block}#onetrust-pc-sdk .ot-vnd-item>button[aria-expanded=true]~.ot-acc-grpcntr{width:auto;margin-top:0px;padding-bottom:10px}#onetrust-pc-sdk .ot-accordion-layout.ot-cat-item{position:relative;border-radius:2px;margin:0;padding:0;border:1px solid #d8d8d8;border-top:none;width:calc(100% - 2px);float:left}#onetrust-pc-sdk .ot-accordion-layout.ot-cat-item:first-of-type{margin-top:10px;border-top:1px solid #d8d8d8}#onetrust-pc-sdk .ot-accordion-layout .ot-acc-grpdesc{padding-left:20px;padding-right:20px;width:calc(100% - 40px);font-size:.812em;margin-bottom:10px;margin-top:15px}#onetrust-pc-sdk .ot-accordion-layout .ot-acc-grpdesc>ul{padding-top:10px}#onetrust-pc-sdk .ot-accordion-layout .ot-acc-grpdesc>ul li{padding-top:0;line-height:1.5;padding-bottom:10px}#onetrust-pc-sdk .ot-accordion-layout div+.ot-acc-grpdesc{margin-top:5px}#onetrust-pc-sdk .ot-accordion-layout .ot-vlst-cntr:first-child{margin-top:10px}#onetrust-pc-sdk .ot-accordion-layout .ot-vlst-cntr:last-child,#onetrust-pc-sdk .ot-accordion-layout .ot-hlst-cntr:last-child{margin-bottom:5px}#onetrust-pc-sdk .ot-accordion-layout .ot-acc-hdr{padding-top:11.5px;padding-bottom:11.5px;padding-left:20px;padding-right:20px;width:calc(100% - 40px);display:inline-block}#onetrust-pc-sdk .ot-accordion-layout .ot-acc-txt{width:100%;padding:0}#onetrust-pc-sdk .ot-accordion-layout .ot-subgrp-cntr{padding-left:20px;padding-right:15px;padding-bottom:0;width:calc(100% - 35px)}#onetrust-pc-sdk .ot-accordion-layout .ot-subgrp{padding-right:5px}#onetrust-pc-sdk .ot-accordion-layout .ot-acc-grpcntr{z-index:1;position:relative}#onetrust-pc-sdk .ot-accordion-layout .ot-cat-header+.ot-arw-cntr{position:absolute;top:50%;transform:translateY(-50%);right:20px;margin-top:-2px}#onetrust-pc-sdk .ot-accordion-layout .ot-cat-header+.ot-arw-cntr .ot-arw{width:15px;height:20px;margin-left:5px;color:dimgray}#onetrust-pc-sdk .ot-accordion-layout .ot-cat-header{float:none;color:#2e3644;margin:0;display:inline-block;height:auto;word-wrap:break-word;min-height:inherit}#onetrust-pc-sdk .ot-accordion-layout .ot-vlst-cntr,#onetrust-pc-sdk .ot-accordion-layout .ot-hlst-cntr{padding-left:20px;width:calc(100% - 20px);display:inline-block;margin-top:0;padding-bottom:2px}#onetrust-pc-sdk .ot-accordion-layout .ot-acc-hdr{position:relative;min-height:25px}#onetrust-pc-sdk .ot-accordion-layout h4~.ot-tgl,#onetrust-pc-sdk .ot-accordion-layout h4~.ot-always-active{position:absolute;top:50%;transform:translateY(-50%);right:20px}#onetrust-pc-sdk .ot-accordion-layout h4~.ot-tgl+.ot-tgl{right:95px}#onetrust-pc-sdk .ot-accordion-layout .category-vendors-list-handler,#onetrust-pc-sdk .ot-accordion-layout .category-vendors-list-handler+a{margin-top:5px}#onetrust-pc-sdk #ot-lst-cnt{margin-top:1rem;max-height:calc(100% - 96px)}#onetrust-pc-sdk #ot-lst-cnt .ot-vnd-info-cntr{border:1px solid #d8d8d8;padding:.75rem 2rem;padding-bottom:0;width:auto;margin-top:.5rem}#onetrust-pc-sdk #ot-lst-cnt .ot-vnd-info{margin-bottom:1rem;padding-left:.75rem;padding-right:.75rem;display:flex;flex-direction:column}#onetrust-pc-sdk #ot-lst-cnt .ot-vnd-info[data-vnd-info-key*=DPOEmail]{border-top:1px solid #d8d8d8;padding-top:1rem}#onetrust-pc-sdk #ot-lst-cnt .ot-vnd-info[data-vnd-info-key*=DPOLink]{border-bottom:1px solid #d8d8d8;padding-bottom:1rem}#onetrust-pc-sdk #ot-lst-cnt .ot-vnd-info .ot-vnd-lbl{font-weight:bold;font-size:.85em;margin-bottom:.5rem}#onetrust-pc-sdk #ot-lst-cnt .ot-vnd-info .ot-vnd-cnt{margin-left:.5rem;font-weight:500;font-size:.85rem}#onetrust-pc-sdk .ot-vs-list,#onetrust-pc-sdk .ot-vnd-serv{width:auto;padding:1rem 1.25rem;padding-bottom:0}#onetrust-pc-sdk .ot-vs-list .ot-vnd-serv-hdr-cntr,#onetrust-pc-sdk .ot-vnd-serv .ot-vnd-serv-hdr-cntr{padding-bottom:.75rem;border-bottom:1px solid #d8d8d8}#onetrust-pc-sdk .ot-vs-list .ot-vnd-serv-hdr-cntr .ot-vnd-serv-hdr,#onetrust-pc-sdk .ot-vnd-serv .ot-vnd-serv-hdr-cntr .ot-vnd-serv-hdr{font-weight:600;font-size:.95em;line-height:2;margin-left:.5rem}#onetrust-pc-sdk .ot-vs-list .ot-vnd-item,#onetrust-pc-sdk .ot-vnd-serv .ot-vnd-item{border:none;margin:0;padding:0}#onetrust-pc-sdk .ot-vs-list .ot-vnd-item button,#onetrust-pc-sdk .ot-vnd-serv .ot-vnd-item button{outline:none;border-bottom:1px solid #d8d8d8}#onetrust-pc-sdk .ot-vs-list .ot-vnd-item button[aria-expanded=true],#onetrust-pc-sdk .ot-vnd-serv .ot-vnd-item button[aria-expanded=true]{border-bottom:none}#onetrust-pc-sdk .ot-vs-list .ot-vnd-item:first-child,#onetrust-pc-sdk .ot-vnd-serv .ot-vnd-item:first-child{margin-top:.25rem;border-top:unset}#onetrust-pc-sdk .ot-vs-list .ot-vnd-item:last-child,#onetrust-pc-sdk .ot-vnd-serv .ot-vnd-item:last-child{margin-bottom:.5rem}#onetrust-pc-sdk .ot-vs-list .ot-vnd-item:last-child button,#onetrust-pc-sdk .ot-vnd-serv .ot-vnd-item:last-child button{border-bottom:none}#onetrust-pc-sdk .ot-vs-list .ot-vnd-item .ot-vnd-info-cntr,#onetrust-pc-sdk .ot-vnd-serv .ot-vnd-item .ot-vnd-info-cntr{border:1px solid #d8d8d8;padding:.75rem 1.75rem;padding-bottom:0;width:auto;margin-top:.5rem}#onetrust-pc-sdk .ot-vs-list .ot-vnd-item .ot-vnd-info,#onetrust-pc-sdk .ot-vnd-serv .ot-vnd-item .ot-vnd-info{margin-bottom:1rem;padding-left:.75rem;padding-right:.75rem;display:flex;flex-direction:column}#onetrust-pc-sdk .ot-vs-list .ot-vnd-item .ot-vnd-info[data-vnd-info-key*=DPOEmail],#onetrust-pc-sdk .ot-vnd-serv .ot-vnd-item .ot-vnd-info[data-vnd-info-key*=DPOEmail]{border-top:1px solid #d8d8d8;padding-top:1rem}#onetrust-pc-sdk .ot-vs-list .ot-vnd-item .ot-vnd-info[data-vnd-info-key*=DPOLink],#onetrust-pc-sdk .ot-vnd-serv .ot-vnd-item .ot-vnd-info[data-vnd-info-key*=DPOLink]{border-bottom:1px solid #d8d8d8;padding-bottom:1rem}#onetrust-pc-sdk .ot-vs-list .ot-vnd-item .ot-vnd-info .ot-vnd-lbl,#onetrust-pc-sdk .ot-vnd-serv .ot-vnd-item .ot-vnd-info .ot-vnd-lbl{font-weight:bold;font-size:.85em;margin-bottom:.5rem}#onetrust-pc-sdk .ot-vs-list .ot-vnd-item .ot-vnd-info .ot-vnd-cnt,#onetrust-pc-sdk .ot-vnd-serv .ot-vnd-item .ot-vnd-info .ot-vnd-cnt{margin-left:.5rem;font-weight:500;font-size:.85rem}#onetrust-pc-sdk .ot-vs-list.ot-vnd-subgrp-cnt,#onetrust-pc-sdk .ot-vnd-serv.ot-vnd-subgrp-cnt{padding-left:40px}#onetrust-pc-sdk .ot-vs-list.ot-vnd-subgrp-cnt .ot-vnd-serv-hdr-cntr .ot-vnd-serv-hdr,#onetrust-pc-sdk .ot-vnd-serv.ot-vnd-subgrp-cnt .ot-vnd-serv-hdr-cntr .ot-vnd-serv-hdr{font-size:.8em}#onetrust-pc-sdk .ot-vs-list.ot-vnd-subgrp-cnt .ot-cat-header,#onetrust-pc-sdk .ot-vnd-serv.ot-vnd-subgrp-cnt .ot-cat-header{font-size:.8em}#onetrust-pc-sdk .ot-subgrp-cntr .ot-vnd-serv{margin-bottom:1rem;padding:1rem .95rem}#onetrust-pc-sdk .ot-subgrp-cntr .ot-vnd-serv .ot-vnd-serv-hdr-cntr{padding-bottom:.75rem;border-bottom:1px solid #d8d8d8}#onetrust-pc-sdk .ot-subgrp-cntr .ot-vnd-serv .ot-vnd-serv-hdr-cntr .ot-vnd-serv-hdr{font-weight:700;font-size:.8em;line-height:20px;margin-left:.82rem}#onetrust-pc-sdk .ot-subgrp-cntr .ot-cat-header{font-weight:700;font-size:.8em;line-height:20px}#onetrust-pc-sdk .ot-subgrp-cntr ul.ot-subgrps .ot-vnd-serv .ot-vnd-lst-cont .ot-accordion-layout .ot-acc-hdr div.ot-chkbox{margin-left:.82rem}#onetrust-pc-sdk .ot-vs-config .ot-acc-hdr,#onetrust-pc-sdk ul.ot-subgrps .ot-acc-hdr,#onetrust-pc-sdk .ot-subgrp-cntr ul.ot-subgrps .ot-acc-hdr,#onetrust-pc-sdk .ot-vs-list .ot-vnd-item .ot-acc-hdr,#onetrust-pc-sdk .ot-vnd-serv .ot-vnd-item .ot-acc-hdr,#onetrust-pc-sdk #ot-pc-lst .ot-vs-list .ot-vnd-item .ot-acc-hdr,#onetrust-pc-sdk .ot-accordion-layout.ot-checkbox-consent .ot-acc-hdr{padding:.7rem 0;margin:0;display:flex;width:100%;align-items:center;justify-content:space-between}#onetrust-pc-sdk .ot-vs-config .ot-acc-hdr div:first-child,#onetrust-pc-sdk ul.ot-subgrps .ot-acc-hdr div:first-child,#onetrust-pc-sdk .ot-subgrp-cntr ul.ot-subgrps .ot-acc-hdr div:first-child,#onetrust-pc-sdk .ot-vs-list .ot-vnd-item .ot-acc-hdr div:first-child,#onetrust-pc-sdk .ot-vnd-serv .ot-vnd-item .ot-acc-hdr div:first-child,#onetrust-pc-sdk #ot-pc-lst .ot-vs-list .ot-vnd-item .ot-acc-hdr div:first-child,#onetrust-pc-sdk .ot-accordion-layout.ot-checkbox-consent .ot-acc-hdr div:first-child{margin-left:.5rem}#onetrust-pc-sdk .ot-vs-config .ot-acc-hdr div:last-child,#onetrust-pc-sdk ul.ot-subgrps .ot-acc-hdr div:last-child,#onetrust-pc-sdk .ot-subgrp-cntr ul.ot-subgrps .ot-acc-hdr div:last-child,#onetrust-pc-sdk .ot-vs-list .ot-vnd-item .ot-acc-hdr div:last-child,#onetrust-pc-sdk .ot-vnd-serv .ot-vnd-item .ot-acc-hdr div:last-child,#onetrust-pc-sdk #ot-pc-lst .ot-vs-list .ot-vnd-item .ot-acc-hdr div:last-child,#onetrust-pc-sdk .ot-accordion-layout.ot-checkbox-consent .ot-acc-hdr div:last-child{margin-right:.5rem;margin-left:.5rem}#onetrust-pc-sdk .ot-vs-config .ot-acc-hdr .ot-always-active,#onetrust-pc-sdk ul.ot-subgrps .ot-acc-hdr .ot-always-active,#onetrust-pc-sdk .ot-subgrp-cntr ul.ot-subgrps .ot-acc-hdr .ot-always-active,#onetrust-pc-sdk .ot-vs-list .ot-vnd-item .ot-acc-hdr .ot-always-active,#onetrust-pc-sdk .ot-vnd-serv .ot-vnd-item .ot-acc-hdr .ot-always-active,#onetrust-pc-sdk #ot-pc-lst .ot-vs-list .ot-vnd-item .ot-acc-hdr .ot-always-active,#onetrust-pc-sdk .ot-accordion-layout.ot-checkbox-consent .ot-acc-hdr .ot-always-active{position:relative;right:unset;top:unset;transform:unset}#onetrust-pc-sdk .ot-vs-config .ot-acc-hdr .ot-plus-minus,#onetrust-pc-sdk ul.ot-subgrps .ot-acc-hdr .ot-plus-minus,#onetrust-pc-sdk .ot-subgrp-cntr ul.ot-subgrps .ot-acc-hdr .ot-plus-minus,#onetrust-pc-sdk .ot-vs-list .ot-vnd-item .ot-acc-hdr .ot-plus-minus,#onetrust-pc-sdk .ot-vnd-serv .ot-vnd-item .ot-acc-hdr .ot-plus-minus,#onetrust-pc-sdk #ot-pc-lst .ot-vs-list .ot-vnd-item .ot-acc-hdr .ot-plus-minus,#onetrust-pc-sdk .ot-accordion-layout.ot-checkbox-consent .ot-acc-hdr .ot-plus-minus{top:0}#onetrust-pc-sdk .ot-vs-config .ot-acc-hdr .ot-arw-cntr,#onetrust-pc-sdk ul.ot-subgrps .ot-acc-hdr .ot-arw-cntr,#onetrust-pc-sdk .ot-subgrp-cntr ul.ot-subgrps .ot-acc-hdr .ot-arw-cntr,#onetrust-pc-sdk .ot-vs-list .ot-vnd-item .ot-acc-hdr .ot-arw-cntr,#onetrust-pc-sdk .ot-vnd-serv .ot-vnd-item .ot-acc-hdr .ot-arw-cntr,#onetrust-pc-sdk #ot-pc-lst .ot-vs-list .ot-vnd-item .ot-acc-hdr .ot-arw-cntr,#onetrust-pc-sdk .ot-accordion-layout.ot-checkbox-consent .ot-acc-hdr .ot-arw-cntr{float:none;top:unset;right:unset;transform:unset;margin-top:-2px;position:relative}#onetrust-pc-sdk .ot-vs-config .ot-acc-hdr .ot-cat-header,#onetrust-pc-sdk ul.ot-subgrps .ot-acc-hdr .ot-cat-header,#onetrust-pc-sdk .ot-subgrp-cntr ul.ot-subgrps .ot-acc-hdr .ot-cat-header,#onetrust-pc-sdk .ot-vs-list .ot-vnd-item .ot-acc-hdr .ot-cat-header,#onetrust-pc-sdk .ot-vnd-serv .ot-vnd-item .ot-acc-hdr .ot-cat-header,#onetrust-pc-sdk #ot-pc-lst .ot-vs-list .ot-vnd-item .ot-acc-hdr .ot-cat-header,#onetrust-pc-sdk .ot-accordion-layout.ot-checkbox-consent .ot-acc-hdr .ot-cat-header{flex:1;margin:0 .5rem}#onetrust-pc-sdk .ot-vs-config .ot-acc-hdr .ot-tgl,#onetrust-pc-sdk ul.ot-subgrps .ot-acc-hdr .ot-tgl,#onetrust-pc-sdk .ot-subgrp-cntr ul.ot-subgrps .ot-acc-hdr .ot-tgl,#onetrust-pc-sdk .ot-vs-list .ot-vnd-item .ot-acc-hdr .ot-tgl,#onetrust-pc-sdk .ot-vnd-serv .ot-vnd-item .ot-acc-hdr .ot-tgl,#onetrust-pc-sdk #ot-pc-lst .ot-vs-list .ot-vnd-item .ot-acc-hdr .ot-tgl,#onetrust-pc-sdk .ot-accordion-layout.ot-checkbox-consent .ot-acc-hdr .ot-tgl{position:relative;transform:none;right:0;top:0;float:none}#onetrust-pc-sdk .ot-vs-config .ot-acc-hdr .ot-chkbox,#onetrust-pc-sdk ul.ot-subgrps .ot-acc-hdr .ot-chkbox,#onetrust-pc-sdk .ot-subgrp-cntr ul.ot-subgrps .ot-acc-hdr .ot-chkbox,#onetrust-pc-sdk .ot-vs-list .ot-vnd-item .ot-acc-hdr .ot-chkbox,#onetrust-pc-sdk .ot-vnd-serv .ot-vnd-item .ot-acc-hdr .ot-chkbox,#onetrust-pc-sdk #ot-pc-lst .ot-vs-list .ot-vnd-item .ot-acc-hdr .ot-chkbox,#onetrust-pc-sdk .ot-accordion-layout.ot-checkbox-consent .ot-acc-hdr .ot-chkbox{position:relative;margin:0 .5rem}#onetrust-pc-sdk .ot-vs-config .ot-acc-hdr .ot-chkbox label,#onetrust-pc-sdk ul.ot-subgrps .ot-acc-hdr .ot-chkbox label,#onetrust-pc-sdk .ot-subgrp-cntr ul.ot-subgrps .ot-acc-hdr .ot-chkbox label,#onetrust-pc-sdk .ot-vs-list .ot-vnd-item .ot-acc-hdr .ot-chkbox label,#onetrust-pc-sdk .ot-vnd-serv .ot-vnd-item .ot-acc-hdr .ot-chkbox label,#onetrust-pc-sdk #ot-pc-lst .ot-vs-list .ot-vnd-item .ot-acc-hdr .ot-chkbox label,#onetrust-pc-sdk .ot-accordion-layout.ot-checkbox-consent .ot-acc-hdr .ot-chkbox label{padding:0}#onetrust-pc-sdk .ot-vs-config .ot-acc-hdr .ot-chkbox label::before,#onetrust-pc-sdk ul.ot-subgrps .ot-acc-hdr .ot-chkbox label::before,#onetrust-pc-sdk .ot-subgrp-cntr ul.ot-subgrps .ot-acc-hdr .ot-chkbox label::before,#onetrust-pc-sdk .ot-vs-list .ot-vnd-item .ot-acc-hdr .ot-chkbox label::before,#onetrust-pc-sdk .ot-vnd-serv .ot-vnd-item .ot-acc-hdr .ot-chkbox label::before,#onetrust-pc-sdk #ot-pc-lst .ot-vs-list .ot-vnd-item .ot-acc-hdr .ot-chkbox label::before,#onetrust-pc-sdk .ot-accordion-layout.ot-checkbox-consent .ot-acc-hdr .ot-chkbox label::before{position:relative}#onetrust-pc-sdk .ot-vs-config .ot-acc-hdr .ot-chkbox input,#onetrust-pc-sdk ul.ot-subgrps .ot-acc-hdr .ot-chkbox input,#onetrust-pc-sdk .ot-subgrp-cntr ul.ot-subgrps .ot-acc-hdr .ot-chkbox input,#onetrust-pc-sdk .ot-vs-list .ot-vnd-item .ot-acc-hdr .ot-chkbox input,#onetrust-pc-sdk .ot-vnd-serv .ot-vnd-item .ot-acc-hdr .ot-chkbox input,#onetrust-pc-sdk #ot-pc-lst .ot-vs-list .ot-vnd-item .ot-acc-hdr .ot-chkbox input,#onetrust-pc-sdk .ot-accordion-layout.ot-checkbox-consent .ot-acc-hdr .ot-chkbox input{position:absolute;cursor:pointer;width:100%;height:100%;opacity:0;margin:0;top:0;left:0;z-index:1}#onetrust-pc-sdk .ot-subgrp-cntr ul.ot-subgrps li.ot-subgrp .ot-acc-hdr h5.ot-cat-header,#onetrust-pc-sdk .ot-subgrp-cntr ul.ot-subgrps li.ot-subgrp .ot-acc-hdr h4.ot-cat-header{margin:0}#onetrust-pc-sdk .ot-vs-config .ot-subgrp-cntr ul.ot-subgrps li.ot-subgrp h5{top:0;line-height:20px}#onetrust-pc-sdk .ot-vs-list{display:flex;flex-direction:column;padding:0;margin:.5rem 4px}#onetrust-pc-sdk .ot-vs-selc-all{display:flex;padding:0;float:unset;align-items:center;justify-content:flex-start}#onetrust-pc-sdk .ot-vs-selc-all.ot-toggle-conf{justify-content:flex-end}#onetrust-pc-sdk .ot-vs-selc-all.ot-toggle-conf.ot-caret-conf .ot-sel-all-chkbox{margin-right:48px}#onetrust-pc-sdk .ot-vs-selc-all.ot-toggle-conf .ot-sel-all-chkbox{margin:0;padding:0;margin-right:14px;justify-content:flex-end}#onetrust-pc-sdk .ot-vs-selc-all.ot-toggle-conf #ot-selall-vencntr.ot-chkbox,#onetrust-pc-sdk .ot-vs-selc-all.ot-toggle-conf #ot-selall-vencntr.ot-tgl{display:inline-block;right:unset;width:auto;height:auto;float:none}#onetrust-pc-sdk .ot-vs-selc-all.ot-toggle-conf #ot-selall-vencntr label{width:45px;height:25px}#onetrust-pc-sdk .ot-vs-selc-all .ot-sel-all-chkbox{margin-right:11px;margin-left:.75rem;display:flex;align-items:center}#onetrust-pc-sdk .ot-vs-selc-all .sel-all-hdr{margin:0 1.25rem;font-size:.812em;line-height:normal;text-align:center;word-break:break-word;word-wrap:break-word}#onetrust-pc-sdk .ot-vnd-list-cnt #ot-selall-vencntr.ot-chkbox{float:unset;right:0}#onetrust-pc-sdk[dir=rtl] #ot-back-arw,#onetrust-pc-sdk[dir=rtl] input~.ot-acc-hdr .ot-arw{transform:rotate(180deg);-o-transform:rotate(180deg);-ms-transform:rotate(180deg);-webkit-transform:rotate(180deg)}#onetrust-pc-sdk[dir=rtl] input:checked~.ot-acc-hdr .ot-arw{transform:rotate(270deg);-o-transform:rotate(270deg);-ms-transform:rotate(270deg);-webkit-transform:rotate(270deg)}#onetrust-pc-sdk[dir=rtl] .ot-chkbox label::after{transform:rotate(45deg);-webkit-transform:rotate(45deg);-o-transform:rotate(45deg);-ms-transform:rotate(45deg);border-left:0;border-right:3px solid}#onetrust-pc-sdk[dir=rtl] .ot-search-cntr>svg{right:0}@media only screen and (max-width: 600px){#onetrust-pc-sdk.otPcCenter{left:0;min-width:100%;height:100%;top:0;border-radius:0}#onetrust-pc-sdk #ot-pc-content,#onetrust-pc-sdk.ot-ftr-stacked .ot-btn-container{margin:1px 3px 0 10px;padding-right:10px;width:calc(100% - 23px)}#onetrust-pc-sdk .ot-btn-container button{max-width:none;letter-spacing:.01em}#onetrust-pc-sdk #close-pc-btn-handler{top:10px;right:17px}#onetrust-pc-sdk p{font-size:.7em}#onetrust-pc-sdk #ot-pc-hdr{margin:10px 10px 0 5px;width:calc(100% - 15px)}#onetrust-pc-sdk .vendor-search-handler{font-size:1em}#onetrust-pc-sdk #ot-back-arw{margin-left:12px}#onetrust-pc-sdk #ot-lst-cnt{margin:0;padding:0 5px 0 10px;min-width:95%}#onetrust-pc-sdk .switch+p{max-width:80%}#onetrust-pc-sdk .ot-ftr-stacked button{width:100%}#onetrust-pc-sdk #ot-fltr-cnt{max-width:320px;width:90%;border-top-right-radius:0;border-bottom-right-radius:0;margin:0;margin-left:15px;left:auto;right:40px;top:85px}#onetrust-pc-sdk .ot-fltr-opt{margin-left:25px;margin-bottom:10px}#onetrust-pc-sdk .ot-pc-refuse-all-handler{margin-bottom:0}#onetrust-pc-sdk #ot-fltr-cnt{right:40px}}@media only screen and (max-width: 476px){#onetrust-pc-sdk .ot-fltr-cntr,#onetrust-pc-sdk #ot-fltr-cnt{right:10px}#onetrust-pc-sdk #ot-anchor{right:25px}#onetrust-pc-sdk button{width:100%}#onetrust-pc-sdk:not(.ot-addtl-vendors) #ot-pc-lst:not(.ot-enbl-chr) .ot-sel-all{padding-right:9px}#onetrust-pc-sdk:not(.ot-addtl-vendors) #ot-pc-lst:not(.ot-enbl-chr) .ot-tgl-cntr{right:0}}@media only screen and (max-width: 896px)and (max-height: 425px)and (orientation: landscape){#onetrust-pc-sdk.otPcCenter{left:0;top:0;min-width:100%;height:100%;border-radius:0}#onetrust-pc-sdk .ot-pc-header{height:auto;min-height:20px}#onetrust-pc-sdk .ot-pc-header .ot-pc-logo{max-height:30px}#onetrust-pc-sdk .ot-pc-footer{max-height:60px;overflow-y:auto}#onetrust-pc-sdk #ot-pc-content,#onetrust-pc-sdk #ot-pc-lst{bottom:70px}#onetrust-pc-sdk.ot-ftr-stacked #ot-pc-content{bottom:70px}#onetrust-pc-sdk #ot-anchor{left:initial;right:50px}#onetrust-pc-sdk #ot-lst-title{margin-top:12px}#onetrust-pc-sdk #ot-lst-title *{font-size:inherit}#onetrust-pc-sdk #ot-pc-hdr input{margin-right:0;padding-right:45px}#onetrust-pc-sdk .switch+p{max-width:85%}#onetrust-pc-sdk #ot-sel-blk{position:static}#onetrust-pc-sdk #ot-pc-lst{overflow:auto}#onetrust-pc-sdk #ot-lst-cnt{max-height:none;overflow:initial}#onetrust-pc-sdk #ot-lst-cnt.no-results{height:auto}#onetrust-pc-sdk input{font-size:1em !important}#onetrust-pc-sdk p{font-size:.6em}#onetrust-pc-sdk #ot-fltr-modal{width:100%;top:0}#onetrust-pc-sdk ul li p,#onetrust-pc-sdk .category-vendors-list-handler,#onetrust-pc-sdk .category-vendors-list-handler+a,#onetrust-pc-sdk .category-host-list-handler{font-size:.6em}#onetrust-pc-sdk.ot-shw-fltr #ot-anchor{display:none !important}#onetrust-pc-sdk.ot-shw-fltr #ot-pc-lst{height:100% !important;overflow:hidden;top:0px}#onetrust-pc-sdk.ot-shw-fltr #ot-fltr-cnt{margin:0;height:100%;max-height:none;padding:10px;top:0;width:calc(100% - 20px);position:absolute;right:0;left:0;max-width:none}#onetrust-pc-sdk.ot-shw-fltr .ot-fltr-scrlcnt{max-height:calc(100% - 65px)}}
            #onetrust-consent-sdk #onetrust-pc-sdk,
                #onetrust-consent-sdk #ot-search-cntr,
                #onetrust-consent-sdk #onetrust-pc-sdk .ot-switch.ot-toggle,
                #onetrust-consent-sdk #onetrust-pc-sdk ot-grp-hdr1 .checkbox,
                #onetrust-consent-sdk #onetrust-pc-sdk #ot-pc-title:after
                ,#onetrust-consent-sdk #onetrust-pc-sdk #ot-sel-blk,
                        #onetrust-consent-sdk #onetrust-pc-sdk #ot-fltr-cnt,
                        #onetrust-consent-sdk #onetrust-pc-sdk #ot-anchor {
                    background-color: #FFF;
                }
               
            #onetrust-consent-sdk #onetrust-pc-sdk h3,
                #onetrust-consent-sdk #onetrust-pc-sdk h4,
                #onetrust-consent-sdk #onetrust-pc-sdk h5,
                #onetrust-consent-sdk #onetrust-pc-sdk h6,
                #onetrust-consent-sdk #onetrust-pc-sdk p,
                #onetrust-consent-sdk #onetrust-pc-sdk #ot-ven-lst .ot-ven-opts p,
                #onetrust-consent-sdk #onetrust-pc-sdk #ot-pc-desc,
                #onetrust-consent-sdk #onetrust-pc-sdk #ot-pc-title,
                #onetrust-consent-sdk #onetrust-pc-sdk .ot-li-title,
                #onetrust-consent-sdk #onetrust-pc-sdk .ot-sel-all-hdr span,
                #onetrust-consent-sdk #onetrust-pc-sdk #ot-host-lst .ot-host-info,
                #onetrust-consent-sdk #onetrust-pc-sdk #ot-fltr-modal #modal-header,
                #onetrust-consent-sdk #onetrust-pc-sdk .ot-checkbox label span,
                #onetrust-consent-sdk #onetrust-pc-sdk #ot-pc-lst #ot-sel-blk p,
                #onetrust-consent-sdk #onetrust-pc-sdk #ot-pc-lst #ot-lst-title h3,
                #onetrust-consent-sdk #onetrust-pc-sdk #ot-pc-lst .back-btn-handler p,
                #onetrust-consent-sdk #onetrust-pc-sdk #ot-pc-lst .ot-ven-name,
                #onetrust-consent-sdk #onetrust-pc-sdk #ot-pc-lst #ot-ven-lst .consent-category,
                #onetrust-consent-sdk #onetrust-pc-sdk .ot-leg-btn-container .ot-inactive-leg-btn,
                #onetrust-consent-sdk #onetrust-pc-sdk .ot-label-status,
                #onetrust-consent-sdk #onetrust-pc-sdk .ot-chkbox label span,
                #onetrust-consent-sdk #onetrust-pc-sdk #clear-filters-handler,
                #onetrust-consent-sdk #onetrust-pc-sdk .ot-optout-signal
                {
                    color: #2E2E2E;
                }
             #onetrust-consent-sdk #onetrust-pc-sdk .privacy-notice-link,
                    #onetrust-consent-sdk #onetrust-pc-sdk .ot-pgph-link,
                    #onetrust-consent-sdk #onetrust-pc-sdk .category-vendors-list-handler,
                    #onetrust-consent-sdk #onetrust-pc-sdk .category-vendors-list-handler + a,
                    #onetrust-consent-sdk #onetrust-pc-sdk .category-host-list-handler,
                    #onetrust-consent-sdk #onetrust-pc-sdk .ot-ven-link,
                    #onetrust-consent-sdk #onetrust-pc-sdk .ot-ven-legclaim-link,
                    #onetrust-consent-sdk #onetrust-pc-sdk #ot-host-lst .ot-host-name a,
                    #onetrust-consent-sdk #onetrust-pc-sdk #ot-host-lst .ot-acc-hdr .ot-host-expand,
                    #onetrust-consent-sdk #onetrust-pc-sdk #ot-host-lst .ot-host-info a,
                    #onetrust-consent-sdk #onetrust-pc-sdk #ot-pc-content #ot-pc-desc .ot-link-btn,
                    #onetrust-consent-sdk #onetrust-pc-sdk .ot-vnd-serv .ot-vnd-item .ot-vnd-info a,
                    #onetrust-consent-sdk #onetrust-pc-sdk #ot-lst-cnt .ot-vnd-info a
                    {
                        color: #007398;
                    }
            #onetrust-consent-sdk #onetrust-pc-sdk .category-vendors-list-handler:hover { text-decoration: underline;}
            #onetrust-consent-sdk #onetrust-pc-sdk .ot-acc-grpcntr.ot-acc-txt,
            #onetrust-consent-sdk #onetrust-pc-sdk .ot-acc-txt .ot-subgrp-tgl .ot-switch.ot-toggle
             {
                background-color: #F8F8F8;
            }
             #onetrust-consent-sdk #onetrust-pc-sdk #ot-host-lst .ot-host-info,
                    #onetrust-consent-sdk #onetrust-pc-sdk .ot-acc-txt .ot-ven-dets
                            {
                                background-color: #F8F8F8;
                            }
        #onetrust-consent-sdk #onetrust-pc-sdk
            button:not(#clear-filters-handler):not(.ot-close-icon):not(#filter-btn-handler):not(.ot-remove-objection-handler):not(.ot-obj-leg-btn-handler):not([aria-expanded]):not(.ot-link-btn),
            #onetrust-consent-sdk #onetrust-pc-sdk .ot-leg-btn-container .ot-active-leg-btn {
                background-color: #007398;border-color: #007398;
                color: #FFF;
            }
            #onetrust-consent-sdk #onetrust-pc-sdk .ot-active-menu {
                border-color: #007398;
            }
            
            #onetrust-consent-sdk #onetrust-pc-sdk .ot-leg-btn-container .ot-remove-objection-handler{
                background-color: transparent;
                border: 1px solid transparent;
            }
            #onetrust-consent-sdk #onetrust-pc-sdk .ot-leg-btn-container .ot-inactive-leg-btn {
                background-color: #FFFFFF;
                color: #78808E; border-color: #78808E;
            }
            #onetrust-consent-sdk #onetrust-pc-sdk .ot-tgl input:focus + .ot-switch, .ot-switch .ot-switch-nob, .ot-switch .ot-switch-nob:before,
            #onetrust-pc-sdk .ot-checkbox input[type="checkbox"]:focus + label::before,
            #onetrust-pc-sdk .ot-chkbox input[type="checkbox"]:focus + label::before {
                outline-color: #000000;
                outline-width: 1px;
            }
            #onetrust-pc-sdk .ot-host-item > button:focus, #onetrust-pc-sdk .ot-ven-item > button:focus {
                border: 1px solid #000000;
            }
            #onetrust-consent-sdk #onetrust-pc-sdk *:focus,
            #onetrust-consent-sdk #onetrust-pc-sdk .ot-vlst-cntr > a:focus {
               outline: 1px solid #000000;
            }#onetrust-pc-sdk .ot-vlst-cntr .ot-ext-lnk,  #onetrust-pc-sdk .ot-ven-hdr .ot-ext-lnk{
                    background-image: url('https://cdn.cookielaw.org/logos/static/ot_external_link.svg');
                }
            /*! Extra code to blur out background */
.onetrust-pc-dark-filter{
background:rgba(0,0,0,.5);
z-index:2147483646;
width:100%;
height:100%;
overflow:hidden;
position:fixed;
top:0;
bottom:0;
left:0;
backdrop-filter: initial
}

/*! v6.12.0 2021-01-19 */
div#onetrust-consent-sdk #onetrust-banner-sdk{border-top:2px solid #eb6500!important;outline:1px solid transparent;box-shadow:none;padding:24px}div#onetrust-consent-sdk button{border-radius:0!important;box-shadow:none!important;box-sizing:border-box!important;font-size:20px!important;font-weight:400!important;letter-spacing:0!important;max-width:none!important;white-space:nowrap!important}div#onetrust-consent-sdk button:not(.ot-link-btn){background-color:#007398!important;border:2px solid #007398!important;color:#fff!important;height:48px!important;padding:0 1em!important;width:auto!important}div#onetrust-consent-sdk button:hover{background-color:#fff!important;border-color:#eb6500!important;color:#2e2e2e!important}div#onetrust-consent-sdk button.ot-link-btn{color:#007398!important;font-size:16px!important;text-decoration:underline}div#onetrust-consent-sdk button.ot-link-btn:hover{color:inherit!important;text-decoration-color:#eb6500!important}div#onetrust-consent-sdk a,div#onetrust-pc-sdk a{color:#007398!important;text-decoration:underline!important}div#onetrust-consent-sdk a,div#onetrust-consent-sdk button,div#onetrust-consent-sdk p:hover{opacity:1!important}div#onetrust-consent-sdk a:focus,div#onetrust-consent-sdk button:focus,div#onetrust-consent-sdk input:focus{outline:2px solid #eb6500!important;outline-offset:1px!important}div#onetrust-banner-sdk .ot-sdk-container{padding:0;width:auto}div#onetrust-banner-sdk .ot-sdk-row{align-items:flex-start;box-sizing:border-box;display:flex;flex-direction:column;justify-content:space-between;margin:auto;max-width:1152px}div#onetrust-banner-sdk .ot-sdk-row:after{display:none}div#onetrust-banner-sdk #onetrust-group-container,div#onetrust-banner-sdk.ot-bnr-flift:not(.ot-iab-2) #onetrust-group-container,div#onetrust-banner-sdk:not(.ot-iab-2) #onetrust-group-container{flex-grow:1;width:auto}div#onetrust-banner-sdk #onetrust-policy,div#onetrust-banner-sdk.ot-bnr-flift #onetrust-policy{margin:0;overflow:visible}div#onetrust-banner-sdk.ot-bnr-flift #onetrust-policy-text,div#onetrust-consent-sdk #onetrust-policy-text{font-size:16px;line-height:24px;max-width:44em;margin:0}div#onetrust-consent-sdk #onetrust-policy-text a[href]{font-weight:400;margin-left:8px}div#onetrust-banner-sdk #onetrust-button-group-parent{flex:0 0 auto;margin:32px 0 0;width:100%}div#onetrust-banner-sdk #onetrust-button-group{display:flex;flex-direction:row;flex-wrap:wrap;justify-content:flex-end;margin:-8px}div#onetrust-banner-sdk .banner-actions-container{display:flex;flex:1 0 auto}div#onetrust-banner-sdk.ot-buttons-fw:not(.ot-iab-2) #onetrust-button-group button:last-of-type,div#onetrust-consent-sdk #onetrust-accept-btn-handler,div#onetrust-consent-sdk #onetrust-pc-btn-handler{flex:1 0 auto;margin:8px;width:auto}div#onetrust-consent-sdk #onetrust-pc-btn-handler{background-color:#fff!important;color:inherit!important}div#onetrust-banner-sdk #onetrust-close-btn-container{display:none}@media only screen and (min-width:556px){div#onetrust-consent-sdk #onetrust-banner-sdk{padding:40px}div#onetrust-banner-sdk #onetrust-policy{margin:0 40px 0 0}div#onetrust-banner-sdk .ot-sdk-row{align-items:center;flex-direction:row}div#onetrust-banner-sdk #onetrust-button-group-parent,div#onetrust-banner-sdk.ot-bnr-flift:not(.ot-iab-2) #onetrust-button-group-parent,div#onetrust-banner-sdk:not(.ot-iab-2) #onetrust-button-group-parent{margin:0;padding:0;width:auto}div#onetrust-banner-sdk #onetrust-button-group,div#onetrust-banner-sdk.ot-buttons-fw:not(.ot-iab-2) #onetrust-button-group{align-items:stretch;flex-direction:column-reverse;margin:0}div#onetrust-consent-sdk #onetrust-accept-btn-handler,div#onetrust-consent-sdk #onetrust-pc-btn-handler{flex:1 0 auto}}@media only screen and (min-width:768px){div#onetrust-banner-sdk #onetrust-policy{margin:0 48px 0 0}div#onetrust-consent-sdk #onetrust-banner-sdk{padding:48px}}div#onetrust-consent-sdk #onetrust-pc-sdk h5{font-size:16px;line-height:24px}div#onetrust-consent-sdk #onetrust-pc-sdk p,div#onetrust-pc-sdk #ot-pc-desc,div#onetrust-pc-sdk .category-host-list-handler,div#onetrust-pc-sdk .ot-accordion-layout .ot-cat-header{font-size:16px;font-weight:400;line-height:24px}div#onetrust-consent-sdk a:hover,div#onetrust-pc-sdk a:hover{color:inherit!important;text-decoration-color:#eb6500!important}div#onetrust-pc-sdk{border-radius:0;bottom:0;height:auto;left:0;margin:auto;max-width:100%;overflow:hidden;right:0;top:0;width:512px;max-height:800px}div#onetrust-pc-sdk .ot-pc-header{display:none}div#onetrust-pc-sdk #ot-pc-content{overscroll-behavior:contain;padding:0 12px 0 24px;margin:16px 4px 0 0;top:0;right:16px;left:0;width:auto}div#onetrust-pc-sdk #ot-category-title,div#onetrust-pc-sdk #ot-pc-title{font-size:24px;font-weight:400;line-height:32px;margin:0 0 16px}div#onetrust-pc-sdk #ot-pc-desc{padding:0}div#onetrust-pc-sdk #ot-pc-desc a{display:inline}div#onetrust-pc-sdk #accept-recommended-btn-handler{display:none!important}div#onetrust-pc-sdk input[type=checkbox]:focus+.ot-acc-hdr{outline:2px solid #eb6500;outline-offset:-1px;transition:none}div#onetrust-pc-sdk .ot-accordion-layout.ot-cat-item{border-width:0 0 2px}div#onetrust-pc-sdk .ot-accordion-layout.ot-cat-item:first-of-type{border-width:2px 0}div#onetrust-pc-sdk .ot-accordion-layout .ot-acc-hdr{padding:8px 0;width:100%}div#onetrust-pc-sdk .ot-plus-minus{transform:translateY(2px)}div#onetrust-pc-sdk .ot-accordion-layout.ot-cat-item>button{background:0 0!important;border:0!important;height:44px!important;max-width:none!important;width:calc(100% - 48px)!important}div#onetrust-consent-sdk #onetrust-pc-sdk h5{font-weight:700}div#onetrust-pc-sdk .ot-accordion-layout .ot-hlst-cntr{padding:0}div#onetrust-pc-sdk .ot-accordion-layout.ot-cat-item .ot-acc-grpdesc{padding:0;width:100%}div#onetrust-pc-sdk .ot-acc-grpcntr .ot-subgrp-cntr{border:0;padding:0}div#onetrust-pc-sdk .ot-subgrp-cntr ul.ot-subgrps li.ot-subgrp{margin:0}div#onetrust-pc-sdk .ot-always-active-group .ot-cat-header{width:calc(100% - 160px)}#onetrust-pc-sdk .ot-accordion-layout .ot-cat-header{width:calc(100% - 88px)}div#onetrust-pc-sdk .ot-accordion-layout h4~.ot-always-active{color:inherit;font-size:12px;font-weight:400;line-height:1.5;padding-right:48px}div#onetrust-pc-sdk .ot-accordion-layout h4~.ot-always-active:before{border-radius:12px;position:absolute;right:0;top:0;content:'';background:#fff;border:2px solid #939393;box-sizing:border-box;height:20px;width:40px}div#onetrust-pc-sdk .ot-accordion-layout h4~.ot-always-active:after{border-radius:50%;position:absolute;right:5px;top:4px;content:'';background-color:#eb6500;height:12px;width:12px}div#onetrust-pc-sdk .ot-accordion-layout h4~.ot-always-active,div#onetrust-pc-sdk .ot-accordion-layout h4~.ot-tgl{right:2px}div#onetrust-pc-sdk .ot-switch{display:block;height:20px;width:40px}div#onetrust-pc-sdk .ot-tgl input+.ot-switch .ot-switch-nob,div#onetrust-pc-sdk .ot-tgl input:checked+.ot-switch .ot-switch-nob{background:#fff;border:2px solid #939393;box-sizing:border-box;height:20px;width:40px}div#onetrust-pc-sdk .ot-tgl input+.ot-switch .ot-switch-nob:before{background-color:#737373;height:8px;left:4px;top:4px;width:8px}div#onetrust-pc-sdk .ot-tgl input:checked+.ot-switch .ot-switch-nob:before{background-color:#eb6500;height:12px;left:0;top:2px;width:12px}div#onetrust-pc-sdk .ot-tgl input:focus+.ot-switch .ot-switch-nob{box-shadow:0 0;outline:2px solid #eb6500!important;outline-offset:1px;transition:none}div#onetrust-consent-sdk #onetrust-pc-sdk .ot-acc-grpcntr.ot-acc-txt{background-color:transparent;padding-left:3px}div#onetrust-pc-sdk .ot-accordion-layout .ot-hlst-cntr,div#onetrust-pc-sdk .ot-accordion-layout .ot-vlst-cntr{overflow:visible;width:100%}div#onetrust-pc-sdk .ot-pc-footer{border-top:0 solid}div#onetrust-pc-sdk .ot-btn-container{padding-top:24px;text-align:center}div#onetrust-pc-sdk .ot-pc-footer button{margin:8px 0;background-color:#fff}div#onetrust-pc-sdk .ot-pc-footer-logo{background-color:#fff}div#onetrust-pc-sdk #ot-lst-title span{font-size:24px;font-weight:400;line-height:32px}div#onetrust-pc-sdk #ot-host-lst .ot-host-desc,div#onetrust-pc-sdk #ot-host-lst .ot-host-expand,div#onetrust-pc-sdk #ot-host-lst .ot-host-name,div#onetrust-pc-sdk #ot-host-lst .ot-host-name a,div#onetrust-pc-sdk .back-btn-handler,div#onetrust-pc-sdk .ot-host-opt li>div div{font-size:16px;font-weight:400;line-height:24px}div#onetrust-pc-sdk #ot-host-lst .ot-acc-txt{width:100%}div#onetrust-pc-sdk #ot-pc-lst{top:0}div#onetrust-pc-sdk .back-btn-handler{text-decoration:none!important}div#onetrust-pc-sdk #filter-btn-handler:hover svg{filter:invert(1)}div#onetrust-pc-sdk .back-btn-handler svg{width:16px;height:16px}div#onetrust-pc-sdk .ot-host-item>button{background:0 0!important;border:0!important;height:66px!important;max-width:none!important;width:calc(100% - 5px)!important;transform:translate(2px,2px)}div#onetrust-pc-sdk .ot-host-item{border-bottom:2px solid #b9b9b9;padding:0}div#onetrust-pc-sdk .ot-host-item .ot-acc-hdr{margin:0 0 -6px;padding:8px 0}div#onetrust-pc-sdk ul li:first-child{border-top:2px solid #b9b9b9}div#onetrust-pc-sdk .ot-host-item .ot-plus-minus{margin:0 8px 0 0}div#onetrust-pc-sdk .ot-search-cntr{width:calc(100% - 48px)}div#onetrust-pc-sdk .ot-host-opt .ot-host-info{background-color:transparent}div#onetrust-pc-sdk .ot-host-opt li>div div{padding:0}div#onetrust-pc-sdk #vendor-search-handler{border-radius:0;border-color:#939393;border-style:solid;border-width:2px 0 2px 2px;font-size:20px;height:48px;margin:0}div#onetrust-pc-sdk #ot-pc-hdr{margin-left:24px}div#onetrust-pc-sdk .ot-lst-subhdr{width:calc(100% - 24px)}div#onetrust-pc-sdk .ot-lst-subhdr svg{right:0;top:8px}div#onetrust-pc-sdk .ot-fltr-cntr{box-sizing:border-box;right:0;width:48px}div#onetrust-pc-sdk #filter-btn-handler{width:48px!important;padding:8px!important}div#onetrust-consent-sdk #onetrust-pc-sdk #clear-filters-handler,div#onetrust-pc-sdk button#filter-apply-handler,div#onetrust-pc-sdk button#filter-cancel-handler{height:2em!important;padding-left:14px!important;padding-right:14px!important}div#onetrust-pc-sdk #ot-fltr-cnt{box-shadow:0 0;border:1px solid #8e8e8e;border-radius:0}div#onetrust-pc-sdk .ot-fltr-scrlcnt{max-height:calc(100% - 80px)}div#onetrust-pc-sdk #ot-fltr-modal{max-height:400px}div#onetrust-pc-sdk .ot-fltr-opt{margin-bottom:16px}div#onetrust-pc-sdk #ot-lst-cnt{margin-left:24px;width:calc(100% - 48px)}div#onetrust-pc-sdk #ot-anchor{display:none!important}
/*! Extra code to blur our background */
.onetrust-pc-dark-filter{
backdrop-filter: blur(3px)
}
.ot-sdk-cookie-policy{font-family:inherit;font-size:16px}.ot-sdk-cookie-policy.otRelFont{font-size:1rem}.ot-sdk-cookie-policy h3,.ot-sdk-cookie-policy h4,.ot-sdk-cookie-policy h6,.ot-sdk-cookie-policy p,.ot-sdk-cookie-policy li,.ot-sdk-cookie-policy a,.ot-sdk-cookie-policy th,.ot-sdk-cookie-policy #cookie-policy-description,.ot-sdk-cookie-policy .ot-sdk-cookie-policy-group,.ot-sdk-cookie-policy #cookie-policy-title{color:dimgray}.ot-sdk-cookie-policy #cookie-policy-description{margin-bottom:1em}.ot-sdk-cookie-policy h4{font-size:1.2em}.ot-sdk-cookie-policy h6{font-size:1em;margin-top:2em}.ot-sdk-cookie-policy th{min-width:75px}.ot-sdk-cookie-policy a,.ot-sdk-cookie-policy a:hover{background:#fff}.ot-sdk-cookie-policy thead{background-color:#f6f6f4;font-weight:bold}.ot-sdk-cookie-policy .ot-mobile-border{display:none}.ot-sdk-cookie-policy section{margin-bottom:2em}.ot-sdk-cookie-policy table{border-collapse:inherit}#ot-sdk-cookie-policy-v2.ot-sdk-cookie-policy{font-family:inherit;font-size:1rem}#ot-sdk-cookie-policy-v2.ot-sdk-cookie-policy h3,#ot-sdk-cookie-policy-v2.ot-sdk-cookie-policy h4,#ot-sdk-cookie-policy-v2.ot-sdk-cookie-policy h6,#ot-sdk-cookie-policy-v2.ot-sdk-cookie-policy p,#ot-sdk-cookie-policy-v2.ot-sdk-cookie-policy li,#ot-sdk-cookie-policy-v2.ot-sdk-cookie-policy a,#ot-sdk-cookie-policy-v2.ot-sdk-cookie-policy th,#ot-sdk-cookie-policy-v2.ot-sdk-cookie-policy #cookie-policy-description,#ot-sdk-cookie-policy-v2.ot-sdk-cookie-policy .ot-sdk-cookie-policy-group,#ot-sdk-cookie-policy-v2.ot-sdk-cookie-policy #cookie-policy-title{color:dimgray}#ot-sdk-cookie-policy-v2.ot-sdk-cookie-policy #cookie-policy-description{margin-bottom:1em}#ot-sdk-cookie-policy-v2.ot-sdk-cookie-policy .ot-sdk-subgroup{margin-left:1.5em}#ot-sdk-cookie-policy-v2.ot-sdk-cookie-policy #cookie-policy-description,#ot-sdk-cookie-policy-v2.ot-sdk-cookie-policy .ot-sdk-cookie-policy-group-desc,#ot-sdk-cookie-policy-v2.ot-sdk-cookie-policy .ot-table-header,#ot-sdk-cookie-policy-v2.ot-sdk-cookie-policy a,#ot-sdk-cookie-policy-v2.ot-sdk-cookie-policy span,#ot-sdk-cookie-policy-v2.ot-sdk-cookie-policy td{font-size:.9em}#ot-sdk-cookie-policy-v2.ot-sdk-cookie-policy td span,#ot-sdk-cookie-policy-v2.ot-sdk-cookie-policy td a{font-size:inherit}#ot-sdk-cookie-policy-v2.ot-sdk-cookie-policy .ot-sdk-cookie-policy-group{font-size:1em;margin-bottom:.6em}#ot-sdk-cookie-policy-v2.ot-sdk-cookie-policy .ot-sdk-cookie-policy-title{margin-bottom:1.2em}#ot-sdk-cookie-policy-v2.ot-sdk-cookie-policy>section{margin-bottom:1em}#ot-sdk-cookie-policy-v2.ot-sdk-cookie-policy th{min-width:75px}#ot-sdk-cookie-policy-v2.ot-sdk-cookie-policy a,#ot-sdk-cookie-policy-v2.ot-sdk-cookie-policy a:hover{background:#fff}#ot-sdk-cookie-policy-v2.ot-sdk-cookie-policy thead{background-color:#f6f6f4;font-weight:bold}#ot-sdk-cookie-policy-v2.ot-sdk-cookie-policy .ot-mobile-border{display:none}#ot-sdk-cookie-policy-v2.ot-sdk-cookie-policy section{margin-bottom:2em}#ot-sdk-cookie-policy-v2.ot-sdk-cookie-policy .ot-sdk-subgroup ul li{list-style:disc;margin-left:1.5em}#ot-sdk-cookie-policy-v2.ot-sdk-cookie-policy .ot-sdk-subgroup ul li h4{display:inline-block}#ot-sdk-cookie-policy-v2.ot-sdk-cookie-policy table{border-collapse:inherit;margin:auto;border:1px solid #d7d7d7;border-radius:5px;border-spacing:initial;width:100%;overflow:hidden}#ot-sdk-cookie-policy-v2.ot-sdk-cookie-policy table th,#ot-sdk-cookie-policy-v2.ot-sdk-cookie-policy table td{border-bottom:1px solid #d7d7d7;border-right:1px solid #d7d7d7}#ot-sdk-cookie-policy-v2.ot-sdk-cookie-policy table tr:last-child td{border-bottom:0px}#ot-sdk-cookie-policy-v2.ot-sdk-cookie-policy table tr th:last-child,#ot-sdk-cookie-policy-v2.ot-sdk-cookie-policy table tr td:last-child{border-right:0px}#ot-sdk-cookie-policy-v2.ot-sdk-cookie-policy table .ot-host,#ot-sdk-cookie-policy-v2.ot-sdk-cookie-policy table .ot-cookies-type{width:25%}.ot-sdk-cookie-policy[dir=rtl]{text-align:left}#ot-sdk-cookie-policy h3{font-size:1.5em}@media only screen and (max-width: 530px){.ot-sdk-cookie-policy:not(#ot-sdk-cookie-policy-v2) table,.ot-sdk-cookie-policy:not(#ot-sdk-cookie-policy-v2) thead,.ot-sdk-cookie-policy:not(#ot-sdk-cookie-policy-v2) tbody,.ot-sdk-cookie-policy:not(#ot-sdk-cookie-policy-v2) th,.ot-sdk-cookie-policy:not(#ot-sdk-cookie-policy-v2) td,.ot-sdk-cookie-policy:not(#ot-sdk-cookie-policy-v2) tr{display:block}.ot-sdk-cookie-policy:not(#ot-sdk-cookie-policy-v2) thead tr{position:absolute;top:-9999px;left:-9999px}.ot-sdk-cookie-policy:not(#ot-sdk-cookie-policy-v2) tr{margin:0 0 1em 0}.ot-sdk-cookie-policy:not(#ot-sdk-cookie-policy-v2) tr:nth-child(odd),.ot-sdk-cookie-policy:not(#ot-sdk-cookie-policy-v2) tr:nth-child(odd) a{background:#f6f6f4}.ot-sdk-cookie-policy:not(#ot-sdk-cookie-policy-v2) td{border:none;border-bottom:1px solid #eee;position:relative;padding-left:50%}.ot-sdk-cookie-policy:not(#ot-sdk-cookie-policy-v2) td:before{position:absolute;height:100%;left:6px;width:40%;padding-right:10px}.ot-sdk-cookie-policy:not(#ot-sdk-cookie-policy-v2) .ot-mobile-border{display:inline-block;background-color:#e4e4e4;position:absolute;height:100%;top:0;left:45%;width:2px}.ot-sdk-cookie-policy:not(#ot-sdk-cookie-policy-v2) td:before{content:attr(data-label);font-weight:bold}.ot-sdk-cookie-policy:not(#ot-sdk-cookie-policy-v2) li{word-break:break-word;word-wrap:break-word}#ot-sdk-cookie-policy-v2.ot-sdk-cookie-policy table{overflow:hidden}#ot-sdk-cookie-policy-v2.ot-sdk-cookie-policy table td{border:none;border-bottom:1px solid #d7d7d7}#ot-sdk-cookie-policy-v2.ot-sdk-cookie-policy table,#ot-sdk-cookie-policy-v2.ot-sdk-cookie-policy thead,#ot-sdk-cookie-policy-v2.ot-sdk-cookie-policy tbody,#ot-sdk-cookie-policy-v2.ot-sdk-cookie-policy th,#ot-sdk-cookie-policy-v2.ot-sdk-cookie-policy td,#ot-sdk-cookie-policy-v2.ot-sdk-cookie-policy tr{display:block}#ot-sdk-cookie-policy-v2.ot-sdk-cookie-policy table .ot-host,#ot-sdk-cookie-policy-v2.ot-sdk-cookie-policy table .ot-cookies-type{width:auto}#ot-sdk-cookie-policy-v2.ot-sdk-cookie-policy tr{margin:0 0 1em 0}#ot-sdk-cookie-policy-v2.ot-sdk-cookie-policy td:before{height:100%;width:40%;padding-right:10px}#ot-sdk-cookie-policy-v2.ot-sdk-cookie-policy td:before{content:attr(data-label);font-weight:bold}#ot-sdk-cookie-policy-v2.ot-sdk-cookie-policy li{word-break:break-word;word-wrap:break-word}#ot-sdk-cookie-policy-v2.ot-sdk-cookie-policy thead tr{position:absolute;top:-9999px;left:-9999px;z-index:-9999}#ot-sdk-cookie-policy-v2.ot-sdk-cookie-policy table tr:last-child td{border-bottom:1px solid #d7d7d7;border-right:0px}#ot-sdk-cookie-policy-v2.ot-sdk-cookie-policy table tr:last-child td:last-child{border-bottom:0px}}
                
                    #ot-sdk-cookie-policy-v2.ot-sdk-cookie-policy h5,
                    #ot-sdk-cookie-policy-v2.ot-sdk-cookie-policy h6,
                    #ot-sdk-cookie-policy-v2.ot-sdk-cookie-policy li,
                    #ot-sdk-cookie-policy-v2.ot-sdk-cookie-policy p,
                    #ot-sdk-cookie-policy-v2.ot-sdk-cookie-policy a,
                    #ot-sdk-cookie-policy-v2.ot-sdk-cookie-policy span,
                    #ot-sdk-cookie-policy-v2.ot-sdk-cookie-policy td,
                    #ot-sdk-cookie-policy-v2.ot-sdk-cookie-policy #cookie-policy-description {
                        color: #696969;
                    }
                    #ot-sdk-cookie-policy-v2.ot-sdk-cookie-policy th {
                        color: #696969;
                    }
                    #ot-sdk-cookie-policy-v2.ot-sdk-cookie-policy .ot-sdk-cookie-policy-group {
                        color: #696969;
                    }
                    
                    #ot-sdk-cookie-policy-v2.ot-sdk-cookie-policy #cookie-policy-title {
                            color: #696969;
                        }
                    
            
                    #ot-sdk-cookie-policy-v2.ot-sdk-cookie-policy table th {
                            background-color: #F8F8F8;
                        }
                    
            .ot-floating-button__front{background-image:url('https://cdn.cookielaw.org/logos/static/ot_persistent_cookie_icon.png')}</style><link type="text/css" rel="stylesheet" href="https://pendo-static-5661679399600128.storage.googleapis.com/guide.-323232.1721046486120.css" id="_pendo-css_"><style type="text/css" scoped="scoped" class=" pendo-style-D_T2uHq_M1r-XQq8htU6Z3GjHfE" style="white-space: pre-wrap;"></style><style type="text/css">.MathJax_SVG_Display {text-align: center; margin: 1em 0em; position: relative; display: block!important; text-indent: 0; max-width: none; max-height: none; min-width: 0; min-height: 0; width: 100%}
.MathJax_SVG .MJX-monospace {font-family: monospace}
.MathJax_SVG .MJX-sans-serif {font-family: sans-serif}
#MathJax_SVG_Tooltip {background-color: InfoBackground; color: InfoText; border: 1px solid black; box-shadow: 2px 2px 5px #AAAAAA; -webkit-box-shadow: 2px 2px 5px #AAAAAA; -moz-box-shadow: 2px 2px 5px #AAAAAA; -khtml-box-shadow: 2px 2px 5px #AAAAAA; padding: 3px 4px; z-index: 401; position: absolute; left: 0; top: 0; width: auto; height: auto; display: none}
.MathJax_SVG {display: inline; font-style: normal; font-weight: normal; line-height: normal; font-size: 100%; font-size-adjust: none; text-indent: 0; text-align: left; text-transform: none; letter-spacing: normal; word-spacing: normal; word-wrap: normal; white-space: nowrap; float: none; direction: ltr; max-width: none; max-height: none; min-width: 0; min-height: 0; border: 0; padding: 0; margin: 0}
.MathJax_SVG * {transition: none; -webkit-transition: none; -moz-transition: none; -ms-transition: none; -o-transition: none}
.MathJax_SVG > div {display: inline-block}
.mjx-svg-href {fill: blue; stroke: blue}
.MathJax_SVG_Processing {visibility: hidden; position: absolute; top: 0; left: 0; width: 0; height: 0; overflow: hidden; display: block!important}
.MathJax_SVG_Processed {display: none!important}
.MathJax_SVG_test {font-style: normal; font-weight: normal; font-size: 100%; font-size-adjust: none; text-indent: 0; text-transform: none; letter-spacing: normal; word-spacing: normal; overflow: hidden; height: 1px}
.MathJax_SVG_test.mjx-test-display {display: table!important}
.MathJax_SVG_test.mjx-test-inline {display: inline!important; margin-right: -1px}
.MathJax_SVG_test.mjx-test-default {display: block!important; clear: both}
.MathJax_SVG_ex_box {display: inline-block!important; position: absolute; overflow: hidden; min-height: 0; max-height: none; padding: 0; border: 0; margin: 0; width: 1px; height: 60ex}
.mjx-test-inline .MathJax_SVG_left_box {display: inline-block; width: 0; float: left}
.mjx-test-inline .MathJax_SVG_right_box {display: inline-block; width: 0; float: right}
.mjx-test-display .MathJax_SVG_right_box {display: table-cell!important; width: 10000em!important; min-width: 0; max-width: none; padding: 0; border: 0; margin: 0}
</style></head>
    <body data-sd-ui-layer-boundary="true" class="toolbar-stuck" style=""><div style="visibility: hidden; overflow: hidden; position: absolute; top: 0px; height: 1px; width: auto; padding: 0px; border: 0px; margin: 0px; text-align: left; text-indent: 0px; text-transform: none; line-height: normal; letter-spacing: normal; word-spacing: normal;"><div id="MathJax_SVG_Hidden"></div><svg><defs id="MathJax_SVG_glyphs"><path stroke-width="1" id="MJMATHI-78" d="M52 289Q59 331 106 386T222 442Q257 442 286 424T329 379Q371 442 430 442Q467 442 494 420T522 361Q522 332 508 314T481 292T458 288Q439 288 427 299T415 328Q415 374 465 391Q454 404 425 404Q412 404 406 402Q368 386 350 336Q290 115 290 78Q290 50 306 38T341 26Q378 26 414 59T463 140Q466 150 469 151T485 153H489Q504 153 504 145Q504 144 502 134Q486 77 440 33T333 -11Q263 -11 227 52Q186 -10 133 -10H127Q78 -10 57 16T35 71Q35 103 54 123T99 143Q142 143 142 101Q142 81 130 66T107 46T94 41L91 40Q91 39 97 36T113 29T132 26Q168 26 194 71Q203 87 217 139T245 247T261 313Q266 340 266 352Q266 380 251 392T217 404Q177 404 142 372T93 290Q91 281 88 280T72 278H58Q52 284 52 289Z"></path><path stroke-width="1" id="MJMAIN-28" d="M94 250Q94 319 104 381T127 488T164 576T202 643T244 695T277 729T302 750H315H319Q333 750 333 741Q333 738 316 720T275 667T226 581T184 443T167 250T184 58T225 -81T274 -167T316 -220T333 -241Q333 -250 318 -250H315H302L274 -226Q180 -141 137 -14T94 250Z"></path><path stroke-width="1" id="MJMATHI-69" d="M184 600Q184 624 203 642T247 661Q265 661 277 649T290 619Q290 596 270 577T226 557Q211 557 198 567T184 600ZM21 287Q21 295 30 318T54 369T98 420T158 442Q197 442 223 419T250 357Q250 340 236 301T196 196T154 83Q149 61 149 51Q149 26 166 26Q175 26 185 29T208 43T235 78T260 137Q263 149 265 151T282 153Q302 153 302 143Q302 135 293 112T268 61T223 11T161 -11Q129 -11 102 10T74 74Q74 91 79 106T122 220Q160 321 166 341T173 380Q173 404 156 404H154Q124 404 99 371T61 287Q60 286 59 284T58 281T56 279T53 278T49 278T41 278H27Q21 284 21 287Z"></path><path stroke-width="1" id="MJMAIN-29" d="M60 749L64 750Q69 750 74 750H86L114 726Q208 641 251 514T294 250Q294 182 284 119T261 12T224 -76T186 -143T145 -194T113 -227T90 -246Q87 -249 86 -250H74Q66 -250 63 -250T58 -247T55 -238Q56 -237 66 -225Q221 -64 221 250T66 725Q56 737 55 738Q55 746 60 749Z"></path><path stroke-width="1" id="MJMAIN-2208" d="M84 250Q84 372 166 450T360 539Q361 539 377 539T419 540T469 540H568Q583 532 583 520Q583 511 570 501L466 500Q355 499 329 494Q280 482 242 458T183 409T147 354T129 306T124 272V270H568Q583 262 583 250T568 230H124V228Q124 207 134 177T167 112T231 48T328 7Q355 1 466 0H570Q583 -10 583 -20Q583 -32 568 -40H471Q464 -40 446 -40T417 -41Q262 -41 172 45Q84 127 84 250Z"></path><path stroke-width="1" id="MJFRAK-52" d="M27 496Q31 569 102 627T234 685Q236 685 241 685T251 686Q287 686 318 672T367 638T399 598T418 564L423 550Q424 554 434 567T463 601T505 639T561 671T626 685Q672 685 688 659T710 572Q713 533 721 523T766 513Q781 513 787 514T794 516Q796 512 798 509T801 504T802 501T787 493Q702 461 624 401L607 389Q655 383 688 358L697 352V342Q699 330 699 297Q704 209 710 173T734 103Q751 69 765 69Q769 69 806 83L824 90V74Q823 73 759 24T693 -26Q692 -26 660 32L628 90L629 111Q631 159 631 177Q631 278 614 300Q584 340 523 340Q500 340 467 333T431 325Q429 325 429 322Q428 321 426 308T420 275T410 230T392 178T366 125L358 112L342 99Q306 70 269 38T213 -10T193 -26Q192 -26 163 0T116 26Q82 26 50 -8L42 -16L35 -8L27 0L35 10Q43 21 58 38T104 80T158 106Q179 106 218 65L235 48Q238 48 255 60T295 99T329 158Q352 231 352 359Q352 555 242 614Q210 628 187 628Q140 628 116 600T91 548Q91 522 138 464T185 382V376Q185 345 158 313T103 263L76 246Q74 244 64 253L54 260L65 267Q91 285 100 302Q111 318 111 337Q111 355 69 410T27 496ZM562 628Q504 628 443 507L435 491L436 479Q437 471 437 446Q437 396 432 351L529 389L602 426Q673 462 673 463H672Q644 470 637 483T622 553Q608 628 562 628Z"></path><path stroke-width="1" id="MJMATHI-6E" d="M21 287Q22 293 24 303T36 341T56 388T89 425T135 442Q171 442 195 424T225 390T231 369Q231 367 232 367L243 378Q304 442 382 442Q436 442 469 415T503 336T465 179T427 52Q427 26 444 26Q450 26 453 27Q482 32 505 65T540 145Q542 153 560 153Q580 153 580 145Q580 144 576 130Q568 101 554 73T508 17T439 -10Q392 -10 371 17T350 73Q350 92 386 193T423 345Q423 404 379 404H374Q288 404 229 303L222 291L189 157Q156 26 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 112 180T152 343Q153 348 153 366Q153 405 129 405Q91 405 66 305Q60 285 60 284Q58 278 41 278H27Q21 284 21 287Z"></path><path stroke-width="1" id="MJMAIN-2B" d="M56 237T56 250T70 270H369V420L370 570Q380 583 389 583Q402 583 409 568V270H707Q722 262 722 250T707 230H409V-68Q401 -82 391 -82H389H387Q375 -82 369 -68V230H70Q56 237 56 250Z"></path><path stroke-width="1" id="MJMAIN-31" d="M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z"></path><path stroke-width="1" id="MJMATHI-53" d="M308 24Q367 24 416 76T466 197Q466 260 414 284Q308 311 278 321T236 341Q176 383 176 462Q176 523 208 573T273 648Q302 673 343 688T407 704H418H425Q521 704 564 640Q565 640 577 653T603 682T623 704Q624 704 627 704T632 705Q645 705 645 698T617 577T585 459T569 456Q549 456 549 465Q549 471 550 475Q550 478 551 494T553 520Q553 554 544 579T526 616T501 641Q465 662 419 662Q362 662 313 616T263 510Q263 480 278 458T319 427Q323 425 389 408T456 390Q490 379 522 342T554 242Q554 216 546 186Q541 164 528 137T492 78T426 18T332 -20Q320 -22 298 -22Q199 -22 144 33L134 44L106 13Q83 -14 78 -18T65 -22Q52 -22 52 -14Q52 -11 110 221Q112 227 130 227H143Q149 221 149 216Q149 214 148 207T144 186T142 153Q144 114 160 87T203 47T255 29T308 24Z"></path><path stroke-width="1" id="MJMAIN-3D" d="M56 347Q56 360 70 367H707Q722 359 722 347Q722 336 708 328L390 327H72Q56 332 56 347ZM56 153Q56 168 72 173H708Q722 163 722 153Q722 140 707 133H70Q56 140 56 153Z"></path><path stroke-width="1" id="MJMAIN-7B" d="M434 -231Q434 -244 428 -250H410Q281 -250 230 -184Q225 -177 222 -172T217 -161T213 -148T211 -133T210 -111T209 -84T209 -47T209 0Q209 21 209 53Q208 142 204 153Q203 154 203 155Q189 191 153 211T82 231Q71 231 68 234T65 250T68 266T82 269Q116 269 152 289T203 345Q208 356 208 377T209 529V579Q209 634 215 656T244 698Q270 724 324 740Q361 748 377 749Q379 749 390 749T408 750H428Q434 744 434 732Q434 719 431 716Q429 713 415 713Q362 710 332 689T296 647Q291 634 291 499V417Q291 370 288 353T271 314Q240 271 184 255L170 250L184 245Q202 239 220 230T262 196T290 137Q291 131 291 1Q291 -134 296 -147Q306 -174 339 -192T415 -213Q429 -213 431 -216Q434 -219 434 -231Z"></path><path stroke-width="1" id="MJMAIN-2C" d="M78 35T78 60T94 103T137 121Q165 121 187 96T210 8Q210 -27 201 -60T180 -117T154 -158T130 -185T117 -194Q113 -194 104 -185T95 -172Q95 -168 106 -156T131 -126T157 -76T173 -3V9L172 8Q170 7 167 6T161 3T152 1T140 0Q113 0 96 17Z"></path><path stroke-width="1" id="MJMATHI-79" d="M21 287Q21 301 36 335T84 406T158 442Q199 442 224 419T250 355Q248 336 247 334Q247 331 231 288T198 191T182 105Q182 62 196 45T238 27Q261 27 281 38T312 61T339 94Q339 95 344 114T358 173T377 247Q415 397 419 404Q432 431 462 431Q475 431 483 424T494 412T496 403Q496 390 447 193T391 -23Q363 -106 294 -155T156 -205Q111 -205 77 -183T43 -117Q43 -95 50 -80T69 -58T89 -48T106 -45Q150 -45 150 -87Q150 -107 138 -122T115 -142T102 -147L99 -148Q101 -153 118 -160T152 -167H160Q177 -167 186 -165Q219 -156 247 -127T290 -65T313 -9T321 21L315 17Q309 13 296 6T270 -6Q250 -11 231 -11Q185 -11 150 11T104 82Q103 89 103 113Q103 170 138 262T173 379Q173 380 173 381Q173 390 173 393T169 400T158 404H154Q131 404 112 385T82 344T65 302T57 280Q55 278 41 278H27Q21 284 21 287Z"></path><path stroke-width="1" id="MJSZ1-28" d="M152 251Q152 646 388 850H416Q422 844 422 841Q422 837 403 816T357 753T302 649T255 482T236 250Q236 124 255 19T301 -147T356 -251T403 -315T422 -340Q422 -343 416 -349H388Q359 -325 332 -296T271 -213T212 -97T170 56T152 251Z"></path><path stroke-width="1" id="MJSZ1-29" d="M305 251Q305 -145 69 -349H56Q43 -349 39 -347T35 -338Q37 -333 60 -307T108 -239T160 -136T204 27T221 250T204 473T160 636T108 740T60 807T35 839Q35 850 50 850H56H69Q197 743 256 566Q305 425 305 251Z"></path><path stroke-width="1" id="MJMAIN-32" d="M109 429Q82 429 66 447T50 491Q50 562 103 614T235 666Q326 666 387 610T449 465Q449 422 429 383T381 315T301 241Q265 210 201 149L142 93L218 92Q375 92 385 97Q392 99 409 186V189H449V186Q448 183 436 95T421 3V0H50V19V31Q50 38 56 46T86 81Q115 113 136 137Q145 147 170 174T204 211T233 244T261 278T284 308T305 340T320 369T333 401T340 431T343 464Q343 527 309 573T212 619Q179 619 154 602T119 569T109 550Q109 549 114 549Q132 549 151 535T170 489Q170 464 154 447T109 429Z"></path><path stroke-width="1" id="MJMAIN-2026" d="M78 60Q78 84 95 102T138 120Q162 120 180 104T199 61Q199 36 182 18T139 0T96 17T78 60ZM525 60Q525 84 542 102T585 120Q609 120 627 104T646 61Q646 36 629 18T586 0T543 17T525 60ZM972 60Q972 84 989 102T1032 120Q1056 120 1074 104T1093 61Q1093 36 1076 18T1033 0T990 17T972 60Z"></path><path stroke-width="1" id="MJMATHI-6D" d="M21 287Q22 293 24 303T36 341T56 388T88 425T132 442T175 435T205 417T221 395T229 376L231 369Q231 367 232 367L243 378Q303 442 384 442Q401 442 415 440T441 433T460 423T475 411T485 398T493 385T497 373T500 364T502 357L510 367Q573 442 659 442Q713 442 746 415T780 336Q780 285 742 178T704 50Q705 36 709 31T724 26Q752 26 776 56T815 138Q818 149 821 151T837 153Q857 153 857 145Q857 144 853 130Q845 101 831 73T785 17T716 -10Q669 -10 648 17T627 73Q627 92 663 193T700 345Q700 404 656 404H651Q565 404 506 303L499 291L466 157Q433 26 428 16Q415 -11 385 -11Q372 -11 364 -4T353 8T350 18Q350 29 384 161L420 307Q423 322 423 345Q423 404 379 404H374Q288 404 229 303L222 291L189 157Q156 26 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 112 181Q151 335 151 342Q154 357 154 369Q154 405 129 405Q107 405 92 377T69 316T57 280Q55 278 41 278H27Q21 284 21 287Z"></path><path stroke-width="1" id="MJMAIN-7D" d="M65 731Q65 745 68 747T88 750Q171 750 216 725T279 670Q288 649 289 635T291 501Q292 362 293 357Q306 312 345 291T417 269Q428 269 431 266T434 250T431 234T417 231Q380 231 345 210T298 157Q293 143 292 121T291 -28V-79Q291 -134 285 -156T256 -198Q202 -250 89 -250Q71 -250 68 -247T65 -230Q65 -224 65 -223T66 -218T69 -214T77 -213Q91 -213 108 -210T146 -200T183 -177T207 -139Q208 -134 209 3L210 139Q223 196 280 230Q315 247 330 250Q305 257 280 270Q225 304 212 352L210 362L209 498Q208 635 207 640Q195 680 154 696T77 713Q68 713 67 716T65 731Z"></path><path stroke-width="1" id="MJSZ1-7B" d="M477 -343L471 -349H458Q432 -349 367 -325T273 -263Q258 -245 250 -212L249 -51Q249 -27 249 12Q248 118 244 128Q243 129 243 130Q220 189 121 228Q109 232 107 235T105 250Q105 256 105 257T105 261T107 265T111 268T118 272T128 276T142 283T162 291Q224 324 243 371Q243 372 244 373Q248 384 249 469Q249 475 249 489Q249 528 249 552L250 714Q253 728 256 736T271 761T299 789T347 816T422 843Q440 849 441 849H443Q445 849 447 849T452 850T457 850H471L477 844V830Q477 820 476 817T470 811T459 807T437 801T404 785Q353 760 338 724Q333 710 333 550Q333 526 333 492T334 447Q334 393 327 368T295 318Q257 280 181 255L169 251L184 245Q318 198 332 112Q333 106 333 -49Q333 -209 338 -223Q351 -255 391 -277T469 -309Q477 -311 477 -329V-343Z"></path><path stroke-width="1" id="MJSZ1-7D" d="M110 849L115 850Q120 850 125 850Q151 850 215 826T309 764Q324 747 332 714L333 552Q333 528 333 489Q334 383 338 373Q339 372 339 371Q353 336 391 310T469 271Q477 268 477 251Q477 241 476 237T472 232T456 225T428 214Q357 179 339 130Q339 129 338 128Q334 117 333 32Q333 26 333 12Q333 -27 333 -51L332 -212Q328 -228 323 -240T302 -271T255 -307T175 -338Q139 -349 125 -349T108 -346T105 -329Q105 -314 107 -312T130 -304Q233 -271 248 -209Q249 -203 249 -49V57Q249 106 253 125T273 167Q307 213 398 245L413 251L401 255Q265 300 250 389Q249 395 249 550Q249 710 244 724Q224 774 112 811Q105 813 105 830Q105 845 110 849Z"></path><path stroke-width="1" id="MJMATHI-68" d="M137 683Q138 683 209 688T282 694Q294 694 294 685Q294 674 258 534Q220 386 220 383Q220 381 227 388Q288 442 357 442Q411 442 444 415T478 336Q478 285 440 178T402 50Q403 36 407 31T422 26Q450 26 474 56T513 138Q516 149 519 151T535 153Q555 153 555 145Q555 144 551 130Q535 71 500 33Q466 -10 419 -10H414Q367 -10 346 17T325 74Q325 90 361 192T398 345Q398 404 354 404H349Q266 404 205 306L198 293L164 158Q132 28 127 16Q114 -11 83 -11Q69 -11 59 -2T48 16Q48 30 121 320L195 616Q195 629 188 632T149 637H128Q122 643 122 645T124 664Q129 683 137 683Z"></path><path stroke-width="1" id="MJMATHI-3B8" d="M35 200Q35 302 74 415T180 610T319 704Q320 704 327 704T339 705Q393 701 423 656Q462 596 462 495Q462 380 417 261T302 66T168 -10H161Q125 -10 99 10T60 63T41 130T35 200ZM383 566Q383 668 330 668Q294 668 260 623T204 521T170 421T157 371Q206 370 254 370L351 371Q352 372 359 404T375 484T383 566ZM113 132Q113 26 166 26Q181 26 198 36T239 74T287 161T335 307L340 324H145Q145 321 136 286T120 208T113 132Z"></path><path stroke-width="1" id="MJMAIN-5B" d="M118 -250V750H255V710H158V-210H255V-250H118Z"></path><path stroke-width="1" id="MJMATHI-70" d="M23 287Q24 290 25 295T30 317T40 348T55 381T75 411T101 433T134 442Q209 442 230 378L240 387Q302 442 358 442Q423 442 460 395T497 281Q497 173 421 82T249 -10Q227 -10 210 -4Q199 1 187 11T168 28L161 36Q160 35 139 -51T118 -138Q118 -144 126 -145T163 -148H188Q194 -155 194 -157T191 -175Q188 -187 185 -190T172 -194Q170 -194 161 -194T127 -193T65 -192Q-5 -192 -24 -194H-32Q-39 -187 -39 -183Q-37 -156 -26 -148H-6Q28 -147 33 -136Q36 -130 94 103T155 350Q156 355 156 364Q156 405 131 405Q109 405 94 377T71 316T59 280Q57 278 43 278H29Q23 284 23 287ZM178 102Q200 26 252 26Q282 26 310 49T356 107Q374 141 392 215T411 325V331Q411 405 350 405Q339 405 328 402T306 393T286 380T269 365T254 350T243 336T235 326L232 322Q232 321 229 308T218 264T204 212Q178 106 178 102Z"></path><path stroke-width="1" id="MJMAIN-7C" d="M139 -249H137Q125 -249 119 -235V251L120 737Q130 750 139 750Q152 750 159 735V-235Q151 -249 141 -249H139Z"></path><path stroke-width="1" id="MJMAIN-3B" d="M78 370Q78 394 95 412T138 430Q162 430 180 414T199 371Q199 346 182 328T139 310T96 327T78 370ZM78 60Q78 85 94 103T137 121Q202 121 202 8Q202 -44 183 -94T144 -169T118 -194Q115 -194 106 -186T95 -174Q94 -171 107 -155T137 -107T160 -38Q161 -32 162 -22T165 -4T165 4Q165 5 161 4T142 0Q110 0 94 18T78 60Z"></path><path stroke-width="1" id="MJMAIN-22EE" d="M78 30Q78 54 95 72T138 90Q162 90 180 74T199 31Q199 6 182 -12T139 -30T96 -13T78 30ZM78 440Q78 464 95 482T138 500Q162 500 180 484T199 441Q199 416 182 398T139 380T96 397T78 440ZM78 840Q78 864 95 882T138 900Q162 900 180 884T199 841Q199 816 182 798T139 780T96 797T78 840Z"></path><path stroke-width="1" id="MJMATHI-6B" d="M121 647Q121 657 125 670T137 683Q138 683 209 688T282 694Q294 694 294 686Q294 679 244 477Q194 279 194 272Q213 282 223 291Q247 309 292 354T362 415Q402 442 438 442Q468 442 485 423T503 369Q503 344 496 327T477 302T456 291T438 288Q418 288 406 299T394 328Q394 353 410 369T442 390L458 393Q446 405 434 405H430Q398 402 367 380T294 316T228 255Q230 254 243 252T267 246T293 238T320 224T342 206T359 180T365 147Q365 130 360 106T354 66Q354 26 381 26Q429 26 459 145Q461 153 479 153H483Q499 153 499 144Q499 139 496 130Q455 -11 378 -11Q333 -11 305 15T277 90Q277 108 280 121T283 145Q283 167 269 183T234 206T200 217T182 220H180Q168 178 159 139T145 81T136 44T129 20T122 7T111 -2Q98 -11 83 -11Q66 -11 57 -1T48 16Q48 26 85 176T158 471L195 616Q196 629 188 632T149 637H144Q134 637 131 637T124 640T121 647Z"></path><path stroke-width="1" id="MJMAIN-5D" d="M22 710V750H159V-250H22V-210H119V710H22Z"></path><path stroke-width="1" id="MJSZ4-23A1" d="M319 -645V1154H666V1070H403V-645H319Z"></path><path stroke-width="1" id="MJSZ4-23A3" d="M319 -644V1155H403V-560H666V-644H319Z"></path><path stroke-width="1" id="MJSZ4-23A2" d="M319 0V602H403V0H319Z"></path><path stroke-width="1" id="MJSZ4-23A4" d="M0 1070V1154H347V-645H263V1070H0Z"></path><path stroke-width="1" id="MJSZ4-23A6" d="M263 -560V1155H347V-644H0V-560H263Z"></path><path stroke-width="1" id="MJSZ4-23A5" d="M263 0V602H347V0H263Z"></path><path stroke-width="1" id="MJSZ1-2211" d="M61 748Q64 750 489 750H913L954 640Q965 609 976 579T993 533T999 516H979L959 517Q936 579 886 621T777 682Q724 700 655 705T436 710H319Q183 710 183 709Q186 706 348 484T511 259Q517 250 513 244L490 216Q466 188 420 134T330 27L149 -187Q149 -188 362 -188Q388 -188 436 -188T506 -189Q679 -189 778 -162T936 -43Q946 -27 959 6H999L913 -249L489 -250Q65 -250 62 -248Q56 -246 56 -239Q56 -234 118 -161Q186 -81 245 -11L428 206Q428 207 242 462L57 717L56 728Q56 744 61 748Z"></path><path stroke-width="1" id="MJMATHI-6A" d="M297 596Q297 627 318 644T361 661Q378 661 389 651T403 623Q403 595 384 576T340 557Q322 557 310 567T297 596ZM288 376Q288 405 262 405Q240 405 220 393T185 362T161 325T144 293L137 279Q135 278 121 278H107Q101 284 101 286T105 299Q126 348 164 391T252 441Q253 441 260 441T272 442Q296 441 316 432Q341 418 354 401T367 348V332L318 133Q267 -67 264 -75Q246 -125 194 -164T75 -204Q25 -204 7 -183T-12 -137Q-12 -110 7 -91T53 -71Q70 -71 82 -81T95 -112Q95 -148 63 -167Q69 -168 77 -168Q111 -168 139 -140T182 -74L193 -32Q204 11 219 72T251 197T278 308T289 365Q289 372 288 376Z"></path><path stroke-width="1" id="MJMATHI-65" d="M39 168Q39 225 58 272T107 350T174 402T244 433T307 442H310Q355 442 388 420T421 355Q421 265 310 237Q261 224 176 223Q139 223 138 221Q138 219 132 186T125 128Q125 81 146 54T209 26T302 45T394 111Q403 121 406 121Q410 121 419 112T429 98T420 82T390 55T344 24T281 -1T205 -11Q126 -11 83 42T39 168ZM373 353Q367 405 305 405Q272 405 244 391T199 357T170 316T154 280T149 261Q149 260 169 260Q282 260 327 284T373 353Z"></path><path stroke-width="1" id="MJMATHI-54" d="M40 437Q21 437 21 445Q21 450 37 501T71 602L88 651Q93 669 101 677H569H659Q691 677 697 676T704 667Q704 661 687 553T668 444Q668 437 649 437Q640 437 637 437T631 442L629 445Q629 451 635 490T641 551Q641 586 628 604T573 629Q568 630 515 631Q469 631 457 630T439 622Q438 621 368 343T298 60Q298 48 386 46Q418 46 427 45T436 36Q436 31 433 22Q429 4 424 1L422 0Q419 0 415 0Q410 0 363 1T228 2Q99 2 64 0H49Q43 6 43 9T45 27Q49 40 55 46H83H94Q174 46 189 55Q190 56 191 56Q196 59 201 76T241 233Q258 301 269 344Q339 619 339 625Q339 630 310 630H279Q212 630 191 624Q146 614 121 583T67 467Q60 445 57 441T43 437H40Z"></path><path stroke-width="1" id="MJMATHI-4A" d="M447 625Q447 637 354 637H329Q323 642 323 645T325 664Q329 677 335 683H352Q393 681 498 681Q541 681 568 681T605 682T619 682Q633 682 633 672Q633 670 630 658Q626 642 623 640T604 637Q552 637 545 623Q541 610 483 376Q420 128 419 127Q397 64 333 21T195 -22Q137 -22 97 8T57 88Q57 130 80 152T132 174Q177 174 182 130Q182 98 164 80T123 56Q115 54 115 53T122 44Q148 15 197 15Q235 15 271 47T324 130Q328 142 387 380T447 625Z"></path><path stroke-width="1" id="MJMAIN-2212" d="M84 237T84 250T98 270H679Q694 262 694 250T679 230H98Q84 237 84 250Z"></path><path stroke-width="1" id="MJMAIN-6C" d="M42 46H56Q95 46 103 60V68Q103 77 103 91T103 124T104 167T104 217T104 272T104 329Q104 366 104 407T104 482T104 542T103 586T103 603Q100 622 89 628T44 637H26V660Q26 683 28 683L38 684Q48 685 67 686T104 688Q121 689 141 690T171 693T182 694H185V379Q185 62 186 60Q190 52 198 49Q219 46 247 46H263V0H255L232 1Q209 2 183 2T145 3T107 3T57 1L34 0H26V46H42Z"></path><path stroke-width="1" id="MJMAIN-6E" d="M41 46H55Q94 46 102 60V68Q102 77 102 91T102 122T103 161T103 203Q103 234 103 269T102 328V351Q99 370 88 376T43 385H25V408Q25 431 27 431L37 432Q47 433 65 434T102 436Q119 437 138 438T167 441T178 442H181V402Q181 364 182 364T187 369T199 384T218 402T247 421T285 437Q305 442 336 442Q450 438 463 329Q464 322 464 190V104Q464 66 466 59T477 49Q498 46 526 46H542V0H534L510 1Q487 2 460 2T422 3Q319 3 310 0H302V46H318Q379 46 379 62Q380 64 380 200Q379 335 378 343Q372 371 358 385T334 402T308 404Q263 404 229 370Q202 343 195 315T187 232V168V108Q187 78 188 68T191 55T200 49Q221 46 249 46H265V0H257L234 1Q210 2 183 2T145 3Q42 3 33 0H25V46H41Z"></path><path stroke-width="1" id="MJMATHI-6C" d="M117 59Q117 26 142 26Q179 26 205 131Q211 151 215 152Q217 153 225 153H229Q238 153 241 153T246 151T248 144Q247 138 245 128T234 90T214 43T183 6T137 -11Q101 -11 70 11T38 85Q38 97 39 102L104 360Q167 615 167 623Q167 626 166 628T162 632T157 634T149 635T141 636T132 637T122 637Q112 637 109 637T101 638T95 641T94 647Q94 649 96 661Q101 680 107 682T179 688Q194 689 213 690T243 693T254 694Q266 694 266 686Q266 675 193 386T118 83Q118 81 118 75T117 65V59Z"></path><path stroke-width="1" id="MJSZ3-5B" d="M247 -949V1450H516V1388H309V-887H516V-949H247Z"></path><path stroke-width="1" id="MJSZ3-5D" d="M11 1388V1450H280V-949H11V-887H218V1388H11Z"></path></defs></svg></div><div id="MathJax_Message" style="display: none;"></div>
      <script type="text/javascript">
        window.__PRELOADED_STATE__ = {"abstracts":{"content":[{"$$":[{"$":{"id":"sctt0001"},"#name":"section-title","_":"Abstract"},{"$$":[{"$":{"view":"all","id":"sp0003"},"#name":"simple-para","_":"Facial expression recognition (FER) in the wild is a novel and challenging topic in the field of human emotion perception. Different kinds of convolutional neural network (CNN) approaches have been applied to this topic, but few of them ever considered what kind of architecture was better for the FER research. In this paper, we proposed three novel CNN models with different architectures. The first one is a shallow network, named the Light-CNN, which is a fully convolutional neural network consisting of six depthwise separable residual convolution modules to solve the problem of complex topology and over-fitting. The second one is a dual-branch CNN which extracts traditional LBP features and deep learning features in parallel. The third one is a pre-trained CNN which is designed by transfer learning technique to overcome the shortage of training samples. Extensive evaluations on three popular datasets (public CK+, multi-view BU-3DEF and FER2013 datasets) demonstrated that our models were competitive and representative in the field of FER in the wild research. We achieved significant better results with comparisons to plenty of state-of-the-art approaches. Moreover, we provided discussions on the effectiveness and practicability of CNNs with different feature types and architectures for FER in the wild as well."}],"$":{"view":"all","id":"abssec0001"},"#name":"abstract-sec"}],"$":{"view":"all","id":"abs0001","class":"author"},"#name":"abstract"}],"floats":[],"footnotes":[],"attachments":[]},"accessbarConfig":{"fallback":false,"id":"accessbar","version":"0.0.1","analytics":{"location":"accessbar","eventName":"ctaImpression"},"label":{},"ariaLabel":{"accessbar":"Download options and search","componentsList":"PDF Options"},"banner":{"id":"Banner"},"banners":[{"id":"Banner"},{"id":"BannerSsrn"}],"components":[{"target":"_blank","analytics":[{"ids":["accessbar:fta:single-article"],"eventName":"ctaClick"}],"label":"View&nbsp;**PDF**","ariaLabel":"View PDF. Opens in a new window.","id":"ViewPDF"},{"analytics":[{"ids":["accessbar:fta:full-issue"],"eventName":"ctaClick"}],"label":"Download full issue","id":"DownloadFullIssue"}],"search":{"inputPlaceHolder":"Search ScienceDirect","ariaLabel":{"input":"Search ScienceDirect","submit":"Submit search"},"formAction":"/search#submit","analytics":[{"ids":["accessbar:search"],"eventName":"searchStart"}],"id":"QuickSearch"}},"adobeTarget":{"sd:genai-question-and-answer":{}},"article":{"analyticsMetadata":{"accountId":"50401","accountName":"IT University of Copenhagen","loginStatus":"logged in","userId":"71970787","isLoggedIn":true},"cid":"271597","content-family":"serial","copyright-line":"Â© 2019 Elsevier B.V. All rights reserved.","cover-date-years":["2019"],"cover-date-start":"2019-08-25","cover-date-text":"25 August 2019","document-subtype":"fla","document-type":"article","entitledToken":"74BDD4BB1A08DFD05CEF466E8E3908C7AB7D508DF7A5E5FBAED8307FF69154B7E4531864F7B9770D","genAiToken":"eyJ0eXAiOiJKV1QiLCJhbGciOiJIUzI1NiJ9.eyJhdWQiOiJnZW5BaUFwcHMiLCJzdWIiOiI1MDQwMSIsInBpaSI6IlMwOTI1MjMxMjE5MzA2MTM3IiwiaXNzIjoiYXJwIiwic2Vzc2lvbklkIjoiNWUwYThhMzI3ZjI3YTA0OGE4NWIyM2E2YTM3MTU2NmQ2OThkZ3hycWEiLCJleHAiOjE3MzAyMDU3MzksImlhdCI6MTczMDIwMzkzOSwidmVyc2lvbiI6MSwianRpIjoiN2U1YTU1ZTktNzhhOS00MjRkLWE0YzUtYTk2M2UzM2UzM2U1In0.xO4sB6bFm0Llrv0-TmPgYQWixtdewDjoTWvl5dZAC78","eid":"1-s2.0-S0925231219306137","doi":"10.1016/j.neucom.2019.05.005","first-fp":"82","hub-eid":"1-s2.0-S0925231219X00259","issuePii":"S0925231219X00259","item-weight":"FULL-TEXT","language":"en","last-lp":"92","last-author":{"#name":"last-author","$":{"xmlns:ce":true,"xmlns:dm":true,"xmlns:sb":true},"$$":[{"#name":"author","$":{"id":"au0002","biographyid":"b2","author-id":"S0925231219306137-a0a51422a17d5c5cc1584d073482c7f0"},"$$":[{"#name":"given-name","_":"Yongsheng"},{"#name":"surname","_":"Qian"},{"#name":"cross-ref","$":{"id":"crf0026","refid":"cor0001"},"$$":[{"#name":"sup","$":{"loc":"post"},"_":"âŽ"}]},{"#name":"encoded-e-address","__encoded":"JTdCJTIyJTIzbmFtZSUyMiUzQSUyMmUtYWRkcmVzcyUyMiUyQyUyMiUyNCUyMiUzQSU3QiUyMnhtbG5zJTNBeGxpbmslMjIlM0F0cnVlJTJDJTIydHlwZSUyMiUzQSUyMmVtYWlsJTIyJTJDJTIyaHJlZiUyMiUzQSUyMm1haWx0byUzQXFpYW5feW9uZ3NoZW5nJTQwMTI2LmNvbSUyMiUyQyUyMmlkJTIyJTNBJTIyZWFkMDAwMSUyMiU3RCUyQyUyMl8lMjIlM0ElMjJxaWFuX3lvbmdzaGVuZyU0MDEyNi5jb20lMjIlN0Q="}]}]},"normalized-first-auth-initial":"J","normalized-first-auth-surname":"SHAO","open-research":{"#name":"open-research","$":{"xmlns:xocs":true},"$$":[{"#name":"or-embargo-opening-date","_":"2021-05-22T00:00:00.000Z"}]},"pages":[{"last-page":"92","first-page":"82"}],"pii":"S0925231219306137","self-archiving":{"#name":"self-archiving","$":{"xmlns:xocs":true},"$$":[{"#name":"sa-user-license","_":"http://creativecommons.org/licenses/by-nc-nd/4.0/"},{"#name":"sa-start-date","_":"2021-05-22T00:00:00.000Z"}]},"srctitle":"Neurocomputing","suppl":"C","timestamp":"2020-02-01T07:05:24.810475Z","title":{"content":[{"#name":"title","$":{"id":"ct0001"},"_":"Three convolutional neural network models for facial expression recognition in the wild"}],"floats":[],"footnotes":[],"attachments":[]},"vol-first":"355","vol-iss-suppl-text":"Volume 355","userSettings":{"forceAbstract":false,"creditCardPurchaseAllowed":true,"blockFullTextForAnonymousAccess":false,"disableWholeIssueDownload":false,"preventTransactionalAccess":false,"preventDocumentDelivery":true},"contentType":"JL","crossmark":true,"document-references":64,"freeHtmlGiven":false,"userProfile":{"departmentName":"Library","webUserId":"71970787","accountName":"IT University of Copenhagen","shibProfile":{"canRegister":false},"departmentId":"71310","hasMultipleOrganizations":false,"accountNumber":"C000050401","userName":"Gergo Gyori","supportUserData":"xyhJEXWoHAMsz8VQOu3h2LHHIekBL3hT38urfpOCxeAty3TF61ibE7vsQPaZh4C6srqm9MNOxus2v65ykDkikA4MoWWax9xsxmy7qS6Jhq1MDk8fC~ZGE1crT~IU0fB88KgH29YS658ka3vhWTqW3QsF38M7JrWC3EPvnlMgTGg39gl1xRqh4DNloSU9hGNUBWmK_Teu~5LuRZ6Al86jUzFxO7CiLa3WIvaVAP5f3g900Gfh5TZfq33GuKqA9hfimBRbW0fFzY3a21RwOu4PLn_qOj_4DdmDZC5TLAXDZVY*","accessType":"SHIBREG","accountId":"50401","userType":"NORMAL","privilegeType":"BASIC","email":"gegy@itu.dk"},"access":{"openAccess":false,"openArchive":false},"aipType":"none","articleEntitlement":{"authenticationMethod":"SHIBBOLETH","entitled":true,"isCasaUser":false,"usageInfo":"(71970787,U|71310,D|50401,A|26,S|34,P|2,PL)(SDFE,CON|5e0a8a327f27a048a85b23a6a371566d698dgxrqa,SSO|REG_SHIBBOLETH,ACCESS_TYPE)","entitledByAccount":false},"crawlerInformation":{"canCrawlPDFContent":false,"isCrawler":false},"dates":{"Available online":"10 May 2019","Received":"9 August 2018","Revised":["9 December 2018"],"Accepted":"6 May 2019","Publication date":"25 August 2019","Version of Record":"22 May 2019"},"downloadFullIssue":true,"entitlementReason":"package","hasBody":true,"has-large-authors":false,"hasScholarlyAbstract":true,"headerConfig":{"helpUrl":"https://service.elsevier.com/ci/pta/login/redirect/home/supporthub/sciencedirect/p_li/xyhJEXWoHAMsz8VQOu3h2LHHIekBL3hT38urfpOCxeAty3TF61ibE7vsQPaZh4C6srqm9MNOxus2v65ykDkikA4MoWWax9xsxmy7qS6Jhq1MDk8fC~ZGE1crT~IU0fB88KgH29YS658ka3vhWTqW3QsF38M7JrWC3EPvnlMgTGg39gl1xRqh4DNloSU9hGNUBWmK_Teu~5LuRZ6Al86jUzFxO7CiLa3WIvaVAP5f3g900Gfh5TZfq33GuKqA9hfimBRbW0fFzY3a21RwOu4PLn_qOj_4DdmDZC5TLAXDZVY*","contactUrl":"https://service.elsevier.com/ci/pta/login/redirect/contact/supporthub/sciencedirect/p_li/xyhJEXWoHAMsz8VQOu3h2LHHIekBL3hT38urfpOCxeAty3TF61ibE7vsQPaZh4C6srqm9MNOxus2v65ykDkikA4MoWWax9xsxmy7qS6Jhq1MDk8fC~ZGE1crT~IU0fB88KgH29YS658ka3vhWTqW3QsF38M7JrWC3EPvnlMgTGg39gl1xRqh4DNloSU9hGNUBWmK_Teu~5LuRZ6Al86jUzFxO7CiLa3WIvaVAP5f3g900Gfh5TZfq33GuKqA9hfimBRbW0fFzY3a21RwOu4PLn_qOj_4DdmDZC5TLAXDZVY*","userName":"Gergo Gyori","userEmail":"gegy@itu.dk","orgName":"IT University of Copenhagen","webUserId":"71970787","libraryBanner":null,"shib_regUrl":"","tick_regUrl":"","recentInstitutions":[],"canActivatePersonalization":false,"hasInstitutionalAssociation":true,"hasMultiOrg":false,"userType":"SHIBREG","userAnonymity":"INDIVIDUAL","allowCart":true,"environment":"prod","cdnAssetsHost":"https://sdfestaticassets-eu-west-1.sciencedirectassets.com","supportUserData":"xyhJEXWoHAMsz8VQOu3h2LHHIekBL3hT38urfpOCxeAty3TF61ibE7vsQPaZh4C6srqm9MNOxus2v65ykDkikA4MoWWax9xsxmy7qS6Jhq1MDk8fC~ZGE1crT~IU0fB88KgH29YS658ka3vhWTqW3QsF38M7JrWC3EPvnlMgTGg39gl1xRqh4DNloSU9hGNUBWmK_Teu~5LuRZ6Al86jUzFxO7CiLa3WIvaVAP5f3g900Gfh5TZfq33GuKqA9hfimBRbW0fFzY3a21RwOu4PLn_qOj_4DdmDZC5TLAXDZVY*","institutionName":"your institution"},"isCorpReq":false,"isPdfFullText":false,"issn":"09252312","issn-primary-formatted":"0925-2312","issRange":"","isThirdParty":false,"pageCount":11,"pdfDownload":{"isPdfFullText":false,"urlMetadata":{"queryParams":{"md5":"b31bdcbb1e65c9378c37c8bc3bd861d0","pid":"1-s2.0-S0925231219306137-main.pdf"},"pii":"S0925231219306137","pdfExtension":"/pdfft","path":"science/article/pii"}},"publication-content":{"noElsevierLogo":false,"imprintPublisher":{"displayName":"Elsevier","id":"47"},"isSpecialIssue":false,"isSampleIssue":false,"transactionsBlocked":false,"publicationOpenAccess":{"oaStatus":"","oaArticleCount":541,"openArchiveStatus":false,"openArchiveArticleCount":18,"openAccessStartDate":"","oaAllowsAuthorPaid":true},"issue-cover":{"attachment":[{"attachment-eid":"1-s2.0-S0925231219X00259-cov200h.gif","file-basename":"cov200h","extension":"gif","filename":"cov200h.gif","ucs-locator":["https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0925231219X00259/cover/DOWNSAMPLED200/image/gif/b71700c62d01ffe535db0a1f97206349/cov200h.gif"],"attachment-type":"IMAGE-COVER-H200","filesize":"7469","pixel-height":"200","pixel-width":"150"},{"attachment-eid":"1-s2.0-S0925231219X00259-cov150h.gif","file-basename":"cov150h","extension":"gif","filename":"cov150h.gif","ucs-locator":["https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0925231219X00259/cover/DOWNSAMPLED/image/gif/5f01117da12a0ef6f9853391d2ab5db7/cov150h.gif"],"attachment-type":"IMAGE-COVER-H150","filesize":"6075","pixel-height":"150","pixel-width":"113"}]},"smallCoverUrl":"https://ars.els-cdn.com/content/image/S09252312.gif","title":"neurocomputing","contentTypeCode":"JL","images":{"coverImage":"https://ars.els-cdn.com/content/image/1-s2.0-S0925231219X00259-cov150h.gif","logo":"https://sdfestaticassets-eu-west-1.sciencedirectassets.com/prod/562c52f0a29e84041e12a6c3286c1d8a5b89ba0b/image/elsevier-non-solus.png","logoAltText":"Elsevier"},"publicationCoverImageUrl":"https://ars.els-cdn.com/content/image/1-s2.0-S0925231219X00259-cov150h.gif"},"volRange":"355","features":["aamAttachments","keywords","references","biography","preview"],"titleString":"Three convolutional neural network models for facial expression recognition in the wild","ssrn":{},"renderingMode":"Article","isAbstract":false,"isContentVisible":false,"ajaxLinks":{"referenceLinks":true,"references":true,"referredToBy":true,"recommendations-entitled":true,"toc":true,"body":true,"recommendations":true,"citingArticles":true,"authorMetadata":true},"pdfEmbed":false,"displayViewFullText":false},"authors":{"content":[{"#name":"author-group","$":{"id":"aut0001"},"$$":[{"#name":"author","$":{"id":"au0001","biographyid":"b1","author-id":"S0925231219306137-6a0fa93aa7ebbbb7cd0fb7227e64bc60"},"$$":[{"#name":"given-name","_":"Jie"},{"#name":"surname","_":"Shao"}]},{"#name":"author","$":{"id":"au0002","biographyid":"b2","author-id":"S0925231219306137-a0a51422a17d5c5cc1584d073482c7f0"},"$$":[{"#name":"given-name","_":"Yongsheng"},{"#name":"surname","_":"Qian"},{"#name":"cross-ref","$":{"id":"crf0026","refid":"cor0001"},"$$":[{"#name":"sup","$":{"loc":"post"},"_":"âŽ"}]},{"#name":"encoded-e-address","__encoded":"JTdCJTIyJTIzbmFtZSUyMiUzQSUyMmUtYWRkcmVzcyUyMiUyQyUyMiUyNCUyMiUzQSU3QiUyMnhtbG5zJTNBeGxpbmslMjIlM0F0cnVlJTJDJTIydHlwZSUyMiUzQSUyMmVtYWlsJTIyJTJDJTIyaHJlZiUyMiUzQSUyMm1haWx0byUzQXFpYW5feW9uZ3NoZW5nJTQwMTI2LmNvbSUyMiUyQyUyMmlkJTIyJTNBJTIyZWFkMDAwMSUyMiU3RCUyQyUyMl8lMjIlM0ElMjJxaWFuX3lvbmdzaGVuZyU0MDEyNi5jb20lMjIlN0Q="}]},{"#name":"affiliation","$":{"id":"aff0001","affiliation-id":"S0925231219306137-8a265e0932b45ea48f1c73b0195392c8"},"$$":[{"#name":"textfn","$":{"id":"textfn0001"},"_":"College of Electronic and Information Engineering, Shanghai University of Electric Power, China"},{"#name":"affiliation","$":{"xmlns:sa":true},"$$":[{"#name":"organization","_":"College of Electronic and Information Engineering"},{"#name":"organization","_":"Shanghai University of Electric Power"},{"#name":"country","_":"China"}]},{"#name":"source-text","$":{"id":"st0001"},"_":"College of Electronic and Information Engineering, Shanghai University of Electric Power, China"}]},{"#name":"correspondence","$":{"id":"cor0001"},"$$":[{"#name":"label","_":"âŽ"},{"#name":"text","$":{"id":"cor1"},"_":"Corresponding author."}]}]}],"floats":[],"footnotes":[],"affiliations":{"aff0001":{"#name":"affiliation","$":{"id":"aff0001","affiliation-id":"S0925231219306137-8a265e0932b45ea48f1c73b0195392c8"},"$$":[{"#name":"textfn","$":{"id":"textfn0001"},"_":"College of Electronic and Information Engineering, Shanghai University of Electric Power, China"},{"#name":"affiliation","$":{"xmlns:sa":true},"$$":[{"#name":"organization","_":"College of Electronic and Information Engineering"},{"#name":"organization","_":"Shanghai University of Electric Power"},{"#name":"country","_":"China"}]},{"#name":"source-text","$":{"id":"st0001"},"_":"College of Electronic and Information Engineering, Shanghai University of Electric Power, China"}]}},"correspondences":{"cor0001":{"#name":"correspondence","$":{"id":"cor0001"},"$$":[{"#name":"label","_":"âŽ"},{"#name":"text","$":{"id":"cor1"},"_":"Corresponding author."}]}},"attachments":[],"scopusAuthorIds":{},"articles":{}},"authorMetadata":[],"banner":{"expanded":false},"biographies":{"content":[{"#name":"biography","$":{"xmlns:ce":true,"xmlns:aep":true,"xmlns:mml":true,"xmlns:xs":true,"xmlns:xlink":true,"xmlns:xocs":true,"xmlns:tb":true,"xmlns:xsi":true,"xmlns:cals":true,"xmlns:sb":true,"xmlns:sa":true,"xmlns:ja":true,"xmlns":true,"id":"b1","view":"all"},"$$":[{"#name":"link","$":{"id":"celink0009","locator":"fx1","type":"simple","role":"http://data.elsevier.com/vocabulary/ElsevierContentTypes/23.4","href":"pii:S0925231219306137/fx1"}},{"#name":"simple-para","$":{"id":"sp0001","view":"all"},"$$":[{"#name":"bold","_":"Jie Shao"},{"#name":"__text__","_":" received the B.S. and M.S. degree in Nanjing University of Aeronauticsand Astronautics. Thenshe got her Ph.D. in Tongji University. At present, she is an associate professor in Shanghai University of Electric Power. Her currentresearch interest includes computer vision, video surveillance, and human emotion analysis."}]}]},{"#name":"biography","$":{"xmlns:ce":true,"xmlns:aep":true,"xmlns:mml":true,"xmlns:xs":true,"xmlns:xlink":true,"xmlns:xocs":true,"xmlns:tb":true,"xmlns:xsi":true,"xmlns:cals":true,"xmlns:sb":true,"xmlns:sa":true,"xmlns:ja":true,"xmlns":true,"id":"b2","view":"all"},"$$":[{"#name":"link","$":{"id":"celink0010","locator":"fx2","type":"simple","role":"http://data.elsevier.com/vocabulary/ElsevierContentTypes/23.4","href":"pii:S0925231219306137/fx2"}},{"#name":"simple-para","$":{"id":"sp0002","view":"all"},"$$":[{"#name":"bold","_":"Yongsheng Qian"},{"#name":"__text__","_":" received his bachelorâ€™s degree in electrical engineering and automation from Hubei University for Nationalities in 2015. He is currently a graduate student in the department of electronics and information engineering in Shanghai University of Electric Power, Shanghai, China. His research interest includes facial expression recognition and deep learning."}]}]}],"floats":[],"footnotes":[],"attachments":[{"attachment-eid":"1-s2.0-S0925231219306137-fx1.sml","ucs-locator":"https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0925231219306137/fx1/THUMBNAIL/image/gif/ffc978b044d7d9ffe379e296a81616fb/fx1.sml","file-basename":"fx1","filename":"fx1.sml","extension":"sml","filesize":"17568","pixel-height":"164","pixel-width":"123","attachment-type":"IMAGE-THUMBNAIL"},{"attachment-eid":"1-s2.0-S0925231219306137-fx2.sml","ucs-locator":"https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0925231219306137/fx2/THUMBNAIL/image/gif/09cb5af4befff1e9c76a9427fc055e17/fx2.sml","file-basename":"fx2","filename":"fx2.sml","extension":"sml","filesize":"18890","pixel-height":"164","pixel-width":"123","attachment-type":"IMAGE-THUMBNAIL"},{"attachment-eid":"1-s2.0-S0925231219306137-fx1.jpg","ucs-locator":"https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0925231219306137/fx1/DOWNSAMPLED/image/jpeg/c085fd6ecd317171bba2d28c106e0d33/fx1.jpg","file-basename":"fx1","filename":"fx1.jpg","extension":"jpg","filesize":"9024","pixel-height":"150","pixel-width":"113","attachment-type":"IMAGE-DOWNSAMPLED"},{"attachment-eid":"1-s2.0-S0925231219306137-fx2.jpg","ucs-locator":"https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0925231219306137/fx2/DOWNSAMPLED/image/jpeg/9107945a7eabac62b213a0a774af8c0b/fx2.jpg","file-basename":"fx2","filename":"fx2.jpg","extension":"jpg","filesize":"8957","pixel-height":"151","pixel-width":"113","attachment-type":"IMAGE-DOWNSAMPLED"},{"attachment-eid":"1-s2.0-S0925231219306137-fx1_lrg.jpg","ucs-locator":"https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0925231219306137/fx1/HIGHRES/image/jpeg/167153fb1dcf3544ac0ba2f144447794/fx1_lrg.jpg","file-basename":"fx1","filename":"fx1_lrg.jpg","extension":"jpg","filesize":"53357","pixel-height":"667","pixel-width":"501","attachment-type":"IMAGE-HIGH-RES"},{"attachment-eid":"1-s2.0-S0925231219306137-fx2_lrg.jpg","ucs-locator":"https://s3.amazonaws.com/prod-ucs-content-store-us-east/content/pii:S0925231219306137/fx2/HIGHRES/image/jpeg/f8b11b0ca76aeadb6f2a9809d112bb17/fx2_lrg.jpg","file-basename":"fx2","filename":"fx2_lrg.jpg","extension":"jpg","filesize":"55078","pixel-height":"667","pixel-width":"500","attachment-type":"IMAGE-HIGH-RES"}]},"body":{},"chapters":{"toc":[],"isLoading":false},"changeViewLinks":{"showFullTextLink":false,"showAbstractLink":true},"citingArticles":{},"combinedContentItems":{"content":[{"#name":"keywords","$$":[{"#name":"keywords","$":{"xmlns:ce":true,"xmlns:aep":true,"xmlns:xoe":true,"xmlns:mml":true,"xmlns:xs":true,"xmlns:xlink":true,"xmlns:xocs":true,"xmlns:tb":true,"xmlns:xsi":true,"xmlns:cals":true,"xmlns:sb":true,"xmlns:sa":true,"xmlns:ja":true,"xmlns":true,"id":"keys0001","class":"keyword","view":"all"},"$$":[{"#name":"section-title","$":{"id":"sctt0002"},"_":"Keywords"},{"#name":"keyword","$":{"id":"key0002"},"$$":[{"#name":"text","$":{"id":"txt0001"},"_":"FER in the wild"}]},{"#name":"keyword","$":{"id":"key0003"},"$$":[{"#name":"text","$":{"id":"txt0002"},"_":"Convolutional neural network"}]},{"#name":"keyword","$":{"id":"key0004"},"$$":[{"#name":"text","$":{"id":"txt0003"},"_":"Shallow network"}]},{"#name":"keyword","$":{"id":"key0005"},"$$":[{"#name":"text","$":{"id":"txt0004"},"_":"Dual-branch CNN"}]},{"#name":"keyword","$":{"id":"key0006"},"$$":[{"#name":"text","$":{"id":"txt0005"},"_":"Pretrained CNN"}]}]}]},{"#name":"miscellaneous","$":{"xmlns:ce":true,"xmlns:aep":true,"xmlns:xoe":true,"xmlns:mml":true,"xmlns:xs":true,"xmlns:xlink":true,"xmlns:xocs":true,"xmlns:tb":true,"xmlns:xsi":true,"xmlns:cals":true,"xmlns:sb":true,"xmlns:sa":true,"xmlns:ja":true,"xmlns":true,"id":"m0001"},"_":"Communicated by Rongni Yang"}],"floats":[],"footnotes":[],"attachments":[]},"crossMark":{"isOpen":false},"domainConfig":{"cdnAssetsHost":"https://sdfestaticassets-eu-west-1.sciencedirectassets.com","assetRoute":"https://sdfestaticassets-eu-west-1.sciencedirectassets.com/prod/562c52f0a29e84041e12a6c3286c1d8a5b89ba0b"},"downloadIssue":{"openOnPageLoad":false,"isOpen":false,"downloadCapOpen":false,"articles":[],"selected":[]},"enrichedContent":{"tableOfContents":false,"researchData":{"hasResearchData":false,"dataProfile":{},"openData":{},"mendeleyData":{},"databaseLinking":{}},"geospatialData":{"attachments":[]},"interactiveCaseInsights":{},"virtualMicroscope":{}},"entitledRecommendations":{"openOnPageLoad":false,"isOpen":false,"articles":[],"selected":[],"currentPage":1,"totalPages":1},"exam":{},"helpText":{"keyDates":{"html":"<div class=\"key-dates-help\"><h3 class=\"u-margin-s-bottom u-h4\">Publication milestones</h3><p class=\"u-margin-m-bottom\">The dates displayed for an article provide information on when various publication milestones were reached at the journal that has published the article. Where applicable, activities on preceding journals at which the article was previously under consideration are not shown (for instance submission, revisions, rejection).</p><p class=\"u-margin-xs-bottom\">The publication milestones include:</p><ul class=\"key-dates-help-list u-margin-m-bottom u-padding-s-left\"><li><span class=\"u-text-italic\">Received</span>: The date the article was originally submitted to the journal.</li><li><span class=\"u-text-italic\">Revised</span>: The date the most recent revision of the article was submitted to the journal. Dates corresponding to intermediate revisions are not shown.</li><li><span class=\"u-text-italic\">Accepted</span>: The date the article was accepted for publication in the journal.</li><li><span class=\"u-text-italic\">Available online</span>: The date a version of the article was made available online in the journal.</li><li><span class=\"u-text-italic\">Version of Record</span>: The date the finalized version of the article was made available in the journal.</li></ul><p>More information on publishing policies can be found on the <a class=\"anchor anchor-secondary u-display-inline anchor-underline\" href=\"https://www.elsevier.com/about/policies-and-standards/publishing-ethics\" target=\"_blank\"><span class=\"anchor-text-container\"><span class=\"anchor-text\">Publishing Ethics Policies</span></span></a> page. View our <a class=\"anchor anchor-secondary u-display-inline anchor-underline\" href=\"https://www.elsevier.com/researcher/author/submit-your-paper\" target=\"_blank\"><span class=\"anchor-text-container\"><span class=\"anchor-text\">Publishing with Elsevier: step-by-step</span></span></a> page to learn more about the publishing process. For any questions on your own submission or other questions related to publishing an article, <a class=\"anchor anchor-secondary u-display-inline anchor-underline\" href=\"https://service.elsevier.com/app/phone/supporthub/publishing\" target=\"_blank\"><span class=\"anchor-text-container\"><span class=\"anchor-text\">contact our Researcher support team.</span></span></a></p></div>","title":"What do these dates mean?"}},"glossary":{},"issueNavigation":{"previous":{},"next":{}},"linkingHubLinks":{},"metrics":{"isOpen":true},"preview":{},"rawtext":"","recommendations":{},"references":{},"referenceLinks":{"internal":[],"internalLoaded":false,"external":[]},"refersTo":{},"referredToBy":{},"relatedContent":{"isModal":false,"isOpenSpecialIssueArticles":false,"isOpenVirtualSpecialIssueLink":false,"isOpenRecommendations":true,"isOpenSubstances":true,"citingArticles":[false,false,false,false,false,false],"recommendations":[false,false,false,false,false,false]},"seamlessAccess":{},"specialIssueArticles":{},"substances":{},"supplementaryFilesData":[],"tableOfContents":{"showEntitledTocLinks":true},"tail":{},"transientError":{"isOpen":false},"sidePanel":{"openState":1},"viewConfig":{"articleFeature":{"rightsAndContentLink":true,"sdAnswersButton":false},"pathPrefix":""},"virtualSpecialIssue":{"showVirtualSpecialIssueLink":false},"userCookiePreferences":{"STRICTLY_NECESSARY":true,"PERFORMANCE":true,"FUNCTIONAL":true,"TARGETING":true}};
      </script>
      <noscript>
      JavaScript is disabled on your browser.
      Please enable JavaScript to use all the features on this page.
      <img src=https://smetrics.elsevier.com/b/ss/elsevier-sd-prod/1/G.4--NS/1730203940018?pageName=sd%3Aproduct%3Ajournal%3Aarticle&c16=els%3Arp%3Ast&c2=sd&v185=img&v33=ae%3AREG_SHIBBOLETH&c1=ae%3A50401&c12=ae%3A71970787 />
    </noscript>
      <a class="anchor sr-only sr-only-focusable u-display-inline anchor-primary" href="#screen-reader-main-content"><span class="anchor-text-container"><span class="anchor-text">Skip to main content</span></span></a><a class="anchor sr-only sr-only-focusable u-display-inline anchor-primary" href="#screen-reader-main-title"><span class="anchor-text-container"><span class="anchor-text">Skip to article</span></span></a>
      <div id="root"><div class="App" id="app" data-aa-name="root"><div class="page"><div class="sd-flex-container"><div class="sd-flex-content"><header id="gh-cnt"><div id="gh-main-cnt" class="u-flex-center-ver u-position-relative u-padding-s-hor u-padding-l-hor-from-xl"><a id="gh-branding" class="u-flex-center-ver" href="/" aria-label="ScienceDirect home page" data-aa-region="header" data-aa-name="ScienceDirect"><img class="gh-logo" src="https://sdfestaticassets-eu-west-1.sciencedirectassets.com/shared-assets/24/images/elsevier-non-solus-new-grey.svg" alt="Elsevier logo" height="48" width="54"><svg xmlns="http://www.w3.org/2000/svg" version="1.1" height="15" viewBox="0 0 190 23" role="img" class="gh-wordmark u-margin-s-left" aria-labelledby="gh-wm-science-direct" focusable="false" aria-hidden="true" alt="ScienceDirect Wordmark"><title id="gh-wm-science-direct">ScienceDirect</title><g><path fill="#EB6500" d="M3.81 6.9c0-1.48 0.86-3.04 3.7-3.04 1.42 0 3.1 0.43 4.65 1.32l0.13-2.64c-1.42-0.63-2.97-0.96-4.78-0.96 -4.62 0-6.6 2.44-6.6 5.45 0 5.61 8.78 6.14 8.78 9.93 0 1.48-1.15 3.04-3.86 3.04 -1.72 0-3.4-0.56-4.72-1.39l-0.36 2.64c1.55 0.76 3.57 1.06 5.15 1.06 4.26 0 6.7-2.48 6.7-5.51C12.59 11.49 3.81 10.76 3.81 6.9M20.27 9.01c0.23-0.13 0.69-0.26 1.72-0.26 1.72 0 2.41 0.3 2.41 1.58h2.38c0-0.36 0-0.79-0.03-1.09 -0.23-1.98-2.15-2.67-4.88-2.67 -3 0-6.7 2.31-6.7 7.76 0 5.22 2.77 7.99 6.63 7.99 1.68 0 3.47-0.36 4.95-1.39l-0.2-2.31c-0.99 0.82-2.84 1.52-4.06 1.52 -2.14 0-4.55-1.71-4.55-5.91C17.93 10.2 20.01 9.18 20.27 9.01"></path><rect x="29.42" y="6.97" fill="#EB6500" width="2.54" height="14.95"></rect><path fill="#EB6500" d="M30.67 0.7c-0.92 0-1.65 0.92-1.65 1.81 0 0.93 0.76 1.85 1.65 1.85 0.89 0 1.68-0.96 1.68-1.88C32.35 1.55 31.56 0.7 30.67 0.7M48.06 14.13c0-5.18-1.42-7.56-6.01-7.56 -3.86 0-6.67 2.77-6.67 7.92 0 4.92 2.97 7.82 6.73 7.82 2.81 0 4.36-0.63 5.68-1.42l-0.2-2.31c-0.89 0.79-2.94 1.55-4.69 1.55 -3.14 0-4.88-1.95-4.88-5.51v-0.49H48.06M39.91 9.18c0.17-0.17 1.29-0.46 1.98-0.46 2.48 0 3.76 0.53 3.86 3.43h-7.46C38.56 10.27 39.71 9.37 39.91 9.18zM58.82 6.57c-2.24 0-3.63 1.12-4.85 2.61l-0.4-2.21h-2.34l0.13 1.19c0.1 0.76 0.13 1.78 0.13 2.97v10.79h2.54V11.88c0.69-0.96 2.15-2.48 2.48-2.64 0.23-0.13 1.29-0.4 2.08-0.4 2.28 0 2.48 1.15 2.54 3.43 0.03 1.19 0.03 3.17 0.03 3.17 0.03 3-0.1 6.47-0.1 6.47h2.54c0 0 0.07-4.49 0.07-6.96 0-1.48 0.03-2.97-0.1-4.46C63.31 7.43 61.49 6.57 58.82 6.57M72.12 9.01c0.23-0.13 0.69-0.26 1.72-0.26 1.72 0 2.41 0.3 2.41 1.58h2.38c0-0.36 0-0.79-0.03-1.09 -0.23-1.98-2.15-2.67-4.88-2.67 -3 0-6.7 2.31-6.7 7.76 0 5.22 2.77 7.99 6.63 7.99 1.68 0 3.47-0.36 4.95-1.39l-0.2-2.31c-0.99 0.82-2.84 1.52-4.06 1.52 -2.15 0-4.55-1.71-4.55-5.91C69.77 10.2 71.85 9.18 72.12 9.01M92.74 14.13c0-5.18-1.42-7.56-6.01-7.56 -3.86 0-6.67 2.77-6.67 7.92 0 4.92 2.97 7.82 6.73 7.82 2.81 0 4.36-0.63 5.68-1.42l-0.2-2.31c-0.89 0.79-2.94 1.55-4.69 1.55 -3.14 0-4.88-1.95-4.88-5.51v-0.49H92.74M84.59 9.18c0.17-0.17 1.29-0.46 1.98-0.46 2.48 0 3.76 0.53 3.86 3.43h-7.46C83.24 10.27 84.39 9.37 84.59 9.18zM103.9 1.98h-7.13v19.93h6.83c7.26 0 9.77-5.68 9.77-10.03C113.37 7.33 110.93 1.98 103.9 1.98M103.14 19.8h-3.76V4.1h4.09c5.38 0 6.96 4.39 6.96 7.79C110.43 16.87 108.19 19.8 103.14 19.8zM118.38 0.7c-0.92 0-1.65 0.92-1.65 1.81 0 0.93 0.76 1.85 1.65 1.85 0.89 0 1.69-0.96 1.69-1.88C120.07 1.55 119.28 0.7 118.38 0.7"></path><rect x="117.13" y="6.97" fill="#EB6500" width="2.54" height="14.95"></rect><path fill="#EB6500" d="M130.2 6.6c-1.62 0-2.87 1.45-3.4 2.74l-0.43-2.37h-2.34l0.13 1.19c0.1 0.76 0.13 1.75 0.13 2.9v10.86h2.54v-9.51c0.53-1.29 1.72-3.7 3.17-3.7 0.96 0 1.06 0.99 1.06 1.22l2.08-0.6V9.18c0-0.03-0.03-0.17-0.06-0.4C132.8 7.36 131.91 6.6 130.2 6.6M145.87 14.13c0-5.18-1.42-7.56-6.01-7.56 -3.86 0-6.67 2.77-6.67 7.92 0 4.92 2.97 7.82 6.73 7.82 2.81 0 4.36-0.63 5.68-1.42l-0.2-2.31c-0.89 0.79-2.94 1.55-4.69 1.55 -3.14 0-4.89-1.95-4.89-5.51v-0.49H145.87M137.72 9.18c0.17-0.17 1.29-0.46 1.98-0.46 2.48 0 3.76 0.53 3.86 3.43h-7.46C136.37 10.27 137.52 9.37 137.72 9.18zM153.23 9.01c0.23-0.13 0.69-0.26 1.72-0.26 1.72 0 2.41 0.3 2.41 1.58h2.38c0-0.36 0-0.79-0.03-1.09 -0.23-1.98-2.14-2.67-4.88-2.67 -3 0-6.7 2.31-6.7 7.76 0 5.22 2.77 7.99 6.63 7.99 1.69 0 3.47-0.36 4.95-1.39l-0.2-2.31c-0.99 0.82-2.84 1.52-4.06 1.52 -2.15 0-4.55-1.71-4.55-5.91C150.89 10.2 152.97 9.18 153.23 9.01M170 19.44c-0.92 0.36-1.72 0.69-2.51 0.69 -1.16 0-1.58-0.66-1.58-2.34V8.95h3.93V6.97h-3.93V2.97h-2.48v3.99h-2.71v1.98h2.71v9.67c0 2.64 1.39 3.73 3.33 3.73 1.15 0 2.54-0.39 3.43-0.79L170 19.44M173.68 5.96c-1.09 0-2-0.87-2-1.97 0-1.1 0.91-1.97 2-1.97s1.98 0.88 1.98 1.98C175.66 5.09 174.77 5.96 173.68 5.96zM173.67 2.46c-0.85 0-1.54 0.67-1.54 1.52 0 0.85 0.69 1.54 1.54 1.54 0.85 0 1.54-0.69 1.54-1.54C175.21 3.13 174.52 2.46 173.67 2.46zM174.17 5.05c-0.09-0.09-0.17-0.19-0.25-0.3l-0.41-0.56h-0.16v0.87h-0.39V2.92c0.22-0.01 0.47-0.03 0.66-0.03 0.41 0 0.82 0.16 0.82 0.64 0 0.29-0.21 0.55-0.49 0.63 0.23 0.32 0.45 0.62 0.73 0.91H174.17zM173.56 3.22l-0.22 0.01v0.63h0.22c0.26 0 0.43-0.05 0.43-0.34C174 3.28 173.83 3.21 173.56 3.22z"></path></g></svg></a><div class="gh-nav-cnt u-hide-from-print"><div class="gh-nav-links-container gh-nav-links-container-h u-hide-from-print gh-nav-content-container"><nav aria-label="links" class="gh-nav gh-nav-links gh-nav-h"><ul class="gh-nav-list u-list-reset"><li class="gh-nav-item gh-move-to-spine"><a class="anchor gh-nav-action text-s anchor-secondary anchor-medium" href="/browse/journals-and-books" id="gh-journals-books-link" data-aa-region="header" data-aa-name="Journals &amp; Books"><span class="anchor-text-container"><span class="anchor-text">Journals &amp; Books</span></span></a></li></ul></nav><nav aria-label="utilities" class="gh-nav gh-nav-utilities gh-nav-h"><ul class="gh-nav-list u-list-reset"><li class="gh-nav-help text-s u-flex-center-ver u-gap-6 gh-nav-action"><div class="gh-move-to-spine gh-help-button gh-help-icon gh-nav-item"><div class="popover" id="gh-help-icon-popover"><div id="popover-trigger-gh-help-icon-popover"><input type="hidden"><button class="button-link button-link-secondary gh-icon-btn button-link-medium button-link-icon-left" title="Help" aria-expanded="false" type="button"><svg focusable="false" viewBox="0 0 114 128" height="20" width="20" class="icon icon-help gh-icon"><path d="M57 8C35.69 7.69 15.11 21.17 6.68 40.71c-8.81 19.38-4.91 43.67 9.63 59.25 13.81 15.59 36.85 21.93 56.71 15.68 21.49-6.26 37.84-26.81 38.88-49.21 1.59-21.15-10.47-42.41-29.29-52.1C74.76 10.17 65.88 7.99 57 8zm0 10c20.38-.37 39.57 14.94 43.85 34.85 4.59 18.53-4.25 39.23-20.76 48.79-17.05 10.59-40.96 7.62-54.9-6.83-14.45-13.94-17.42-37.85-6.83-54.9C26.28 26.5 41.39 17.83 57 18zm-.14 14C45.31 32.26 40 40.43 40 50v2h10v-2c0-4.22 2.22-9.66 8-9.24 5.5.4 6.32 5.14 5.78 8.14C62.68 55.06 52 58.4 52 69.4V76h10v-5.56c0-8.16 11.22-11.52 12-21.7.74-9.86-5.56-16.52-16-16.74-.39-.01-.76-.01-1.14 0zM52 82v10h10V82H52z"></path></svg><span class="button-link-text-container"><span class="button-link-text">Help</span></span></button></div></div></div></li><li class="gh-nav-search text-s u-flex-center-ver u-gap-6 gh-nav-action"><div class="gh-search-toggle gh-nav-item search-button-link"><a class="anchor button-link-secondary anchor-secondary u-margin-l-left gh-nav-action gh-icon-btn anchor-medium anchor-icon-left anchor-with-icon" href="/search" id="gh-search-link" title="Search" data-aa-button="search-in-header-opened-from-article" role="button"><svg focusable="false" viewBox="0 0 100 128" height="20" class="icon icon-search gh-icon"><path d="M19.22 76.91c-5.84-5.84-9.05-13.6-9.05-21.85s3.21-16.01 9.05-21.85c5.84-5.83 13.59-9.05 21.85-9.05 8.25 0 16.01 3.22 21.84 9.05 5.84 5.84 9.05 13.6 9.05 21.85s-3.21 16.01-9.05 21.85c-5.83 5.83-13.59 9.05-21.84 9.05-8.26 0-16.01-3.22-21.85-9.05zm80.33 29.6L73.23 80.19c5.61-7.15 8.68-15.9 8.68-25.13 0-10.91-4.25-21.17-11.96-28.88-7.72-7.71-17.97-11.96-28.88-11.96S19.9 18.47 12.19 26.18C4.47 33.89.22 44.15.22 55.06s4.25 21.17 11.97 28.88C19.9 91.65 30.16 95.9 41.07 95.9c9.23 0 17.98-3.07 25.13-8.68l26.32 26.32 7.03-7.03"></path></svg><span class="anchor-text-container"><span class="anchor-text">Search</span></span></a></div></li></ul></nav></div></div><div class="gh-profile-container u-hide-from-print"><div id="gh-profile-cnt" class="u-flex-center-ver gh-move-to-spine"><div class="popover" id="gh-profile-dropdown"><div id="popover-trigger-gh-profile-dropdown"><input type="hidden"><button class="button-link gh-icon-btn gh-user-icon u-margin-l-left gh-truncate text-s button-link-secondary button-link-medium button-link-icon-left" title="Gergo Gyori" aria-expanded="false" type="button"><svg focusable="false" viewBox="0 0 106 128" height="20" class="icon icon-person"><path d="M11.07 120l.84-9.29C13.88 91.92 35.25 87.78 53 87.78c17.74 0 39.11 4.13 41.08 22.84l.84 9.38h10.04l-.93-10.34C101.88 89.23 83.89 78 53 78S4.11 89.22 1.95 109.73L1.04 120h10.03M53 17.71c-9.72 0-18.24 8.69-18.24 18.59 0 13.67 7.84 23.98 18.24 23.98S71.24 49.97 71.24 36.3c0-9.9-8.52-18.59-18.24-18.59zM53 70c-15.96 0-28-14.48-28-33.67C25 20.97 37.82 8 53 8s28 12.97 28 28.33C81 55.52 68.96 70 53 70"></path></svg><span class="button-link-text-container"><span class="button-link-text">Gergo Gyori</span></span></button></div></div></div></div><div class="gh-move-to-spine u-hide-from-print gh-institution-item"><div class="popover text-s" id="institution-popover"><div id="popover-trigger-institution-popover"><input type="hidden"><button class="button-link gh-icon-btn gh-has-institution gh-truncate text-s button-link-secondary u-margin-l-left button-link-medium button-link-icon-left" id="gh-inst-icon-btn" aria-expanded="false" aria-label="Institutional Access" title="IT University of Copenhagen" type="button"><svg focusable="false" viewBox="0 0 106 128" height="20" class="icon icon-institution gh-inst-icon"><path d="M84 98h10v10H12V98h10V52h14v46h10V52h14v46h10V52h14v46zM12 36.86l41-20.84 41 20.84V42H12v-5.14zM104 52V30.74L53 4.8 2 30.74V52h10v36H2v30h102V88H94V52h10z"></path></svg><span class="button-link-text-container"><span class="button-link-text">IT University of Copenhagen</span></span></button></div></div></div><div id="gh-mobile-menu" class="mobile-menu u-hide-from-print"><div class="gh-hamburger u-fill-grey7"><button class="button-link u-flex-center-ver button-link-primary button-link-icon-left" aria-label="Toggle mobile menu" aria-expanded="false" type="button"><svg class="gh-hamburger-svg-el gh-hamburger-closed" role="img" aria-hidden="true" height="20" width="20"><path d="M0 14h40v2H0zm0-7h40v2H0zm0-7h40v2H0z"></path></svg></button></div><div id="gh-overlay" class="mobile-menu-overlay u-overlay u-display-none" role="button" tabindex="-1"></div><div id="gh-drawer" aria-label="Mobile menu" class="" role="navigation"></div></div></div></header><div class="Article" id="mathjax-container" role="main"><div class="accessbar-sticky"><div id="screen-reader-main-content"></div><div role="region" aria-label="Download options and search"><div class="accessbar"><div class="accessbar-label"></div><ul aria-label="PDF Options"><li class="ViewPDF"><a class="link-button accessbar-utility-component accessbar-utility-link link-button-primary link-button-icon-left" target="_blank" aria-label="View PDF. Opens in a new window." href="/science/article/pii/S0925231219306137/pdfft?md5=b31bdcbb1e65c9378c37c8bc3bd861d0&amp;pid=1-s2.0-S0925231219306137-main.pdf" rel="nofollow"><svg focusable="false" viewBox="0 0 35 32" height="20" class="icon icon-pdf-multicolor"><path d="M7 .362h17.875l6.763 6.1V31.64H6.948V16z" stroke="#000" stroke-width=".703" fill="#fff"></path><path d="M.167 2.592H22.39V9.72H.166z" fill="#da0000"></path><path fill="#fff9f9" d="M5.97 3.638h1.62c1.053 0 1.483.677 1.488 1.564.008.96-.6 1.564-1.492 1.564h-.644v1.66h-.977V3.64m.977.897v1.34h.542c.27 0 .596-.068.596-.673-.002-.6-.32-.667-.596-.667h-.542m3.8.036v2.92h.35c.933 0 1.223-.448 1.228-1.462.008-1.06-.316-1.45-1.23-1.45h-.347m-.977-.94h1.03c1.68 0 2.523.586 2.534 2.39.01 1.688-.607 2.4-2.534 2.4h-1.03V3.64m4.305 0h2.63v.934h-1.657v.894H16.6V6.4h-1.56v2.026h-.97V3.638"></path><path d="M19.462 13.46c.348 4.274-6.59 16.72-8.508 15.792-1.82-.85 1.53-3.317 2.92-4.366-2.864.894-5.394 3.252-3.837 3.93 2.113.895 7.048-9.25 9.41-15.394zM14.32 24.874c4.767-1.526 14.735-2.974 15.152-1.407.824-3.157-13.72-.37-15.153 1.407zm5.28-5.043c2.31 3.237 9.816 7.498 9.788 3.82-.306 2.046-6.66-1.097-8.925-4.164-4.087-5.534-2.39-8.772-1.682-8.732.917.047 1.074 1.307.67 2.442-.173-1.406-.58-2.44-1.224-2.415-1.835.067-1.905 4.46 1.37 9.065z" fill="#f91d0a"></path></svg><span class="link-button-text-container"><span class="link-button-text"><span>View&nbsp;<strong>PDF</strong></span></span></span></a></li><li class="DownloadFullIssue"><button class="button-link accessbar-utility-component button-link-primary" aria-label="Download full issue" type="button"><span class="button-link-text-container"><span class="button-link-text"><span>Download full issue</span></span></span></button></li></ul><form class="QuickSearch" action="/search#submit" method="get" aria-label="form"><div class="search-input"><div class="search-input-container search-input-container-no-label"><label class="search-input-label u-hide-visually" for="article-quick-search">Search ScienceDirect</label><input type="search" id="article-quick-search" name="qs" class="search-input-field" aria-describedby="article-quick-search-description-message" aria-invalid="false" aria-label="Search ScienceDirect" placeholder="Search ScienceDirect" value=""></div><div class="search-input-message-container"><div class="search-input-validation-error" aria-live="polite"></div><div id="article-quick-search-description-message"></div></div></div><button type="submit" class="button u-margin-xs-left button-primary small button-icon-only" aria-disabled="false" aria-label="Submit search"><svg focusable="false" viewBox="0 0 100 128" height="20" class="icon icon-search"><path d="M19.22 76.91c-5.84-5.84-9.05-13.6-9.05-21.85s3.21-16.01 9.05-21.85c5.84-5.83 13.59-9.05 21.85-9.05 8.25 0 16.01 3.22 21.84 9.05 5.84 5.84 9.05 13.6 9.05 21.85s-3.21 16.01-9.05 21.85c-5.83 5.83-13.59 9.05-21.84 9.05-8.26 0-16.01-3.22-21.85-9.05zm80.33 29.6L73.23 80.19c5.61-7.15 8.68-15.9 8.68-25.13 0-10.91-4.25-21.17-11.96-28.88-7.72-7.71-17.97-11.96-28.88-11.96S19.9 18.47 12.19 26.18C4.47 33.89.22 44.15.22 55.06s4.25 21.17 11.97 28.88C19.9 91.65 30.16 95.9 41.07 95.9c9.23 0 17.98-3.07 25.13-8.68l26.32 26.32 7.03-7.03"></path></svg></button><input type="hidden" name="origin" value="article"><input type="hidden" name="zone" value="qSearch"></form></div></div></div><div class="article-wrapper grid row"><div role="navigation" class="u-display-block-from-lg col-lg-6 u-padding-s-top sticky-table-of-contents" aria-label="Table of contents"><div class="TableOfContents" lang="en"><div class="Outline" id="toc-outline"><h2 class="u-h4">Outline</h2><ol class="u-padding-xs-bottom"><li class="toc-list-entry-outline-padding"><a class="anchor u-truncate-anchor-text anchor-primary" href="#abs0001" data-aa-button="sd:product:journal:article:type=anchor:name=outlinelink" title="Abstract"><span class="anchor-text-container"><span class="anchor-text">Abstract</span></span></a></li><li class="ai-components-toc-entry" id="ai-components-toc-entry"></li><li class="toc-list-entry-outline-padding"><a class="anchor u-truncate-anchor-text anchor-primary" href="#keys0001" data-aa-button="sd:product:journal:article:type=anchor:name=outlinelink" title="Keywords"><span class="anchor-text-container"><span class="anchor-text">Keywords</span></span></a></li><li class="toc-list-entry-outline-padding"><a class="anchor u-truncate-anchor-text anchor-primary" href="#sec0001" data-aa-button="sd:product:journal:article:type=anchor:name=outlinelink" title="1. Introduction"><span class="anchor-text-container"><span class="anchor-text">1. Introduction</span></span></a></li><li class="toc-list-entry-outline-padding"><a class="anchor u-truncate-anchor-text anchor-primary" href="#sec0002" data-aa-button="sd:product:journal:article:type=anchor:name=outlinelink" title="2. Related work"><span class="anchor-text-container"><span class="anchor-text">2. Related work</span></span></a></li><li class="toc-list-entry-outline-padding"><a class="anchor u-truncate-anchor-text anchor-primary" href="#sec0003" data-aa-button="sd:product:journal:article:type=anchor:name=outlinelink" title="3. Proposed method"><span class="anchor-text-container"><span class="anchor-text">3. Proposed method</span></span></a></li><li class="toc-list-entry-outline-padding"><a class="anchor u-truncate-anchor-text anchor-primary" href="#sec0007" data-aa-button="sd:product:journal:article:type=anchor:name=outlinelink" title="4. Experimental results"><span class="anchor-text-container"><span class="anchor-text">4. Experimental results</span></span></a></li><li class="toc-list-entry-outline-padding"><a class="anchor u-truncate-anchor-text anchor-primary" href="#sec0013" data-aa-button="sd:product:journal:article:type=anchor:name=outlinelink" title="5. Conclusions and future works"><span class="anchor-text-container"><span class="anchor-text">5. Conclusions and future works</span></span></a></li><li class="toc-list-entry-outline-padding"><a class="anchor u-truncate-anchor-text anchor-primary" href="#sec0013a" data-aa-button="sd:product:journal:article:type=anchor:name=outlinelink" title="Conflict of interests"><span class="anchor-text-container"><span class="anchor-text">Conflict of interests</span></span></a></li><li class="toc-list-entry-outline-padding"><a class="anchor u-truncate-anchor-text anchor-primary" href="#ack0001" data-aa-button="sd:product:journal:article:type=anchor:name=outlinelink" title="Acknowledgment"><span class="anchor-text-container"><span class="anchor-text">Acknowledgment</span></span></a></li><li class="toc-list-entry-outline-padding"><a class="anchor u-truncate-anchor-text anchor-primary" href="#bib001" data-aa-button="sd:product:journal:article:type=anchor:name=outlinelink" title="References"><span class="anchor-text-container"><span class="anchor-text">References</span></span></a></li><li class="toc-list-entry-outline-padding"><a class="anchor u-truncate-anchor-text anchor-primary" href="#b1" data-aa-button="sd:product:journal:article:type=anchor:name=outlinelink" title="Vitae"><span class="anchor-text-container"><span class="anchor-text">Vitae</span></span></a></li></ol><button class="button-link u-margin-xs-top u-margin-s-bottom button-link-primary button-link-icon-right" aria-expanded="false" data-aa-button="sd:product:journal:article:type=menu:name=show-full-outline" type="button"><span class="button-link-text-container"><span class="button-link-text">Show full outline</span></span><svg focusable="false" viewBox="0 0 92 128" height="20" class="icon icon-navigate-down"><path d="M1 51l7-7 38 38 38-38 7 7-45 45z"></path></svg></button><div class="PageDivider"></div></div><div class="CitedBy" id="toc-cited-by"><h2 class="u-h4"><a class="anchor anchor-primary" href="#section-cited-by"><span class="anchor-text-container"><span class="anchor-text">Cited by (149)</span></span></a></h2><div class="PageDivider"></div></div><div class="Figures" id="toc-figures"><h2 class="u-h4">Figures (8)</h2><ol class="u-margin-s-bottom"><li><a class="anchor u-display-block anchor-primary anchor-icon-only anchor-with-icon" href="#fig0001" data-aa-button="sd:product:journal:article:type=anchor:name=figure"><img alt="Fig. 1. The basic structure of the Light-CNN" class="u-display-block" height="143px" src="https://ars.els-cdn.com/content/image/1-s2.0-S0925231219306137-gr1.sml" width="219px"></a></li><li><a class="anchor u-display-block anchor-primary anchor-icon-only anchor-with-icon" href="#fig0002" data-aa-button="sd:product:journal:article:type=anchor:name=figure"><img alt="Fig. 2. The structure of 6 depthwise separable residual convolution modules" class="u-display-block" height="163px" src="https://ars.els-cdn.com/content/image/1-s2.0-S0925231219306137-gr2.sml" width="164px"></a></li><li><a class="anchor u-display-block anchor-primary anchor-icon-only anchor-with-icon" href="#fig0003" data-aa-button="sd:product:journal:article:type=anchor:name=figure"><img alt="Fig. 3. Feature visualization of the image" class="u-display-block" height="58px" src="https://ars.els-cdn.com/content/image/1-s2.0-S0925231219306137-gr3.sml" width="219px"></a></li><li><a class="anchor u-display-block anchor-primary anchor-icon-only anchor-with-icon" href="#fig0004" data-aa-button="sd:product:journal:article:type=anchor:name=figure"><img alt="Fig. 4. Framework of the dual-branch CNN" class="u-display-block" height="100px" src="https://ars.els-cdn.com/content/image/1-s2.0-S0925231219306137-gr4.sml" width="219px"></a></li><li><a class="anchor u-display-block anchor-primary anchor-icon-only anchor-with-icon" href="#fig0005" data-aa-button="sd:product:journal:article:type=anchor:name=figure"><img alt="Fig. 5. The framework of the pretrained CNN" class="u-display-block" height="164px" src="https://ars.els-cdn.com/content/image/1-s2.0-S0925231219306137-gr5.sml" width="124px"></a></li><li><a class="anchor u-display-block anchor-primary anchor-icon-only anchor-with-icon" href="#fig0006" data-aa-button="sd:product:journal:article:type=anchor:name=figure"><img alt="Fig. 6. Examples Images in CK+(top), BU-3DFE (middle), FER2013 (bottom) Datasets" class="u-display-block" height="142px" src="https://ars.els-cdn.com/content/image/1-s2.0-S0925231219306137-gr6.sml" width="219px"></a></li></ol><button class="button-link u-margin-xs-top u-margin-s-bottom button-link-primary button-link-icon-right" data-aa-button="sd:product:journal:article:type=menu:name=show-figures" type="button"><span class="button-link-text-container"><span class="button-link-text">Show 2 more figures</span></span><svg focusable="false" viewBox="0 0 92 128" height="20" class="icon icon-navigate-down"><path d="M1 51l7-7 38 38 38-38 7 7-45 45z"></path></svg></button><div class="PageDivider"></div></div><div class="Tables" id="toc-tables"><h2 class="u-h4">Tables (6)</h2><ol class="u-padding-s-bottom"><li class="toc-list-entry-outline-padding"><a class="anchor u-truncate-anchor-text anchor-primary anchor-icon-left anchor-with-icon" href="#tbl0001" data-aa-button="sd:product:journal:article:type=anchor:name=table" title="Architectures of the two branches."><svg focusable="false" viewBox="0 0 98 128" height="20" class="icon icon-table"><path d="M54 68h32v32H54V68zm-42 0h32v32H12V68zm0-42h32v32H12V26zm42 0h32v32H54V26zM2 110h94V16H2v94z"></path></svg><span class="anchor-text-container"><span class="anchor-text">Table 1</span></span></a></li><li class="toc-list-entry-outline-padding"><a class="anchor u-truncate-anchor-text anchor-primary anchor-icon-left anchor-with-icon" href="#tbl0002" data-aa-button="sd:product:journal:article:type=anchor:name=table" title="The parameter setting of Light-CNN, Dual-Branch Network and Pre-trained network."><svg focusable="false" viewBox="0 0 98 128" height="20" class="icon icon-table"><path d="M54 68h32v32H54V68zm-42 0h32v32H12V68zm0-42h32v32H12V26zm42 0h32v32H54V26zM2 110h94V16H2v94z"></path></svg><span class="anchor-text-container"><span class="anchor-text">Table 2</span></span></a></li><li class="toc-list-entry-outline-padding"><a class="anchor u-truncate-anchor-text anchor-primary anchor-icon-left anchor-with-icon" href="#tbl0003" data-aa-button="sd:product:journal:article:type=anchor:name=table" title="Comparison of parameters in three networks and their running time on FER2013 dataset."><svg focusable="false" viewBox="0 0 98 128" height="20" class="icon icon-table"><path d="M54 68h32v32H54V68zm-42 0h32v32H12V68zm0-42h32v32H12V26zm42 0h32v32H54V26zM2 110h94V16H2v94z"></path></svg><span class="anchor-text-container"><span class="anchor-text">Table 3</span></span></a></li><li class="toc-list-entry-outline-padding"><a class="anchor u-truncate-anchor-text anchor-primary anchor-icon-left anchor-with-icon" href="#tbl0004" data-aa-button="sd:product:journal:article:type=anchor:name=table" title="The accuracy (%) of different methods on CK+ dataset."><svg focusable="false" viewBox="0 0 98 128" height="20" class="icon icon-table"><path d="M54 68h32v32H54V68zm-42 0h32v32H12V68zm0-42h32v32H12V26zm42 0h32v32H54V26zM2 110h94V16H2v94z"></path></svg><span class="anchor-text-container"><span class="anchor-text">Table 4</span></span></a></li><li class="toc-list-entry-outline-padding"><a class="anchor u-truncate-anchor-text anchor-primary anchor-icon-left anchor-with-icon" href="#tbl0005" data-aa-button="sd:product:journal:article:type=anchor:name=table" title="Accuracy (%) using different methods on BU-3DFE dataset."><svg focusable="false" viewBox="0 0 98 128" height="20" class="icon icon-table"><path d="M54 68h32v32H54V68zm-42 0h32v32H12V68zm0-42h32v32H12V26zm42 0h32v32H54V26zM2 110h94V16H2v94z"></path></svg><span class="anchor-text-container"><span class="anchor-text">Table 5</span></span></a></li><li class="toc-list-entry-outline-padding"><a class="anchor u-truncate-anchor-text anchor-primary anchor-icon-left anchor-with-icon" href="#tbl0006" data-aa-button="sd:product:journal:article:type=anchor:name=table" title="Accuracy (%) using different methods on FER2013 dataset."><svg focusable="false" viewBox="0 0 98 128" height="20" class="icon icon-table"><path d="M54 68h32v32H54V68zm-42 0h32v32H12V68zm0-42h32v32H12V26zm42 0h32v32H54V26zM2 110h94V16H2v94z"></path></svg><span class="anchor-text-container"><span class="anchor-text">Table 6</span></span></a></li></ol><div class="PageDivider"></div></div></div></div><article class="col-lg-12 col-md-16 pad-left pad-right u-padding-s-top" lang="en"><div class="Publication" id="publication"><div class="publication-brand u-display-block-from-sm"><a class="anchor anchor-primary" href="/journal/neurocomputing" title="Go to Neurocomputing on ScienceDirect"><span class="anchor-text-container"><span class="anchor-text"><img class="publication-brand-image" src="https://sdfestaticassets-eu-west-1.sciencedirectassets.com/prod/562c52f0a29e84041e12a6c3286c1d8a5b89ba0b/image/elsevier-non-solus.png" alt="Elsevier"></span></span></a></div><div class="publication-volume u-text-center"><h2 class="publication-title u-h3" id="publication-title"><a class="anchor anchor-secondary publication-title-link" href="/journal/neurocomputing" title="Go to Neurocomputing on ScienceDirect"><span class="anchor-text-container"><span class="anchor-text">Neurocomputing</span></span></a></h2><div class="text-xs"><a class="anchor anchor-primary" href="/journal/neurocomputing/vol/355/suppl/C" title="Go to table of contents for this volume/issue"><span class="anchor-text-container"><span class="anchor-text">Volume 355</span></span></a>, <!-- -->25 August 2019<!-- -->, Pages 82-92</div></div><div class="publication-cover u-display-block-from-sm"><a class="anchor anchor-primary" href="/journal/neurocomputing/vol/355/suppl/C"><span class="anchor-text-container"><span class="anchor-text"><img class="publication-cover-image" src="https://ars.els-cdn.com/content/image/1-s2.0-S0925231219X00259-cov150h.gif" alt="Neurocomputing"></span></span></a></div></div><h1 id="screen-reader-main-title" class="Head u-font-serif u-h2 u-margin-s-ver"><span class="title-text">Three convolutional neural network models for facial expression recognition in the wild</span></h1><div class="Banner" id="banner"><div class="wrapper truncated"><div class="AuthorGroups"><div class="author-group" id="author-group"><span class="sr-only">Author links open overlay panel</span><button class="button-link button-link-secondary button-link-underline" data-sd-ui-side-panel-opener="true" data-xocs-content-type="author" data-xocs-content-id="au0001" type="button"><span class="button-link-text-container"><span class="button-link-text"><span class="react-xocs-alternative-link"><span class="given-name">Jie</span> <span class="text surname">Shao</span></span></span></span></button>, <button class="button-link button-link-secondary button-link-underline" data-sd-ui-side-panel-opener="true" data-xocs-content-type="author" data-xocs-content-id="au0002" type="button"><span class="button-link-text-container"><span class="button-link-text"><span class="react-xocs-alternative-link"><span class="given-name">Yongsheng</span> <span class="text surname">Qian</span></span><svg focusable="false" viewBox="0 0 106 128" height="20" title="Correspondence author icon" class="icon icon-person react-xocs-author-icon u-fill-grey8"><path d="M11.07 120l.84-9.29C13.88 91.92 35.25 87.78 53 87.78c17.74 0 39.11 4.13 41.08 22.84l.84 9.38h10.04l-.93-10.34C101.88 89.23 83.89 78 53 78S4.11 89.22 1.95 109.73L1.04 120h10.03M53 17.71c-9.72 0-18.24 8.69-18.24 18.59 0 13.67 7.84 23.98 18.24 23.98S71.24 49.97 71.24 36.3c0-9.9-8.52-18.59-18.24-18.59zM53 70c-15.96 0-28-14.48-28-33.67C25 20.97 37.82 8 53 8s28 12.97 28 28.33C81 55.52 68.96 70 53 70"></path></svg><svg focusable="false" viewBox="0 0 102 128" height="20" title="Author email or social media contact details icon" class="icon icon-envelope react-xocs-author-icon u-fill-grey8"><path d="M55.8 57.2c-1.78 1.31-5.14 1.31-6.9 0L17.58 34h69.54L55.8 57.19zM0 32.42l42.94 32.62c2.64 1.95 6.02 2.93 9.4 2.93s6.78-.98 9.42-2.93L102 34.34V24H0zM92 88.9L73.94 66.16l-8.04 5.95L83.28 94H18.74l18.38-23.12-8.04-5.96L10 88.94V51.36L0 42.9V104h102V44.82l-10 8.46V88.9"></path></svg></span></span></button></div></div></div><button class="button-link u-margin-s-ver button-link-primary button-link-icon-right" id="show-more-btn" type="button" data-aa-button="icon-expand"><span class="button-link-text-container"><span class="button-link-text">Show more</span></span><svg focusable="false" viewBox="0 0 92 128" height="20" class="icon icon-navigate-down"><path d="M1 51l7-7 38 38 38-38 7 7-45 45z"></path></svg></button><div class="banner-options u-padding-xs-bottom"><div class="toc-button-wrap u-display-inline-block u-display-none-from-lg u-margin-s-right"><button class="button-link button-link-secondary button-link-icon-left button-link-has-colored-icon" type="button"><svg focusable="false" viewBox="0 0 128 128" height="20" class="icon icon-list"><path d="M23 26a9 9 0 0 0-9 9 9 9 0 0 0 9 9 9 9 0 0 0 9-9 9 9 0 0 0-9-9zm23 4v10h68V30zM23 56a9 9 0 0 0-9 9 9 9 0 0 0 9 9 9 9 0 0 0 9-9 9 9 0 0 0-9-9zm23 4v10h68V60zM23 86a9 9 0 0 0-9 9 9 9 0 0 0 9 9 9 9 0 0 0 9-9 9 9 0 0 0-9-9zm23 4v10h68V90z"></path></svg><span class="button-link-text-container"><span class="button-link-text">Outline</span></span></button></div><button class="button-link AddToMendeley button-link-secondary u-margin-s-right u-display-inline-flex-from-md button-link-icon-left button-link-has-colored-icon" type="button"><svg focusable="false" viewBox="0 0 86 128" height="20" class="icon icon-plus"><path d="M48 58V20H38v38H0v10h38v38h10V68h38V58z"></path></svg><span class="button-link-text-container"><span class="button-link-text">Add to Mendeley</span></span></button><div class="Social u-display-inline-block" id="social"><div class="popover social-popover" id="social-popover"><div id="popover-trigger-social-popover"><button class="button-link button-link-secondary u-margin-s-right button-link-icon-left button-link-has-colored-icon" aria-expanded="false" aria-haspopup="true" type="button"><svg focusable="false" viewBox="0 0 114 128" height="20" class="icon icon-share"><path d="M90 112c-6.62 0-12-5.38-12-12s5.38-12 12-12 12 5.38 12 12-5.38 12-12 12zM24 76c-6.62 0-12-5.38-12-12s5.38-12 12-12 12 5.38 12 12-5.38 12-12 12zm66-60c6.62 0 12 5.38 12 12s-5.38 12-12 12-12-5.38-12-12 5.38-12 12-12zm0 62c-6.56 0-12.44 2.9-16.48 7.48L45.1 70.2c.58-1.98.9-4.04.9-6.2s-.32-4.22-.9-6.2l28.42-15.28C77.56 47.1 83.44 50 90 50c12.14 0 22-9.86 22-22S102.14 6 90 6s-22 9.86-22 22c0 1.98.28 3.9.78 5.72L40.14 49.1C36.12 44.76 30.38 42 24 42 11.86 42 2 51.86 2 64s9.86 22 22 22c6.38 0 12.12-2.76 16.14-7.12l28.64 15.38c-.5 1.84-.78 3.76-.78 5.74 0 12.14 9.86 22 22 22s22-9.86 22-22-9.86-22-22-22z"></path></svg><span class="button-link-text-container"><span class="button-link-text">Share</span></span></button></div></div></div><div class="ExportCitation u-display-inline-block" id="export-citation"><div class="popover export-citation-popover" id="export-citation-popover"><div id="popover-trigger-export-citation-popover"><button class="button-link button-link-secondary button-link-icon-left button-link-has-colored-icon" aria-expanded="false" aria-haspopup="true" type="button"><svg focusable="false" viewBox="0 0 104 128" height="20" class="icon icon-cited-by-66"><path d="M2 58.78V106h44V64H12v-5.22C12 40.28 29.08 32 46 32V22C20.1 22 2 37.12 2 58.78zM102 32V22c-25.9 0-44 15.12-44 36.78V106h44V64H68v-5.22C68 40.28 85.08 32 102 32z"></path></svg><span class="button-link-text-container"><span class="button-link-text">Cite</span></span></button></div></div></div></div></div><div class="ArticleIdentifierLinks u-margin-xs-bottom text-xs" id="article-identifier-links"><a class="anchor doi anchor-primary" href="https://doi.org/10.1016/j.neucom.2019.05.005" target="_blank" rel="noreferrer noopener" aria-label="Persistent link using digital object identifier" title="Persistent link using digital object identifier"><span class="anchor-text-container"><span class="anchor-text">https://doi.org/10.1016/j.neucom.2019.05.005</span><svg focusable="false" viewBox="0 0 8 8" height="20" aria-label="Opens in new window" class="icon icon-arrow-up-right-tiny arrow-external-link"><path d="M1.12949 2.1072V1H7V6.85795H5.89111V2.90281L0.784057 8L0 7.21635L5.11902 2.1072H1.12949Z"></path></svg></span></a><a class="anchor rights-and-content anchor-primary" href="https://s100.copyright.com/AppDispatchServlet?publisherName=ELS&amp;contentID=S0925231219306137&amp;orderBeanReset=true" target="_blank" rel="noreferrer noopener"><span class="anchor-text-container"><span class="anchor-text">Get rights and content</span><svg focusable="false" viewBox="0 0 8 8" height="20" aria-label="Opens in new window" class="icon icon-arrow-up-right-tiny arrow-external-link"><path d="M1.12949 2.1072V1H7V6.85795H5.89111V2.90281L0.784057 8L0 7.21635L5.11902 2.1072H1.12949Z"></path></svg></span></a></div><section class="ReferencedArticles"></section><section class="ReferencedArticles"></section><div class="PageDivider"></div><div class="Abstracts u-font-serif" id="abstracts"><div class="abstract author" id="abs0001"><h2 class="section-title u-h4 u-margin-l-top u-margin-xs-bottom">Abstract</h2><div id="abssec0001"><div class="u-margin-s-bottom" id="sp0003"><span><a href="/topics/biochemistry-genetics-and-molecular-biology/facial-recognition" title="Learn more about Facial expression recognition from ScienceDirect's AI-generated Topic Pages" class="topic-link">Facial expression recognition</a> (FER) in the wild is a novel and challenging topic in the field of human emotion perception. Different kinds of </span><a href="/topics/computer-science/convolutional-neural-network" title="Learn more about convolutional neural network from ScienceDirect's AI-generated Topic Pages" class="topic-link">convolutional neural network</a><span><span><span> (CNN) approaches have been applied to this topic, but few of them ever considered what kind of architecture was better for the FER research. In this paper, we proposed three novel <a href="/topics/computer-science/neural-network-model" title="Learn more about CNN models from ScienceDirect's AI-generated Topic Pages" class="topic-link">CNN models</a><span><span> with different architectures. The first one is a shallow network, named the Light-CNN, which is a fully <a href="/topics/engineering/convolutional-neural-network" title="Learn more about convolutional neural network from ScienceDirect's AI-generated Topic Pages" class="topic-link">convolutional neural network</a> consisting of six depthwise separable residual convolution modules to solve the problem of complex topology and over-fitting. The second one is a dual-branch CNN which extracts traditional </span><a href="/topics/engineering/local-binary-pattern" title="Learn more about LBP from ScienceDirect's AI-generated Topic Pages" class="topic-link">LBP</a> features and </span></span><a href="/topics/engineering/deep-learning" title="Learn more about deep learning from ScienceDirect's AI-generated Topic Pages" class="topic-link">deep learning</a> features in parallel. The third one is a pre-trained CNN which is designed by </span><a href="/topics/biochemistry-genetics-and-molecular-biology/transfer-of-learning" title="Learn more about transfer learning from ScienceDirect's AI-generated Topic Pages" class="topic-link">transfer learning</a><span> technique to overcome the shortage of <a href="/topics/computer-science/training-sample" title="Learn more about training samples from ScienceDirect's AI-generated Topic Pages" class="topic-link">training samples</a>. Extensive evaluations on three popular datasets (public CK+, multi-view BU-3DEF and FER2013 datasets) demonstrated that our models were competitive and representative in the field of FER in the wild research. We achieved significant better results with comparisons to plenty of state-of-the-art approaches. Moreover, we provided discussions on the effectiveness and practicability of CNNs with different feature types and architectures for FER in the wild as well.</span></span></div></div></div></div><div id="reading-assistant-main-body-section"></div><ul id="issue-navigation" class="issue-navigation u-margin-s-bottom u-bg-grey1"><li class="previous move-left u-padding-s-ver u-padding-s-left"><a class="button-alternative button-alternative-tertiary u-display-flex button-alternative-icon-left" href="/science/article/pii/S0925231219306095"><svg focusable="false" viewBox="0 0 54 128" height="20" class="icon icon-navigate-left"><path d="M1 61l45-45 7 7-38 38 38 38-7 7z"></path></svg><span class="button-alternative-text-container"><span class="button-alternative-text">Previous <span class="extra-detail-1">article</span><span class="extra-detail-2"> in issue</span></span></span></a></li><li class="next move-right u-padding-s-ver u-padding-s-right"><a class="button-alternative button-alternative-tertiary u-display-flex button-alternative-icon-right" href="/science/article/pii/S092523121930623X"><span class="button-alternative-text-container"><span class="button-alternative-text">Next <span class="extra-detail-1">article</span><span class="extra-detail-2"> in issue</span></span></span><svg focusable="false" viewBox="0 0 54 128" height="20" class="icon icon-navigate-right"><path d="M1 99l38-38L1 23l7-7 45 45-45 45z"></path></svg></a></li></ul><div class="Keywords u-font-serif"><div id="keys0001" class="keywords-section"><h2 class="section-title u-h4 u-margin-l-top u-margin-xs-bottom">Keywords</h2><div id="key0002" class="keyword"><span id="txt0001">FER in the wild</span></div><div id="key0003" class="keyword"><span id="txt0002">Convolutional neural network</span></div><div id="key0004" class="keyword"><span id="txt0003">Shallow network</span></div><div id="key0005" class="keyword"><span id="txt0004">Dual-branch CNN</span></div><div id="key0006" class="keyword"><span id="txt0005">Pretrained CNN</span></div></div></div><div class="Body u-font-serif" id="body"><div><section id="sec0001"><h2 id="sctt0003" class="u-h4 u-margin-l-top u-margin-xs-bottom">1. Introduction</h2><div class="u-margin-s-bottom" id="p0001">Emotion recognition by facial expression plays an important role in intelligent social interaction. It is widely used in intelligent security <a class="anchor anchor-primary" href="#bib0001" name="bbib0001" data-sd-ui-side-panel-opener="true" data-xocs-content-type="reference" data-xocs-content-id="bib0001"><span class="anchor-text-container"><span class="anchor-text">[1]</span></span></a><span>, <a href="/topics/engineering/manufacturing-robotics" title="Learn more about robotics manufacturing from ScienceDirect's AI-generated Topic Pages" class="topic-link">robotics manufacturing</a> </span><a class="anchor anchor-primary" href="#bib0002" name="bbib0002" data-sd-ui-side-panel-opener="true" data-xocs-content-type="reference" data-xocs-content-id="bib0002"><span class="anchor-text-container"><span class="anchor-text">[2]</span></span></a>, clinical psychology <a class="anchor anchor-primary" href="#bib0003" name="bbib0003" data-sd-ui-side-panel-opener="true" data-xocs-content-type="reference" data-xocs-content-id="bib0003"><span class="anchor-text-container"><span class="anchor-text">[3]</span></span></a>, multimedia <a class="anchor anchor-primary" href="#bib0004" name="bbib0004" data-sd-ui-side-panel-opener="true" data-xocs-content-type="reference" data-xocs-content-id="bib0004"><span class="anchor-text-container"><span class="anchor-text">[4]</span></span></a> and automotive security <a class="anchor anchor-primary" href="#bib0005" name="bbib0005" data-sd-ui-side-panel-opener="true" data-xocs-content-type="reference" data-xocs-content-id="bib0005"><span class="anchor-text-container"><span class="anchor-text">[5]</span></span></a><span>. In most above-mentioned applications, their inputs are faces captured in the real world. Nevertheless, the main contributions of traditional <a href="/topics/biochemistry-genetics-and-molecular-biology/facial-recognition" title="Learn more about facial expression recognition from ScienceDirect's AI-generated Topic Pages" class="topic-link">facial expression recognition</a> methods focused on expressions of the frontal faces. Those expressions were performed by actors staying in a controlled environment. As a result, facial expression recognition in the wild is a novel and challenging topic due to various poses, illumination changes, occlusions, and subtle expressions, etc.</span></div><div class="u-margin-s-bottom" id="p0002">Previous traditional methods for FER in the wild mainly focused on modeling features, e.g., Zhong et&nbsp;al. <a class="anchor anchor-primary" href="#bib0006" name="bbib0006" data-sd-ui-side-panel-opener="true" data-xocs-content-type="reference" data-xocs-content-id="bib0006"><span class="anchor-text-container"><span class="anchor-text">[6]</span></span></a> built a two-stage multi-task sparse learning framework to discriminate facial patches. Zheng et&nbsp;al. <a class="anchor anchor-primary" href="#bib0007" name="bbib0007" data-sd-ui-side-panel-opener="true" data-xocs-content-type="reference" data-xocs-content-id="bib0007"><span class="anchor-text-container"><span class="anchor-text">[7]</span></span></a><span> treated the feature extraction problem as a convex <a href="/topics/computer-science/optimization-problem" title="Learn more about optimization problem from ScienceDirect's AI-generated Topic Pages" class="topic-link">optimization problem</a><span>. They both applied traditional state-of-the-art classifier for the final recognition. However, they made <a href="/topics/computer-science/good-performance" title="Learn more about good performance from ScienceDirect's AI-generated Topic Pages" class="topic-link">good performance</a> on frontal faces, leaving much to be desired on non-frontal faces.</span></span></div><div class="u-margin-s-bottom" id="p0003"><span>In recent years, <a href="/topics/computer-science/machine-learning-technique" title="Learn more about machine learning techniques from ScienceDirect's AI-generated Topic Pages" class="topic-link">machine learning techniques</a><span> of <a href="/topics/computer-science/convolutional-neural-network" title="Learn more about convolutional neural networks from ScienceDirect's AI-generated Topic Pages" class="topic-link">convolutional neural networks</a><span> have achieved great success in the field of <a href="/topics/engineering/computervision" title="Learn more about computer vision from ScienceDirect's AI-generated Topic Pages" class="topic-link">computer vision</a>. It is wildly used in the fields of visual object recognition </span></span></span><a class="anchor anchor-primary" href="#bib0008" name="bbib0008" data-sd-ui-side-panel-opener="true" data-xocs-content-type="reference" data-xocs-content-id="bib0008"><span class="anchor-text-container"><span class="anchor-text">[8]</span></span></a><span>, <a href="/topics/engineering/natural-language-processing" title="Learn more about Natural Language Processing from ScienceDirect's AI-generated Topic Pages" class="topic-link">Natural Language Processing</a> </span><a class="anchor anchor-primary" href="#bib0009" name="bbib0009" data-sd-ui-side-panel-opener="true" data-xocs-content-type="reference" data-xocs-content-id="bib0009"><span class="anchor-text-container"><span class="anchor-text">[9]</span></span></a>, driverless <a class="anchor anchor-primary" href="#bib0010" name="bbib0010" data-sd-ui-side-panel-opener="true" data-xocs-content-type="reference" data-xocs-content-id="bib0010"><span class="anchor-text-container"><span class="anchor-text">[10]</span></span></a><span><span>, and so on. It is also a promising approach for the research of FER. Different from traditional techniques, <a href="/topics/engineering/convolutional-neural-network" title="Learn more about convolutional neural networks from ScienceDirect's AI-generated Topic Pages" class="topic-link">convolutional neural networks</a> can perform tasks in an end-to-end way, associating both feature extraction and classification steps together by training. However, there are still some problems existing in the development of </span><a href="/topics/computer-science/deep-learning" title="Learn more about deep learning network from ScienceDirect's AI-generated Topic Pages" class="topic-link">deep learning network</a><span>: First, typically the efficiency of a CNN is improved by increasing the number of neurons or the number of layers, so that the network is hoped to learn more complex functions. For example, the early network AlexNet has 7 layers. Then the VGG model with 16 layers appeared, followed by the GoogLeNet consisting of 22 layers. Later came the <a href="/topics/computer-science/residual-neural-network" title="Learn more about ResNet from ScienceDirect's AI-generated Topic Pages" class="topic-link">ResNet</a> model with 152 layers, and the modified ResNet even includes thousands of layers. Although the networkâ€™s performance has been improved, their efficiency issues appeared, namely the storage problem of the model and the speed of prediction </span></span><a class="anchor anchor-primary" href="#bib0011" name="bbib0011" data-sd-ui-side-panel-opener="true" data-xocs-content-type="reference" data-xocs-content-id="bib0011"><span class="anchor-text-container"><span class="anchor-text">[11]</span></span></a><span>. Secondly, it may not be robust for the <a href="/topics/computer-science/deep-convolutional-neural-networks" title="Learn more about deep CNN from ScienceDirect's AI-generated Topic Pages" class="topic-link">deep CNN</a> to extract features from images with low-resolution, high noise and various rotational changes </span><a class="anchor anchor-primary" href="#bib0012" name="bbib0012" data-sd-ui-side-panel-opener="true" data-xocs-content-type="reference" data-xocs-content-id="bib0012"><span class="anchor-text-container"><span class="anchor-text">[12]</span></span></a>, <a class="anchor anchor-primary" href="#bib0013" name="bbib0013" data-sd-ui-side-panel-opener="true" data-xocs-content-type="reference" data-xocs-content-id="bib0013"><span class="anchor-text-container"><span class="anchor-text">[13]</span></span></a><span>. The third is the data problem. The deeper the CNN is, the more weights there need to be determined. Consequently, the network needs to be fed with thousands of samples in a larger database, then it could acquire better performance. However, it is impossible to provide large-scale samples in every <a href="/topics/computer-science/application-area" title="Learn more about application area from ScienceDirect's AI-generated Topic Pages" class="topic-link">application area</a>. It means that the shallow CNNs may have better performance in various industrial applications than the deeper ones.</span></div><div class="u-margin-s-bottom" id="p0004">Referring to the first problem we mentioned above, increasing the depth brings a series of negative issues such as overfitting, gradients disappearance, and enormous computational costs. A possible solution to this problem is to create deep sparsely compressed network. Gao Et al. <a class="anchor anchor-primary" href="#bib0014" name="bbib0014" data-sd-ui-side-panel-opener="true" data-xocs-content-type="reference" data-xocs-content-id="bib0014"><span class="anchor-text-container"><span class="anchor-text">[14]</span></span></a><span> proposed a feed-forward approach to build connections directly between each pair of <a href="/topics/engineering/convolutional-layer" title="Learn more about convolutional layers from ScienceDirect's AI-generated Topic Pages" class="topic-link">convolutional layers</a><span> to form a dense <a href="/topics/computer-science/convolutional-network" title="Learn more about convolutional network from ScienceDirect's AI-generated Topic Pages" class="topic-link">convolutional network</a><span> (DenseNet). It made use of the short connections between the input layer and the layer close to the output to make the convolutional network deeper, so that the training process would be more precise and more effective. Unfortunately, most current <a href="/topics/engineering/graphics-processing-unit" title="Learn more about GPUs from ScienceDirect's AI-generated Topic Pages" class="topic-link">GPUs</a> and CPUs are not able to efficiently run sparse network model </span></span></span><a class="anchor anchor-primary" href="#bib0015" name="bbib0015" data-sd-ui-side-panel-opener="true" data-xocs-content-type="reference" data-xocs-content-id="bib0015"><span class="anchor-text-container"><span class="anchor-text">[15]</span></span></a>. Therefore, in the paper we propose a shallow CNN with good performance on facial expression recognition in the wild. So that it would be suitable for practical problems currently.</div><div class="u-margin-s-bottom" id="p0005"><span>At present, most <a href="/topics/computer-science/neural-network-model" title="Learn more about CNN models from ScienceDirect's AI-generated Topic Pages" class="topic-link">CNN models</a><span> for facial expression recognition use the features generated by the <a href="/topics/computer-science/convolution-layer" title="Learn more about convolution layers from ScienceDirect's AI-generated Topic Pages" class="topic-link">convolution layers</a><span> using the raw pixel data as the main features. <a href="/topics/engineering/local-binary-pattern" title="Learn more about Local Binary Pattern from ScienceDirect's AI-generated Topic Pages" class="topic-link">Local Binary Pattern</a> (Local Binary Pattern, LBP) is a texture description operator which is usually used for facial expression recognition. It can effectively adapt to changes in illumination and local rotation </span></span></span><a class="anchor anchor-primary" href="#bib0016" name="bbib0016" data-sd-ui-side-panel-opener="true" data-xocs-content-type="reference" data-xocs-content-id="bib0016"><span class="anchor-text-container"><span class="anchor-text">[16]</span></span></a><span>. Features extracted by convolutional neural network may not be robust to the <a href="/topics/computer-science/image-rotation" title="Learn more about image rotation from ScienceDirect's AI-generated Topic Pages" class="topic-link">image rotation</a> changes. We wanted to explore if there was any way to apply LBP features along with raw pixels to a network and observe the performance of the model when it had a combination of two different features.</span></div><div class="u-margin-s-bottom" id="p0006"><span><span>The data problem, the third one we mentioned above is the most troublesome problem we met. Facial expressions in the wild have hundreds of thousands of variations referring to different poses, <a href="/topics/biochemistry-genetics-and-molecular-biology/human" title="Learn more about human races from ScienceDirect's AI-generated Topic Pages" class="topic-link">human races</a>, genders, conventions and environments. On the contrary, datasets of facial expression in the wild are quite limited. Some datasets only have hundreds of samples, so it is difficult for deeper CNN models to learn as good results as they have in some other fields. A study on </span><a href="/topics/biochemistry-genetics-and-molecular-biology/transfer-of-learning" title="Learn more about transfer learning of from ScienceDirect's AI-generated Topic Pages" class="topic-link">transfer learning of</a> facial expression recognition seems to offer a better chance of producing more accurate predictions </span><a class="anchor anchor-primary" href="#bib0017" name="bbib0017" data-sd-ui-side-panel-opener="true" data-xocs-content-type="reference" data-xocs-content-id="bib0017"><span class="anchor-text-container"><span class="anchor-text">[17]</span></span></a>, <a class="anchor anchor-primary" href="#bib0018" name="bbib0018" data-sd-ui-side-panel-opener="true" data-xocs-content-type="reference" data-xocs-content-id="bib0018"><span class="anchor-text-container"><span class="anchor-text">[18]</span></span></a>, <a class="anchor anchor-primary" href="#bib0019" name="bbib0019" data-sd-ui-side-panel-opener="true" data-xocs-content-type="reference" data-xocs-content-id="bib0019"><span class="anchor-text-container"><span class="anchor-text">[19]</span></span></a>.</div><div class="u-margin-s-bottom" id="p0007">Based on the above discussion, in this paper, we proposed three kinds of convolutional neural networks for facial expression recognition in the wild. The first one is a shallow CNN named Light-CNN. The second one is a dual-branch CNN, which is an attempt to integrate traditional features with the original data in a uniform network. The third method is a pre-trained CNN, which is a deep network. We elaborated their architectures and conducted comprehensive experiments on three public facial expression datasets: CK+, BU-3DFE and FER2013. Plenty of comparisons were made among our three CNNs and other state-of-the-art methods. We demonstrated that our proposed methods are significantly better than the previous methods. Meanwhile, we also provided a discussion on the merits and shortcomings of our three <a href="/topics/computer-science/network-architecture" title="Learn more about network architectures from ScienceDirect's AI-generated Topic Pages" class="topic-link">network architectures</a>.</div><div class="u-margin-s-bottom" id="p0008">Our contributions are as follows:<ul class="list"><li class="react-xocs-list-item"><span class="list-label">â€¢</span><span><div class="u-margin-s-bottom" id="p0009"><span>We elaborately designed three representative CNN models for facial expression recognition in the wild, in order to discuss their advantages and disadvantages, and to provide possible solutions for problems of over-fitting, high <a href="/topics/computer-science/computational-complexity" title="Learn more about computational complexity from ScienceDirect's AI-generated Topic Pages" class="topic-link">computational complexity</a>, and lack of </span><a href="/topics/computer-science/training-sample" title="Learn more about training samples from ScienceDirect's AI-generated Topic Pages" class="topic-link">training samples</a> et&nbsp;al. in FER in the wild by deep learning.</div></span></li><li class="react-xocs-list-item"><span class="list-label">â€¢</span><span><div class="u-margin-s-bottom" id="p0010">A large number of experiments are implemented on different facial expression datasets, including CK+, BU-3DFE and FER2013. CK+ is a traditional facial expression dataset. BU-3DFE has samples with different poses but captured in a lab-controlled environment. FER2013 includes face samples captured in the real world.</div></span></li><li class="react-xocs-list-item"><span class="list-label">â€¢</span><span><div class="u-margin-s-bottom" id="p0011">We made comparisons among the three <a href="/topics/engineering/neural-network-architecture" title="Learn more about CNN architectures from ScienceDirect's AI-generated Topic Pages" class="topic-link">CNN architectures</a>, as well as the comparison between our three methods and the state-of-the-art methods. We provide conclusions about different network structures and demonstrated that our proposed methods are competitive with state-of-the-art methods.</div></span></li></ul></div><div class="u-margin-s-bottom" id="p0012">The structure of this paper is as follows: <a class="anchor anchor-primary" href="#sec0002" name="bsec0002" data-sd-ui-side-panel-opener="true" data-xocs-content-type="reference" data-xocs-content-id="sec0002"><span class="anchor-text-container"><span class="anchor-text">Section&nbsp;2</span></span></a> introduces existing state-of-the-art emotion recognition approaches based on CNN, and some traditional feature extraction methods. We introduce our CNNs in details in <a class="anchor anchor-primary" href="#sec0003" name="bsec0003" data-sd-ui-side-panel-opener="true" data-xocs-content-type="reference" data-xocs-content-id="sec0003"><span class="anchor-text-container"><span class="anchor-text">Section&nbsp;3</span></span></a>. <a class="anchor anchor-primary" href="#sec0007" name="bsec0007" data-sd-ui-side-panel-opener="true" data-xocs-content-type="reference" data-xocs-content-id="sec0007"><span class="anchor-text-container"><span class="anchor-text">Section&nbsp;4</span></span></a> describes the datasets along with details of our experiments, and then we present our results and discussions. <a class="anchor anchor-primary" href="#sec0013" name="bsec0013" data-sd-ui-side-panel-opener="true" data-xocs-content-type="reference" data-xocs-content-id="sec0013"><span class="anchor-text-container"><span class="anchor-text">Section&nbsp;5</span></span></a> give a conclusion followed by a list of references.</div></section><section id="sec0002"><h2 id="sctt0004" class="u-h4 u-margin-l-top u-margin-xs-bottom">2. Related work</h2><div class="u-margin-s-bottom" id="p0013"><span>Traditional methods on <a href="/topics/biochemistry-genetics-and-molecular-biology/facial-recognition" title="Learn more about FER from ScienceDirect's AI-generated Topic Pages" class="topic-link">FER</a> can be categorized into three major steps: facial detection, feature extraction and classification, where face detection </span><a class="anchor anchor-primary" href="#bib0020" name="bbib0020" data-sd-ui-side-panel-opener="true" data-xocs-content-type="reference" data-xocs-content-id="bib0020"><span class="anchor-text-container"><span class="anchor-text">[20]</span></span></a>, <a class="anchor anchor-primary" href="#bib0021" name="bbib0021" data-sd-ui-side-panel-opener="true" data-xocs-content-type="reference" data-xocs-content-id="bib0021"><span class="anchor-text-container"><span class="anchor-text">[21]</span></span></a>, <a class="anchor anchor-primary" href="#bib0022" name="bbib0022" data-sd-ui-side-panel-opener="true" data-xocs-content-type="reference" data-xocs-content-id="bib0022"><span class="anchor-text-container"><span class="anchor-text">[22]</span></span></a><span> has become a well-developed technology and been applied to the real-world applications. Extracting powerful features and designing effective classifiers are two key components of FER. For feature-based methods, hand-crafted features are often used to represent expression images. For example, <a href="/topics/engineering/gabor-wavelet" title="Learn more about Gabor wavelets from ScienceDirect's AI-generated Topic Pages" class="topic-link">Gabor wavelets</a> </span><a class="anchor anchor-primary" href="#bib0023" name="bbib0023" data-sd-ui-side-panel-opener="true" data-xocs-content-type="reference" data-xocs-content-id="bib0023"><span class="anchor-text-container"><span class="anchor-text">[23]</span></span></a><span> show good robustness through capturing image edges at different scales and orientations. <a href="/topics/engineering/local-binary-pattern" title="Learn more about Local binary pattern from ScienceDirect's AI-generated Topic Pages" class="topic-link">Local binary pattern</a> (LBP) is demonstrated to be useful in FER. Ying et&nbsp;al. </span><a class="anchor anchor-primary" href="#bib0024" name="bbib0024" data-sd-ui-side-panel-opener="true" data-xocs-content-type="reference" data-xocs-content-id="bib0024"><span class="anchor-text-container"><span class="anchor-text">[24]</span></span></a><span> proposed a facial expression recognition method based on LBP and <a href="/topics/engineering/adaboost" title="Learn more about Adaboost from ScienceDirect's AI-generated Topic Pages" class="topic-link">Adaboost</a> in 2008. LBP was later extended for modeling spatio-temporal features, naming LBP-TOP </span><a class="anchor anchor-primary" href="#bib0025" name="bbib0025" data-sd-ui-side-panel-opener="true" data-xocs-content-type="reference" data-xocs-content-id="bib0025"><span class="anchor-text-container"><span class="anchor-text">[25]</span></span></a>. Later, Qi et&nbsp;al. <a class="anchor anchor-primary" href="#bib0026" name="bbib0026" data-sd-ui-side-panel-opener="true" data-xocs-content-type="reference" data-xocs-content-id="bib0026"><span class="anchor-text-container"><span class="anchor-text">[26]</span></span></a><span> proposed a new expression recognition method based on cognitive and mapping binary patterns. They applied pseudo-3D model to segment face areas into six facial sub-regions. Although the LBP operator is robust to monotonic gray-level changes and computational efficiency, there are some limitations. For example, it is sensitive to noise, and in its <a href="/topics/biochemistry-genetics-and-molecular-biology/dna-template" title="Learn more about template from ScienceDirect's AI-generated Topic Pages" class="topic-link">template</a>, only gradients between the central pixel and its neighborhood are considered. Thus, it inevitably loses some information </span><a class="anchor anchor-primary" href="#bib0027" name="bbib0027" data-sd-ui-side-panel-opener="true" data-xocs-content-type="reference" data-xocs-content-id="bib0027"><span class="anchor-text-container"><span class="anchor-text">[27]</span></span></a><span>. Other features, including <a href="/topics/computer-science/histogram-of-oriented-gradient" title="Learn more about Histograms of Oriented Gradients from ScienceDirect's AI-generated Topic Pages" class="topic-link">Histograms of Oriented Gradients</a> (HOG) </span><a class="anchor anchor-primary" href="#bib0028" name="bbib0028" data-sd-ui-side-panel-opener="true" data-xocs-content-type="reference" data-xocs-content-id="bib0028"><span class="anchor-text-container"><span class="anchor-text">[28]</span></span></a><span>, Scale-Invariant Feature Transform (SIFT), and <a href="/topics/computer-science/singular-value" title="Learn more about Singular Value from ScienceDirect's AI-generated Topic Pages" class="topic-link">Singular Value</a> Decomposition (SVD) </span><a class="anchor anchor-primary" href="#bib0029" name="bbib0029" data-sd-ui-side-panel-opener="true" data-xocs-content-type="reference" data-xocs-content-id="bib0029"><span class="anchor-text-container"><span class="anchor-text">[29]</span></span></a> have also been widely used. In <a class="anchor anchor-primary" href="#bib0030" name="bbib0030" data-sd-ui-side-panel-opener="true" data-xocs-content-type="reference" data-xocs-content-id="bib0030"><span class="anchor-text-container"><span class="anchor-text">[30]</span></span></a>, <a class="anchor anchor-primary" href="#bib0031" name="bbib0031" data-sd-ui-side-panel-opener="true" data-xocs-content-type="reference" data-xocs-content-id="bib0031"><span class="anchor-text-container"><span class="anchor-text">[31]</span></span></a><span>, proved that the <a href="/topics/engineering/singular-value" title="Learn more about singular value from ScienceDirect's AI-generated Topic Pages" class="topic-link">singular value</a><span> of the image can be used as the global feature with invariant scale of rotation shift. These special attributes of the singular value are used to design the compact global feature of <a href="/topics/computer-science/facial-image" title="Learn more about facial image from ScienceDirect's AI-generated Topic Pages" class="topic-link">facial image</a> representation to improve the accuracy of low-resolution face recognition. Facial expression images in the wild are more challenging in face detection, facial landmark location, and pose standardization than traditional facial expression images. Consequently, traditional methods are not suitable for the research on FER in the wild.</span></span></div><div class="u-margin-s-bottom" id="p0014"><span>In recent years, the appearance of <a href="/topics/computer-science/deep-learning" title="Learn more about deep learning from ScienceDirect's AI-generated Topic Pages" class="topic-link">deep learning</a> has significantly improved the performance of FER related tasks </span><a class="anchor anchor-primary" href="#bib0032" name="bbib0032" data-sd-ui-side-panel-opener="true" data-xocs-content-type="reference" data-xocs-content-id="bib0032"><span class="anchor-text-container"><span class="anchor-text">[32]</span></span></a>, <a class="anchor anchor-primary" href="#bib0033" name="bbib0033" data-sd-ui-side-panel-opener="true" data-xocs-content-type="reference" data-xocs-content-id="bib0033"><span class="anchor-text-container"><span class="anchor-text">[33]</span></span></a>, <a class="anchor anchor-primary" href="#bib0034" name="bbib0034" data-sd-ui-side-panel-opener="true" data-xocs-content-type="reference" data-xocs-content-id="bib0034"><span class="anchor-text-container"><span class="anchor-text">[34]</span></span></a>, <a class="anchor anchor-primary" href="#bib0035" name="bbib0035" data-sd-ui-side-panel-opener="true" data-xocs-content-type="reference" data-xocs-content-id="bib0035"><span class="anchor-text-container"><span class="anchor-text">[35]</span></span></a>, <a class="anchor anchor-primary" href="#bib0036" name="bbib0036" data-sd-ui-side-panel-opener="true" data-xocs-content-type="reference" data-xocs-content-id="bib0036"><span class="anchor-text-container"><span class="anchor-text">[36]</span></span></a><span>. Then there were two trends. On the one hand, the FER problem increasingly utilized deeper and <a href="/topics/computer-science/deep-neural-network" title="Learn more about deeper neural networks from ScienceDirect's AI-generated Topic Pages" class="topic-link">deeper neural networks</a> to improve the ability of tackling big-data problems. Mollahossein et&nbsp;al. </span><a class="anchor anchor-primary" href="#bib0032" name="bbib0032" data-sd-ui-side-panel-opener="true" data-xocs-content-type="reference" data-xocs-content-id="bib0032"><span class="anchor-text-container"><span class="anchor-text">[32]</span></span></a><span> proposed an in-depth <a href="/topics/engineering/neural-network-architecture" title="Learn more about neural network architecture from ScienceDirect's AI-generated Topic Pages" class="topic-link">neural network architecture</a> for FER, which was inspired by GoogLeNet and AlexNet. It outperformed traditional methods based on hand-crafted features. Training deep networks with limited data may even result in poor performance due to over-fitting. To solve the problem, Zhang et&nbsp;al. </span><a class="anchor anchor-primary" href="#bib0034" name="bbib0034" data-sd-ui-side-panel-opener="true" data-xocs-content-type="reference" data-xocs-content-id="bib0034"><span class="anchor-text-container"><span class="anchor-text">[34]</span></span></a> proposed a deep neural network (DNN) with the SIFT feature, which achieved the accuracy of 78.9% on the multi-view BU-3DFE dataset. To reduce the influence of various head poses, Jung et&nbsp;al. <a class="anchor anchor-primary" href="#bib0035" name="bbib0035" data-sd-ui-side-panel-opener="true" data-xocs-content-type="reference" data-xocs-content-id="bib0035"><span class="anchor-text-container"><span class="anchor-text">[35]</span></span></a><span><span> proposed a jointly <a href="/topics/computer-science/convolutional-neural-network" title="Learn more about CNNs from ScienceDirect's AI-generated Topic Pages" class="topic-link">CNNs</a> with facial landmarks and color images, which achieved the accuracy of 72.5%, but the network consisted of only three </span><a href="/topics/engineering/convolutional-layer" title="Learn more about convolutional layers from ScienceDirect's AI-generated Topic Pages" class="topic-link">convolutional layers</a><span> and two hidden layers, making it be difficult to accurately learn <a href="/topics/computer-science/facial-feature" title="Learn more about facial features from ScienceDirect's AI-generated Topic Pages" class="topic-link">facial features</a>. Lopes et&nbsp;al. </span></span><a class="anchor anchor-primary" href="#bib0036" name="bbib0036" data-sd-ui-side-panel-opener="true" data-xocs-content-type="reference" data-xocs-content-id="bib0036"><span class="anchor-text-container"><span class="anchor-text">[36]</span></span></a><span> proposed a combination of <a href="/topics/engineering/convolutional-neural-network" title="Learn more about Convolutional Neural Network from ScienceDirect's AI-generated Topic Pages" class="topic-link">Convolutional Neural Network</a> and special image pre-processing steps (C-CNN) to recognize six expressions under head pose at 0</span><sup>âˆ˜</sup><span>, whose accuracy was 90.96% on the BU-3DFE dataset. Its robustness was unknown under different head poses. On the other hand, some works preferred to aggregate different features in deep networks. They demonstrated that comprehensive feature representations had better performance than <a href="/topics/computer-science/single-feature" title="Learn more about single feature from ScienceDirect's AI-generated Topic Pages" class="topic-link">single feature</a>. For example, Majumder et&nbsp;al. </span><a class="anchor anchor-primary" href="#bib0037" name="bbib0037" data-sd-ui-side-panel-opener="true" data-xocs-content-type="reference" data-xocs-content-id="bib0037"><span class="anchor-text-container"><span class="anchor-text">[37]</span></span></a><span><span> fused LBP features and facial <a href="/topics/engineering/geometric-feature" title="Learn more about geometric features from ScienceDirect's AI-generated Topic Pages" class="topic-link">geometric features</a> with a deep network-based technique for FER in the wild, and achieved </span><a href="/topics/computer-science/good-performance" title="Learn more about good performance from ScienceDirect's AI-generated Topic Pages" class="topic-link">good performance</a>. Hamester et&nbsp;al. </span><a class="anchor anchor-primary" href="#bib0038" name="bbib0038" data-sd-ui-side-panel-opener="true" data-xocs-content-type="reference" data-xocs-content-id="bib0038"><span class="anchor-text-container"><span class="anchor-text">[38]</span></span></a> proposed a new architecture by constructing a multi-channel convolutional neural network (MCCNN). It utilized CNN and an automatic encoder to extract features. On the contrary, Alizadeh et&nbsp;al. <a class="anchor anchor-primary" href="#bib0039" name="bbib0039" data-sd-ui-side-panel-opener="true" data-xocs-content-type="reference" data-xocs-content-id="bib0039"><span class="anchor-text-container"><span class="anchor-text">[39]</span></span></a><span> claimed that hybrid feature sets did not help in improving the model accuracy. Therefore, we attempt to provide a dual-branch model solution in this paper which includes both traditional <a href="/topics/computer-science/texture-feature" title="Learn more about texture features from ScienceDirect's AI-generated Topic Pages" class="topic-link">texture features</a> and raw data.</span></div><div class="u-margin-s-bottom" id="p0015"><span>Lack of <a href="/topics/computer-science/training-sample" title="Learn more about training samples from ScienceDirect's AI-generated Topic Pages" class="topic-link">training samples</a> is a big problem for FER in the wild using deep CNNs. To solve this problem, some methods used pre-trained network for classification or re-trained a network model to re-initialize the weights for new datasets </span><a class="anchor anchor-primary" href="#bib0040" name="bbib0040" data-sd-ui-side-panel-opener="true" data-xocs-content-type="reference" data-xocs-content-id="bib0040"><span class="anchor-text-container"><span class="anchor-text">[40]</span></span></a>. The techniques are regarded as â€œtransfer learningâ€. Ruiz-Garcia et&nbsp;al. <a class="anchor anchor-primary" href="#bib0041" name="bbib0041" data-sd-ui-side-panel-opener="true" data-xocs-content-type="reference" data-xocs-content-id="bib0041"><span class="anchor-text-container"><span class="anchor-text">[41]</span></span></a> used greedy layer-wise fashion to pre-train deep CNNs as a stacked convolution auto-encoder (SCAE) for emotion recognition. Employing SCAE as a pre-training model improves not only performance but training time. Yanai et&nbsp;al. <a class="anchor anchor-primary" href="#bib0042" name="bbib0042" data-sd-ui-side-panel-opener="true" data-xocs-content-type="reference" data-xocs-content-id="bib0042"><span class="anchor-text-container"><span class="anchor-text">[42]</span></span></a><span> sought a good combination of DCNN-related techniques. The fine-tuning and activation features were extracted from the pre-trained DCNN. In addition to its high <a href="/topics/engineering/classification-accuracy" title="Learn more about classification accuracy from ScienceDirect's AI-generated Topic Pages" class="topic-link">classification accuracy</a><span>, DCNN was very suitable for large-scale <a href="/topics/engineering/image-data" title="Learn more about image data from ScienceDirect's AI-generated Topic Pages" class="topic-link">image data</a>.</span></span></div></section><section id="sec0003"><h2 id="sctt0005" class="u-h4 u-margin-l-top u-margin-xs-bottom">3. Proposed method</h2><div class="u-margin-s-bottom" id="p0016">In this section, the proposed three CNNs: a Light-CNN, a dual-branch CNN and a Pretrained CNN are described in details.</div><section id="sec0004"><h3 id="sctt0006" class="u-h4 u-margin-m-top u-margin-xs-bottom">3.1. The Light-CNN</h3><div class="u-margin-s-bottom"><div id="p0017">The Light-CNN is a shallow CNN, its architecture is shown in <a class="anchor anchor-primary" href="#fig0001" name="bfig0001" data-sd-ui-side-panel-opener="true" data-xocs-content-type="reference" data-xocs-content-id="fig0001"><span class="anchor-text-container"><span class="anchor-text">Fig.&nbsp;1</span></span></a>. It is a fully convolutional neural network. It consists of 6 depthwise separable residual convolution modules whose architectures are shown in <a class="anchor anchor-primary" href="#fig0002" name="bfig0002" data-sd-ui-side-panel-opener="true" data-xocs-content-type="reference" data-xocs-content-id="fig0002"><span class="anchor-text-container"><span class="anchor-text">Fig.&nbsp;2</span></span></a><span><span>. The architecture of the module was inspired by the Xception and <a href="/topics/computer-science/residual-neural-network" title="Learn more about ResNet from ScienceDirect's AI-generated Topic Pages" class="topic-link">ResNet</a>. We associated the depthwise separable module with the residual network module to build a depthwise separable residual convolution module. The depthwise separable residual convolution module has three separable </span><a href="/topics/computer-science/convolution-layer" title="Learn more about convolution layers from ScienceDirect's AI-generated Topic Pages" class="topic-link">convolution layers</a><span> (SeparableConv2D) and one convolution layer. In the first SeparableConv2D layer, we had 16 1â€¯Ã—â€¯1 filters along with <a href="/topics/computer-science/batch-normalization" title="Learn more about batch normalization from ScienceDirect's AI-generated Topic Pages" class="topic-link">batch normalization</a>, but without max pooling. In the second SeparableConv2D layer, we had 16 3â€¯Ã—â€¯3 filters along with batch normalization, but without max pooling as well. In the third SeparableConv2D layer, we had 16 1â€¯Ã—â€¯1 filters along with batch normalization, as well as max pooling with a filter of size 2â€¯Ã—â€¯2. The number of filters gradually increases from 16 to 512 in 6 modules, as shown in </span></span><a class="anchor anchor-primary" href="#fig0002" name="bfig0002" data-sd-ui-side-panel-opener="true" data-xocs-content-type="reference" data-xocs-content-id="fig0002"><span class="anchor-text-container"><span class="anchor-text">Fig.&nbsp;2</span></span></a>. Each depthwise separable residual convolution module is followed by a Rectified Linear unit (ReLU). The images are resized to be 64â€¯Ã—â€¯64â€¯Ã—â€¯1 pixels before being sent to the network. In the first and the second convolutional layer, we have 8 3â€¯Ã—â€¯3 filters respectively, with the stride of size 1, along with batch normalization and ReLU. They extract low-level edge features of the image and retain the details. The low-level edge features are shown in <a class="anchor anchor-primary" href="#fig0003" name="bfig0003" data-sd-ui-side-panel-opener="true" data-xocs-content-type="reference" data-xocs-content-id="fig0003"><span class="anchor-text-container"><span class="anchor-text">Fig.&nbsp;3</span></span></a>-a. The deep features of the extracted image from first depthwise separable residual convolution modules are shown in <a class="anchor anchor-primary" href="#fig0003" name="bfig0003" data-sd-ui-side-panel-opener="true" data-xocs-content-type="reference" data-xocs-content-id="fig0003"><span class="anchor-text-container"><span class="anchor-text">Fig.&nbsp;3</span></span></a>-b. It can be found that the deeper it is, the more abstract the output features are.</div><figure class="figure text-xs" id="fig0001"><span><img src="https://ars.els-cdn.com/content/image/1-s2.0-S0925231219306137-gr1.jpg" height="529" alt="Fig. 1" aria-describedby="cap0001"><ol class="u-margin-s-bottom"><li><a class="anchor download-link u-font-sans anchor-primary" href="https://ars.els-cdn.com/content/image/1-s2.0-S0925231219306137-gr1_lrg.jpg" target="_blank" download="" title="Download high-res image (800KB)"><span class="anchor-text-container"><span class="anchor-text">Download: <span class="download-link-title">Download high-res image (800KB)</span></span></span></a></li><li><a class="anchor download-link u-font-sans anchor-primary" href="https://ars.els-cdn.com/content/image/1-s2.0-S0925231219306137-gr1.jpg" target="_blank" download="" title="Download full-size image"><span class="anchor-text-container"><span class="anchor-text">Download: <span class="download-link-title">Download full-size image</span></span></span></a></li></ol></span><span class="captions text-s"><span id="cap0001"><p id="sp0005"><span class="label">Fig. 1</span>. The basic structure of the Light-CNN.</p></span></span></figure><figure class="figure text-xs" id="fig0002"><span><img src="https://ars.els-cdn.com/content/image/1-s2.0-S0925231219306137-gr2.jpg" height="805" alt="Fig. 2" aria-describedby="cap0002"><ol class="u-margin-s-bottom"><li><a class="anchor download-link u-font-sans anchor-primary" href="https://ars.els-cdn.com/content/image/1-s2.0-S0925231219306137-gr2_lrg.jpg" target="_blank" download="" title="Download high-res image (2MB)"><span class="anchor-text-container"><span class="anchor-text">Download: <span class="download-link-title">Download high-res image (2MB)</span></span></span></a></li><li><a class="anchor download-link u-font-sans anchor-primary" href="https://ars.els-cdn.com/content/image/1-s2.0-S0925231219306137-gr2.jpg" target="_blank" download="" title="Download full-size image"><span class="anchor-text-container"><span class="anchor-text">Download: <span class="download-link-title">Download full-size image</span></span></span></a></li></ol></span><span class="captions text-s"><span id="cap0002"><p id="sp0006"><span class="label">Fig. 2</span>. The structure of 6 depthwise separable residual convolution modules.</p></span></span></figure><figure class="figure text-xs" id="fig0003"><span><img src="https://ars.els-cdn.com/content/image/1-s2.0-S0925231219306137-gr3.jpg" height="215" alt="Fig. 3" aria-describedby="cap0003"><ol class="u-margin-s-bottom"><li><a class="anchor download-link u-font-sans anchor-primary" href="https://ars.els-cdn.com/content/image/1-s2.0-S0925231219306137-gr3_lrg.jpg" target="_blank" download="" title="Download high-res image (376KB)"><span class="anchor-text-container"><span class="anchor-text">Download: <span class="download-link-title">Download high-res image (376KB)</span></span></span></a></li><li><a class="anchor download-link u-font-sans anchor-primary" href="https://ars.els-cdn.com/content/image/1-s2.0-S0925231219306137-gr3.jpg" target="_blank" download="" title="Download full-size image"><span class="anchor-text-container"><span class="anchor-text">Download: <span class="download-link-title">Download full-size image</span></span></span></a></li></ol></span><span class="captions text-s"><span id="cap0003"><p id="sp0007"><span class="label">Fig. 3</span>. Feature visualization of the image.</p></span></span></figure></div><div class="u-margin-s-bottom" id="p0018"><span><span>After 6 depth wise separable residual convolution modules, we designed a convolutional layer following with a global <a href="/topics/computer-science/average-pooling" title="Learn more about average pooling from ScienceDirect's AI-generated Topic Pages" class="topic-link">average pooling</a> layer to reduce the number of features, and to regularize the entire network to prevent overfitting. The output of the layer is a vector whose dimension is the number of expressions. A softmax layer is at the bottom, which is a generalization of the </span><a href="/topics/computer-science/logistic-regression-model" title="Learn more about logistic regression model from ScienceDirect's AI-generated Topic Pages" class="topic-link">logistic regression model</a> for multi-classification problems. In the multi-classification problem, k possibilities are predicted (k is the number of sample tags). Assume that the input feature is </span><span class="math"><span class="MathJax_Preview" style=""></span><span class="MathJax_SVG" id="MathJax-Element-1-Frame" tabindex="0" data-mathml="<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mrow is=&quot;true&quot;><msup is=&quot;true&quot;><mi is=&quot;true&quot;>x</mi><mrow is=&quot;true&quot;><mo is=&quot;true&quot;>(</mo><mi is=&quot;true&quot;>i</mi><mo is=&quot;true&quot;>)</mo></mrow></msup><mo is=&quot;true&quot;>&amp;#x2208;</mo><msup is=&quot;true&quot;><mi is=&quot;true&quot;>&amp;#x211C;</mi><mrow is=&quot;true&quot;><mi is=&quot;true&quot;>n</mi><mo linebreak=&quot;badbreak&quot; is=&quot;true&quot;>+</mo><mn is=&quot;true&quot;>1</mn></mrow></msup></mrow></math>" role="presentation" style="font-size: 90%; display: inline-block; position: relative;"><svg xmlns:xlink="http://www.w3.org/1999/xlink" width="11.493ex" height="2.432ex" viewBox="0 -945.9 4948.2 1047.3" role="img" focusable="false" style="vertical-align: -0.235ex;" aria-hidden="true"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><g is="true"><g is="true"><g is="true"><use xlink:href="#MJMATHI-78"></use></g><g is="true" transform="translate(572,362)"><g is="true"><use transform="scale(0.707)" xlink:href="#MJMAIN-28"></use></g><g is="true" transform="translate(275,0)"><use transform="scale(0.707)" xlink:href="#MJMATHI-69"></use></g><g is="true" transform="translate(519,0)"><use transform="scale(0.707)" xlink:href="#MJMAIN-29"></use></g></g></g><g is="true" transform="translate(1745,0)"><use xlink:href="#MJMAIN-2208"></use></g><g is="true" transform="translate(2690,0)"><g is="true"><use xlink:href="#MJFRAK-52"></use></g><g is="true" transform="translate(828,362)"><g is="true"><use transform="scale(0.707)" xlink:href="#MJMATHI-6E"></use></g><g is="true" transform="translate(424,0)"><use transform="scale(0.707)" xlink:href="#MJMAIN-2B"></use></g><g is="true" transform="translate(975,0)"><use transform="scale(0.707)" xlink:href="#MJMAIN-31"></use></g></g></g></g></g></svg><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow is="true"><msup is="true"><mi is="true">x</mi><mrow is="true"><mo is="true">(</mo><mi is="true">i</mi><mo is="true">)</mo></mrow></msup><mo is="true">âˆˆ</mo><msup is="true"><mi is="true">â„œ</mi><mrow is="true"><mi is="true">n</mi><mo linebreak="badbreak" is="true">+</mo><mn is="true">1</mn></mrow></msup></mrow></math></span></span><script type="math/mml" id="MathJax-Element-1"><math><mrow is="true"><msup is="true"><mi is="true">x</mi><mrow is="true"><mo is="true">(</mo><mi is="true">i</mi><mo is="true">)</mo></mrow></msup><mo is="true">âˆˆ</mo><msup is="true"><mi is="true">â„œ</mi><mrow is="true"><mi is="true">n</mi><mo linebreak="badbreak" is="true">+</mo><mn is="true">1</mn></mrow></msup></mrow></math></script></span>, and the sample tag is <em>y</em><sup>(<em>i</em>)</sup>, so the training set <span class="math"><span class="MathJax_Preview" style=""></span><span class="MathJax_SVG" id="MathJax-Element-2-Frame" tabindex="0" data-mathml="<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mrow is=&quot;true&quot;><mi is=&quot;true&quot;>S</mi><mo linebreak=&quot;goodbreak&quot; is=&quot;true&quot;>=</mo><mrow is=&quot;true&quot;><mo stretchy=&quot;true&quot; is=&quot;true&quot;>{</mo><mrow is=&quot;true&quot;><mo stretchy=&quot;true&quot; is=&quot;true&quot;>(</mo><msup is=&quot;true&quot;><mi is=&quot;true&quot;>x</mi><mrow is=&quot;true&quot;><mo is=&quot;true&quot;>(</mo><mn is=&quot;true&quot;>1</mn><mo is=&quot;true&quot;>)</mo></mrow></msup><mo is=&quot;true&quot;>,</mo><msup is=&quot;true&quot;><mi is=&quot;true&quot;>y</mi><mrow is=&quot;true&quot;><mo is=&quot;true&quot;>(</mo><mn is=&quot;true&quot;>1</mn><mo is=&quot;true&quot;>)</mo></mrow></msup><mo stretchy=&quot;true&quot; is=&quot;true&quot;>)</mo></mrow><mo is=&quot;true&quot;>,</mo><mrow is=&quot;true&quot;><mo stretchy=&quot;true&quot; is=&quot;true&quot;>(</mo><msup is=&quot;true&quot;><mi is=&quot;true&quot;>x</mi><mrow is=&quot;true&quot;><mo is=&quot;true&quot;>(</mo><mn is=&quot;true&quot;>2</mn><mo is=&quot;true&quot;>)</mo></mrow></msup><mo is=&quot;true&quot;>,</mo><msup is=&quot;true&quot;><mi is=&quot;true&quot;>y</mi><mrow is=&quot;true&quot;><mo is=&quot;true&quot;>(</mo><mn is=&quot;true&quot;>2</mn><mo is=&quot;true&quot;>)</mo></mrow></msup><mo stretchy=&quot;true&quot; is=&quot;true&quot;>)</mo></mrow><mo is=&quot;true&quot;>,</mo><mo is=&quot;true&quot;>&amp;#x2026;</mo><mo is=&quot;true&quot;>,</mo><mrow is=&quot;true&quot;><mo stretchy=&quot;true&quot; is=&quot;true&quot;>(</mo><msup is=&quot;true&quot;><mi is=&quot;true&quot;>x</mi><mrow is=&quot;true&quot;><mo is=&quot;true&quot;>(</mo><mi is=&quot;true&quot;>m</mi><mo is=&quot;true&quot;>)</mo></mrow></msup><mo is=&quot;true&quot;>,</mo><msup is=&quot;true&quot;><mi is=&quot;true&quot;>y</mi><mrow is=&quot;true&quot;><mo is=&quot;true&quot;>(</mo><mi is=&quot;true&quot;>m</mi><mo is=&quot;true&quot;>)</mo></mrow></msup><mo stretchy=&quot;true&quot; is=&quot;true&quot;>)</mo></mrow><mo stretchy=&quot;true&quot; is=&quot;true&quot;>}</mo></mrow></mrow></math>" role="presentation" style="font-size: 90%; display: inline-block; position: relative;"><svg xmlns:xlink="http://www.w3.org/1999/xlink" width="46.499ex" height="3.24ex" viewBox="0 -945.9 20020.5 1395" role="img" focusable="false" style="vertical-align: -1.043ex;" aria-hidden="true"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><g is="true"><g is="true"><use xlink:href="#MJMATHI-53"></use></g><g is="true" transform="translate(923,0)"><use xlink:href="#MJMAIN-3D"></use></g><g is="true" transform="translate(1979,0)"><use xlink:href="#MJSZ1-7B" is="true" x="0" y="-1"></use><g is="true" transform="translate(583,0)"><use xlink:href="#MJSZ1-28" is="true"></use><g is="true" transform="translate(458,0)"><g is="true"><use xlink:href="#MJMATHI-78"></use></g><g is="true" transform="translate(572,362)"><g is="true"><use transform="scale(0.707)" xlink:href="#MJMAIN-28"></use></g><g is="true" transform="translate(275,0)"><use transform="scale(0.707)" xlink:href="#MJMAIN-31"></use></g><g is="true" transform="translate(629,0)"><use transform="scale(0.707)" xlink:href="#MJMAIN-29"></use></g></g></g><g is="true" transform="translate(2035,0)"><use xlink:href="#MJMAIN-2C"></use></g><g is="true" transform="translate(2480,0)"><g is="true"><use xlink:href="#MJMATHI-79"></use></g><g is="true" transform="translate(499,362)"><g is="true"><use transform="scale(0.707)" xlink:href="#MJMAIN-28"></use></g><g is="true" transform="translate(275,0)"><use transform="scale(0.707)" xlink:href="#MJMAIN-31"></use></g><g is="true" transform="translate(629,0)"><use transform="scale(0.707)" xlink:href="#MJMAIN-29"></use></g></g></g><use xlink:href="#MJSZ1-29" is="true" x="3985" y="-1"></use></g><g is="true" transform="translate(5193,0)"><use xlink:href="#MJMAIN-2C"></use></g><g is="true" transform="translate(5639,0)"><use xlink:href="#MJSZ1-28" is="true"></use><g is="true" transform="translate(458,0)"><g is="true"><use xlink:href="#MJMATHI-78"></use></g><g is="true" transform="translate(572,362)"><g is="true"><use transform="scale(0.707)" xlink:href="#MJMAIN-28"></use></g><g is="true" transform="translate(275,0)"><use transform="scale(0.707)" xlink:href="#MJMAIN-32"></use></g><g is="true" transform="translate(629,0)"><use transform="scale(0.707)" xlink:href="#MJMAIN-29"></use></g></g></g><g is="true" transform="translate(2035,0)"><use xlink:href="#MJMAIN-2C"></use></g><g is="true" transform="translate(2480,0)"><g is="true"><use xlink:href="#MJMATHI-79"></use></g><g is="true" transform="translate(499,362)"><g is="true"><use transform="scale(0.707)" xlink:href="#MJMAIN-28"></use></g><g is="true" transform="translate(275,0)"><use transform="scale(0.707)" xlink:href="#MJMAIN-32"></use></g><g is="true" transform="translate(629,0)"><use transform="scale(0.707)" xlink:href="#MJMAIN-29"></use></g></g></g><use xlink:href="#MJSZ1-29" is="true" x="3985" y="-1"></use></g><g is="true" transform="translate(10249,0)"><use xlink:href="#MJMAIN-2C"></use></g><g is="true" transform="translate(10694,0)"><use xlink:href="#MJMAIN-2026"></use></g><g is="true" transform="translate(12033,0)"><use xlink:href="#MJMAIN-2C"></use></g><g is="true" transform="translate(12479,0)"><use xlink:href="#MJSZ1-28" is="true"></use><g is="true" transform="translate(458,0)"><g is="true"><use xlink:href="#MJMATHI-78"></use></g><g is="true" transform="translate(572,362)"><g is="true"><use transform="scale(0.707)" xlink:href="#MJMAIN-28"></use></g><g is="true" transform="translate(275,0)"><use transform="scale(0.707)" xlink:href="#MJMATHI-6D"></use></g><g is="true" transform="translate(896,0)"><use transform="scale(0.707)" xlink:href="#MJMAIN-29"></use></g></g></g><g is="true" transform="translate(2303,0)"><use xlink:href="#MJMAIN-2C"></use></g><g is="true" transform="translate(2748,0)"><g is="true"><use xlink:href="#MJMATHI-79"></use></g><g is="true" transform="translate(499,362)"><g is="true"><use transform="scale(0.707)" xlink:href="#MJMAIN-28"></use></g><g is="true" transform="translate(275,0)"><use transform="scale(0.707)" xlink:href="#MJMATHI-6D"></use></g><g is="true" transform="translate(896,0)"><use transform="scale(0.707)" xlink:href="#MJMAIN-29"></use></g></g></g><use xlink:href="#MJSZ1-29" is="true" x="4519" y="-1"></use></g><use xlink:href="#MJSZ1-7D" is="true" x="17457" y="-1"></use></g></g></g></svg><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow is="true"><mi is="true">S</mi><mo linebreak="goodbreak" is="true">=</mo><mrow is="true"><mo stretchy="true" is="true">{</mo><mrow is="true"><mo stretchy="true" is="true">(</mo><msup is="true"><mi is="true">x</mi><mrow is="true"><mo is="true">(</mo><mn is="true">1</mn><mo is="true">)</mo></mrow></msup><mo is="true">,</mo><msup is="true"><mi is="true">y</mi><mrow is="true"><mo is="true">(</mo><mn is="true">1</mn><mo is="true">)</mo></mrow></msup><mo stretchy="true" is="true">)</mo></mrow><mo is="true">,</mo><mrow is="true"><mo stretchy="true" is="true">(</mo><msup is="true"><mi is="true">x</mi><mrow is="true"><mo is="true">(</mo><mn is="true">2</mn><mo is="true">)</mo></mrow></msup><mo is="true">,</mo><msup is="true"><mi is="true">y</mi><mrow is="true"><mo is="true">(</mo><mn is="true">2</mn><mo is="true">)</mo></mrow></msup><mo stretchy="true" is="true">)</mo></mrow><mo is="true">,</mo><mo is="true">â€¦</mo><mo is="true">,</mo><mrow is="true"><mo stretchy="true" is="true">(</mo><msup is="true"><mi is="true">x</mi><mrow is="true"><mo is="true">(</mo><mi is="true">m</mi><mo is="true">)</mo></mrow></msup><mo is="true">,</mo><msup is="true"><mi is="true">y</mi><mrow is="true"><mo is="true">(</mo><mi is="true">m</mi><mo is="true">)</mo></mrow></msup><mo stretchy="true" is="true">)</mo></mrow><mo stretchy="true" is="true">}</mo></mrow></mrow></math></span></span><script type="math/mml" id="MathJax-Element-2"><math><mrow is="true"><mi is="true">S</mi><mo linebreak="goodbreak" is="true">=</mo><mrow is="true"><mo stretchy="true" is="true">{</mo><mrow is="true"><mo stretchy="true" is="true">(</mo><msup is="true"><mi is="true">x</mi><mrow is="true"><mo is="true">(</mo><mn is="true">1</mn><mo is="true">)</mo></mrow></msup><mo is="true">,</mo><msup is="true"><mi is="true">y</mi><mrow is="true"><mo is="true">(</mo><mn is="true">1</mn><mo is="true">)</mo></mrow></msup><mo stretchy="true" is="true">)</mo></mrow><mo is="true">,</mo><mrow is="true"><mo stretchy="true" is="true">(</mo><msup is="true"><mi is="true">x</mi><mrow is="true"><mo is="true">(</mo><mn is="true">2</mn><mo is="true">)</mo></mrow></msup><mo is="true">,</mo><msup is="true"><mi is="true">y</mi><mrow is="true"><mo is="true">(</mo><mn is="true">2</mn><mo is="true">)</mo></mrow></msup><mo stretchy="true" is="true">)</mo></mrow><mo is="true">,</mo><mo is="true">â€¦</mo><mo is="true">,</mo><mrow is="true"><mo stretchy="true" is="true">(</mo><msup is="true"><mi is="true">x</mi><mrow is="true"><mo is="true">(</mo><mi is="true">m</mi><mo is="true">)</mo></mrow></msup><mo is="true">,</mo><msup is="true"><mi is="true">y</mi><mrow is="true"><mo is="true">(</mo><mi is="true">m</mi><mo is="true">)</mo></mrow></msup><mo stretchy="true" is="true">)</mo></mrow><mo stretchy="true" is="true">}</mo></mrow></mrow></math></script></span><span> of the supervised learning constitutes the classification layer. Then the function and <a href="/topics/engineering/cost-function" title="Learn more about cost function from ScienceDirect's AI-generated Topic Pages" class="topic-link">cost function</a> forms are as follows:</span><span class="display"><span id="eq0001" class="formula"><span class="label">(1)</span><span class="math"><span class="MathJax_Preview" style=""></span><span class="MathJax_SVG" id="MathJax-Element-3-Frame" tabindex="0" data-mathml="<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mrow is=&quot;true&quot;><msub is=&quot;true&quot;><mi is=&quot;true&quot;>h</mi><mi is=&quot;true&quot;>&amp;#x3B8;</mi></msub><mrow is=&quot;true&quot;><mo stretchy=&quot;true&quot; is=&quot;true&quot;>(</mo><msup is=&quot;true&quot;><mi is=&quot;true&quot;>x</mi><mrow is=&quot;true&quot;><mo is=&quot;true&quot;>(</mo><mi is=&quot;true&quot;>i</mi><mo is=&quot;true&quot;>)</mo></mrow></msup><mo stretchy=&quot;true&quot; is=&quot;true&quot;>)</mo></mrow><mo linebreak=&quot;goodbreak&quot; is=&quot;true&quot;>=</mo><mrow is=&quot;true&quot;><mo stretchy=&quot;true&quot; is=&quot;true&quot;>[</mo><mtable is=&quot;true&quot;><mtr is=&quot;true&quot;><mtd is=&quot;true&quot;><mrow is=&quot;true&quot;><mi is=&quot;true&quot;>p</mi><mrow is=&quot;true&quot;><mo stretchy=&quot;true&quot; is=&quot;true&quot;>(</mo><msup is=&quot;true&quot;><mi is=&quot;true&quot;>y</mi><mrow is=&quot;true&quot;><mo is=&quot;true&quot;>(</mo><mi is=&quot;true&quot;>i</mi><mo is=&quot;true&quot;>)</mo></mrow></msup><mrow is=&quot;true&quot;><mo is=&quot;true&quot;>=</mo><mn is=&quot;true&quot;>1</mn><mo is=&quot;true&quot;>|</mo></mrow><msup is=&quot;true&quot;><mi is=&quot;true&quot;>x</mi><mrow is=&quot;true&quot;><mo is=&quot;true&quot;>(</mo><mi is=&quot;true&quot;>i</mi><mo is=&quot;true&quot;>)</mo></mrow></msup><mo is=&quot;true&quot;>;</mo><mi is=&quot;true&quot;>&amp;#x3B8;</mi><mo stretchy=&quot;true&quot; is=&quot;true&quot;>)</mo></mrow></mrow></mtd></mtr><mtr is=&quot;true&quot;><mtd is=&quot;true&quot; /></mtr><mtr is=&quot;true&quot;><mtd is=&quot;true&quot;><mrow is=&quot;true&quot;><mi is=&quot;true&quot;>p</mi><mrow is=&quot;true&quot;><mo stretchy=&quot;true&quot; is=&quot;true&quot;>(</mo><msup is=&quot;true&quot;><mi is=&quot;true&quot;>y</mi><mrow is=&quot;true&quot;><mo is=&quot;true&quot;>(</mo><mi is=&quot;true&quot;>i</mi><mo is=&quot;true&quot;>)</mo></mrow></msup><mrow is=&quot;true&quot;><mo is=&quot;true&quot;>=</mo><mn is=&quot;true&quot;>2</mn><mo is=&quot;true&quot;>|</mo></mrow><msup is=&quot;true&quot;><mi is=&quot;true&quot;>x</mi><mrow is=&quot;true&quot;><mo is=&quot;true&quot;>(</mo><mi is=&quot;true&quot;>i</mi><mo is=&quot;true&quot;>)</mo></mrow></msup><mo is=&quot;true&quot;>;</mo><mi is=&quot;true&quot;>&amp;#x3B8;</mi><mo stretchy=&quot;true&quot; is=&quot;true&quot;>)</mo></mrow></mrow></mtd></mtr><mtr is=&quot;true&quot;><mtd is=&quot;true&quot; /></mtr><mtr is=&quot;true&quot;><mtd is=&quot;true&quot;><mo is=&quot;true&quot;>&amp;#x22EE;</mo></mtd></mtr><mtr is=&quot;true&quot;><mtd is=&quot;true&quot; /></mtr><mtr is=&quot;true&quot;><mtd is=&quot;true&quot;><mrow is=&quot;true&quot;><mi is=&quot;true&quot;>p</mi><mrow is=&quot;true&quot;><mo stretchy=&quot;true&quot; is=&quot;true&quot;>(</mo><msup is=&quot;true&quot;><mi is=&quot;true&quot;>y</mi><mrow is=&quot;true&quot;><mo is=&quot;true&quot;>(</mo><mi is=&quot;true&quot;>i</mi><mo is=&quot;true&quot;>)</mo></mrow></msup><mrow is=&quot;true&quot;><mo is=&quot;true&quot;>=</mo><mi is=&quot;true&quot;>k</mi><mo is=&quot;true&quot;>|</mo></mrow><msup is=&quot;true&quot;><mi is=&quot;true&quot;>x</mi><mrow is=&quot;true&quot;><mo is=&quot;true&quot;>(</mo><mi is=&quot;true&quot;>i</mi><mo is=&quot;true&quot;>)</mo></mrow></msup><mo is=&quot;true&quot;>;</mo><mi is=&quot;true&quot;>&amp;#x3B8;</mi><mo stretchy=&quot;true&quot; is=&quot;true&quot;>)</mo></mrow></mrow></mtd></mtr></mtable><mo stretchy=&quot;true&quot; is=&quot;true&quot;>]</mo></mrow><mo linebreak=&quot;goodbreak&quot; is=&quot;true&quot;>=</mo><mfrac is=&quot;true&quot;><mn is=&quot;true&quot;>1</mn><mrow is=&quot;true&quot;><munderover is=&quot;true&quot;><mo is=&quot;true&quot;>&amp;#x2211;</mo><mrow is=&quot;true&quot;><mi is=&quot;true&quot;>j</mi><mo is=&quot;true&quot;>=</mo><mn is=&quot;true&quot;>1</mn></mrow><mi is=&quot;true&quot;>k</mi></munderover><msup is=&quot;true&quot;><mi is=&quot;true&quot;>e</mi><mrow is=&quot;true&quot;><msubsup is=&quot;true&quot;><mi is=&quot;true&quot;>&amp;#x3B8;</mi><mi is=&quot;true&quot;>j</mi><mi is=&quot;true&quot;>T</mi></msubsup><msup is=&quot;true&quot;><mi is=&quot;true&quot;>x</mi><mrow is=&quot;true&quot;><mo is=&quot;true&quot;>(</mo><mi is=&quot;true&quot;>i</mi><mo is=&quot;true&quot;>)</mo></mrow></msup></mrow></msup></mrow></mfrac><mrow is=&quot;true&quot;><mo stretchy=&quot;true&quot; is=&quot;true&quot;>[</mo><mtable is=&quot;true&quot;><mtr is=&quot;true&quot;><mtd is=&quot;true&quot;><msup is=&quot;true&quot;><mi is=&quot;true&quot;>e</mi><mrow is=&quot;true&quot;><msubsup is=&quot;true&quot;><mi is=&quot;true&quot;>&amp;#x3B8;</mi><mn is=&quot;true&quot;>1</mn><mi is=&quot;true&quot;>T</mi></msubsup><msup is=&quot;true&quot;><mi is=&quot;true&quot;>x</mi><mrow is=&quot;true&quot;><mo is=&quot;true&quot;>(</mo><mi is=&quot;true&quot;>i</mi><mo is=&quot;true&quot;>)</mo></mrow></msup></mrow></msup></mtd></mtr><mtr is=&quot;true&quot;><mtd is=&quot;true&quot; /></mtr><mtr is=&quot;true&quot;><mtd is=&quot;true&quot;><msup is=&quot;true&quot;><mi is=&quot;true&quot;>e</mi><mrow is=&quot;true&quot;><msubsup is=&quot;true&quot;><mi is=&quot;true&quot;>&amp;#x3B8;</mi><mn is=&quot;true&quot;>2</mn><mi is=&quot;true&quot;>T</mi></msubsup><msup is=&quot;true&quot;><mi is=&quot;true&quot;>x</mi><mrow is=&quot;true&quot;><mo is=&quot;true&quot;>(</mo><mi is=&quot;true&quot;>i</mi><mo is=&quot;true&quot;>)</mo></mrow></msup></mrow></msup></mtd></mtr><mtr is=&quot;true&quot;><mtd is=&quot;true&quot; /></mtr><mtr is=&quot;true&quot;><mtd is=&quot;true&quot;><mo is=&quot;true&quot;>&amp;#x22EE;</mo></mtd></mtr><mtr is=&quot;true&quot;><mtd is=&quot;true&quot; /></mtr><mtr is=&quot;true&quot;><mtd is=&quot;true&quot;><msup is=&quot;true&quot;><mi is=&quot;true&quot;>e</mi><mrow is=&quot;true&quot;><msubsup is=&quot;true&quot;><mi is=&quot;true&quot;>&amp;#x3B8;</mi><mi is=&quot;true&quot;>k</mi><mi is=&quot;true&quot;>T</mi></msubsup><msup is=&quot;true&quot;><mi is=&quot;true&quot;>x</mi><mrow is=&quot;true&quot;><mo is=&quot;true&quot;>(</mo><mi is=&quot;true&quot;>i</mi><mo is=&quot;true&quot;>)</mo></mrow></msup></mrow></msup></mtd></mtr></mtable><mo stretchy=&quot;true&quot; is=&quot;true&quot;>]</mo></mrow></mrow></math>" role="presentation" style="font-size: 90%; display: inline-block; position: relative;"><svg xmlns:xlink="http://www.w3.org/1999/xlink" width="54.626ex" height="25.394ex" viewBox="0 -5715.1 23519.5 10933.4" role="img" focusable="false" style="vertical-align: -12.12ex;" aria-hidden="true"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><g is="true"><g is="true"><g is="true"><use xlink:href="#MJMATHI-68"></use></g><g is="true" transform="translate(576,-155)"><use transform="scale(0.707)" xlink:href="#MJMATHI-3B8"></use></g></g><g is="true" transform="translate(1175,0)"><use xlink:href="#MJSZ1-28" is="true"></use><g is="true" transform="translate(458,0)"><g is="true"><use xlink:href="#MJMATHI-78"></use></g><g is="true" transform="translate(572,362)"><g is="true"><use transform="scale(0.707)" xlink:href="#MJMAIN-28"></use></g><g is="true" transform="translate(275,0)"><use transform="scale(0.707)" xlink:href="#MJMATHI-69"></use></g><g is="true" transform="translate(519,0)"><use transform="scale(0.707)" xlink:href="#MJMAIN-29"></use></g></g></g><use xlink:href="#MJSZ1-29" is="true" x="1926" y="-1"></use></g><g is="true" transform="translate(3837,0)"><use xlink:href="#MJMAIN-3D"></use></g><g is="true" transform="translate(4893,0)"><g is="true" transform="translate(0,5658)"><use xlink:href="#MJSZ4-23A1" x="0" y="-1155"></use><g transform="translate(0,-9054.499638314595) scale(1,12.111939698697505)"><use xlink:href="#MJSZ4-23A2"></use></g><use xlink:href="#MJSZ4-23A3" x="0" y="-10173"></use></g><g is="true" transform="translate(834,0)"><g transform="translate(-16,0)"><g is="true" transform="translate(10,4764)"><g is="true"><g is="true"><use xlink:href="#MJMATHI-70"></use></g><g is="true" transform="translate(670,0)"><use xlink:href="#MJSZ1-28" is="true"></use><g is="true" transform="translate(458,0)"><g is="true"><use xlink:href="#MJMATHI-79"></use></g><g is="true" transform="translate(499,362)"><g is="true"><use transform="scale(0.707)" xlink:href="#MJMAIN-28"></use></g><g is="true" transform="translate(275,0)"><use transform="scale(0.707)" xlink:href="#MJMATHI-69"></use></g><g is="true" transform="translate(519,0)"><use transform="scale(0.707)" xlink:href="#MJMAIN-29"></use></g></g></g><g is="true" transform="translate(2131,0)"><g is="true"><use xlink:href="#MJMAIN-3D"></use></g><g is="true" transform="translate(1056,0)"><use xlink:href="#MJMAIN-31"></use></g><g is="true" transform="translate(1556,0)"><use xlink:href="#MJMAIN-7C"></use></g></g><g is="true" transform="translate(3966,0)"><g is="true"><use xlink:href="#MJMATHI-78"></use></g><g is="true" transform="translate(572,362)"><g is="true"><use transform="scale(0.707)" xlink:href="#MJMAIN-28"></use></g><g is="true" transform="translate(275,0)"><use transform="scale(0.707)" xlink:href="#MJMATHI-69"></use></g><g is="true" transform="translate(519,0)"><use transform="scale(0.707)" xlink:href="#MJMAIN-29"></use></g></g></g><g is="true" transform="translate(5433,0)"><use xlink:href="#MJMAIN-3B"></use></g><g is="true" transform="translate(5879,0)"><use xlink:href="#MJMATHI-3B8"></use></g><use xlink:href="#MJSZ1-29" is="true" x="6348" y="-1"></use></g></g></g><g is="true"></g><g is="true" transform="translate(10,1659)"><g is="true"><g is="true"><use xlink:href="#MJMATHI-70"></use></g><g is="true" transform="translate(670,0)"><use xlink:href="#MJSZ1-28" is="true"></use><g is="true" transform="translate(458,0)"><g is="true"><use xlink:href="#MJMATHI-79"></use></g><g is="true" transform="translate(499,362)"><g is="true"><use transform="scale(0.707)" xlink:href="#MJMAIN-28"></use></g><g is="true" transform="translate(275,0)"><use transform="scale(0.707)" xlink:href="#MJMATHI-69"></use></g><g is="true" transform="translate(519,0)"><use transform="scale(0.707)" xlink:href="#MJMAIN-29"></use></g></g></g><g is="true" transform="translate(2131,0)"><g is="true"><use xlink:href="#MJMAIN-3D"></use></g><g is="true" transform="translate(1056,0)"><use xlink:href="#MJMAIN-32"></use></g><g is="true" transform="translate(1556,0)"><use xlink:href="#MJMAIN-7C"></use></g></g><g is="true" transform="translate(3966,0)"><g is="true"><use xlink:href="#MJMATHI-78"></use></g><g is="true" transform="translate(572,362)"><g is="true"><use transform="scale(0.707)" xlink:href="#MJMAIN-28"></use></g><g is="true" transform="translate(275,0)"><use transform="scale(0.707)" xlink:href="#MJMATHI-69"></use></g><g is="true" transform="translate(519,0)"><use transform="scale(0.707)" xlink:href="#MJMAIN-29"></use></g></g></g><g is="true" transform="translate(5433,0)"><use xlink:href="#MJMAIN-3B"></use></g><g is="true" transform="translate(5879,0)"><use xlink:href="#MJMATHI-3B8"></use></g><use xlink:href="#MJSZ1-29" is="true" x="6348" y="-1"></use></g></g></g><g is="true"></g><g is="true" transform="translate(3609,-1854)"><g is="true"><use xlink:href="#MJMAIN-22EE"></use></g></g><g is="true"></g><g is="true" transform="translate(0,-4809)"><g is="true"><g is="true"><use xlink:href="#MJMATHI-70"></use></g><g is="true" transform="translate(670,0)"><use xlink:href="#MJSZ1-28" is="true"></use><g is="true" transform="translate(458,0)"><g is="true"><use xlink:href="#MJMATHI-79"></use></g><g is="true" transform="translate(499,362)"><g is="true"><use transform="scale(0.707)" xlink:href="#MJMAIN-28"></use></g><g is="true" transform="translate(275,0)"><use transform="scale(0.707)" xlink:href="#MJMATHI-69"></use></g><g is="true" transform="translate(519,0)"><use transform="scale(0.707)" xlink:href="#MJMAIN-29"></use></g></g></g><g is="true" transform="translate(2131,0)"><g is="true"><use xlink:href="#MJMAIN-3D"></use></g><g is="true" transform="translate(1056,0)"><use xlink:href="#MJMATHI-6B"></use></g><g is="true" transform="translate(1577,0)"><use xlink:href="#MJMAIN-7C"></use></g></g><g is="true" transform="translate(3987,0)"><g is="true"><use xlink:href="#MJMATHI-78"></use></g><g is="true" transform="translate(572,362)"><g is="true"><use transform="scale(0.707)" xlink:href="#MJMAIN-28"></use></g><g is="true" transform="translate(275,0)"><use transform="scale(0.707)" xlink:href="#MJMATHI-69"></use></g><g is="true" transform="translate(519,0)"><use transform="scale(0.707)" xlink:href="#MJMAIN-29"></use></g></g></g><g is="true" transform="translate(5454,0)"><use xlink:href="#MJMAIN-3B"></use></g><g is="true" transform="translate(5900,0)"><use xlink:href="#MJMATHI-3B8"></use></g><use xlink:href="#MJSZ1-29" is="true" x="6369" y="-1"></use></g></g></g></g></g><g is="true" transform="translate(8484,5658)"><use xlink:href="#MJSZ4-23A4" x="0" y="-1155"></use><g transform="translate(0,-9054.499638314595) scale(1,12.111939698697505)"><use xlink:href="#MJSZ4-23A5"></use></g><use xlink:href="#MJSZ4-23A6" x="0" y="-10173"></use></g></g><g is="true" transform="translate(14323,0)"><use xlink:href="#MJMAIN-3D"></use></g><g is="true" transform="translate(15102,0)"><g transform="translate(397,0)"><rect stroke="none" width="3886" height="60" x="0" y="220"></rect><g is="true" transform="translate(1766,403)"><use transform="scale(0.707)" xlink:href="#MJMAIN-31"></use></g><g is="true" transform="translate(60,-886)"><g is="true"><g is="true"><use transform="scale(0.707)" xlink:href="#MJSZ1-2211"></use></g><g is="true" transform="translate(747,337)"><use transform="scale(0.5)" xlink:href="#MJMATHI-6B"></use></g><g is="true" transform="translate(747,-203)"><g is="true"><use transform="scale(0.5)" xlink:href="#MJMATHI-6A"></use></g><g is="true" transform="translate(206,0)"><use transform="scale(0.5)" xlink:href="#MJMAIN-3D"></use></g><g is="true" transform="translate(595,0)"><use transform="scale(0.5)" xlink:href="#MJMAIN-31"></use></g></g></g><g is="true" transform="translate(1830,0)"><g is="true"><use transform="scale(0.707)" xlink:href="#MJMATHI-65"></use></g><g is="true" transform="translate(329,427)"><g is="true"><g is="true"><use transform="scale(0.5)" xlink:href="#MJMATHI-3B8"></use></g><g is="true" transform="translate(234,172)"><use transform="scale(0.5)" xlink:href="#MJMATHI-54"></use></g><g is="true" transform="translate(234,-249)"><use transform="scale(0.5)" xlink:href="#MJMATHI-6A"></use></g></g><g is="true" transform="translate(637,0)"><g is="true"><use transform="scale(0.5)" xlink:href="#MJMATHI-78"></use></g><g is="true" transform="translate(286,179)"><g is="true"><use transform="scale(0.5)" xlink:href="#MJMAIN-28"></use></g><g is="true" transform="translate(194,0)"><use transform="scale(0.5)" xlink:href="#MJMATHI-69"></use></g><g is="true" transform="translate(367,0)"><use transform="scale(0.5)" xlink:href="#MJMAIN-29"></use></g></g></g></g></g></g></g></g><g is="true" transform="translate(19506,0)"><g is="true" transform="translate(0,5604)"><use xlink:href="#MJSZ4-23A1" x="0" y="-1155"></use><g transform="translate(0,-8945.558887449544) scale(1,11.93127510356475)"><use xlink:href="#MJSZ4-23A2"></use></g><use xlink:href="#MJSZ4-23A3" x="0" y="-10064"></use></g><g is="true" transform="translate(834,0)"><g transform="translate(-16,0)"><g is="true" transform="translate(0,4596)"><g is="true"><g is="true"><use xlink:href="#MJMATHI-65"></use></g><g is="true" transform="translate(466,362)"><g is="true"><g is="true"><use transform="scale(0.707)" xlink:href="#MJMATHI-3B8"></use></g><g is="true" transform="translate(331,306)"><use transform="scale(0.5)" xlink:href="#MJMATHI-54"></use></g><g is="true" transform="translate(331,-175)"><use transform="scale(0.5)" xlink:href="#MJMAIN-31"></use></g></g><g is="true" transform="translate(754,0)"><g is="true"><use transform="scale(0.707)" xlink:href="#MJMATHI-78"></use></g><g is="true" transform="translate(404,256)"><g is="true"><use transform="scale(0.5)" xlink:href="#MJMAIN-28"></use></g><g is="true" transform="translate(194,0)"><use transform="scale(0.5)" xlink:href="#MJMATHI-69"></use></g><g is="true" transform="translate(367,0)"><use transform="scale(0.5)" xlink:href="#MJMAIN-29"></use></g></g></g></g></g></g><g is="true"></g><g is="true" transform="translate(0,1527)"><g is="true"><g is="true"><use xlink:href="#MJMATHI-65"></use></g><g is="true" transform="translate(466,362)"><g is="true"><g is="true"><use transform="scale(0.707)" xlink:href="#MJMATHI-3B8"></use></g><g is="true" transform="translate(331,306)"><use transform="scale(0.5)" xlink:href="#MJMATHI-54"></use></g><g is="true" transform="translate(331,-175)"><use transform="scale(0.5)" xlink:href="#MJMAIN-32"></use></g></g><g is="true" transform="translate(754,0)"><g is="true"><use transform="scale(0.707)" xlink:href="#MJMATHI-78"></use></g><g is="true" transform="translate(404,256)"><g is="true"><use transform="scale(0.5)" xlink:href="#MJMAIN-28"></use></g><g is="true" transform="translate(194,0)"><use transform="scale(0.5)" xlink:href="#MJMATHI-69"></use></g><g is="true" transform="translate(367,0)"><use transform="scale(0.5)" xlink:href="#MJMAIN-29"></use></g></g></g></g></g></g><g is="true"></g><g is="true" transform="translate(1040,-1836)"><g is="true"><use xlink:href="#MJMAIN-22EE"></use></g></g><g is="true"></g><g is="true" transform="translate(0,-4905)"><g is="true"><g is="true"><use xlink:href="#MJMATHI-65"></use></g><g is="true" transform="translate(466,362)"><g is="true"><g is="true"><use transform="scale(0.707)" xlink:href="#MJMATHI-3B8"></use></g><g is="true" transform="translate(331,306)"><use transform="scale(0.5)" xlink:href="#MJMATHI-54"></use></g><g is="true" transform="translate(331,-175)"><use transform="scale(0.5)" xlink:href="#MJMATHI-6B"></use></g></g><g is="true" transform="translate(754,0)"><g is="true"><use transform="scale(0.707)" xlink:href="#MJMATHI-78"></use></g><g is="true" transform="translate(404,256)"><g is="true"><use transform="scale(0.5)" xlink:href="#MJMAIN-28"></use></g><g is="true" transform="translate(194,0)"><use transform="scale(0.5)" xlink:href="#MJMATHI-69"></use></g><g is="true" transform="translate(367,0)"><use transform="scale(0.5)" xlink:href="#MJMAIN-29"></use></g></g></g></g></g></g></g></g><g is="true" transform="translate(3345,5604)"><use xlink:href="#MJSZ4-23A4" x="0" y="-1155"></use><g transform="translate(0,-8945.558887449544) scale(1,11.93127510356475)"><use xlink:href="#MJSZ4-23A5"></use></g><use xlink:href="#MJSZ4-23A6" x="0" y="-10064"></use></g></g></g></g></svg><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow is="true"><msub is="true"><mi is="true">h</mi><mi is="true">Î¸</mi></msub><mrow is="true"><mo stretchy="true" is="true">(</mo><msup is="true"><mi is="true">x</mi><mrow is="true"><mo is="true">(</mo><mi is="true">i</mi><mo is="true">)</mo></mrow></msup><mo stretchy="true" is="true">)</mo></mrow><mo linebreak="goodbreak" is="true">=</mo><mrow is="true"><mo stretchy="true" is="true">[</mo><mtable is="true"><mtr is="true"><mtd is="true"><mrow is="true"><mi is="true">p</mi><mrow is="true"><mo stretchy="true" is="true">(</mo><msup is="true"><mi is="true">y</mi><mrow is="true"><mo is="true">(</mo><mi is="true">i</mi><mo is="true">)</mo></mrow></msup><mrow is="true"><mo is="true">=</mo><mn is="true">1</mn><mo is="true">|</mo></mrow><msup is="true"><mi is="true">x</mi><mrow is="true"><mo is="true">(</mo><mi is="true">i</mi><mo is="true">)</mo></mrow></msup><mo is="true">;</mo><mi is="true">Î¸</mi><mo stretchy="true" is="true">)</mo></mrow></mrow></mtd></mtr><mtr is="true"><mtd is="true"></mtd></mtr><mtr is="true"><mtd is="true"><mrow is="true"><mi is="true">p</mi><mrow is="true"><mo stretchy="true" is="true">(</mo><msup is="true"><mi is="true">y</mi><mrow is="true"><mo is="true">(</mo><mi is="true">i</mi><mo is="true">)</mo></mrow></msup><mrow is="true"><mo is="true">=</mo><mn is="true">2</mn><mo is="true">|</mo></mrow><msup is="true"><mi is="true">x</mi><mrow is="true"><mo is="true">(</mo><mi is="true">i</mi><mo is="true">)</mo></mrow></msup><mo is="true">;</mo><mi is="true">Î¸</mi><mo stretchy="true" is="true">)</mo></mrow></mrow></mtd></mtr><mtr is="true"><mtd is="true"></mtd></mtr><mtr is="true"><mtd is="true"><mo is="true">â‹®</mo></mtd></mtr><mtr is="true"><mtd is="true"></mtd></mtr><mtr is="true"><mtd is="true"><mrow is="true"><mi is="true">p</mi><mrow is="true"><mo stretchy="true" is="true">(</mo><msup is="true"><mi is="true">y</mi><mrow is="true"><mo is="true">(</mo><mi is="true">i</mi><mo is="true">)</mo></mrow></msup><mrow is="true"><mo is="true">=</mo><mi is="true">k</mi><mo is="true">|</mo></mrow><msup is="true"><mi is="true">x</mi><mrow is="true"><mo is="true">(</mo><mi is="true">i</mi><mo is="true">)</mo></mrow></msup><mo is="true">;</mo><mi is="true">Î¸</mi><mo stretchy="true" is="true">)</mo></mrow></mrow></mtd></mtr></mtable><mo stretchy="true" is="true">]</mo></mrow><mo linebreak="goodbreak" is="true">=</mo><mfrac is="true"><mn is="true">1</mn><mrow is="true"><munderover is="true"><mo is="true">âˆ‘</mo><mrow is="true"><mi is="true">j</mi><mo is="true">=</mo><mn is="true">1</mn></mrow><mi is="true">k</mi></munderover><msup is="true"><mi is="true">e</mi><mrow is="true"><msubsup is="true"><mi is="true">Î¸</mi><mi is="true">j</mi><mi is="true">T</mi></msubsup><msup is="true"><mi is="true">x</mi><mrow is="true"><mo is="true">(</mo><mi is="true">i</mi><mo is="true">)</mo></mrow></msup></mrow></msup></mrow></mfrac><mrow is="true"><mo stretchy="true" is="true">[</mo><mtable is="true"><mtr is="true"><mtd is="true"><msup is="true"><mi is="true">e</mi><mrow is="true"><msubsup is="true"><mi is="true">Î¸</mi><mn is="true">1</mn><mi is="true">T</mi></msubsup><msup is="true"><mi is="true">x</mi><mrow is="true"><mo is="true">(</mo><mi is="true">i</mi><mo is="true">)</mo></mrow></msup></mrow></msup></mtd></mtr><mtr is="true"><mtd is="true"></mtd></mtr><mtr is="true"><mtd is="true"><msup is="true"><mi is="true">e</mi><mrow is="true"><msubsup is="true"><mi is="true">Î¸</mi><mn is="true">2</mn><mi is="true">T</mi></msubsup><msup is="true"><mi is="true">x</mi><mrow is="true"><mo is="true">(</mo><mi is="true">i</mi><mo is="true">)</mo></mrow></msup></mrow></msup></mtd></mtr><mtr is="true"><mtd is="true"></mtd></mtr><mtr is="true"><mtd is="true"><mo is="true">â‹®</mo></mtd></mtr><mtr is="true"><mtd is="true"></mtd></mtr><mtr is="true"><mtd is="true"><msup is="true"><mi is="true">e</mi><mrow is="true"><msubsup is="true"><mi is="true">Î¸</mi><mi is="true">k</mi><mi is="true">T</mi></msubsup><msup is="true"><mi is="true">x</mi><mrow is="true"><mo is="true">(</mo><mi is="true">i</mi><mo is="true">)</mo></mrow></msup></mrow></msup></mtd></mtr></mtable><mo stretchy="true" is="true">]</mo></mrow></mrow></math></span></span><script type="math/mml" id="MathJax-Element-3"><math><mrow is="true"><msub is="true"><mi is="true">h</mi><mi is="true">Î¸</mi></msub><mrow is="true"><mo stretchy="true" is="true">(</mo><msup is="true"><mi is="true">x</mi><mrow is="true"><mo is="true">(</mo><mi is="true">i</mi><mo is="true">)</mo></mrow></msup><mo stretchy="true" is="true">)</mo></mrow><mo linebreak="goodbreak" is="true">=</mo><mrow is="true"><mo stretchy="true" is="true">[</mo><mtable is="true"><mtr is="true"><mtd is="true"><mrow is="true"><mi is="true">p</mi><mrow is="true"><mo stretchy="true" is="true">(</mo><msup is="true"><mi is="true">y</mi><mrow is="true"><mo is="true">(</mo><mi is="true">i</mi><mo is="true">)</mo></mrow></msup><mrow is="true"><mo is="true">=</mo><mn is="true">1</mn><mo is="true">|</mo></mrow><msup is="true"><mi is="true">x</mi><mrow is="true"><mo is="true">(</mo><mi is="true">i</mi><mo is="true">)</mo></mrow></msup><mo is="true">;</mo><mi is="true">Î¸</mi><mo stretchy="true" is="true">)</mo></mrow></mrow></mtd></mtr><mtr is="true"><mtd is="true"></mtd></mtr><mtr is="true"><mtd is="true"><mrow is="true"><mi is="true">p</mi><mrow is="true"><mo stretchy="true" is="true">(</mo><msup is="true"><mi is="true">y</mi><mrow is="true"><mo is="true">(</mo><mi is="true">i</mi><mo is="true">)</mo></mrow></msup><mrow is="true"><mo is="true">=</mo><mn is="true">2</mn><mo is="true">|</mo></mrow><msup is="true"><mi is="true">x</mi><mrow is="true"><mo is="true">(</mo><mi is="true">i</mi><mo is="true">)</mo></mrow></msup><mo is="true">;</mo><mi is="true">Î¸</mi><mo stretchy="true" is="true">)</mo></mrow></mrow></mtd></mtr><mtr is="true"><mtd is="true"></mtd></mtr><mtr is="true"><mtd is="true"><mo is="true">â‹®</mo></mtd></mtr><mtr is="true"><mtd is="true"></mtd></mtr><mtr is="true"><mtd is="true"><mrow is="true"><mi is="true">p</mi><mrow is="true"><mo stretchy="true" is="true">(</mo><msup is="true"><mi is="true">y</mi><mrow is="true"><mo is="true">(</mo><mi is="true">i</mi><mo is="true">)</mo></mrow></msup><mrow is="true"><mo is="true">=</mo><mi is="true">k</mi><mo is="true">|</mo></mrow><msup is="true"><mi is="true">x</mi><mrow is="true"><mo is="true">(</mo><mi is="true">i</mi><mo is="true">)</mo></mrow></msup><mo is="true">;</mo><mi is="true">Î¸</mi><mo stretchy="true" is="true">)</mo></mrow></mrow></mtd></mtr></mtable><mo stretchy="true" is="true">]</mo></mrow><mo linebreak="goodbreak" is="true">=</mo><mfrac is="true"><mn is="true">1</mn><mrow is="true"><munderover is="true"><mo is="true">âˆ‘</mo><mrow is="true"><mi is="true">j</mi><mo is="true">=</mo><mn is="true">1</mn></mrow><mi is="true">k</mi></munderover><msup is="true"><mi is="true">e</mi><mrow is="true"><msubsup is="true"><mi is="true">Î¸</mi><mi is="true">j</mi><mi is="true">T</mi></msubsup><msup is="true"><mi is="true">x</mi><mrow is="true"><mo is="true">(</mo><mi is="true">i</mi><mo is="true">)</mo></mrow></msup></mrow></msup></mrow></mfrac><mrow is="true"><mo stretchy="true" is="true">[</mo><mtable is="true"><mtr is="true"><mtd is="true"><msup is="true"><mi is="true">e</mi><mrow is="true"><msubsup is="true"><mi is="true">Î¸</mi><mn is="true">1</mn><mi is="true">T</mi></msubsup><msup is="true"><mi is="true">x</mi><mrow is="true"><mo is="true">(</mo><mi is="true">i</mi><mo is="true">)</mo></mrow></msup></mrow></msup></mtd></mtr><mtr is="true"><mtd is="true"></mtd></mtr><mtr is="true"><mtd is="true"><msup is="true"><mi is="true">e</mi><mrow is="true"><msubsup is="true"><mi is="true">Î¸</mi><mn is="true">2</mn><mi is="true">T</mi></msubsup><msup is="true"><mi is="true">x</mi><mrow is="true"><mo is="true">(</mo><mi is="true">i</mi><mo is="true">)</mo></mrow></msup></mrow></msup></mtd></mtr><mtr is="true"><mtd is="true"></mtd></mtr><mtr is="true"><mtd is="true"><mo is="true">â‹®</mo></mtd></mtr><mtr is="true"><mtd is="true"></mtd></mtr><mtr is="true"><mtd is="true"><msup is="true"><mi is="true">e</mi><mrow is="true"><msubsup is="true"><mi is="true">Î¸</mi><mi is="true">k</mi><mi is="true">T</mi></msubsup><msup is="true"><mi is="true">x</mi><mrow is="true"><mo is="true">(</mo><mi is="true">i</mi><mo is="true">)</mo></mrow></msup></mrow></msup></mtd></mtr></mtable><mo stretchy="true" is="true">]</mo></mrow></mrow></math></script></span></span></span></div><div class="u-margin-s-bottom" id="p0019">Where <span class="math"><span class="MathJax_Preview" style=""></span><span class="MathJax_SVG" id="MathJax-Element-4-Frame" tabindex="0" data-mathml="<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mrow is=&quot;true&quot;><msub is=&quot;true&quot;><mi is=&quot;true&quot;>&amp;#x3B8;</mi><mn is=&quot;true&quot;>1</mn></msub><mo is=&quot;true&quot;>,</mo><msub is=&quot;true&quot;><mi is=&quot;true&quot;>&amp;#x3B8;</mi><mn is=&quot;true&quot;>2</mn></msub><mo is=&quot;true&quot;>,</mo><mo is=&quot;true&quot;>&amp;#x2026;</mo><mo is=&quot;true&quot;>,</mo><msub is=&quot;true&quot;><mi is=&quot;true&quot;>&amp;#x3B8;</mi><mi is=&quot;true&quot;>k</mi></msub><mo is=&quot;true&quot;>&amp;#x2208;</mo><msup is=&quot;true&quot;><mi is=&quot;true&quot;>&amp;#x211C;</mi><mrow is=&quot;true&quot;><mi is=&quot;true&quot;>n</mi><mo linebreak=&quot;badbreak&quot; is=&quot;true&quot;>+</mo><mn is=&quot;true&quot;>1</mn></mrow></msup></mrow></math>" role="presentation" style="font-size: 90%; display: inline-block; position: relative;"><svg xmlns:xlink="http://www.w3.org/1999/xlink" width="20.765ex" height="2.663ex" viewBox="0 -896.2 8940.3 1146.6" role="img" focusable="false" style="vertical-align: -0.582ex;" aria-hidden="true"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><g is="true"><g is="true"><g is="true"><use xlink:href="#MJMATHI-3B8"></use></g><g is="true" transform="translate(469,-150)"><use transform="scale(0.707)" xlink:href="#MJMAIN-31"></use></g></g><g is="true" transform="translate(923,0)"><use xlink:href="#MJMAIN-2C"></use></g><g is="true" transform="translate(1368,0)"><g is="true"><use xlink:href="#MJMATHI-3B8"></use></g><g is="true" transform="translate(469,-150)"><use transform="scale(0.707)" xlink:href="#MJMAIN-32"></use></g></g><g is="true" transform="translate(2291,0)"><use xlink:href="#MJMAIN-2C"></use></g><g is="true" transform="translate(2737,0)"><use xlink:href="#MJMAIN-2026"></use></g><g is="true" transform="translate(4076,0)"><use xlink:href="#MJMAIN-2C"></use></g><g is="true" transform="translate(4521,0)"><g is="true"><use xlink:href="#MJMATHI-3B8"></use></g><g is="true" transform="translate(469,-150)"><use transform="scale(0.707)" xlink:href="#MJMATHI-6B"></use></g></g><g is="true" transform="translate(5737,0)"><use xlink:href="#MJMAIN-2208"></use></g><g is="true" transform="translate(6682,0)"><g is="true"><use xlink:href="#MJFRAK-52"></use></g><g is="true" transform="translate(828,362)"><g is="true"><use transform="scale(0.707)" xlink:href="#MJMATHI-6E"></use></g><g is="true" transform="translate(424,0)"><use transform="scale(0.707)" xlink:href="#MJMAIN-2B"></use></g><g is="true" transform="translate(975,0)"><use transform="scale(0.707)" xlink:href="#MJMAIN-31"></use></g></g></g></g></g></svg><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow is="true"><msub is="true"><mi is="true">Î¸</mi><mn is="true">1</mn></msub><mo is="true">,</mo><msub is="true"><mi is="true">Î¸</mi><mn is="true">2</mn></msub><mo is="true">,</mo><mo is="true">â€¦</mo><mo is="true">,</mo><msub is="true"><mi is="true">Î¸</mi><mi is="true">k</mi></msub><mo is="true">âˆˆ</mo><msup is="true"><mi is="true">â„œ</mi><mrow is="true"><mi is="true">n</mi><mo linebreak="badbreak" is="true">+</mo><mn is="true">1</mn></mrow></msup></mrow></math></span></span><script type="math/mml" id="MathJax-Element-4"><math><mrow is="true"><msub is="true"><mi is="true">Î¸</mi><mn is="true">1</mn></msub><mo is="true">,</mo><msub is="true"><mi is="true">Î¸</mi><mn is="true">2</mn></msub><mo is="true">,</mo><mo is="true">â€¦</mo><mo is="true">,</mo><msub is="true"><mi is="true">Î¸</mi><mi is="true">k</mi></msub><mo is="true">âˆˆ</mo><msup is="true"><mi is="true">â„œ</mi><mrow is="true"><mi is="true">n</mi><mo linebreak="badbreak" is="true">+</mo><mn is="true">1</mn></mrow></msup></mrow></math></script></span> is the model parameter and <span class="math"><span class="MathJax_Preview" style=""></span><span class="MathJax_SVG" id="MathJax-Element-5-Frame" tabindex="0" data-mathml="<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mfrac is=&quot;true&quot;><mn is=&quot;true&quot;>1</mn><mrow is=&quot;true&quot;><munderover is=&quot;true&quot;><mo is=&quot;true&quot;>&amp;#x2211;</mo><mrow is=&quot;true&quot;><mi is=&quot;true&quot;>j</mi><mo is=&quot;true&quot;>=</mo><mn is=&quot;true&quot;>1</mn></mrow><mi is=&quot;true&quot;>k</mi></munderover><msup is=&quot;true&quot;><mi is=&quot;true&quot;>e</mi><mrow is=&quot;true&quot;><msubsup is=&quot;true&quot;><mi is=&quot;true&quot;>&amp;#x3B8;</mi><mi is=&quot;true&quot;>j</mi><mi is=&quot;true&quot;>T</mi></msubsup><msup is=&quot;true&quot;><mi is=&quot;true&quot;>x</mi><mrow is=&quot;true&quot;><mo is=&quot;true&quot;>(</mo><mi is=&quot;true&quot;>i</mi><mo is=&quot;true&quot;>)</mo></mrow></msup></mrow></msup></mrow></mfrac></math>" role="presentation" style="font-size: 90%; display: inline-block; position: relative;"><svg xmlns:xlink="http://www.w3.org/1999/xlink" width="9.584ex" height="5.086ex" viewBox="0 -945.9 4126.3 2189.9" role="img" focusable="false" style="vertical-align: -2.889ex;" aria-hidden="true"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><g is="true"><g transform="translate(120,0)"><rect stroke="none" width="3886" height="60" x="0" y="220"></rect><g is="true" transform="translate(1766,403)"><use transform="scale(0.707)" xlink:href="#MJMAIN-31"></use></g><g is="true" transform="translate(60,-886)"><g is="true"><g is="true"><use transform="scale(0.707)" xlink:href="#MJSZ1-2211"></use></g><g is="true" transform="translate(747,337)"><use transform="scale(0.5)" xlink:href="#MJMATHI-6B"></use></g><g is="true" transform="translate(747,-203)"><g is="true"><use transform="scale(0.5)" xlink:href="#MJMATHI-6A"></use></g><g is="true" transform="translate(206,0)"><use transform="scale(0.5)" xlink:href="#MJMAIN-3D"></use></g><g is="true" transform="translate(595,0)"><use transform="scale(0.5)" xlink:href="#MJMAIN-31"></use></g></g></g><g is="true" transform="translate(1830,0)"><g is="true"><use transform="scale(0.707)" xlink:href="#MJMATHI-65"></use></g><g is="true" transform="translate(329,427)"><g is="true"><g is="true"><use transform="scale(0.5)" xlink:href="#MJMATHI-3B8"></use></g><g is="true" transform="translate(234,172)"><use transform="scale(0.5)" xlink:href="#MJMATHI-54"></use></g><g is="true" transform="translate(234,-249)"><use transform="scale(0.5)" xlink:href="#MJMATHI-6A"></use></g></g><g is="true" transform="translate(637,0)"><g is="true"><use transform="scale(0.5)" xlink:href="#MJMATHI-78"></use></g><g is="true" transform="translate(286,179)"><g is="true"><use transform="scale(0.5)" xlink:href="#MJMAIN-28"></use></g><g is="true" transform="translate(194,0)"><use transform="scale(0.5)" xlink:href="#MJMATHI-69"></use></g><g is="true" transform="translate(367,0)"><use transform="scale(0.5)" xlink:href="#MJMAIN-29"></use></g></g></g></g></g></g></g></g></g></svg><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><mfrac is="true"><mn is="true">1</mn><mrow is="true"><munderover is="true"><mo is="true">âˆ‘</mo><mrow is="true"><mi is="true">j</mi><mo is="true">=</mo><mn is="true">1</mn></mrow><mi is="true">k</mi></munderover><msup is="true"><mi is="true">e</mi><mrow is="true"><msubsup is="true"><mi is="true">Î¸</mi><mi is="true">j</mi><mi is="true">T</mi></msubsup><msup is="true"><mi is="true">x</mi><mrow is="true"><mo is="true">(</mo><mi is="true">i</mi><mo is="true">)</mo></mrow></msup></mrow></msup></mrow></mfrac></math></span></span><script type="math/mml" id="MathJax-Element-5"><math><mfrac is="true"><mn is="true">1</mn><mrow is="true"><munderover is="true"><mo is="true">âˆ‘</mo><mrow is="true"><mi is="true">j</mi><mo is="true">=</mo><mn is="true">1</mn></mrow><mi is="true">k</mi></munderover><msup is="true"><mi is="true">e</mi><mrow is="true"><msubsup is="true"><mi is="true">Î¸</mi><mi is="true">j</mi><mi is="true">T</mi></msubsup><msup is="true"><mi is="true">x</mi><mrow is="true"><mo is="true">(</mo><mi is="true">i</mi><mo is="true">)</mo></mrow></msup></mrow></msup></mrow></mfrac></math></script></span> is the normalization term for the probability distribution, making the sum of all probabilities equal to 1.<span class="display"><span id="eq0002" class="formula"><span class="label">(2)</span><span class="math"><span class="MathJax_Preview" style=""></span><span class="MathJax_SVG" id="MathJax-Element-6-Frame" tabindex="0" data-mathml="<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mrow is=&quot;true&quot;><mi is=&quot;true&quot;>J</mi><mrow is=&quot;true&quot;><mo is=&quot;true&quot;>(</mo><mi is=&quot;true&quot;>&amp;#x3B8;</mi><mo is=&quot;true&quot;>)</mo></mrow><mo linebreak=&quot;goodbreak&quot; is=&quot;true&quot;>=</mo><mrow is=&quot;true&quot;><mo is=&quot;true&quot;>&amp;#x2212;</mo><mfrac is=&quot;true&quot;><mn is=&quot;true&quot;>1</mn><mi is=&quot;true&quot;>m</mi></mfrac></mrow><mrow is=&quot;true&quot;><mo stretchy=&quot;true&quot; is=&quot;true&quot;>[</mo><munderover is=&quot;true&quot;><mo is=&quot;true&quot;>&amp;#x2211;</mo><mrow is=&quot;true&quot;><mi is=&quot;true&quot;>i</mi><mo is=&quot;true&quot;>=</mo><mn is=&quot;true&quot;>1</mn></mrow><mi is=&quot;true&quot;>m</mi></munderover><munderover is=&quot;true&quot;><mo is=&quot;true&quot;>&amp;#x2211;</mo><mrow is=&quot;true&quot;><mi is=&quot;true&quot;>j</mi><mo is=&quot;true&quot;>=</mo><mn is=&quot;true&quot;>1</mn></mrow><mi is=&quot;true&quot;>k</mi></munderover><mrow is=&quot;true&quot;><mn is=&quot;true&quot;>1</mn><mrow is=&quot;true&quot;><mo stretchy=&quot;true&quot; is=&quot;true&quot;>{</mo><msup is=&quot;true&quot;><mi is=&quot;true&quot;>y</mi><mrow is=&quot;true&quot;><mo is=&quot;true&quot;>(</mo><mi is=&quot;true&quot;>i</mi><mo is=&quot;true&quot;>)</mo></mrow></msup><mo linebreak=&quot;badbreak&quot; is=&quot;true&quot;>=</mo><mi is=&quot;true&quot;>j</mi><mo stretchy=&quot;true&quot; is=&quot;true&quot;>}</mo></mrow></mrow><mi is=&quot;true&quot;>ln</mi><mfrac is=&quot;true&quot;><mrow is=&quot;true&quot;><msubsup is=&quot;true&quot;><mi is=&quot;true&quot;>&amp;#x3B8;</mi><mi is=&quot;true&quot;>j</mi><mi is=&quot;true&quot;>T</mi></msubsup><msup is=&quot;true&quot;><mi is=&quot;true&quot;>x</mi><mrow is=&quot;true&quot;><mo is=&quot;true&quot;>(</mo><mi is=&quot;true&quot;>i</mi><mo is=&quot;true&quot;>)</mo></mrow></msup></mrow><mrow is=&quot;true&quot;><munderover is=&quot;true&quot;><mo is=&quot;true&quot;>&amp;#x2211;</mo><mrow is=&quot;true&quot;><mi is=&quot;true&quot;>l</mi><mo is=&quot;true&quot;>=</mo><mn is=&quot;true&quot;>1</mn></mrow><mi is=&quot;true&quot;>k</mi></munderover><msup is=&quot;true&quot;><mi is=&quot;true&quot;>e</mi><mrow is=&quot;true&quot;><msubsup is=&quot;true&quot;><mi is=&quot;true&quot;>&amp;#x3B8;</mi><mi is=&quot;true&quot;>l</mi><mi is=&quot;true&quot;>T</mi></msubsup><msup is=&quot;true&quot;><mi is=&quot;true&quot;>x</mi><mrow is=&quot;true&quot;><mo is=&quot;true&quot;>(</mo><mi is=&quot;true&quot;>i</mi><mo is=&quot;true&quot;>)</mo></mrow></msup></mrow></msup></mrow></mfrac><mo stretchy=&quot;true&quot; is=&quot;true&quot;>]</mo></mrow></mrow></math>" role="presentation" style="font-size: 90%; display: inline-block; position: relative;"><svg xmlns:xlink="http://www.w3.org/1999/xlink" width="49.712ex" height="6.125ex" viewBox="0 -1542.1 21403.6 2637" role="img" focusable="false" style="vertical-align: -2.543ex;" aria-hidden="true"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><g is="true"><g is="true"><use xlink:href="#MJMATHI-4A"></use></g><g is="true" transform="translate(800,0)"><g is="true"><use xlink:href="#MJMAIN-28"></use></g><g is="true" transform="translate(389,0)"><use xlink:href="#MJMATHI-3B8"></use></g><g is="true" transform="translate(859,0)"><use xlink:href="#MJMAIN-29"></use></g></g><g is="true" transform="translate(2326,0)"><use xlink:href="#MJMAIN-3D"></use></g><g is="true" transform="translate(3382,0)"><g is="true"><use xlink:href="#MJMAIN-2212"></use></g><g is="true" transform="translate(778,0)"><g transform="translate(120,0)"><rect stroke="none" width="741" height="60" x="0" y="220"></rect><g is="true" transform="translate(193,403)"><use transform="scale(0.707)" xlink:href="#MJMAIN-31"></use></g><g is="true" transform="translate(60,-345)"><use transform="scale(0.707)" xlink:href="#MJMATHI-6D"></use></g></g></g></g><g is="true" transform="translate(5142,0)"><use xlink:href="#MJSZ3-5B" is="true"></use><g is="true" transform="translate(528,0)"><g is="true"><use xlink:href="#MJSZ1-2211"></use></g><g is="true" transform="translate(1056,477)"><use transform="scale(0.707)" xlink:href="#MJMATHI-6D"></use></g><g is="true" transform="translate(1056,-287)"><g is="true"><use transform="scale(0.707)" xlink:href="#MJMATHI-69"></use></g><g is="true" transform="translate(244,0)"><use transform="scale(0.707)" xlink:href="#MJMAIN-3D"></use></g><g is="true" transform="translate(794,0)"><use transform="scale(0.707)" xlink:href="#MJMAIN-31"></use></g></g></g><g is="true" transform="translate(3000,0)"><g is="true"><use xlink:href="#MJSZ1-2211"></use></g><g is="true" transform="translate(1056,477)"><use transform="scale(0.707)" xlink:href="#MJMATHI-6B"></use></g><g is="true" transform="translate(1056,-287)"><g is="true"><use transform="scale(0.707)" xlink:href="#MJMATHI-6A"></use></g><g is="true" transform="translate(291,0)"><use transform="scale(0.707)" xlink:href="#MJMAIN-3D"></use></g><g is="true" transform="translate(842,0)"><use transform="scale(0.707)" xlink:href="#MJMAIN-31"></use></g></g></g><g is="true" transform="translate(5519,0)"><g is="true"><use xlink:href="#MJMAIN-31"></use></g><g is="true" transform="translate(667,0)"><use xlink:href="#MJSZ1-7B" is="true" x="0" y="-1"></use><g is="true" transform="translate(583,0)"><g is="true"><use xlink:href="#MJMATHI-79"></use></g><g is="true" transform="translate(499,362)"><g is="true"><use transform="scale(0.707)" xlink:href="#MJMAIN-28"></use></g><g is="true" transform="translate(275,0)"><use transform="scale(0.707)" xlink:href="#MJMATHI-69"></use></g><g is="true" transform="translate(519,0)"><use transform="scale(0.707)" xlink:href="#MJMAIN-29"></use></g></g></g><g is="true" transform="translate(2256,0)"><use xlink:href="#MJMAIN-3D"></use></g><g is="true" transform="translate(3312,0)"><use xlink:href="#MJMATHI-6A"></use></g><use xlink:href="#MJSZ1-7D" is="true" x="3724" y="-1"></use></g></g><g is="true" transform="translate(10661,0)"><use xlink:href="#MJMAIN-6C"></use><use xlink:href="#MJMAIN-6E" x="278" y="0"></use></g><g is="true" transform="translate(11496,0)"><g transform="translate(286,0)"><rect stroke="none" width="3829" height="60" x="0" y="220"></rect><g is="true" transform="translate(1018,680)"><g is="true"><g is="true"><use transform="scale(0.707)" xlink:href="#MJMATHI-3B8"></use></g><g is="true" transform="translate(331,306)"><use transform="scale(0.5)" xlink:href="#MJMATHI-54"></use></g><g is="true" transform="translate(331,-175)"><use transform="scale(0.5)" xlink:href="#MJMATHI-6A"></use></g></g><g is="true" transform="translate(754,0)"><g is="true"><use transform="scale(0.707)" xlink:href="#MJMATHI-78"></use></g><g is="true" transform="translate(404,256)"><g is="true"><use transform="scale(0.5)" xlink:href="#MJMAIN-28"></use></g><g is="true" transform="translate(194,0)"><use transform="scale(0.5)" xlink:href="#MJMATHI-69"></use></g><g is="true" transform="translate(367,0)"><use transform="scale(0.5)" xlink:href="#MJMAIN-29"></use></g></g></g></g><g is="true" transform="translate(60,-807)"><g is="true"><g is="true"><use transform="scale(0.707)" xlink:href="#MJSZ1-2211"></use></g><g is="true" transform="translate(747,337)"><use transform="scale(0.5)" xlink:href="#MJMATHI-6B"></use></g><g is="true" transform="translate(747,-203)"><g is="true"><use transform="scale(0.5)" xlink:href="#MJMATHI-6C"></use></g><g is="true" transform="translate(149,0)"><use transform="scale(0.5)" xlink:href="#MJMAIN-3D"></use></g><g is="true" transform="translate(538,0)"><use transform="scale(0.5)" xlink:href="#MJMAIN-31"></use></g></g></g><g is="true" transform="translate(1773,0)"><g is="true"><use transform="scale(0.707)" xlink:href="#MJMATHI-65"></use></g><g is="true" transform="translate(329,348)"><g is="true"><g is="true"><use transform="scale(0.5)" xlink:href="#MJMATHI-3B8"></use></g><g is="true" transform="translate(234,172)"><use transform="scale(0.5)" xlink:href="#MJMATHI-54"></use></g><g is="true" transform="translate(234,-266)"><use transform="scale(0.5)" xlink:href="#MJMATHI-6C"></use></g></g><g is="true" transform="translate(637,0)"><g is="true"><use transform="scale(0.5)" xlink:href="#MJMATHI-78"></use></g><g is="true" transform="translate(286,179)"><g is="true"><use transform="scale(0.5)" xlink:href="#MJMAIN-28"></use></g><g is="true" transform="translate(194,0)"><use transform="scale(0.5)" xlink:href="#MJMATHI-69"></use></g><g is="true" transform="translate(367,0)"><use transform="scale(0.5)" xlink:href="#MJMAIN-29"></use></g></g></g></g></g></g></g></g><use xlink:href="#MJSZ3-5D" is="true" x="15732" y="-1"></use></g></g></g></svg><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow is="true"><mi is="true">J</mi><mrow is="true"><mo is="true">(</mo><mi is="true">Î¸</mi><mo is="true">)</mo></mrow><mo linebreak="goodbreak" is="true">=</mo><mrow is="true"><mo is="true">âˆ’</mo><mfrac is="true"><mn is="true">1</mn><mi is="true">m</mi></mfrac></mrow><mrow is="true"><mo stretchy="true" is="true">[</mo><munderover is="true"><mo is="true">âˆ‘</mo><mrow is="true"><mi is="true">i</mi><mo is="true">=</mo><mn is="true">1</mn></mrow><mi is="true">m</mi></munderover><munderover is="true"><mo is="true">âˆ‘</mo><mrow is="true"><mi is="true">j</mi><mo is="true">=</mo><mn is="true">1</mn></mrow><mi is="true">k</mi></munderover><mrow is="true"><mn is="true">1</mn><mrow is="true"><mo stretchy="true" is="true">{</mo><msup is="true"><mi is="true">y</mi><mrow is="true"><mo is="true">(</mo><mi is="true">i</mi><mo is="true">)</mo></mrow></msup><mo linebreak="badbreak" is="true">=</mo><mi is="true">j</mi><mo stretchy="true" is="true">}</mo></mrow></mrow><mi is="true">ln</mi><mfrac is="true"><mrow is="true"><msubsup is="true"><mi is="true">Î¸</mi><mi is="true">j</mi><mi is="true">T</mi></msubsup><msup is="true"><mi is="true">x</mi><mrow is="true"><mo is="true">(</mo><mi is="true">i</mi><mo is="true">)</mo></mrow></msup></mrow><mrow is="true"><munderover is="true"><mo is="true">âˆ‘</mo><mrow is="true"><mi is="true">l</mi><mo is="true">=</mo><mn is="true">1</mn></mrow><mi is="true">k</mi></munderover><msup is="true"><mi is="true">e</mi><mrow is="true"><msubsup is="true"><mi is="true">Î¸</mi><mi is="true">l</mi><mi is="true">T</mi></msubsup><msup is="true"><mi is="true">x</mi><mrow is="true"><mo is="true">(</mo><mi is="true">i</mi><mo is="true">)</mo></mrow></msup></mrow></msup></mrow></mfrac><mo stretchy="true" is="true">]</mo></mrow></mrow></math></span></span><script type="math/mml" id="MathJax-Element-6"><math><mrow is="true"><mi is="true">J</mi><mrow is="true"><mo is="true">(</mo><mi is="true">Î¸</mi><mo is="true">)</mo></mrow><mo linebreak="goodbreak" is="true">=</mo><mrow is="true"><mo is="true">âˆ’</mo><mfrac is="true"><mn is="true">1</mn><mi is="true">m</mi></mfrac></mrow><mrow is="true"><mo stretchy="true" is="true">[</mo><munderover is="true"><mo is="true">âˆ‘</mo><mrow is="true"><mi is="true">i</mi><mo is="true">=</mo><mn is="true">1</mn></mrow><mi is="true">m</mi></munderover><munderover is="true"><mo is="true">âˆ‘</mo><mrow is="true"><mi is="true">j</mi><mo is="true">=</mo><mn is="true">1</mn></mrow><mi is="true">k</mi></munderover><mrow is="true"><mn is="true">1</mn><mrow is="true"><mo stretchy="true" is="true">{</mo><msup is="true"><mi is="true">y</mi><mrow is="true"><mo is="true">(</mo><mi is="true">i</mi><mo is="true">)</mo></mrow></msup><mo linebreak="badbreak" is="true">=</mo><mi is="true">j</mi><mo stretchy="true" is="true">}</mo></mrow></mrow><mi is="true">ln</mi><mfrac is="true"><mrow is="true"><msubsup is="true"><mi is="true">Î¸</mi><mi is="true">j</mi><mi is="true">T</mi></msubsup><msup is="true"><mi is="true">x</mi><mrow is="true"><mo is="true">(</mo><mi is="true">i</mi><mo is="true">)</mo></mrow></msup></mrow><mrow is="true"><munderover is="true"><mo is="true">âˆ‘</mo><mrow is="true"><mi is="true">l</mi><mo is="true">=</mo><mn is="true">1</mn></mrow><mi is="true">k</mi></munderover><msup is="true"><mi is="true">e</mi><mrow is="true"><msubsup is="true"><mi is="true">Î¸</mi><mi is="true">l</mi><mi is="true">T</mi></msubsup><msup is="true"><mi is="true">x</mi><mrow is="true"><mo is="true">(</mo><mi is="true">i</mi><mo is="true">)</mo></mrow></msup></mrow></msup></mrow></mfrac><mo stretchy="true" is="true">]</mo></mrow></mrow></math></script></span></span></span></div><div class="u-margin-s-bottom" id="p0020">Among them, 1{} = 1 is an indicative function whose value rule is: when the expression in the <a href="/topics/engineering/curly-brace" title="Learn more about curly braces from ScienceDirect's AI-generated Topic Pages" class="topic-link">curly braces</a> is true, the result of the function is 1, otherwise the result is 0.</div></section><section id="sec0005"><h3 id="sctt0007" class="u-h4 u-margin-m-top u-margin-xs-bottom">3.2. The dual-branch CNN</h3><div class="u-margin-s-bottom"><div id="p0021"><span>The dual-branch CNN is designed to simultaneously estimate the global features and local <a href="/topics/computer-science/texture-feature" title="Learn more about texture features from ScienceDirect's AI-generated Topic Pages" class="topic-link">texture features</a>. </span><a class="anchor anchor-primary" href="#fig0004" name="bfig0004" data-sd-ui-side-panel-opener="true" data-xocs-content-type="reference" data-xocs-content-id="fig0004"><span class="anchor-text-container"><span class="anchor-text">Fig.&nbsp;4</span></span></a> illustrates its flowchart. The architecture consists of three modules: two individual CNN branch modules and a fusion module. The first branch takes the entire image as input and extract global features. The other branch takes the texture feature image preprocessed by LBP as input. Finally, the third module is a fusion network that takes as input the global and texture features. The global feature is intended to represent the integrity of the expression, while the texture feature focuses on the details of the description of the local area, which can directly indicate some active expression areas on the face. These two separate branches represent expressions from two different aspects. They are complementary and both are of interest.</div><figure class="figure text-xs" id="fig0004"><span><img src="https://ars.els-cdn.com/content/image/1-s2.0-S0925231219306137-gr4.jpg" height="371" alt="Fig. 4" aria-describedby="cap0004"><ol class="u-margin-s-bottom"><li><a class="anchor download-link u-font-sans anchor-primary" href="https://ars.els-cdn.com/content/image/1-s2.0-S0925231219306137-gr4_lrg.jpg" target="_blank" download="" title="Download high-res image (533KB)"><span class="anchor-text-container"><span class="anchor-text">Download: <span class="download-link-title">Download high-res image (533KB)</span></span></span></a></li><li><a class="anchor download-link u-font-sans anchor-primary" href="https://ars.els-cdn.com/content/image/1-s2.0-S0925231219306137-gr4.jpg" target="_blank" download="" title="Download full-size image"><span class="anchor-text-container"><span class="anchor-text">Download: <span class="download-link-title">Download full-size image</span></span></span></a></li></ol></span><span class="captions text-s"><span id="cap0004"><p id="sp0008"><span class="label">Fig. 4</span>. Framework of the dual-branch CNN.</p></span></span></figure></div><div class="u-margin-s-bottom"><div id="para0001a"><span>The Light-CNN, we introduced in the previous sub-section, is truncated to apply for the first branch. The <a href="/topics/computer-science/dimensional-reduction" title="Learn more about dimensional reduction from ScienceDirect's AI-generated Topic Pages" class="topic-link">dimensional reduction</a><span> CNN for the second branch consists of two Convolutional layers. It reduces the dimension of LBP features and facilitates the following combination of the two features. The <a href="/topics/computer-science/architecture-detail" title="Learn more about architecture details from ScienceDirect's AI-generated Topic Pages" class="topic-link">architecture details</a> of the two branches are shown in Table I. We omitted the architecture details between layer1 and layer28 of the first branch in </span></span><a class="anchor anchor-primary" href="#tbl0001" name="btbl0001" data-sd-ui-side-panel-opener="true" data-xocs-content-type="reference" data-xocs-content-id="tbl0001"><span class="anchor-text-container"><span class="anchor-text">Table&nbsp;1</span></span></a>.</div><div class="tables rowsep-0 colsep-0 frame-topbot" id="tbl0001"><span class="captions text-s"><span id="cap0009"><p id="sp0013"><span class="label">Table 1</span>. Architectures of the two branches.</p></span></span><div class="groups"><table><thead><tr><th scope="col" class="align-left">The first branch</th><td scope="col" class="align-left valign-top"><span class="screen-reader-only">Empty Cell</span></td><th scope="col" class="align-left valign-top">Layer1</th><th scope="col" class="align-left" colspan="3">â€“</th><th scope="col" class="align-left valign-top">Layer28</th><th scope="col" class="align-left valign-top">Layer29</th></tr><tr><td scope="col" class="align-left valign-top"><span class="screen-reader-only">Empty Cell</span></td><th scope="col" class="align-left valign-top">type</th><th scope="col" class="align-left valign-top">Input</th><th scope="col" class="align-left" colspan="3">â€“</th><th scope="col" class="align-left valign-top">GlobalAveragePooling2D</th><th scope="col" class="align-left valign-top">Flatten</th></tr><tr class="rowsep-1"><td scope="col" class="align-left valign-top"><span class="screen-reader-only">Empty Cell</span></td><th scope="col" class="align-left valign-top">size</th><th scope="col" class="align-left valign-top">224â€¯Ã—â€¯224â€¯Ã—â€¯1</th><th scope="col" class="align-left rowsep-1" colspan="3">â€“</th><th scope="col" class="align-left valign-top">4096</th><th scope="col" class="align-left valign-top">4096</th></tr></thead><tbody><tr class="rowsep-1"><td class="align-left valign-top">The second branch</td><td class="align-left"></td><td class="align-left valign-top">Layer1</td><td class="align-left valign-top">Layer2</td><td class="align-left valign-top">Layer3</td><td class="align-left valign-top">Layer4</td><td class="align-left valign-top">Layer5</td><td class="align-left valign-top">Layer6</td></tr><tr><td class="align-left"></td><td class="align-left valign-top">type</td><td class="align-left valign-top">Input</td><td class="align-left valign-top">Conv2D</td><td class="align-left valign-top">Max Pooling</td><td class="align-left valign-top">Conv2D</td><td class="align-left valign-top">Max Pooling</td><td class="align-left valign-top">Flatten</td></tr><tr><td class="align-left"></td><td class="align-left valign-top">size</td><td class="align-left valign-top">64â€¯Ã—â€¯64â€¯Ã—â€¯1</td><td class="align-left valign-top">4â€¯Ã—â€¯4â€¯Ã—â€¯32</td><td class="align-left valign-top">2â€¯Ã—â€¯2</td><td class="align-left valign-top">4â€¯Ã—â€¯4â€¯Ã—â€¯16</td><td class="align-left valign-top">2â€¯Ã—â€¯2</td><td class="align-left valign-top">2704</td></tr></tbody></table></div></div></div></section><section id="sec0006"><h3 id="sctt0008" class="u-h4 u-margin-m-top u-margin-xs-bottom">3.3. The pretrained CNN</h3><div class="u-margin-s-bottom"><div id="p0022"><span>To observe the effect of <a href="/topics/computer-science/deep-convolutional-neural-networks" title="Learn more about deeper CNN from ScienceDirect's AI-generated Topic Pages" class="topic-link">deeper CNN</a>, the ResNet101</span><a class="anchor anchor-primary" href="#bib0043" name="bbib0043" data-sd-ui-side-panel-opener="true" data-xocs-content-type="reference" data-xocs-content-id="bib0043"><span class="anchor-text-container"><span class="anchor-text">[43]</span></span></a> network was exploited to construct our pretrained network model. As we didnâ€™t have big databases to train the network, we directly used the model which was previously trained by ImageNet <a class="anchor anchor-primary" href="#bib0044" name="bbib0044" data-sd-ui-side-panel-opener="true" data-xocs-content-type="reference" data-xocs-content-id="bib0044"><span class="anchor-text-container"><span class="anchor-text">[44]</span></span></a> dataset. ImageNet has thousands of different face images, so we could retain the most original network parameters for initialization. Then we trained the model and performed fine-tuning on some of the layers to extract more specific features. <a class="anchor anchor-primary" href="#fig0005" name="bfig0005" data-sd-ui-side-panel-opener="true" data-xocs-content-type="reference" data-xocs-content-id="fig0005"><span class="anchor-text-container"><span class="anchor-text">Fig.&nbsp;5</span></span></a> shows the architecture of the pretrained CNN. The original network consists of five convolution modules. Then average pooling is followed by a flatten layer. The output of the full connection layer is 1000. We modified the full connection layer from 1000 to 6 or 7, according to the number of expression categories.</div><figure class="figure text-xs" id="fig0005"><span><img src="https://ars.els-cdn.com/content/image/1-s2.0-S0925231219306137-gr5.jpg" height="510" alt="Fig. 5" aria-describedby="cap0005"><ol class="u-margin-s-bottom"><li><a class="anchor download-link u-font-sans anchor-primary" href="https://ars.els-cdn.com/content/image/1-s2.0-S0925231219306137-gr5_lrg.jpg" target="_blank" download="" title="Download high-res image (497KB)"><span class="anchor-text-container"><span class="anchor-text">Download: <span class="download-link-title">Download high-res image (497KB)</span></span></span></a></li><li><a class="anchor download-link u-font-sans anchor-primary" href="https://ars.els-cdn.com/content/image/1-s2.0-S0925231219306137-gr5.jpg" target="_blank" download="" title="Download full-size image"><span class="anchor-text-container"><span class="anchor-text">Download: <span class="download-link-title">Download full-size image</span></span></span></a></li></ol></span><span class="captions text-s"><span id="cap0005"><p id="sp0009"><span class="label">Fig. 5</span>. The framework of the pretrained CNN.</p></span></span></figure></div></section></section><section id="sec0007"><h2 id="sctt0009" class="u-h4 u-margin-l-top u-margin-xs-bottom">4. Experimental results</h2><div class="u-margin-s-bottom"><div id="p0023">We evaluated the proposed methods on three publicly available facial expression datasets. Some image samples are shown in <a class="anchor anchor-primary" href="#fig0006" name="bfig0006" data-sd-ui-side-panel-opener="true" data-xocs-content-type="reference" data-xocs-content-id="fig0006"><span class="anchor-text-container"><span class="anchor-text">Fig.&nbsp;6</span></span></a>. Images from the CK+ Database are in the top row. Images from the BU-3DFE Database are in the middle row. Images from the FER2013 Database are in the bottom row. The experimental details will be described in this section.</div><figure class="figure text-xs" id="fig0006"><span><img src="https://ars.els-cdn.com/content/image/1-s2.0-S0925231219306137-gr6.jpg" height="489" alt="Fig. 6" aria-describedby="cap0006"><ol class="u-margin-s-bottom"><li><a class="anchor download-link u-font-sans anchor-primary" href="https://ars.els-cdn.com/content/image/1-s2.0-S0925231219306137-gr6_lrg.jpg" target="_blank" download="" title="Download high-res image (851KB)"><span class="anchor-text-container"><span class="anchor-text">Download: <span class="download-link-title">Download high-res image (851KB)</span></span></span></a></li><li><a class="anchor download-link u-font-sans anchor-primary" href="https://ars.els-cdn.com/content/image/1-s2.0-S0925231219306137-gr6.jpg" target="_blank" download="" title="Download full-size image"><span class="anchor-text-container"><span class="anchor-text">Download: <span class="download-link-title">Download full-size image</span></span></span></a></li></ol></span><span class="captions text-s"><span id="cap0006"><p id="sp0010"><span class="label">Fig. 6</span>. Examples Images in CK+(top), BU-3DFE (middle), FER2013 (bottom) Datasets.</p></span></span></figure></div><section id="sec0008"><h3 id="sctt0010" class="u-h4 u-margin-m-top u-margin-xs-bottom">4.1. Databases and Protocols</h3><div class="u-margin-s-bottom" id="p0024"><em>CK+ Database:</em> The Extended Cohn-Kanade (CK+) database <a class="anchor anchor-primary" href="#bib0045" name="bbib0045" data-sd-ui-side-panel-opener="true" data-xocs-content-type="reference" data-xocs-content-id="bib0045"><span class="anchor-text-container"><span class="anchor-text">[45]</span></span></a> includes 593 facial expression video sequences recorded from 123 subjects ranging from 18 to 30 years old in lab-controlled environment. Most are frontal faces. We only retained the final frames with peak expression of video sequences in our experiments. Totally we got 327 static expression images with seven emotion labels (anger, contempt, disgust, fear, happy, sadness, surprise). We divided the CK+ dataset into a training set with 90% samples and a validation set with the other 10% samples.</div><div class="u-margin-s-bottom" id="p0025"><em>BU-3DFE Database:</em> The BU-3DFE multi-view facial expression database <a class="anchor anchor-primary" href="#bib0046" name="bbib0046" data-sd-ui-side-panel-opener="true" data-xocs-content-type="reference" data-xocs-content-id="bib0046"><span class="anchor-text-container"><span class="anchor-text">[46]</span></span></a><span> contains 100 subjects of different ethnicities, including 56 females and 44 males. Six facial expressions (anger, disgust, fear, happiness, sadness, and surprise) are elicited by various manners and head poses. Each of them includes 4 levels of intensities. The images are also captured in the lab-controlled environment. These models are comprised by both 3D geometrical shapes and color textures with 83 feature points. We use 3D facial models to restore 2D <a href="/topics/computer-science/facial-image" title="Learn more about facial images from ScienceDirect's AI-generated Topic Pages" class="topic-link">facial images</a> of multiple viewing angles (0</span><sup>âˆ˜</sup>, 30<sup>âˆ˜</sup>, 45<sup>âˆ˜</sup>, 60<sup>âˆ˜</sup> and 90<sup>âˆ˜</sup>). We divided the dataset into a training set with 90% samples and a validation set with the other 10% samples as well.</div><div class="u-margin-s-bottom" id="p0026"><em>FER2013 database:</em> The FER2013 dataset <a class="anchor anchor-primary" href="#bib0047" name="bbib0047" data-sd-ui-side-panel-opener="true" data-xocs-content-type="reference" data-xocs-content-id="bib0047"><span class="anchor-text-container"><span class="anchor-text">[47]</span></span></a> is a static real world facial expression database, which consists of 35,887 48â€¯Ã—â€¯48 gray face images. The image is processed in such a way that the face is centered and the occupancy of each face in the image is approximately the same. Each image is divided into one of seven categories that express different facial emotions. These facial emotions have been categorized as: anger, disgust, fear, happy, sad, surprise and neutral. Besides the image category, images are divided into three different sets, a training set, a validation set, and a test set. There are approximately 29,000 training images, 4,000 verification images and 4000 images for testing. For the purpose of data enhancement, we make a mirror image by horizontally flipping the image in the training set.</div></section><section id="sec0009"><h3 id="sctt0011" class="u-h4 u-margin-m-top u-margin-xs-bottom">4.2. Experimental parameters</h3><div class="u-margin-s-bottom"><div id="p0027"><span>The experimental platform consists of AMD Ryzen 5 1600(6â€¯Ã—â€¯3.2&nbsp;GHz processor), 16GB memory, GTX1080 and Ubuntu 16.04 operation system. The deep learning framework <a href="/topics/computer-science/keras" title="Learn more about Keras from ScienceDirect's AI-generated Topic Pages" class="topic-link">Keras</a> is exploited. The parameter settings of the Light-CNN, the dual-branch CNN and the pretrained CNN are presented in </span><a class="anchor anchor-primary" href="#tbl0002" name="btbl0002" data-sd-ui-side-panel-opener="true" data-xocs-content-type="reference" data-xocs-content-id="tbl0002"><span class="anchor-text-container"><span class="anchor-text">Table&nbsp;2</span></span></a>.</div><div class="tables rowsep-0 colsep-0 frame-topbot" id="tbl0002"><span class="captions text-s"><span id="cap0010"><p id="sp0014"><span class="label">Table 2</span>. The parameter setting of Light-CNN, Dual-Branch Network and Pre-trained network.</p></span></span><div class="groups"><table><thead><tr class="rowsep-1"><th scope="col" class="align-left valign-top">Models</th><th scope="col" class="align-left valign-top">Parameters</th><th scope="col" class="align-left valign-top">Values</th></tr></thead><tbody><tr><td class="align-left valign-top">The Light-CNN</td><td class="align-left valign-top">Optimizer</td><td class="align-left valign-top">Adam</td></tr><tr><td class="align-left"></td><td class="align-left valign-top">Image size</td><td class="align-left valign-top">224â€¯Ã—â€¯224</td></tr><tr><td class="align-left valign-top">The dual-branch CNN</td><td class="align-left valign-top">Optimizer</td><td class="align-left valign-top">SGD</td></tr><tr><td class="align-left"></td><td class="align-left valign-top">Learning rate</td><td class="align-left valign-top">1eâˆ’3</td></tr><tr><td class="align-left"></td><td class="align-left valign-top">Momentum</td><td class="align-left valign-top">0.9</td></tr><tr><td class="align-left"></td><td class="align-left valign-top">Learning decaying factor</td><td class="align-left valign-top">1eâˆ’6</td></tr><tr><td class="align-left"></td><td class="align-left valign-top">Image size</td><td class="align-left valign-top">224â€¯Ã—â€¯224</td></tr><tr><td class="align-left valign-top">The pretrained CNN</td><td class="align-left valign-top">Optimizer</td><td class="align-left valign-top">SGD</td></tr><tr><td class="align-left"></td><td class="align-left valign-top">Learning rate</td><td class="align-left valign-top">1e-3</td></tr><tr><td class="align-left"></td><td class="align-left valign-top">Momentum</td><td class="align-left valign-top">0.9</td></tr><tr><td class="align-left"></td><td class="align-left valign-top">Learning decaying factor</td><td class="align-left valign-top">1eâˆ’6</td></tr><tr><td class="align-left"></td><td class="align-left valign-top">Image size</td><td class="align-left valign-top">224â€¯Ã—â€¯224</td></tr></tbody></table></div></div></div><div class="u-margin-s-bottom" id="p0028">In preprocessing, we applied Multi-Task Convolutional Neural Network (MT-CNN)<a class="anchor anchor-primary" href="#bib0048" name="bbib0048" data-sd-ui-side-panel-opener="true" data-xocs-content-type="reference" data-xocs-content-id="bib0048"><span class="anchor-text-container"><span class="anchor-text">[48]</span></span></a><span> for face detection. Then, the cropped face and five facial landmarks were detected. The five landmarks indicate the centers of two eyes, the end of the nose and two corners of the mouth. All face images were resized to 224â€¯Ã—â€¯224 pixels and aligned based on three landmarks (two center points of eyes and the center point of mouth). In the dual-branch network, LBP <a href="/topics/computer-science/image-feature" title="Learn more about feature images from ScienceDirect's AI-generated Topic Pages" class="topic-link">feature images</a> were resized to 64â€¯Ã—â€¯64 pixels.</span></div><div class="u-margin-s-bottom" id="p0029">For image enhancement, we used a series of random transformations to â€œenhanceâ€ the image so that the model would not be fed with two identical images <a class="anchor anchor-primary" href="#bib0049" name="bbib0049" data-sd-ui-side-panel-opener="true" data-xocs-content-type="reference" data-xocs-content-id="bib0049"><span class="anchor-text-container"><span class="anchor-text">[49]</span></span></a>. It would effectively improve image utilization. The transformations included rotation, flipping, scaling, and panning. In this paper, the width and height displacement were used. The shifting range of width and height were set under 20%. The random rotation range was 0â€“20<sup>âˆ˜</sup>. Both the shear range and the zoom range were [0â€“0.1]. We flipped the images horizontally and applied the fill pattern strategy to fill the newly created pixels as well.</div></section><section id="sec0010"><h3 id="sctt0012" class="u-h4 u-margin-m-top u-margin-xs-bottom">4.3. Experiments on three popular datasets</h3><div class="u-margin-s-bottom" id="p0030">We tested our methods on three widely used FER datasets: CK+, BU-3DFE and FER2013. The CK+ dataset includes expressions of seven labels: anger, contempt,disgust, fear, happy, sadness, surprise. The BU-3DFE dataset has six labels: anger, disgust, fear, happiness, sadness, and surprise. The FER2013 dataset has seven labels: anger, disgust, fear, happy, sad, surprise and neutral.</div><div class="u-margin-s-bottom"><div id="p0031"><span>To evaluate the overall performance, the <a href="/topics/engineering/confusion-matrix" title="Learn more about confusion matrices from ScienceDirect's AI-generated Topic Pages" class="topic-link">confusion matrices</a> of our methods on three datasets are illustrated in </span><a class="anchor anchor-primary" href="#fig0007" name="bfig0007" data-sd-ui-side-panel-opener="true" data-xocs-content-type="reference" data-xocs-content-id="fig0007"><span class="anchor-text-container"><span class="anchor-text">Fig.&nbsp;7</span></span></a>. <a class="anchor anchor-primary" href="#fig0007" name="bfig0007" data-sd-ui-side-panel-opener="true" data-xocs-content-type="reference" data-xocs-content-id="fig0007"><span class="anchor-text-container"><span class="anchor-text">Fig.&nbsp;7</span></span></a>(a)â€“(c) are experimental results on CK+, implemented by the Light-CNN, the dual-branch CNN and the pretrained CNN respectively. <a class="anchor anchor-primary" href="#fig0007" name="bfig0007" data-sd-ui-side-panel-opener="true" data-xocs-content-type="reference" data-xocs-content-id="fig0007"><span class="anchor-text-container"><span class="anchor-text">Fig.&nbsp;7</span></span></a>(d)â€“(f) are experimental results on BU-3DFE dataset with three models. <a class="anchor anchor-primary" href="#fig0007" name="bfig0007" data-sd-ui-side-panel-opener="true" data-xocs-content-type="reference" data-xocs-content-id="fig0007"><span class="anchor-text-container"><span class="anchor-text">Fig.&nbsp;7</span></span></a>(g)â€“(i) are experimental results on FER2013. As demonstrated in these figures, the pretrained CNN resulted in higher accuracy for most of the labels. All the three models performed well on CK+ datasets especially the Light-CNN and the pretrained CNN, as CK+ is a dataset with facial expression samples captured in a lab-controlled environment. It is interesting to see that the happy label has the highest accuracy in CK+ and FER2013 datasets, which implies that the features of a happy face are more distinguishable than other expressions. Besides, the sadness and the surprise expressions are relatively easier to be recognized from an acted face than from a face in the real world. Because the sad and surprise labels have high accuracy on CK+ and BU-3DFE datasets, but fail to be good on FER2013. Their matrices also reveal which labels are likely to be confused by the trained networks. For example, we can see the correlation of angry label with the fear and surprise labels. There are lots of instances that their true label is angry but the classifier has misclassified them as fear or surprise. These mistakes are consistent with what we see when looking at images in the dataset; even as a human, it can be difficult to recognize whether an angry expression is actually surprise or angry. This is due to the fact that people do not all express emotions in the same way.</div><figure class="figure text-xs" id="fig0007"><span><img src="https://ars.els-cdn.com/content/image/1-s2.0-S0925231219306137-gr7.jpg" height="810" alt="Fig. 7" aria-describedby="cap0007"><ol class="u-margin-s-bottom"><li><a class="anchor download-link u-font-sans anchor-primary" href="https://ars.els-cdn.com/content/image/1-s2.0-S0925231219306137-gr7_lrg.jpg" target="_blank" download="" title="Download high-res image (2MB)"><span class="anchor-text-container"><span class="anchor-text">Download: <span class="download-link-title">Download high-res image (2MB)</span></span></span></a></li><li><a class="anchor download-link u-font-sans anchor-primary" href="https://ars.els-cdn.com/content/image/1-s2.0-S0925231219306137-gr7.jpg" target="_blank" download="" title="Download full-size image"><span class="anchor-text-container"><span class="anchor-text">Download: <span class="download-link-title">Download full-size image</span></span></span></a></li></ol></span><span class="captions text-s"><span id="cap0007"><p id="sp0011"><span class="label">Fig. 7</span>. <a href="/topics/computer-science/confusion-matrix" title="Learn more about Confusion matrices from ScienceDirect's AI-generated Topic Pages" class="topic-link">Confusion matrices</a> for three networks on three expression databases. (a)â€“(c) are confusion matrices for the Light-CNNs, dual-branch CNN and the pretrained CNN on CK+, (d)â€“(f) are confusion matrices for the three networks on BU-3DFE, (g)â€“(i) are confusion matrices for the three networks on FER2013.</p></span></span></figure></div><div class="u-margin-s-bottom"><div id="p0032">Moreover, we plotted the obtained accuracy of FER2013 using the Light-CNN, the dual-branch CNN and the pretrained CNN during epochs in <a class="anchor anchor-primary" href="#fig0008" name="bfig0008" data-sd-ui-side-panel-opener="true" data-xocs-content-type="reference" data-xocs-content-id="fig0008"><span class="anchor-text-container"><span class="anchor-text">Fig.&nbsp;8</span></span></a>. As seen in <a class="anchor anchor-primary" href="#fig0008" name="bfig0008" data-sd-ui-side-panel-opener="true" data-xocs-content-type="reference" data-xocs-content-id="fig0008"><span class="anchor-text-container"><span class="anchor-text">Fig.&nbsp;8</span></span></a>, the pretrained CNN has the best validation accuracy. The performance of the Light-CNN is close to the best one. Furthermore, one can observe that the Light-CNN has less overfitting behavior than the others. We also provided the number of parameters in networks and their running time on FER2013 for comparison in <a class="anchor anchor-primary" href="#tbl0003" name="btbl0003" data-sd-ui-side-panel-opener="true" data-xocs-content-type="reference" data-xocs-content-id="tbl0003"><span class="anchor-text-container"><span class="anchor-text">Table&nbsp;3</span></span></a>. The Light-CNN has the least parameters, and it runs much faster than the others. By integrating the results shown in <a class="anchor anchor-primary" href="#fig0008" name="bfig0008" data-sd-ui-side-panel-opener="true" data-xocs-content-type="reference" data-xocs-content-id="fig0008"><span class="anchor-text-container"><span class="anchor-text">Fig.&nbsp;8</span></span></a> and <a class="anchor anchor-primary" href="#tbl0003" name="btbl0003" data-sd-ui-side-panel-opener="true" data-xocs-content-type="reference" data-xocs-content-id="tbl0003"><span class="anchor-text-container"><span class="anchor-text">Table&nbsp;3</span></span></a>, we concluded that LBP features were not helpful in deep network. With the development of the architecture, CNNs adopting raw pixel data is strong enough to extract sufficient information for facial expression in the wild. Besides, the Light-CNN got good scores on all three datasets and its performances are quite close to those of the pretrained CNN. Besides, it runs much faster than the pretrained CNN, which is beneficial for practical applications.</div><figure class="figure text-xs" id="fig0008"><span><img src="https://ars.els-cdn.com/content/image/1-s2.0-S0925231219306137-gr8.jpg" height="310" alt="Fig. 8" aria-describedby="cap0008"><ol class="u-margin-s-bottom"><li><a class="anchor download-link u-font-sans anchor-primary" href="https://ars.els-cdn.com/content/image/1-s2.0-S0925231219306137-gr8_lrg.jpg" target="_blank" download="" title="Download high-res image (425KB)"><span class="anchor-text-container"><span class="anchor-text">Download: <span class="download-link-title">Download high-res image (425KB)</span></span></span></a></li><li><a class="anchor download-link u-font-sans anchor-primary" href="https://ars.els-cdn.com/content/image/1-s2.0-S0925231219306137-gr8.jpg" target="_blank" download="" title="Download full-size image"><span class="anchor-text-container"><span class="anchor-text">Download: <span class="download-link-title">Download full-size image</span></span></span></a></li></ol></span><span class="captions text-s"><span id="cap0008"><p id="sp0012"><span class="label">Fig. 8</span>. Comparison of parameters and running time on FER2013 dataset.</p></span></span></figure><div class="tables rowsep-0 colsep-0 frame-topbot" id="tbl0003"><span class="captions text-s"><span id="cap0011"><p id="sp0015"><span class="label">Table 3</span>. Comparison of parameters in three networks and their running time on FER2013 dataset.</p></span></span><div class="groups"><table><thead><tr class="rowsep-1"><th scope="col" class="align-left valign-top">Models</th><th scope="col" class="align-left valign-top">Parameters</th><th scope="col" class="align-left valign-top">Running time (h)</th></tr></thead><tbody><tr><td class="align-left valign-top">The Light-CNN</td><td class="align-left valign-top">1,108,151</td><td class="align-left valign-top">12.7</td></tr><tr><td class="align-left valign-top">The dual-branch CNN</td><td class="align-left valign-top">64,629,847</td><td class="align-left valign-top">23.3</td></tr><tr><td class="align-left valign-top">The pretrained CNN</td><td class="align-left valign-top">7,128,327</td><td class="align-left valign-top">18.8</td></tr></tbody></table></div></div></div></section><section id="sec0011"><h3 id="sctt0013" class="u-h4 u-margin-m-top u-margin-xs-bottom">4.4. Comparisons with the state-of-the-art methods</h3><div class="u-margin-s-bottom"><div id="p0033">To evaluate the performance of the proposed algorithm with other algorithms, <a class="anchor anchor-primary" href="#tbl0004" name="btbl0004" data-sd-ui-side-panel-opener="true" data-xocs-content-type="reference" data-xocs-content-id="tbl0004"><span class="anchor-text-container"><span class="anchor-text">Table&nbsp;4</span></span></a> and <a class="anchor anchor-primary" href="#tbl0005" name="btbl0005" data-sd-ui-side-panel-opener="true" data-xocs-content-type="reference" data-xocs-content-id="tbl0005"><span class="anchor-text-container"><span class="anchor-text">5</span></span></a><span><span> list the accuracy of our proposed and the state-of-the-art algorithms on the CK+ and BU-3DFE databases. LBP, <a href="/topics/computer-science/histogram-of-oriented-gradient" title="Learn more about HOG from ScienceDirect's AI-generated Topic Pages" class="topic-link">HOG</a> and </span><a href="/topics/engineering/gabor-filter" title="Learn more about Gabor filters from ScienceDirect's AI-generated Topic Pages" class="topic-link">Gabor filters</a><span><span> are traditional <a href="/topics/computer-science/feature-descriptor" title="Learn more about feature descriptors from ScienceDirect's AI-generated Topic Pages" class="topic-link">feature descriptors</a> in facial expression recognition and have been widely used. However, the </span><a href="/topics/computer-science/recognition-accuracy" title="Learn more about recognition accuracy from ScienceDirect's AI-generated Topic Pages" class="topic-link">recognition accuracy</a> of most traditional methods are lower than that of deep learning.</span></span></div><div class="tables rowsep-0 colsep-0 frame-topbot" id="tbl0004"><span class="captions text-s"><span id="cap0012"><p id="sp0016"><span class="label">Table 4</span>. The accuracy (%) of different methods on CK+ dataset.</p></span></span><div class="groups"><table><thead><tr class="rowsep-1"><th scope="col" class="align-left valign-top">Methods</th><th scope="col" class="align-left valign-top"># of Expression</th><th scope="col" class="align-left valign-top">Accuracy(%)</th></tr></thead><tbody><tr><td class="align-left valign-top">LBP <a class="anchor anchor-primary" href="#bib0016" name="bbib0016" data-sd-ui-side-panel-opener="true" data-xocs-content-type="reference" data-xocs-content-id="bib0016"><span class="anchor-text-container"><span class="anchor-text">[16]</span></span></a></td><td class="align-left valign-top">6+neutral</td><td class="align-left valign-top">87.20</td></tr><tr><td class="align-left valign-top">HOG <a class="anchor anchor-primary" href="#bib0028" name="bbib0028" data-sd-ui-side-panel-opener="true" data-xocs-content-type="reference" data-xocs-content-id="bib0028"><span class="anchor-text-container"><span class="anchor-text">[28]</span></span></a></td><td class="align-left valign-top">6+neutral</td><td class="align-left valign-top">89.70</td></tr><tr><td class="align-left valign-top">Gabor filter <a class="anchor anchor-primary" href="#bib0050" name="bbib0050" data-sd-ui-side-panel-opener="true" data-xocs-content-type="reference" data-xocs-content-id="bib0050"><span class="anchor-text-container"><span class="anchor-text">[50]</span></span></a></td><td class="align-left valign-top">7</td><td class="align-left valign-top">84.80</td></tr><tr><td class="align-left valign-top">Poursaberi et&nbsp;al. <a class="anchor anchor-primary" href="#bib0051" name="bbib0051" data-sd-ui-side-panel-opener="true" data-xocs-content-type="reference" data-xocs-content-id="bib0051"><span class="anchor-text-container"><span class="anchor-text">[51]</span></span></a></td><td class="align-left valign-top">6</td><td class="align-left valign-top">92.02</td></tr><tr><td class="align-left valign-top">Deepak Ghimire <a class="anchor anchor-primary" href="#bib0052" name="bbib0052" data-sd-ui-side-panel-opener="true" data-xocs-content-type="reference" data-xocs-content-id="bib0052"><span class="anchor-text-container"><span class="anchor-text">[52]</span></span></a></td><td class="align-left valign-top">6</td><td class="align-left valign-top">94.10</td></tr><tr><td class="align-left valign-top">AU-DNN <a class="anchor anchor-primary" href="#bib0033" name="bbib0033" data-sd-ui-side-panel-opener="true" data-xocs-content-type="reference" data-xocs-content-id="bib0033"><span class="anchor-text-container"><span class="anchor-text">[33]</span></span></a></td><td class="align-left valign-top">6+neutral</td><td class="align-left valign-top">92.05</td></tr><tr><td class="align-left valign-top">JFDNN <a class="anchor anchor-primary" href="#bib0035" name="bbib0035" data-sd-ui-side-panel-opener="true" data-xocs-content-type="reference" data-xocs-content-id="bib0035"><span class="anchor-text-container"><span class="anchor-text">[35]</span></span></a></td><td class="align-left valign-top">6</td><td class="align-left valign-top">97.3</td></tr><tr><td class="align-left valign-top">CNN <a class="anchor anchor-primary" href="#bib0032" name="bbib0032" data-sd-ui-side-panel-opener="true" data-xocs-content-type="reference" data-xocs-content-id="bib0032"><span class="anchor-text-container"><span class="anchor-text">[32]</span></span></a></td><td class="align-left valign-top">6</td><td class="align-left valign-top">93.2(Top-1)</td></tr><tr><td class="align-left valign-top">C-CNN <a class="anchor anchor-primary" href="#bib0036" name="bbib0036" data-sd-ui-side-panel-opener="true" data-xocs-content-type="reference" data-xocs-content-id="bib0036"><span class="anchor-text-container"><span class="anchor-text">[36]</span></span></a></td><td class="align-left valign-top">6</td><td class="align-left valign-top">91.64</td></tr><tr><td class="align-left valign-top"><strong>Our Light-CNN</strong></td><td class="align-left valign-top"><strong>7</strong></td><td class="align-left valign-top"><strong>92.86</strong></td></tr><tr><td class="align-left valign-top"><strong>Our dual-branch CNN</strong></td><td class="align-left valign-top"><strong>7</strong></td><td class="align-left valign-top"><strong>85.71</strong></td></tr><tr><td class="align-left valign-top"><strong>Our pre-trained CNN</strong></td><td class="align-left valign-top"><strong>7</strong></td><td class="align-left valign-top"><strong>95.29</strong></td></tr></tbody></table></div></div></div><div class="u-margin-s-bottom" id="p0034">For the CK+ database, the accuracy of our algorithm is superior to most of the other advanced algorithms. The best performance of the existing deep learning methods is 97.3%, which is achieved by Jung <a class="anchor anchor-primary" href="#bib0035" name="bbib0035" data-sd-ui-side-panel-opener="true" data-xocs-content-type="reference" data-xocs-content-id="bib0035"><span class="anchor-text-container"><span class="anchor-text">[35]</span></span></a><span>. His network consists of three convolutional layers and two hidden layers. The filter size in the three convolutional layers is 5&nbsp;â€¯Ã—â€¯â€‰5, and the numbers of hidden nodes is set to 100 and 600 respectively. But his results declined to 92.35% without <a href="/topics/engineering/joints-structural-components" title="Learn more about joint from ScienceDirect's AI-generated Topic Pages" class="topic-link">joint</a><span> fine-tuning. By contrast our proposed method does not use any <a href="/topics/engineering/geometric-feature" title="Learn more about geometric features from ScienceDirect's AI-generated Topic Pages" class="topic-link">geometric features</a> or temporal video information, and improved the accuracy to 95.29% under seven expressions.</span></span></div><div class="u-margin-s-bottom"><div id="p0035">The comparison results on BU-3DFE dataset are shown in <a class="anchor anchor-primary" href="#tbl0005" name="btbl0005" data-sd-ui-side-panel-opener="true" data-xocs-content-type="reference" data-xocs-content-id="tbl0005"><span class="anchor-text-container"><span class="anchor-text">Table&nbsp;5</span></span></a>, the accuracy of method<a class="anchor anchor-primary" href="#bib0053" name="bbib0053" data-sd-ui-side-panel-opener="true" data-xocs-content-type="reference" data-xocs-content-id="bib0053"><span class="anchor-text-container"><span class="anchor-text">[53]</span></span></a> based on HOG is 54.64%. The accuracy of multi-class SVM with LBP and LGBP in <a class="anchor anchor-primary" href="#bib0054" name="bbib0054" data-sd-ui-side-panel-opener="true" data-xocs-content-type="reference" data-xocs-content-id="bib0054"><span class="anchor-text-container"><span class="anchor-text">[54]</span></span></a> is 71.1%. Dapogny et. al. <a class="anchor anchor-primary" href="#bib0055" name="bbib0055" data-sd-ui-side-panel-opener="true" data-xocs-content-type="reference" data-xocs-content-id="bib0055"><span class="anchor-text-container"><span class="anchor-text">[55]</span></span></a><span> proposed PCRF to capture low-level expression transition patterns on the condition of <a href="/topics/engineering/head-pose-estimation" title="Learn more about head pose estimation from ScienceDirect's AI-generated Topic Pages" class="topic-link">head pose estimation</a> for multi-view dynamic facial expression recognition. Their average accuracy reached 76.1%. The JFDNN </span><a class="anchor anchor-primary" href="#bib0035" name="bbib0035" data-sd-ui-side-panel-opener="true" data-xocs-content-type="reference" data-xocs-content-id="bib0035"><span class="anchor-text-container"><span class="anchor-text">[35]</span></span></a><span> reaches only 72.5%, which used to get the best result in CK+ dataset. The higher accuracies are achieved with <a href="/topics/computer-science/scale-invariant-feature-transform" title="Learn more about SIFT from ScienceDirect's AI-generated Topic Pages" class="topic-link">SIFT</a> feature using GSRRR and DNN-Driven methods proposed in </span><a class="anchor anchor-primary" href="#bib0056" name="bbib0056" data-sd-ui-side-panel-opener="true" data-xocs-content-type="reference" data-xocs-content-id="bib0056"><span class="anchor-text-container"><span class="anchor-text">[56]</span></span></a> and <a class="anchor anchor-primary" href="#bib0034" name="bbib0034" data-sd-ui-side-panel-opener="true" data-xocs-content-type="reference" data-xocs-content-id="bib0034"><span class="anchor-text-container"><span class="anchor-text">[34]</span></span></a>, which are 78.9% and 80.1%, respectively. In addition, Lopes et&nbsp;al. <a class="anchor anchor-primary" href="#bib0036" name="bbib0036" data-sd-ui-side-panel-opener="true" data-xocs-content-type="reference" data-xocs-content-id="bib0036"><span class="anchor-text-container"><span class="anchor-text">[36]</span></span></a> used intensity features to recognize six expressions with frontal poses and achieved an average accuracy of 90.96%. Our best result reaches 86.5%, which is competitive with the above method.</div><div class="tables rowsep-0 colsep-0 frame-topbot" id="tbl0005"><span class="captions text-s"><span id="cap0013"><p id="sp0017"><span class="label">Table 5</span>. Accuracy (%) using different methods on BU-3DFE dataset.</p></span></span><div class="groups"><table><thead><tr class="rowsep-1"><th scope="col" class="align-left valign-top">Methods</th><th scope="col" class="align-left valign-top">Poses</th><th scope="col" class="align-left valign-top">Accuracy (%)</th></tr></thead><tbody><tr><td class="align-left valign-top">HOG <a class="anchor anchor-primary" href="#bib0053" name="bbib0053" data-sd-ui-side-panel-opener="true" data-xocs-content-type="reference" data-xocs-content-id="bib0053"><span class="anchor-text-container"><span class="anchor-text">[53]</span></span></a></td><td class="align-left valign-top">5</td><td class="align-left valign-top">54.64</td></tr><tr><td class="align-left valign-top">LBP and LGBP <a class="anchor anchor-primary" href="#bib0054" name="bbib0054" data-sd-ui-side-panel-opener="true" data-xocs-content-type="reference" data-xocs-content-id="bib0054"><span class="anchor-text-container"><span class="anchor-text">[54]</span></span></a></td><td class="align-left valign-top">7</td><td class="align-left valign-top">71.1</td></tr><tr><td class="align-left valign-top">JFDNN <a class="anchor anchor-primary" href="#bib0035" name="bbib0035" data-sd-ui-side-panel-opener="true" data-xocs-content-type="reference" data-xocs-content-id="bib0035"><span class="anchor-text-container"><span class="anchor-text">[35]</span></span></a></td><td class="align-left valign-top">5</td><td class="align-left valign-top">72.5</td></tr><tr><td class="align-left valign-top">PCRF <a class="anchor anchor-primary" href="#bib0055" name="bbib0055" data-sd-ui-side-panel-opener="true" data-xocs-content-type="reference" data-xocs-content-id="bib0055"><span class="anchor-text-container"><span class="anchor-text">[55]</span></span></a></td><td class="align-left valign-top">5</td><td class="align-left valign-top">76.1</td></tr><tr><td class="align-left valign-top">CGPR <a class="anchor anchor-primary" href="#bib0057" name="bbib0057" data-sd-ui-side-panel-opener="true" data-xocs-content-type="reference" data-xocs-content-id="bib0057"><span class="anchor-text-container"><span class="anchor-text">[57]</span></span></a></td><td class="align-left valign-top">5</td><td class="align-left valign-top">76.5</td></tr><tr><td class="align-left valign-top">GSRRR <a class="anchor anchor-primary" href="#bib0056" name="bbib0056" data-sd-ui-side-panel-opener="true" data-xocs-content-type="reference" data-xocs-content-id="bib0056"><span class="anchor-text-container"><span class="anchor-text">[56]</span></span></a></td><td class="align-left valign-top">5</td><td class="align-left valign-top">78.90</td></tr><tr><td class="align-left valign-top">DNN-Driven <a class="anchor anchor-primary" href="#bib0034" name="bbib0034" data-sd-ui-side-panel-opener="true" data-xocs-content-type="reference" data-xocs-content-id="bib0034"><span class="anchor-text-container"><span class="anchor-text">[34]</span></span></a></td><td class="align-left valign-top">5</td><td class="align-left valign-top">80.10</td></tr><tr><td class="align-left valign-top">C-CNN <a class="anchor anchor-primary" href="#bib0036" name="bbib0036" data-sd-ui-side-panel-opener="true" data-xocs-content-type="reference" data-xocs-content-id="bib0036"><span class="anchor-text-container"><span class="anchor-text">[36]</span></span></a></td><td class="align-left valign-top">1 (frontal)</td><td class="align-left valign-top">90.96</td></tr><tr><td class="align-left valign-top"><strong>Our Light-CNN</strong></td><td class="align-left valign-top"><strong>5</strong></td><td class="align-left valign-top"><strong>86.20</strong></td></tr><tr><td class="align-left valign-top"><strong>Our dual-branch CNN</strong></td><td class="align-left valign-top"><strong>5</strong></td><td class="align-left valign-top"><strong>48.17</strong></td></tr><tr><td class="align-left valign-top"><strong>Our pre-trained CNN</strong></td><td class="align-left valign-top"><strong>5</strong></td><td class="align-left valign-top"><strong>86.50</strong></td></tr></tbody></table></div></div></div><div class="u-margin-s-bottom"><div id="p0036">Besides, <a class="anchor anchor-primary" href="#tbl0006" name="btbl0006" data-sd-ui-side-panel-opener="true" data-xocs-content-type="reference" data-xocs-content-id="tbl0006"><span class="anchor-text-container"><span class="anchor-text">Table&nbsp;6</span></span></a> shows the results achieved by the competing methods on the FER2013 database, which is the most challenging database in our experiment. There was a leaderboard of facial expression recognition challenge on FER2013 dataset. The number one method is the RBM. Our Light-CNN model achieved the accuracy of 68%, which is ranked #5 in the list, and the pretrained model ranked #2 among all the participating teams. It has almost the same accuracy with the first team.</div><div class="tables rowsep-0 colsep-0 frame-topbot" id="tbl0006"><span class="captions text-s"><span id="cap0014"><p id="sp0018"><span class="label">Table 6</span>. Accuracy (%) using different methods on FER2013 dataset.</p></span></span><div class="groups"><table><thead><tr class="rowsep-1"><th scope="col" class="align-left valign-top">Methods</th><th scope="col" class="align-left valign-top">Accuracy (%)</th></tr></thead><tbody><tr><td class="align-left valign-top">RBM <a class="anchor anchor-primary" href="#bib0058" name="bbib0058" data-sd-ui-side-panel-opener="true" data-xocs-content-type="reference" data-xocs-content-id="bib0058"><span class="anchor-text-container"><span class="anchor-text">[58]</span></span></a></td><td class="align-left valign-top">71.16</td></tr><tr><td class="align-left valign-top">Kim et&nbsp;al. <a class="anchor anchor-primary" href="#bib0059" name="bbib0059" data-sd-ui-side-panel-opener="true" data-xocs-content-type="reference" data-xocs-content-id="bib0059"><span class="anchor-text-container"><span class="anchor-text">[59]</span></span></a></td><td class="align-left valign-top">70.58</td></tr><tr><td class="align-left valign-top">Jeon et&nbsp;al. <a class="anchor anchor-primary" href="#bib0060" name="bbib0060" data-sd-ui-side-panel-opener="true" data-xocs-content-type="reference" data-xocs-content-id="bib0060"><span class="anchor-text-container"><span class="anchor-text">[60]</span></span></a></td><td class="align-left valign-top">70.47</td></tr><tr><td class="align-left valign-top">Devries et&nbsp;al. <a class="anchor anchor-primary" href="#bib0061" name="bbib0061" data-sd-ui-side-panel-opener="true" data-xocs-content-type="reference" data-xocs-content-id="bib0061"><span class="anchor-text-container"><span class="anchor-text">[61]</span></span></a></td><td class="align-left valign-top">67.21</td></tr><tr><td class="align-left valign-top">CNN <a class="anchor anchor-primary" href="#bib0032" name="bbib0032" data-sd-ui-side-panel-opener="true" data-xocs-content-type="reference" data-xocs-content-id="bib0032"><span class="anchor-text-container"><span class="anchor-text">[32]</span></span></a></td><td class="align-left valign-top">66.4 (Top-1)</td></tr><tr><td class="align-left valign-top">Liu et&nbsp;al. <a class="anchor anchor-primary" href="#bib0062" name="bbib0062" data-sd-ui-side-panel-opener="true" data-xocs-content-type="reference" data-xocs-content-id="bib0062"><span class="anchor-text-container"><span class="anchor-text">[62]</span></span></a></td><td class="align-left valign-top">65.03</td></tr><tr><td class="align-left valign-top">Shen et&nbsp;al. <a class="anchor anchor-primary" href="#bib0063" name="bbib0063" data-sd-ui-side-panel-opener="true" data-xocs-content-type="reference" data-xocs-content-id="bib0063"><span class="anchor-text-container"><span class="anchor-text">[63]</span></span></a></td><td class="align-left valign-top">61.86</td></tr><tr><td class="align-left valign-top">Ergen et&nbsp;al. <a class="anchor anchor-primary" href="#bib0064" name="bbib0064" data-sd-ui-side-panel-opener="true" data-xocs-content-type="reference" data-xocs-content-id="bib0064"><span class="anchor-text-container"><span class="anchor-text">[64]</span></span></a></td><td class="align-left valign-top">57.10</td></tr><tr><td class="align-left valign-top"><strong>Our Light-CNN</strong></td><td class="align-left valign-top"><strong>68</strong></td></tr><tr><td class="align-left valign-top"><strong>Our dual-branch CNN</strong></td><td class="align-left valign-top"><strong>54.64</strong></td></tr><tr><td class="align-left valign-top"><strong>Our pre-trained CNN</strong></td><td class="align-left valign-top"><strong>71.14</strong></td></tr></tbody></table></div></div></div></section><section id="sec0012"><h3 id="sctt0014" class="u-h4 u-margin-m-top u-margin-xs-bottom">4.5. Discussion</h3><div class="u-margin-s-bottom" id="p0037"><span>Above all, Our CNN models achieved state-of-the-art performance without using additional <a href="/topics/computer-science/training-data" title="Learn more about training data from ScienceDirect's AI-generated Topic Pages" class="topic-link">training data</a> or functions, comprehensive data enhancement or facial registration. It is predictable that it will success in processing larger database in the future. Under the same conditions, the performance of deeper pre-trained CNN was better than the others. Our experimental results demonstrated the potential to significantly improve FER performance using pre-trained deep network structures, which could solve the problems of the lack of training samples and over-fitting. The Light-CNN overcome the challenge of overfitting, and kept good performance in all the popular FER datasets (see </span><a class="anchor anchor-primary" href="#tbl0003" name="btbl0003" data-sd-ui-side-panel-opener="true" data-xocs-content-type="reference" data-xocs-content-id="tbl0003"><span class="anchor-text-container"><span class="anchor-text">Table&nbsp;3</span></span></a><span>) as well. In addition, in our dual-branch CNN, <a href="/topics/computer-science/representation-learning" title="Learn more about learning features from ScienceDirect's AI-generated Topic Pages" class="topic-link">learning features</a> and manual features were put into the final fusion layers to explore whether the combination of features can improve the classification effect. The results showed that the effect of learning deep features was not improved under the guidance of traditional features.</span></div></section></section><section id="sec0013"><h2 id="sctt0015" class="u-h4 u-margin-l-top u-margin-xs-bottom">5. Conclusions and future works</h2><div class="u-margin-s-bottom" id="p0038">We developed three CNN models for facial expression recognition in the wild and evaluated their performances using different analyzing and visualization techniques. The results demonstrated that the deeper model has better performance on <a href="/topics/computer-science/facial-feature" title="Learn more about facial feature from ScienceDirect's AI-generated Topic Pages" class="topic-link">facial feature</a> learning and emotion classification. However, the experiments implemented by the Light-CNN proved that a shallow CNN could also achieve good scores in facial expression recognition in the wild. In addition, mixing feature sets do not help to improve accuracy, which means that convolutional neutral networks can learn key facial features simply by using raw pixel data. In future work, we will use more efficient hand-crafted features to join our dual-branch CNN and change the fusion mode. Moreover, we will use cross-database training network parameters to get better generalization capabilities.</div></section><section id="sec0013a"><h2 id="sctt0015a" class="u-h4 u-margin-l-top u-margin-xs-bottom">Conflict of interests</h2><div class="u-margin-s-bottom" id="p0038a">The authors declare that there is no conflict of interests regarding the publication of this paper.</div></section></div><section id="ack0001"><h2 id="sctt0016" class="u-h4 u-margin-l-top u-margin-xs-bottom">Acknowledgment</h2><div class="u-margin-s-bottom" id="p0039">This work was supported by the <span id="gs00001">National Natural Science Foundation of China</span> Youth Science Foundation project (Nos. <a class="anchor anchor-primary" href="#gs00001"><span class="anchor-text-container"><span class="anchor-text">61802250</span></span></a>, <a class="anchor anchor-primary" href="#gs00001"><span class="anchor-text-container"><span class="anchor-text">61401268</span></span></a>) and <span id="gs00002">Shanghai Natural Science Foundation</span> of China (<a class="anchor anchor-primary" href="#gs00002"><span class="anchor-text-container"><span class="anchor-text">15ZR1418400</span></span></a>).</div></section></div><div class="related-content-links u-display-none-from-md"><button class="button-link button-link-primary button-link-small" type="button"><span class="button-link-text-container"><span class="button-link-text">Recommended articles</span></span></button></div><div class="Tail"></div><div><section class="bibliography u-font-serif text-s" id="bib001"><h2 class="section-title u-h4 u-margin-l-top u-margin-xs-bottom">References</h2><section class="bibliography-sec" id="bibsec002"><ol class="references" id="reference-links-bibsec002"><li><span class="label u-font-sans"><a class="anchor anchor-primary" href="#bbib0001" id="ref-id-bib0001" data-aa-button="sd:product:journal:article:location=references:type=anchor:name=citation-name"><span class="anchor-text-container"><span class="anchor-text">[1]</span></span></a></span><span class="reference" id="sbref0001"><div class="contribution"><div class="authors u-font-sans">Wang R., Fang B.</div><div id="ref-id-sbref0001" class="title text-m">Affective computing and biometrics based HCI surveillance system</div></div><div class="host u-font-sans">Proceedings of the International Symposium on Information Science and Engineering (2008), pp. 192-195</div><div class="ReferenceLinks u-font-sans"><a class="anchor link anchor-primary" href="https://www.scopus.com/inward/record.url?eid=2-s2.0-62449133933&amp;partnerID=10&amp;rel=R3.0.0" target="_blank" rel="noopener noreferrer" aria-describedby="ref-id-sbref0001"><span class="anchor-text-container"><span class="anchor-text">View in Scopus</span><svg focusable="false" viewBox="0 0 8 8" height="20" aria-label="Opens in new window" class="icon icon-arrow-up-right-tiny arrow-external-link"><path d="M1.12949 2.1072V1H7V6.85795H5.89111V2.90281L0.784057 8L0 7.21635L5.11902 2.1072H1.12949Z"></path></svg></span></a><a class="anchor link anchor-primary" href="https://scholar.google.com/scholar_lookup?title=Affective%20computing%20and%20biometrics%20based%20HCI%20surveillance%20system&amp;publication_year=2008&amp;author=R.%20Wang&amp;author=B.%20Fang" target="_blank" rel="noopener noreferrer" aria-describedby="ref-id-sbref0001"><span class="anchor-text-container"><span class="anchor-text">Google Scholar</span><svg focusable="false" viewBox="0 0 8 8" height="20" aria-label="Opens in new window" class="icon icon-arrow-up-right-tiny arrow-external-link"><path d="M1.12949 2.1072V1H7V6.85795H5.89111V2.90281L0.784057 8L0 7.21635L5.11902 2.1072H1.12949Z"></path></svg></span></a></div></span></li><li><span class="label u-font-sans"><a class="anchor anchor-primary" href="#bbib0002" id="ref-id-bib0002" data-aa-button="sd:product:journal:article:location=references:type=anchor:name=citation-name"><span class="anchor-text-container"><span class="anchor-text">[2]</span></span></a></span><span class="reference" id="sbref0002"><div class="contribution"><div class="authors u-font-sans">W. Weiguo, Qingmei M., Yu W.</div><div id="ref-id-sbref0002" class="title text-m">Development of the humanoid head portrait robot system with flexible face and expression</div></div><div class="host u-font-sans">Proceedings of the 2004 IEEE International Conference on Robotics and Biomimetics (2004), pp. 757-762, <a class="anchor anchor-primary" href="https://doi.org/10.1109/ROBIO.2004.1521877" target="_blank"><span class="anchor-text-container"><span class="anchor-text">10.1109/ROBIO.2004.1521877</span><svg focusable="false" viewBox="0 0 8 8" height="20" aria-label="Opens in new window" class="icon icon-arrow-up-right-tiny arrow-external-link"><path d="M1.12949 2.1072V1H7V6.85795H5.89111V2.90281L0.784057 8L0 7.21635L5.11902 2.1072H1.12949Z"></path></svg></span></a></div><div class="ReferenceLinks u-font-sans"><span class="link lazy-third-party-pdf-link"><span></span></span><a class="anchor link anchor-primary" href="https://scholar.google.com/scholar_lookup?title=Development%20of%20the%20humanoid%20head%20portrait%20robot%20system%20with%20flexible%20face%20and%20expression&amp;publication_year=2004&amp;author=W.%20Weiguo&amp;author=M.%20Qingmei&amp;author=W.%20Yu" target="_blank" rel="noopener noreferrer" aria-describedby="ref-id-sbref0002"><span class="anchor-text-container"><span class="anchor-text">Google Scholar</span><svg focusable="false" viewBox="0 0 8 8" height="20" aria-label="Opens in new window" class="icon icon-arrow-up-right-tiny arrow-external-link"><path d="M1.12949 2.1072V1H7V6.85795H5.89111V2.90281L0.784057 8L0 7.21635L5.11902 2.1072H1.12949Z"></path></svg></span></a></div></span></li><li><span class="label u-font-sans"><a class="anchor anchor-primary" href="#bbib0003" id="ref-id-bib0003" data-aa-button="sd:product:journal:article:location=references:type=anchor:name=citation-name"><span class="anchor-text-container"><span class="anchor-text">[3]</span></span></a></span><span class="reference" id="sbref0003"><div class="contribution"><div class="authors u-font-sans">Su M.H., Wu C.H., Huang K.Y., Hong Q.B., Wang H.M.</div><div id="ref-id-sbref0003" class="title text-m">Exploring microscopic fluctuation of facial expression for mood disorder classification</div></div><div class="host u-font-sans">Proceedings of the International Conference on Orange Technologies (2017), pp. 65-69</div><div class="ReferenceLinks u-font-sans"><span class="link lazy-third-party-pdf-link"><span></span></span><a class="anchor link anchor-primary" href="https://doi.org/10.1109/icot.2017.8336090" target="_blank" rel="noopener noreferrer" aria-describedby="ref-id-sbref0003"><span class="anchor-text-container"><span class="anchor-text">Crossref</span><svg focusable="false" viewBox="0 0 8 8" height="20" aria-label="Opens in new window" class="icon icon-arrow-up-right-tiny arrow-external-link"><path d="M1.12949 2.1072V1H7V6.85795H5.89111V2.90281L0.784057 8L0 7.21635L5.11902 2.1072H1.12949Z"></path></svg></span></a><a class="anchor link anchor-primary" href="https://www.scopus.com/inward/record.url?eid=2-s2.0-85048561858&amp;partnerID=10&amp;rel=R3.0.0" target="_blank" rel="noopener noreferrer" aria-describedby="ref-id-sbref0003"><span class="anchor-text-container"><span class="anchor-text">View in Scopus</span><svg focusable="false" viewBox="0 0 8 8" height="20" aria-label="Opens in new window" class="icon icon-arrow-up-right-tiny arrow-external-link"><path d="M1.12949 2.1072V1H7V6.85795H5.89111V2.90281L0.784057 8L0 7.21635L5.11902 2.1072H1.12949Z"></path></svg></span></a><a class="anchor link anchor-primary" href="https://scholar.google.com/scholar_lookup?title=Exploring%20microscopic%20fluctuation%20of%20facial%20expression%20for%20mood%20disorder%20classification&amp;publication_year=2017&amp;author=M.H.%20Su&amp;author=C.H.%20Wu&amp;author=K.Y.%20Huang&amp;author=Q.B.%20Hong&amp;author=H.M.%20Wang" target="_blank" rel="noopener noreferrer" aria-describedby="ref-id-sbref0003"><span class="anchor-text-container"><span class="anchor-text">Google Scholar</span><svg focusable="false" viewBox="0 0 8 8" height="20" aria-label="Opens in new window" class="icon icon-arrow-up-right-tiny arrow-external-link"><path d="M1.12949 2.1072V1H7V6.85795H5.89111V2.90281L0.784057 8L0 7.21635L5.11902 2.1072H1.12949Z"></path></svg></span></a></div></span></li><li><span class="label u-font-sans"><a class="anchor anchor-primary" href="#bbib0004" id="ref-id-bib0004" data-aa-button="sd:product:journal:article:location=references:type=anchor:name=citation-name"><span class="anchor-text-container"><span class="anchor-text">[4]</span></span></a></span><span class="reference" id="othref0001"><div class="other-ref"><span>M.B. Mariappan, M. Suk, B. Prabhakaran, Facefetch: a user emotion driven multimedia content recommendation system based on facial expression recognition, Proceedings of the 2012 IEEE International Symposium on Multimedia(2012) 84â€“87.</span></div><div class="ReferenceLinks u-font-sans"><a class="anchor link anchor-primary" href="https://scholar.google.com/scholar?q=M.B.%20Mariappan%2C%20M.%20Suk%2C%20B.%20Prabhakaran%2C%20Facefetch%3A%20a%20user%20emotion%20driven%20multimedia%20content%20recommendation%20system%20based%20on%20facial%20expression%20recognition%2C%20Proceedings%20of%20the%202012%20IEEE%20International%20Symposium%20on%20Multimedia(2012)%2084%E2%80%9387." target="_blank" rel="noopener noreferrer"><span class="anchor-text-container"><span class="anchor-text">Google Scholar</span><svg focusable="false" viewBox="0 0 8 8" height="20" aria-label="Opens in new window" class="icon icon-arrow-up-right-tiny arrow-external-link"><path d="M1.12949 2.1072V1H7V6.85795H5.89111V2.90281L0.784057 8L0 7.21635L5.11902 2.1072H1.12949Z"></path></svg></span></a></div></span></li><li><span class="label u-font-sans"><a class="anchor anchor-primary" href="#bbib0005" id="ref-id-bib0005" data-aa-button="sd:product:journal:article:location=references:type=anchor:name=citation-name"><span class="anchor-text-container"><span class="anchor-text">[5]</span></span></a></span><span class="reference" id="sbref0004"><div class="contribution"><div class="authors u-font-sans">S.A. Patil, P.J. Deore</div><div id="ref-id-sbref0004" class="title text-m">Local binary pattern based face recognition system for automotive security</div></div><div class="host u-font-sans">Proceedings of the International Conference on Signal Processing, Computing and Control (2016), pp. 13-17</div><div class="ReferenceLinks u-font-sans"><a class="anchor link anchor-primary" href="https://scholar.google.com/scholar_lookup?title=Local%20binary%20pattern%20based%20face%20recognition%20system%20for%20automotive%20security&amp;publication_year=2016&amp;author=S.A.%20Patil&amp;author=P.J.%20Deore" target="_blank" rel="noopener noreferrer" aria-describedby="ref-id-sbref0004"><span class="anchor-text-container"><span class="anchor-text">Google Scholar</span><svg focusable="false" viewBox="0 0 8 8" height="20" aria-label="Opens in new window" class="icon icon-arrow-up-right-tiny arrow-external-link"><path d="M1.12949 2.1072V1H7V6.85795H5.89111V2.90281L0.784057 8L0 7.21635L5.11902 2.1072H1.12949Z"></path></svg></span></a></div></span></li><li><span class="label u-font-sans"><a class="anchor anchor-primary" href="#bbib0006" id="ref-id-bib0006" data-aa-button="sd:product:journal:article:location=references:type=anchor:name=citation-name"><span class="anchor-text-container"><span class="anchor-text">[6]</span></span></a></span><span class="reference" id="sbref0005"><div class="contribution"><div class="authors u-font-sans">Zhong L., Liu Q., Yang P., Liu B., Huang J., D.N. Metaxas</div><div id="ref-id-sbref0005" class="title text-m">Learning multiscale active facial patches for expression analysis</div></div><div class="host u-font-sans">Proceedings of the Computer Vision and Pattern Recognition (2012), pp. 2562-2569</div><div class="ReferenceLinks u-font-sans"><a class="anchor link anchor-primary" href="https://www.scopus.com/inward/record.url?eid=2-s2.0-84866697202&amp;partnerID=10&amp;rel=R3.0.0" target="_blank" rel="noopener noreferrer" aria-describedby="ref-id-sbref0005"><span class="anchor-text-container"><span class="anchor-text">View in Scopus</span><svg focusable="false" viewBox="0 0 8 8" height="20" aria-label="Opens in new window" class="icon icon-arrow-up-right-tiny arrow-external-link"><path d="M1.12949 2.1072V1H7V6.85795H5.89111V2.90281L0.784057 8L0 7.21635L5.11902 2.1072H1.12949Z"></path></svg></span></a><a class="anchor link anchor-primary" href="https://scholar.google.com/scholar_lookup?title=Learning%20multiscale%20active%20facial%20patches%20for%20expression%20analysis&amp;publication_year=2012&amp;author=L.%20Zhong&amp;author=Q.%20Liu&amp;author=P.%20Yang&amp;author=B.%20Liu&amp;author=J.%20Huang&amp;author=D.N.%20Metaxas" target="_blank" rel="noopener noreferrer" aria-describedby="ref-id-sbref0005"><span class="anchor-text-container"><span class="anchor-text">Google Scholar</span><svg focusable="false" viewBox="0 0 8 8" height="20" aria-label="Opens in new window" class="icon icon-arrow-up-right-tiny arrow-external-link"><path d="M1.12949 2.1072V1H7V6.85795H5.89111V2.90281L0.784057 8L0 7.21635L5.11902 2.1072H1.12949Z"></path></svg></span></a></div></span></li><li><span class="label u-font-sans"><a class="anchor anchor-primary" href="#bbib0007" id="ref-id-bib0007" data-aa-button="sd:product:journal:article:location=references:type=anchor:name=citation-name"><span class="anchor-text-container"><span class="anchor-text">[7]</span></span></a></span><span class="reference" id="sbref0006"><div class="contribution"><div class="authors u-font-sans">Zheng H., Geng X., Tao D., Jin Z.</div><div id="ref-id-sbref0006" class="title text-m">A multi-task model for simultaneous face identification and facial expression recognition</div></div><div class="host u-font-sans">Neurocomputing, 171 (C) (2016), pp. 515-523</div><div class="ReferenceLinks u-font-sans"><a class="anchor pdf link anchor-primary anchor-icon-left anchor-with-icon" href="/science/article/pii/S0925231215010097/pdfft?md5=ded95acdc127ac544ec76f7c7a63234a&amp;pid=1-s2.0-S0925231215010097-main.pdf" target="_blank" rel="nofollow" aria-describedby="ref-id-sbref0006"><svg focusable="false" viewBox="0 0 35 32" height="20" class="icon icon-pdf-multicolor"><path d="M7 .362h17.875l6.763 6.1V31.64H6.948V16z" stroke="#000" stroke-width=".703" fill="#fff"></path><path d="M.167 2.592H22.39V9.72H.166z" fill="#da0000"></path><path fill="#fff9f9" d="M5.97 3.638h1.62c1.053 0 1.483.677 1.488 1.564.008.96-.6 1.564-1.492 1.564h-.644v1.66h-.977V3.64m.977.897v1.34h.542c.27 0 .596-.068.596-.673-.002-.6-.32-.667-.596-.667h-.542m3.8.036v2.92h.35c.933 0 1.223-.448 1.228-1.462.008-1.06-.316-1.45-1.23-1.45h-.347m-.977-.94h1.03c1.68 0 2.523.586 2.534 2.39.01 1.688-.607 2.4-2.534 2.4h-1.03V3.64m4.305 0h2.63v.934h-1.657v.894H16.6V6.4h-1.56v2.026h-.97V3.638"></path><path d="M19.462 13.46c.348 4.274-6.59 16.72-8.508 15.792-1.82-.85 1.53-3.317 2.92-4.366-2.864.894-5.394 3.252-3.837 3.93 2.113.895 7.048-9.25 9.41-15.394zM14.32 24.874c4.767-1.526 14.735-2.974 15.152-1.407.824-3.157-13.72-.37-15.153 1.407zm5.28-5.043c2.31 3.237 9.816 7.498 9.788 3.82-.306 2.046-6.66-1.097-8.925-4.164-4.087-5.534-2.39-8.772-1.682-8.732.917.047 1.074 1.307.67 2.442-.173-1.406-.58-2.44-1.224-2.415-1.835.067-1.905 4.46 1.37 9.065z" fill="#f91d0a"></path></svg><span class="anchor-text-container"><span class="anchor-text">View PDF</span></span></a><a class="anchor link anchor-primary" href="/science/article/pii/S0925231215010097" aria-describedby="ref-id-sbref0006"><span class="anchor-text-container"><span class="anchor-text">View article</span></span></a><a class="anchor link anchor-primary" href="https://www.scopus.com/inward/record.url?eid=2-s2.0-84947025752&amp;partnerID=10&amp;rel=R3.0.0" target="_blank" rel="noopener noreferrer" aria-describedby="ref-id-sbref0006"><span class="anchor-text-container"><span class="anchor-text">View in Scopus</span><svg focusable="false" viewBox="0 0 8 8" height="20" aria-label="Opens in new window" class="icon icon-arrow-up-right-tiny arrow-external-link"><path d="M1.12949 2.1072V1H7V6.85795H5.89111V2.90281L0.784057 8L0 7.21635L5.11902 2.1072H1.12949Z"></path></svg></span></a><a class="anchor link anchor-primary" href="https://scholar.google.com/scholar_lookup?title=A%20multi-task%20model%20for%20simultaneous%20face%20identification%20and%20facial%20expression%20recognition&amp;publication_year=2016&amp;author=H.%20Zheng&amp;author=X.%20Geng&amp;author=D.%20Tao&amp;author=Z.%20Jin" target="_blank" rel="noopener noreferrer" aria-describedby="ref-id-sbref0006"><span class="anchor-text-container"><span class="anchor-text">Google Scholar</span><svg focusable="false" viewBox="0 0 8 8" height="20" aria-label="Opens in new window" class="icon icon-arrow-up-right-tiny arrow-external-link"><path d="M1.12949 2.1072V1H7V6.85795H5.89111V2.90281L0.784057 8L0 7.21635L5.11902 2.1072H1.12949Z"></path></svg></span></a></div></span></li><li><span class="label u-font-sans"><a class="anchor anchor-primary" href="#bbib0008" id="ref-id-bib0008" data-aa-button="sd:product:journal:article:location=references:type=anchor:name=citation-name"><span class="anchor-text-container"><span class="anchor-text">[8]</span></span></a></span><span class="reference" id="sbref0007"><div class="contribution"><div class="authors u-font-sans">Qi T., Yong X., Quan Y., Wang Y., Ling H.</div><div id="ref-id-sbref0007" class="title text-m">Image-based action recognition using hint-enhanced deep neural networks</div></div><div class="host u-font-sans">Neurocomputing, 267 (2017), pp. 475-488</div><div class="ReferenceLinks u-font-sans"><a class="anchor pdf link anchor-primary anchor-icon-left anchor-with-icon" href="/science/article/pii/S0925231217311694/pdfft?md5=2b1606747164108bb810d7403a86a3b3&amp;pid=1-s2.0-S0925231217311694-main.pdf" target="_blank" rel="nofollow" aria-describedby="ref-id-sbref0007"><svg focusable="false" viewBox="0 0 35 32" height="20" class="icon icon-pdf-multicolor"><path d="M7 .362h17.875l6.763 6.1V31.64H6.948V16z" stroke="#000" stroke-width=".703" fill="#fff"></path><path d="M.167 2.592H22.39V9.72H.166z" fill="#da0000"></path><path fill="#fff9f9" d="M5.97 3.638h1.62c1.053 0 1.483.677 1.488 1.564.008.96-.6 1.564-1.492 1.564h-.644v1.66h-.977V3.64m.977.897v1.34h.542c.27 0 .596-.068.596-.673-.002-.6-.32-.667-.596-.667h-.542m3.8.036v2.92h.35c.933 0 1.223-.448 1.228-1.462.008-1.06-.316-1.45-1.23-1.45h-.347m-.977-.94h1.03c1.68 0 2.523.586 2.534 2.39.01 1.688-.607 2.4-2.534 2.4h-1.03V3.64m4.305 0h2.63v.934h-1.657v.894H16.6V6.4h-1.56v2.026h-.97V3.638"></path><path d="M19.462 13.46c.348 4.274-6.59 16.72-8.508 15.792-1.82-.85 1.53-3.317 2.92-4.366-2.864.894-5.394 3.252-3.837 3.93 2.113.895 7.048-9.25 9.41-15.394zM14.32 24.874c4.767-1.526 14.735-2.974 15.152-1.407.824-3.157-13.72-.37-15.153 1.407zm5.28-5.043c2.31 3.237 9.816 7.498 9.788 3.82-.306 2.046-6.66-1.097-8.925-4.164-4.087-5.534-2.39-8.772-1.682-8.732.917.047 1.074 1.307.67 2.442-.173-1.406-.58-2.44-1.224-2.415-1.835.067-1.905 4.46 1.37 9.065z" fill="#f91d0a"></path></svg><span class="anchor-text-container"><span class="anchor-text">View PDF</span></span></a><a class="anchor link anchor-primary" href="/science/article/pii/S0925231217311694" aria-describedby="ref-id-sbref0007"><span class="anchor-text-container"><span class="anchor-text">View article</span></span></a><a class="anchor link anchor-primary" href="https://www.scopus.com/inward/record.url?eid=2-s2.0-85026394713&amp;partnerID=10&amp;rel=R3.0.0" target="_blank" rel="noopener noreferrer" aria-describedby="ref-id-sbref0007"><span class="anchor-text-container"><span class="anchor-text">View in Scopus</span><svg focusable="false" viewBox="0 0 8 8" height="20" aria-label="Opens in new window" class="icon icon-arrow-up-right-tiny arrow-external-link"><path d="M1.12949 2.1072V1H7V6.85795H5.89111V2.90281L0.784057 8L0 7.21635L5.11902 2.1072H1.12949Z"></path></svg></span></a><a class="anchor link anchor-primary" href="https://scholar.google.com/scholar_lookup?title=Image-based%20action%20recognition%20using%20hint-enhanced%20deep%20neural%20networks&amp;publication_year=2017&amp;author=T.%20Qi&amp;author=X.%20Yong&amp;author=Y.%20Quan&amp;author=Y.%20Wang&amp;author=H.%20Ling" target="_blank" rel="noopener noreferrer" aria-describedby="ref-id-sbref0007"><span class="anchor-text-container"><span class="anchor-text">Google Scholar</span><svg focusable="false" viewBox="0 0 8 8" height="20" aria-label="Opens in new window" class="icon icon-arrow-up-right-tiny arrow-external-link"><path d="M1.12949 2.1072V1H7V6.85795H5.89111V2.90281L0.784057 8L0 7.21635L5.11902 2.1072H1.12949Z"></path></svg></span></a></div></span></li><li><span class="label u-font-sans"><a class="anchor anchor-primary" href="#bbib0009" id="ref-id-bib0009" data-aa-button="sd:product:journal:article:location=references:type=anchor:name=citation-name"><span class="anchor-text-container"><span class="anchor-text">[9]</span></span></a></span><span class="reference" id="sbref0008"><div class="contribution"><div class="authors u-font-sans">M. Morchid</div><div id="ref-id-sbref0008" class="title text-m">Parsimonious memory unit for recurrent neural networks with application to natural language processing</div></div><div class="host u-font-sans">Neurocomputing, 314 (2018), pp. 48-64</div><div class="ReferenceLinks u-font-sans"><a class="anchor pdf link anchor-primary anchor-icon-left anchor-with-icon" href="/science/article/pii/S0925231218306660/pdfft?md5=fc0a068ff2b0cf16c1bbe4f27e332ce2&amp;pid=1-s2.0-S0925231218306660-main.pdf" target="_blank" rel="nofollow" aria-describedby="ref-id-sbref0008"><svg focusable="false" viewBox="0 0 35 32" height="20" class="icon icon-pdf-multicolor"><path d="M7 .362h17.875l6.763 6.1V31.64H6.948V16z" stroke="#000" stroke-width=".703" fill="#fff"></path><path d="M.167 2.592H22.39V9.72H.166z" fill="#da0000"></path><path fill="#fff9f9" d="M5.97 3.638h1.62c1.053 0 1.483.677 1.488 1.564.008.96-.6 1.564-1.492 1.564h-.644v1.66h-.977V3.64m.977.897v1.34h.542c.27 0 .596-.068.596-.673-.002-.6-.32-.667-.596-.667h-.542m3.8.036v2.92h.35c.933 0 1.223-.448 1.228-1.462.008-1.06-.316-1.45-1.23-1.45h-.347m-.977-.94h1.03c1.68 0 2.523.586 2.534 2.39.01 1.688-.607 2.4-2.534 2.4h-1.03V3.64m4.305 0h2.63v.934h-1.657v.894H16.6V6.4h-1.56v2.026h-.97V3.638"></path><path d="M19.462 13.46c.348 4.274-6.59 16.72-8.508 15.792-1.82-.85 1.53-3.317 2.92-4.366-2.864.894-5.394 3.252-3.837 3.93 2.113.895 7.048-9.25 9.41-15.394zM14.32 24.874c4.767-1.526 14.735-2.974 15.152-1.407.824-3.157-13.72-.37-15.153 1.407zm5.28-5.043c2.31 3.237 9.816 7.498 9.788 3.82-.306 2.046-6.66-1.097-8.925-4.164-4.087-5.534-2.39-8.772-1.682-8.732.917.047 1.074 1.307.67 2.442-.173-1.406-.58-2.44-1.224-2.415-1.835.067-1.905 4.46 1.37 9.065z" fill="#f91d0a"></path></svg><span class="anchor-text-container"><span class="anchor-text">View PDF</span></span></a><a class="anchor link anchor-primary" href="/science/article/pii/S0925231218306660" aria-describedby="ref-id-sbref0008"><span class="anchor-text-container"><span class="anchor-text">View article</span></span></a><a class="anchor link anchor-primary" href="https://www.scopus.com/inward/record.url?eid=2-s2.0-85049643418&amp;partnerID=10&amp;rel=R3.0.0" target="_blank" rel="noopener noreferrer" aria-describedby="ref-id-sbref0008"><span class="anchor-text-container"><span class="anchor-text">View in Scopus</span><svg focusable="false" viewBox="0 0 8 8" height="20" aria-label="Opens in new window" class="icon icon-arrow-up-right-tiny arrow-external-link"><path d="M1.12949 2.1072V1H7V6.85795H5.89111V2.90281L0.784057 8L0 7.21635L5.11902 2.1072H1.12949Z"></path></svg></span></a><a class="anchor link anchor-primary" href="https://scholar.google.com/scholar_lookup?title=Parsimonious%20memory%20unit%20for%20recurrent%20neural%20networks%20with%20application%20to%20natural%20language%20processing&amp;publication_year=2018&amp;author=M.%20Morchid" target="_blank" rel="noopener noreferrer" aria-describedby="ref-id-sbref0008"><span class="anchor-text-container"><span class="anchor-text">Google Scholar</span><svg focusable="false" viewBox="0 0 8 8" height="20" aria-label="Opens in new window" class="icon icon-arrow-up-right-tiny arrow-external-link"><path d="M1.12949 2.1072V1H7V6.85795H5.89111V2.90281L0.784057 8L0 7.21635L5.11902 2.1072H1.12949Z"></path></svg></span></a></div></span></li><li><span class="label u-font-sans"><a class="anchor anchor-primary" href="#bbib0010" id="ref-id-bib0010" data-aa-button="sd:product:journal:article:location=references:type=anchor:name=citation-name"><span class="anchor-text-container"><span class="anchor-text">[10]</span></span></a></span><span class="reference" id="sbref0009"><div class="contribution"><div class="authors u-font-sans">Yu L., Shao X., Yan X.</div><div id="ref-id-sbref0009" class="title text-m">Autonomous overtaking decision making of driverless bus based on deep q-learning method</div></div><div class="host u-font-sans">Proceedings of the 2017 IEEE International Conference on Robotics and Biomimetics (ROBIO) (2017), pp. 2267-2272</div><div class="ReferenceLinks u-font-sans"><a class="anchor link anchor-primary" href="https://www.scopus.com/inward/record.url?eid=2-s2.0-85050031143&amp;partnerID=10&amp;rel=R3.0.0" target="_blank" rel="noopener noreferrer" aria-describedby="ref-id-sbref0009"><span class="anchor-text-container"><span class="anchor-text">View in Scopus</span><svg focusable="false" viewBox="0 0 8 8" height="20" aria-label="Opens in new window" class="icon icon-arrow-up-right-tiny arrow-external-link"><path d="M1.12949 2.1072V1H7V6.85795H5.89111V2.90281L0.784057 8L0 7.21635L5.11902 2.1072H1.12949Z"></path></svg></span></a><a class="anchor link anchor-primary" href="https://scholar.google.com/scholar_lookup?title=Autonomous%20overtaking%20decision%20making%20of%20driverless%20bus%20based%20on%20deep%20q-learning%20method&amp;publication_year=2017&amp;author=L.%20Yu&amp;author=X.%20Shao&amp;author=X.%20Yan" target="_blank" rel="noopener noreferrer" aria-describedby="ref-id-sbref0009"><span class="anchor-text-container"><span class="anchor-text">Google Scholar</span><svg focusable="false" viewBox="0 0 8 8" height="20" aria-label="Opens in new window" class="icon icon-arrow-up-right-tiny arrow-external-link"><path d="M1.12949 2.1072V1H7V6.85795H5.89111V2.90281L0.784057 8L0 7.21635L5.11902 2.1072H1.12949Z"></path></svg></span></a></div></span></li><li><span class="label u-font-sans"><a class="anchor anchor-primary" href="#bbib0011" id="ref-id-bib0011" data-aa-button="sd:product:journal:article:location=references:type=anchor:name=citation-name"><span class="anchor-text-container"><span class="anchor-text">[11]</span></span></a></span><span class="reference" id="sbref0010"><div class="contribution"><div class="authors u-font-sans">Yang K., Gong X., Liu Y., Li Z., Xing T., Chen X., Fang D.</div><div id="ref-id-sbref0010" class="title text-m">CDEEPARCH: a compact deep neural network architecture for mobile sensing</div></div><div class="host u-font-sans">Proceedings of the 2018 15th Annual IEEE International Conference on Sensing, Communication, and Networking (SECON) (2018), pp. 1-9</div><div class="ReferenceLinks u-font-sans"><a class="anchor link anchor-primary" href="https://www.scopus.com/inward/record.url?eid=2-s2.0-85050232026&amp;partnerID=10&amp;rel=R3.0.0" target="_blank" rel="noopener noreferrer" aria-describedby="ref-id-sbref0010"><span class="anchor-text-container"><span class="anchor-text">View in Scopus</span><svg focusable="false" viewBox="0 0 8 8" height="20" aria-label="Opens in new window" class="icon icon-arrow-up-right-tiny arrow-external-link"><path d="M1.12949 2.1072V1H7V6.85795H5.89111V2.90281L0.784057 8L0 7.21635L5.11902 2.1072H1.12949Z"></path></svg></span></a><a class="anchor link anchor-primary" href="https://scholar.google.com/scholar_lookup?title=CDEEPARCH%3A%20a%20compact%20deep%20neural%20network%20architecture%20for%20mobile%20sensing&amp;publication_year=2018&amp;author=K.%20Yang&amp;author=X.%20Gong&amp;author=Y.%20Liu&amp;author=Z.%20Li&amp;author=T.%20Xing&amp;author=X.%20Chen&amp;author=D.%20Fang" target="_blank" rel="noopener noreferrer" aria-describedby="ref-id-sbref0010"><span class="anchor-text-container"><span class="anchor-text">Google Scholar</span><svg focusable="false" viewBox="0 0 8 8" height="20" aria-label="Opens in new window" class="icon icon-arrow-up-right-tiny arrow-external-link"><path d="M1.12949 2.1072V1H7V6.85795H5.89111V2.90281L0.784057 8L0 7.21635L5.11902 2.1072H1.12949Z"></path></svg></span></a></div></span></li><li><span class="label u-font-sans"><a class="anchor anchor-primary" href="#bbib0012" id="ref-id-bib0012" data-aa-button="sd:product:journal:article:location=references:type=anchor:name=citation-name"><span class="anchor-text-container"><span class="anchor-text">[12]</span></span></a></span><span class="reference" id="sbref0011"><div class="contribution"><div class="authors u-font-sans">M.D. Zeiler, R. Fergus</div><div id="ref-id-sbref0011" class="title text-m">Visualizing and understanding convolutional networks</div></div><div class="host u-font-sans">Proceedings of the ECCV (2014)</div><div class="ReferenceLinks u-font-sans"><a class="anchor link anchor-primary" href="https://scholar.google.com/scholar_lookup?title=Visualizing%20and%20understanding%20convolutional%20networks&amp;publication_year=2014&amp;author=M.D.%20Zeiler&amp;author=R.%20Fergus" target="_blank" rel="noopener noreferrer" aria-describedby="ref-id-sbref0011"><span class="anchor-text-container"><span class="anchor-text">Google Scholar</span><svg focusable="false" viewBox="0 0 8 8" height="20" aria-label="Opens in new window" class="icon icon-arrow-up-right-tiny arrow-external-link"><path d="M1.12949 2.1072V1H7V6.85795H5.89111V2.90281L0.784057 8L0 7.21635L5.11902 2.1072H1.12949Z"></path></svg></span></a></div></span></li><li><span class="label u-font-sans"><a class="anchor anchor-primary" href="#bbib0013" id="ref-id-bib0013" data-aa-button="sd:product:journal:article:location=references:type=anchor:name=citation-name"><span class="anchor-text-container"><span class="anchor-text">[13]</span></span></a></span><span class="reference" id="othref0001a"><div class="other-ref"><span>A. Azulay, Y. Weiss, Why do deep convolutional networks generalize so poorly to small image transformations? 2018, arXiv preprint arXiv:<a class="anchor anchor-primary" href="http://arxiv.org/abs/1805.12177" target="_blank"><span class="anchor-text-container"><span class="anchor-text">1805.12177</span><svg focusable="false" viewBox="0 0 8 8" height="20" aria-label="Opens in new window" class="icon icon-arrow-up-right-tiny arrow-external-link"><path d="M1.12949 2.1072V1H7V6.85795H5.89111V2.90281L0.784057 8L0 7.21635L5.11902 2.1072H1.12949Z"></path></svg></span></a>.</span></div><div class="ReferenceLinks u-font-sans"><a class="anchor link anchor-primary" href="https://scholar.google.com/scholar?q=A.%20Azulay%2C%20Y.%20Weiss%2C%20Why%20do%20deep%20convolutional%20networks%20generalize%20so%20poorly%20to%20small%20image%20transformations%3F%202018%2C%20arXiv%20preprint%20arXiv%3A1805.12177." target="_blank" rel="noopener noreferrer"><span class="anchor-text-container"><span class="anchor-text">Google Scholar</span><svg focusable="false" viewBox="0 0 8 8" height="20" aria-label="Opens in new window" class="icon icon-arrow-up-right-tiny arrow-external-link"><path d="M1.12949 2.1072V1H7V6.85795H5.89111V2.90281L0.784057 8L0 7.21635L5.11902 2.1072H1.12949Z"></path></svg></span></a></div></span></li><li><span class="label u-font-sans"><a class="anchor anchor-primary" href="#bbib0014" id="ref-id-bib0014" data-aa-button="sd:product:journal:article:location=references:type=anchor:name=citation-name"><span class="anchor-text-container"><span class="anchor-text">[14]</span></span></a></span><span class="reference" id="sbref0013"><div class="contribution"><div class="authors u-font-sans">Huang G., Liu Z., L. van der Maaten, K.Q. Weinberger</div><div id="ref-id-sbref0013" class="title text-m">Densely connected convolutional networks</div></div><div class="host u-font-sans">Proceedings of the 2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR) (2017), pp. 2261-2269</div><div class="ReferenceLinks u-font-sans"><a class="anchor link anchor-primary" href="https://www.scopus.com/inward/record.url?eid=2-s2.0-85035343801&amp;partnerID=10&amp;rel=R3.0.0" target="_blank" rel="noopener noreferrer" aria-describedby="ref-id-sbref0013"><span class="anchor-text-container"><span class="anchor-text">View in Scopus</span><svg focusable="false" viewBox="0 0 8 8" height="20" aria-label="Opens in new window" class="icon icon-arrow-up-right-tiny arrow-external-link"><path d="M1.12949 2.1072V1H7V6.85795H5.89111V2.90281L0.784057 8L0 7.21635L5.11902 2.1072H1.12949Z"></path></svg></span></a><a class="anchor link anchor-primary" href="https://scholar.google.com/scholar_lookup?title=Densely%20connected%20convolutional%20networks&amp;publication_year=2017&amp;author=G.%20Huang&amp;author=Z.%20Liu&amp;author=L.%20van%20der%20Maaten&amp;author=K.Q.%20Weinberger" target="_blank" rel="noopener noreferrer" aria-describedby="ref-id-sbref0013"><span class="anchor-text-container"><span class="anchor-text">Google Scholar</span><svg focusable="false" viewBox="0 0 8 8" height="20" aria-label="Opens in new window" class="icon icon-arrow-up-right-tiny arrow-external-link"><path d="M1.12949 2.1072V1H7V6.85795H5.89111V2.90281L0.784057 8L0 7.21635L5.11902 2.1072H1.12949Z"></path></svg></span></a></div></span></li><li><span class="label u-font-sans"><a class="anchor anchor-primary" href="#bbib0015" id="ref-id-bib0015" data-aa-button="sd:product:journal:article:location=references:type=anchor:name=citation-name"><span class="anchor-text-container"><span class="anchor-text">[15]</span></span></a></span><span class="reference" id="sbref0014"><div class="contribution"><div class="authors u-font-sans">G. Pleiss, Chen D., Huang G., Li T., L. van der Maaten, K.Q. Weinberger</div><div id="ref-id-sbref0014" class="title text-m">Memory-efficient implementation of densenets</div></div><div class="host u-font-sans"> (2017)</div><div class="comment">, arXiv preprint arXiv:<a class="anchor anchor-primary" href="http://arxiv.org/abs/1707.06990" target="_blank"><span class="anchor-text-container"><span class="anchor-text">1707.06990</span><svg focusable="false" viewBox="0 0 8 8" height="20" aria-label="Opens in new window" class="icon icon-arrow-up-right-tiny arrow-external-link"><path d="M1.12949 2.1072V1H7V6.85795H5.89111V2.90281L0.784057 8L0 7.21635L5.11902 2.1072H1.12949Z"></path></svg></span></a></div><div class="ReferenceLinks u-font-sans"><a class="anchor link anchor-primary" href="https://scholar.google.com/scholar_lookup?title=Memory-efficient%20implementation%20of%20densenets&amp;publication_year=2017&amp;author=G.%20Pleiss&amp;author=D.%20Chen&amp;author=G.%20Huang&amp;author=T.%20Li&amp;author=L.%20van%20der%20Maaten&amp;author=K.Q.%20Weinberger" target="_blank" rel="noopener noreferrer" aria-describedby="ref-id-sbref0014"><span class="anchor-text-container"><span class="anchor-text">Google Scholar</span><svg focusable="false" viewBox="0 0 8 8" height="20" aria-label="Opens in new window" class="icon icon-arrow-up-right-tiny arrow-external-link"><path d="M1.12949 2.1072V1H7V6.85795H5.89111V2.90281L0.784057 8L0 7.21635L5.11902 2.1072H1.12949Z"></path></svg></span></a></div></span></li><li><span class="label u-font-sans"><a class="anchor anchor-primary" href="#bbib0016" id="ref-id-bib0016" data-aa-button="sd:product:journal:article:location=references:type=anchor:name=citation-name"><span class="anchor-text-container"><span class="anchor-text">[16]</span></span></a></span><span class="reference" id="sbref0015"><div class="contribution"><div class="authors u-font-sans">Shan C., Gong S., P.W. Mcowan</div><div id="ref-id-sbref0015" class="title text-m">Robust facial expression recognition using local binary patterns</div></div><div class="host u-font-sans">Proceedings of the IEEE International Conference on Image Processing (2005)</div><div class="ReferenceLinks u-font-sans"><a class="anchor link anchor-primary" href="https://scholar.google.com/scholar_lookup?title=Robust%20facial%20expression%20recognition%20using%20local%20binary%20patterns&amp;publication_year=2005&amp;author=C.%20Shan&amp;author=S.%20Gong&amp;author=P.W.%20Mcowan" target="_blank" rel="noopener noreferrer" aria-describedby="ref-id-sbref0015"><span class="anchor-text-container"><span class="anchor-text">Google Scholar</span><svg focusable="false" viewBox="0 0 8 8" height="20" aria-label="Opens in new window" class="icon icon-arrow-up-right-tiny arrow-external-link"><path d="M1.12949 2.1072V1H7V6.85795H5.89111V2.90281L0.784057 8L0 7.21635L5.11902 2.1072H1.12949Z"></path></svg></span></a></div></span></li><li><span class="label u-font-sans"><a class="anchor anchor-primary" href="#bbib0017" id="ref-id-bib0017" data-aa-button="sd:product:journal:article:location=references:type=anchor:name=citation-name"><span class="anchor-text-container"><span class="anchor-text">[17]</span></span></a></span><span class="reference" id="sbref0016"><div class="contribution"><div class="authors u-font-sans">Xu M., Cheng W., Zhao Q., Ma L., Xu F.</div><div id="ref-id-sbref0016" class="title text-m">Facial expression recognition based on transfer learning from deep convolutional networks</div></div><div class="host u-font-sans">Proceedings of the International Conference on Natural Computation (2016), pp. 702-708</div><div class="ReferenceLinks u-font-sans"><a class="anchor link anchor-primary" href="https://scholar.google.com/scholar_lookup?title=Facial%20expression%20recognition%20based%20on%20transfer%20learning%20from%20deep%20convolutional%20networks&amp;publication_year=2016&amp;author=M.%20Xu&amp;author=W.%20Cheng&amp;author=Q.%20Zhao&amp;author=L.%20Ma&amp;author=F.%20Xu" target="_blank" rel="noopener noreferrer" aria-describedby="ref-id-sbref0016"><span class="anchor-text-container"><span class="anchor-text">Google Scholar</span><svg focusable="false" viewBox="0 0 8 8" height="20" aria-label="Opens in new window" class="icon icon-arrow-up-right-tiny arrow-external-link"><path d="M1.12949 2.1072V1H7V6.85795H5.89111V2.90281L0.784057 8L0 7.21635L5.11902 2.1072H1.12949Z"></path></svg></span></a></div></span></li><li><span class="label u-font-sans"><a class="anchor anchor-primary" href="#bbib0018" id="ref-id-bib0018" data-aa-button="sd:product:journal:article:location=references:type=anchor:name=citation-name"><span class="anchor-text-container"><span class="anchor-text">[18]</span></span></a></span><span class="reference" id="sbref0017"><div class="contribution"><div class="authors u-font-sans">J. Luttrell, Zhou Z., Zhang Y., Zhang C., Gong P., Yang B., Li R.</div><div id="ref-id-sbref0017" class="title text-m">A deep transfer learning approach to fine-tuning facial recognition models</div></div><div class="host u-font-sans">Proceedings of the 2018 13th IEEE Conference on Industrial Electronics and Applications (ICIEA) (2018), pp. 2671-2676, <a class="anchor anchor-primary" href="https://doi.org/10.1109/ICIEA.2018.8398162" target="_blank"><span class="anchor-text-container"><span class="anchor-text">10.1109/ICIEA.2018.8398162</span><svg focusable="false" viewBox="0 0 8 8" height="20" aria-label="Opens in new window" class="icon icon-arrow-up-right-tiny arrow-external-link"><path d="M1.12949 2.1072V1H7V6.85795H5.89111V2.90281L0.784057 8L0 7.21635L5.11902 2.1072H1.12949Z"></path></svg></span></a></div><div class="ReferenceLinks u-font-sans"><span class="link lazy-third-party-pdf-link"><span></span></span><a class="anchor link anchor-primary" href="https://www.scopus.com/inward/record.url?eid=2-s2.0-85050080831&amp;partnerID=10&amp;rel=R3.0.0" target="_blank" rel="noopener noreferrer" aria-describedby="ref-id-sbref0017"><span class="anchor-text-container"><span class="anchor-text">View in Scopus</span><svg focusable="false" viewBox="0 0 8 8" height="20" aria-label="Opens in new window" class="icon icon-arrow-up-right-tiny arrow-external-link"><path d="M1.12949 2.1072V1H7V6.85795H5.89111V2.90281L0.784057 8L0 7.21635L5.11902 2.1072H1.12949Z"></path></svg></span></a><a class="anchor link anchor-primary" href="https://scholar.google.com/scholar_lookup?title=A%20deep%20transfer%20learning%20approach%20to%20fine-tuning%20facial%20recognition%20models&amp;publication_year=2018&amp;author=J.%20Luttrell&amp;author=Z.%20Zhou&amp;author=Y.%20Zhang&amp;author=C.%20Zhang&amp;author=P.%20Gong&amp;author=B.%20Yang&amp;author=R.%20Li" target="_blank" rel="noopener noreferrer" aria-describedby="ref-id-sbref0017"><span class="anchor-text-container"><span class="anchor-text">Google Scholar</span><svg focusable="false" viewBox="0 0 8 8" height="20" aria-label="Opens in new window" class="icon icon-arrow-up-right-tiny arrow-external-link"><path d="M1.12949 2.1072V1H7V6.85795H5.89111V2.90281L0.784057 8L0 7.21635L5.11902 2.1072H1.12949Z"></path></svg></span></a></div></span></li><li><span class="label u-font-sans"><a class="anchor anchor-primary" href="#bbib0019" id="ref-id-bib0019" data-aa-button="sd:product:journal:article:location=references:type=anchor:name=citation-name"><span class="anchor-text-container"><span class="anchor-text">[19]</span></span></a></span><span class="reference" id="sbref0018"><div class="contribution"><div class="authors u-font-sans">Peng M., Wu Z., Zhang Z., Chen T.</div><div id="ref-id-sbref0018" class="title text-m">From macro to micro expression recognition: deep learning on small datasets using transfer learning</div></div><div class="host u-font-sans">Proceedings of the IEEE International Conference on Automatic Face &amp; Gesture Recognition (2018), pp. 657-661</div><div class="ReferenceLinks u-font-sans"><a class="anchor link anchor-primary" href="https://www.scopus.com/inward/record.url?eid=2-s2.0-85049397417&amp;partnerID=10&amp;rel=R3.0.0" target="_blank" rel="noopener noreferrer" aria-describedby="ref-id-sbref0018"><span class="anchor-text-container"><span class="anchor-text">View in Scopus</span><svg focusable="false" viewBox="0 0 8 8" height="20" aria-label="Opens in new window" class="icon icon-arrow-up-right-tiny arrow-external-link"><path d="M1.12949 2.1072V1H7V6.85795H5.89111V2.90281L0.784057 8L0 7.21635L5.11902 2.1072H1.12949Z"></path></svg></span></a><a class="anchor link anchor-primary" href="https://scholar.google.com/scholar_lookup?title=From%20macro%20to%20micro%20expression%20recognition%3A%20deep%20learning%20on%20small%20datasets%20using%20transfer%20learning&amp;publication_year=2018&amp;author=M.%20Peng&amp;author=Z.%20Wu&amp;author=Z.%20Zhang&amp;author=T.%20Chen" target="_blank" rel="noopener noreferrer" aria-describedby="ref-id-sbref0018"><span class="anchor-text-container"><span class="anchor-text">Google Scholar</span><svg focusable="false" viewBox="0 0 8 8" height="20" aria-label="Opens in new window" class="icon icon-arrow-up-right-tiny arrow-external-link"><path d="M1.12949 2.1072V1H7V6.85795H5.89111V2.90281L0.784057 8L0 7.21635L5.11902 2.1072H1.12949Z"></path></svg></span></a></div></span></li><li><span class="label u-font-sans"><a class="anchor anchor-primary" href="#bbib0020" id="ref-id-bib0020" data-aa-button="sd:product:journal:article:location=references:type=anchor:name=citation-name"><span class="anchor-text-container"><span class="anchor-text">[20]</span></span></a></span><span class="reference" id="sbref0019"><div class="contribution"><div class="authors u-font-sans">Jian M., Lam K.M., Dong J.</div><div id="ref-id-sbref0019" class="title text-m">Facial-feature detection and localization based on a hierarchical scheme</div></div><div class="host u-font-sans">Inf. Sci., 262 (3) (2014), pp. 1-14</div><div class="ReferenceLinks u-font-sans"><a class="anchor pdf link anchor-primary anchor-icon-left anchor-with-icon" href="/science/article/pii/S0020025513008451/pdfft?md5=7ad1c9e3608f4e6f8c33c6a6ee891efd&amp;pid=1-s2.0-S0020025513008451-main.pdf" target="_blank" rel="nofollow" aria-describedby="ref-id-sbref0019"><svg focusable="false" viewBox="0 0 35 32" height="20" class="icon icon-pdf-multicolor"><path d="M7 .362h17.875l6.763 6.1V31.64H6.948V16z" stroke="#000" stroke-width=".703" fill="#fff"></path><path d="M.167 2.592H22.39V9.72H.166z" fill="#da0000"></path><path fill="#fff9f9" d="M5.97 3.638h1.62c1.053 0 1.483.677 1.488 1.564.008.96-.6 1.564-1.492 1.564h-.644v1.66h-.977V3.64m.977.897v1.34h.542c.27 0 .596-.068.596-.673-.002-.6-.32-.667-.596-.667h-.542m3.8.036v2.92h.35c.933 0 1.223-.448 1.228-1.462.008-1.06-.316-1.45-1.23-1.45h-.347m-.977-.94h1.03c1.68 0 2.523.586 2.534 2.39.01 1.688-.607 2.4-2.534 2.4h-1.03V3.64m4.305 0h2.63v.934h-1.657v.894H16.6V6.4h-1.56v2.026h-.97V3.638"></path><path d="M19.462 13.46c.348 4.274-6.59 16.72-8.508 15.792-1.82-.85 1.53-3.317 2.92-4.366-2.864.894-5.394 3.252-3.837 3.93 2.113.895 7.048-9.25 9.41-15.394zM14.32 24.874c4.767-1.526 14.735-2.974 15.152-1.407.824-3.157-13.72-.37-15.153 1.407zm5.28-5.043c2.31 3.237 9.816 7.498 9.788 3.82-.306 2.046-6.66-1.097-8.925-4.164-4.087-5.534-2.39-8.772-1.682-8.732.917.047 1.074 1.307.67 2.442-.173-1.406-.58-2.44-1.224-2.415-1.835.067-1.905 4.46 1.37 9.065z" fill="#f91d0a"></path></svg><span class="anchor-text-container"><span class="anchor-text">View PDF</span></span></a><a class="anchor link anchor-primary" href="/science/article/pii/S0020025513008451" aria-describedby="ref-id-sbref0019"><span class="anchor-text-container"><span class="anchor-text">View article</span></span></a><a class="anchor link anchor-primary" href="https://www.scopus.com/inward/record.url?eid=2-s2.0-84892528250&amp;partnerID=10&amp;rel=R3.0.0" target="_blank" rel="noopener noreferrer" aria-describedby="ref-id-sbref0019"><span class="anchor-text-container"><span class="anchor-text">View in Scopus</span><svg focusable="false" viewBox="0 0 8 8" height="20" aria-label="Opens in new window" class="icon icon-arrow-up-right-tiny arrow-external-link"><path d="M1.12949 2.1072V1H7V6.85795H5.89111V2.90281L0.784057 8L0 7.21635L5.11902 2.1072H1.12949Z"></path></svg></span></a><a class="anchor link anchor-primary" href="https://scholar.google.com/scholar_lookup?title=Facial-feature%20detection%20and%20localization%20based%20on%20a%20hierarchical%20scheme&amp;publication_year=2014&amp;author=M.%20Jian&amp;author=K.M.%20Lam&amp;author=J.%20Dong" target="_blank" rel="noopener noreferrer" aria-describedby="ref-id-sbref0019"><span class="anchor-text-container"><span class="anchor-text">Google Scholar</span><svg focusable="false" viewBox="0 0 8 8" height="20" aria-label="Opens in new window" class="icon icon-arrow-up-right-tiny arrow-external-link"><path d="M1.12949 2.1072V1H7V6.85795H5.89111V2.90281L0.784057 8L0 7.21635L5.11902 2.1072H1.12949Z"></path></svg></span></a></div></span></li><li><span class="label u-font-sans"><a class="anchor anchor-primary" href="#bbib0021" id="ref-id-bib0021" data-aa-button="sd:product:journal:article:location=references:type=anchor:name=citation-name"><span class="anchor-text-container"><span class="anchor-text">[21]</span></span></a></span><span class="reference" id="sbref0020"><div class="contribution"><div class="authors u-font-sans">G. Sikander, S. Anwar, Y.A. Djawad</div><div id="ref-id-sbref0020" class="title text-m">Facial feature detection: a facial symmetry approach</div></div><div class="host u-font-sans">Proceedings of the International Symposium on Computational and Business Intelligence (2017), pp. 26-31</div><div class="ReferenceLinks u-font-sans"><a class="anchor link anchor-primary" href="https://www.scopus.com/inward/record.url?eid=2-s2.0-85034821893&amp;partnerID=10&amp;rel=R3.0.0" target="_blank" rel="noopener noreferrer" aria-describedby="ref-id-sbref0020"><span class="anchor-text-container"><span class="anchor-text">View in Scopus</span><svg focusable="false" viewBox="0 0 8 8" height="20" aria-label="Opens in new window" class="icon icon-arrow-up-right-tiny arrow-external-link"><path d="M1.12949 2.1072V1H7V6.85795H5.89111V2.90281L0.784057 8L0 7.21635L5.11902 2.1072H1.12949Z"></path></svg></span></a><a class="anchor link anchor-primary" href="https://scholar.google.com/scholar_lookup?title=Facial%20feature%20detection%3A%20a%20facial%20symmetry%20approach&amp;publication_year=2017&amp;author=G.%20Sikander&amp;author=S.%20Anwar&amp;author=Y.A.%20Djawad" target="_blank" rel="noopener noreferrer" aria-describedby="ref-id-sbref0020"><span class="anchor-text-container"><span class="anchor-text">Google Scholar</span><svg focusable="false" viewBox="0 0 8 8" height="20" aria-label="Opens in new window" class="icon icon-arrow-up-right-tiny arrow-external-link"><path d="M1.12949 2.1072V1H7V6.85795H5.89111V2.90281L0.784057 8L0 7.21635L5.11902 2.1072H1.12949Z"></path></svg></span></a></div></span></li><li><span class="label u-font-sans"><a class="anchor anchor-primary" href="#bbib0022" id="ref-id-bib0022" data-aa-button="sd:product:journal:article:location=references:type=anchor:name=citation-name"><span class="anchor-text-container"><span class="anchor-text">[22]</span></span></a></span><span class="reference" id="sbref0021"><div class="contribution"><div class="authors u-font-sans">Zhang K., Zhang Z., Li Z., Qiao Y.</div><div id="ref-id-sbref0021" class="title text-m">Joint face detection and alignment using multitask cascaded convolutional networks</div></div><div class="host u-font-sans">IEEE Signal Process. Lett., 23 (10) (2016), pp. 1499-1503</div><div class="ReferenceLinks u-font-sans"><a class="anchor link anchor-primary" href="https://www.scopus.com/inward/record.url?eid=2-s2.0-85021706027&amp;partnerID=10&amp;rel=R3.0.0" target="_blank" rel="noopener noreferrer" aria-describedby="ref-id-sbref0021"><span class="anchor-text-container"><span class="anchor-text">View in Scopus</span><svg focusable="false" viewBox="0 0 8 8" height="20" aria-label="Opens in new window" class="icon icon-arrow-up-right-tiny arrow-external-link"><path d="M1.12949 2.1072V1H7V6.85795H5.89111V2.90281L0.784057 8L0 7.21635L5.11902 2.1072H1.12949Z"></path></svg></span></a><a class="anchor link anchor-primary" href="https://scholar.google.com/scholar_lookup?title=Joint%20face%20detection%20and%20alignment%20using%20multitask%20cascaded%20convolutional%20networks&amp;publication_year=2016&amp;author=K.%20Zhang&amp;author=Z.%20Zhang&amp;author=Z.%20Li&amp;author=Y.%20Qiao" target="_blank" rel="noopener noreferrer" aria-describedby="ref-id-sbref0021"><span class="anchor-text-container"><span class="anchor-text">Google Scholar</span><svg focusable="false" viewBox="0 0 8 8" height="20" aria-label="Opens in new window" class="icon icon-arrow-up-right-tiny arrow-external-link"><path d="M1.12949 2.1072V1H7V6.85795H5.89111V2.90281L0.784057 8L0 7.21635L5.11902 2.1072H1.12949Z"></path></svg></span></a></div></span></li><li><span class="label u-font-sans"><a class="anchor anchor-primary" href="#bbib0023" id="ref-id-bib0023" data-aa-button="sd:product:journal:article:location=references:type=anchor:name=citation-name"><span class="anchor-text-container"><span class="anchor-text">[23]</span></span></a></span><span class="reference" id="sbref0022"><div class="contribution"><div class="authors u-font-sans">S.C. Bakchy, M.J. Ferdous, A.H. Sathi, K.C. Ray, F. Imran, M.M. Ali</div><div id="ref-id-sbref0022" class="title text-m">Facial expression recognition based on support vector machine using Gabor wavelet filter</div></div><div class="host u-font-sans">Proceedings of the 2017 2nd International Conference on Electrical Electronic Engineering (ICEEE) (2017), pp. 1-4, <a class="anchor anchor-primary" href="https://doi.org/10.1109/CEEE.2017.8412888" target="_blank"><span class="anchor-text-container"><span class="anchor-text">10.1109/CEEE.2017.8412888</span><svg focusable="false" viewBox="0 0 8 8" height="20" aria-label="Opens in new window" class="icon icon-arrow-up-right-tiny arrow-external-link"><path d="M1.12949 2.1072V1H7V6.85795H5.89111V2.90281L0.784057 8L0 7.21635L5.11902 2.1072H1.12949Z"></path></svg></span></a></div><div class="ReferenceLinks u-font-sans"><span class="link lazy-third-party-pdf-link"><span></span></span><a class="anchor link anchor-primary" href="https://www.scopus.com/inward/record.url?eid=2-s2.0-85050992317&amp;partnerID=10&amp;rel=R3.0.0" target="_blank" rel="noopener noreferrer" aria-describedby="ref-id-sbref0022"><span class="anchor-text-container"><span class="anchor-text">View in Scopus</span><svg focusable="false" viewBox="0 0 8 8" height="20" aria-label="Opens in new window" class="icon icon-arrow-up-right-tiny arrow-external-link"><path d="M1.12949 2.1072V1H7V6.85795H5.89111V2.90281L0.784057 8L0 7.21635L5.11902 2.1072H1.12949Z"></path></svg></span></a><a class="anchor link anchor-primary" href="https://scholar.google.com/scholar_lookup?title=Facial%20expression%20recognition%20based%20on%20support%20vector%20machine%20using%20Gabor%20wavelet%20filter&amp;publication_year=2017&amp;author=S.C.%20Bakchy&amp;author=M.J.%20Ferdous&amp;author=A.H.%20Sathi&amp;author=K.C.%20Ray&amp;author=F.%20Imran&amp;author=M.M.%20Ali" target="_blank" rel="noopener noreferrer" aria-describedby="ref-id-sbref0022"><span class="anchor-text-container"><span class="anchor-text">Google Scholar</span><svg focusable="false" viewBox="0 0 8 8" height="20" aria-label="Opens in new window" class="icon icon-arrow-up-right-tiny arrow-external-link"><path d="M1.12949 2.1072V1H7V6.85795H5.89111V2.90281L0.784057 8L0 7.21635L5.11902 2.1072H1.12949Z"></path></svg></span></a></div></span></li><li><span class="label u-font-sans"><a class="anchor anchor-primary" href="#bbib0024" id="ref-id-bib0024" data-aa-button="sd:product:journal:article:location=references:type=anchor:name=citation-name"><span class="anchor-text-container"><span class="anchor-text">[24]</span></span></a></span><span class="reference" id="sbref0023"><div class="contribution"><div class="authors u-font-sans">Ying Z., Fang X.</div><div id="ref-id-sbref0023" class="title text-m">Combining LBP and adaboost for facial expression recognition</div></div><div class="host u-font-sans">Proceedings of the 9th international conference on signal processing (2008), pp. 1461-1464</div><div class="ReferenceLinks u-font-sans"><a class="anchor link anchor-primary" href="https://scholar.google.com/scholar_lookup?title=Combining%20LBP%20and%20adaboost%20for%20facial%20expression%20recognition&amp;publication_year=2008&amp;author=Z.%20Ying&amp;author=X.%20Fang" target="_blank" rel="noopener noreferrer" aria-describedby="ref-id-sbref0023"><span class="anchor-text-container"><span class="anchor-text">Google Scholar</span><svg focusable="false" viewBox="0 0 8 8" height="20" aria-label="Opens in new window" class="icon icon-arrow-up-right-tiny arrow-external-link"><path d="M1.12949 2.1072V1H7V6.85795H5.89111V2.90281L0.784057 8L0 7.21635L5.11902 2.1072H1.12949Z"></path></svg></span></a></div></span></li><li><span class="label u-font-sans"><a class="anchor anchor-primary" href="#bbib0025" id="ref-id-bib0025" data-aa-button="sd:product:journal:article:location=references:type=anchor:name=citation-name"><span class="anchor-text-container"><span class="anchor-text">[25]</span></span></a></span><span class="reference" id="sbref0024"><div class="contribution"><div class="authors u-font-sans">Wang Y., Yu H., B. Stevens, Liu H.</div><div id="ref-id-sbref0024" class="title text-m">Dynamic facial expression recognition using local patch and LBP-top</div></div><div class="host u-font-sans">Proceedings of the International Conference on Human System Interactions (2015), pp. 362-367</div><div class="ReferenceLinks u-font-sans"><span class="link lazy-third-party-pdf-link"><span></span></span><a class="anchor link anchor-primary" href="https://doi.org/10.1109/HSI.2015.7170694" target="_blank" rel="noopener noreferrer" aria-describedby="ref-id-sbref0024"><span class="anchor-text-container"><span class="anchor-text">Crossref</span><svg focusable="false" viewBox="0 0 8 8" height="20" aria-label="Opens in new window" class="icon icon-arrow-up-right-tiny arrow-external-link"><path d="M1.12949 2.1072V1H7V6.85795H5.89111V2.90281L0.784057 8L0 7.21635L5.11902 2.1072H1.12949Z"></path></svg></span></a><a class="anchor link anchor-primary" href="https://www.scopus.com/inward/record.url?eid=2-s2.0-84945949106&amp;partnerID=10&amp;rel=R3.0.0" target="_blank" rel="noopener noreferrer" aria-describedby="ref-id-sbref0024"><span class="anchor-text-container"><span class="anchor-text">View in Scopus</span><svg focusable="false" viewBox="0 0 8 8" height="20" aria-label="Opens in new window" class="icon icon-arrow-up-right-tiny arrow-external-link"><path d="M1.12949 2.1072V1H7V6.85795H5.89111V2.90281L0.784057 8L0 7.21635L5.11902 2.1072H1.12949Z"></path></svg></span></a><a class="anchor link anchor-primary" href="https://scholar.google.com/scholar_lookup?title=Dynamic%20facial%20expression%20recognition%20using%20local%20patch%20and%20LBP-top&amp;publication_year=2015&amp;author=Y.%20Wang&amp;author=H.%20Yu&amp;author=B.%20Stevens&amp;author=H.%20Liu" target="_blank" rel="noopener noreferrer" aria-describedby="ref-id-sbref0024"><span class="anchor-text-container"><span class="anchor-text">Google Scholar</span><svg focusable="false" viewBox="0 0 8 8" height="20" aria-label="Opens in new window" class="icon icon-arrow-up-right-tiny arrow-external-link"><path d="M1.12949 2.1072V1H7V6.85795H5.89111V2.90281L0.784057 8L0 7.21635L5.11902 2.1072H1.12949Z"></path></svg></span></a></div></span></li><li><span class="label u-font-sans"><a class="anchor anchor-primary" href="#bbib0026" id="ref-id-bib0026" data-aa-button="sd:product:journal:article:location=references:type=anchor:name=citation-name"><span class="anchor-text-container"><span class="anchor-text">[26]</span></span></a></span><span class="reference" id="sbref0025"><div class="contribution"><div class="authors u-font-sans">Qi C., Li M., Wang Q., Zhang H., Xing J., Gao Z., Zhanga H.</div><div id="ref-id-sbref0025" class="title text-m">Facial expressions recognition based on cognition and mapped binary patterns</div></div><div class="host u-font-sans">IEEE Access, PP (99) (2018)</div><div class="ReferenceLinks u-font-sans"><a class="anchor link anchor-primary" href="https://scholar.google.com/scholar_lookup?title=Facial%20expressions%20recognition%20based%20on%20cognition%20and%20mapped%20binary%20patterns&amp;publication_year=2018&amp;author=C.%20Qi&amp;author=M.%20Li&amp;author=Q.%20Wang&amp;author=H.%20Zhang&amp;author=J.%20Xing&amp;author=Z.%20Gao&amp;author=H.%20Zhanga" target="_blank" rel="noopener noreferrer" aria-describedby="ref-id-sbref0025"><span class="anchor-text-container"><span class="anchor-text">Google Scholar</span><svg focusable="false" viewBox="0 0 8 8" height="20" aria-label="Opens in new window" class="icon icon-arrow-up-right-tiny arrow-external-link"><path d="M1.12949 2.1072V1H7V6.85795H5.89111V2.90281L0.784057 8L0 7.21635L5.11902 2.1072H1.12949Z"></path></svg></span></a></div></span><div class="reference note"><div class="u-margin-s-bottom" id="sp0004">1â€“1.</div></div></li><li><span class="label u-font-sans"><a class="anchor anchor-primary" href="#bbib0027" id="ref-id-bib0027" data-aa-button="sd:product:journal:article:location=references:type=anchor:name=citation-name"><span class="anchor-text-container"><span class="anchor-text">[27]</span></span></a></span><span class="reference" id="sbref0026"><div class="contribution"><div class="authors u-font-sans">Huang D., M. Ardabilian, Wang Y., Chen L.</div><div id="ref-id-sbref0026" class="title text-m">Asymmetric 3D/2D face recognition based on LBP facial representation and canonical correlation analysis</div></div><div class="host u-font-sans">Proceedings of the IEEE International Conference on Image Processing (2010), pp. 3289-3292</div><div class="ReferenceLinks u-font-sans"><a class="anchor link anchor-primary" href="https://scholar.google.com/scholar_lookup?title=Asymmetric%203D2D%20face%20recognition%20based%20on%20LBP%20facial%20representation%20and%20canonical%20correlation%20analysis&amp;publication_year=2010&amp;author=D.%20Huang&amp;author=M.%20Ardabilian&amp;author=Y.%20Wang&amp;author=L.%20Chen" target="_blank" rel="noopener noreferrer" aria-describedby="ref-id-sbref0026"><span class="anchor-text-container"><span class="anchor-text">Google Scholar</span><svg focusable="false" viewBox="0 0 8 8" height="20" aria-label="Opens in new window" class="icon icon-arrow-up-right-tiny arrow-external-link"><path d="M1.12949 2.1072V1H7V6.85795H5.89111V2.90281L0.784057 8L0 7.21635L5.11902 2.1072H1.12949Z"></path></svg></span></a></div></span></li><li><span class="label u-font-sans"><a class="anchor anchor-primary" href="#bbib0028" id="ref-id-bib0028" data-aa-button="sd:product:journal:article:location=references:type=anchor:name=citation-name"><span class="anchor-text-container"><span class="anchor-text">[28]</span></span></a></span><span class="reference" id="sbref0027"><div class="contribution"><div class="authors u-font-sans">P. Kumar, S.L. Happy, A. Routray</div><div id="ref-id-sbref0027" class="title text-m">A real-time robust facial expression recognition system using hog features</div></div><div class="host u-font-sans">Proceedings of the International Conference on Computing, Analytics and Security Trends (2017), pp. 289-293</div><div class="ReferenceLinks u-font-sans"><span class="link lazy-third-party-pdf-link"><span></span></span><a class="anchor link anchor-primary" href="https://doi.org/10.5958/2249-7315.2017.00387.2" target="_blank" rel="noopener noreferrer" aria-describedby="ref-id-sbref0027"><span class="anchor-text-container"><span class="anchor-text">Crossref</span><svg focusable="false" viewBox="0 0 8 8" height="20" aria-label="Opens in new window" class="icon icon-arrow-up-right-tiny arrow-external-link"><path d="M1.12949 2.1072V1H7V6.85795H5.89111V2.90281L0.784057 8L0 7.21635L5.11902 2.1072H1.12949Z"></path></svg></span></a><a class="anchor link anchor-primary" href="https://scholar.google.com/scholar_lookup?title=A%20real-time%20robust%20facial%20expression%20recognition%20system%20using%20hog%20features&amp;publication_year=2017&amp;author=P.%20Kumar&amp;author=S.L.%20Happy&amp;author=A.%20Routray" target="_blank" rel="noopener noreferrer" aria-describedby="ref-id-sbref0027"><span class="anchor-text-container"><span class="anchor-text">Google Scholar</span><svg focusable="false" viewBox="0 0 8 8" height="20" aria-label="Opens in new window" class="icon icon-arrow-up-right-tiny arrow-external-link"><path d="M1.12949 2.1072V1H7V6.85795H5.89111V2.90281L0.784057 8L0 7.21635L5.11902 2.1072H1.12949Z"></path></svg></span></a></div></span></li><li><span class="label u-font-sans"><a class="anchor anchor-primary" href="#bbib0029" id="ref-id-bib0029" data-aa-button="sd:product:journal:article:location=references:type=anchor:name=citation-name"><span class="anchor-text-container"><span class="anchor-text">[29]</span></span></a></span><span class="reference" id="sbref0028"><div class="contribution"><div class="authors u-font-sans">Jian M., Lam K.M.</div><div id="ref-id-sbref0028" class="title text-m">Face-image retrieval based on singular values and potential-field representation</div></div><div class="host u-font-sans">Signal Process., 100 (7) (2014), pp. 9-15</div><div class="ReferenceLinks u-font-sans"><a class="anchor pdf link anchor-primary anchor-icon-left anchor-with-icon" href="/science/article/pii/S0165168414000073/pdfft?md5=1626a623f7622bf7d74af8cf0bd90e62&amp;pid=1-s2.0-S0165168414000073-main.pdf" target="_blank" rel="nofollow" aria-describedby="ref-id-sbref0028"><svg focusable="false" viewBox="0 0 35 32" height="20" class="icon icon-pdf-multicolor"><path d="M7 .362h17.875l6.763 6.1V31.64H6.948V16z" stroke="#000" stroke-width=".703" fill="#fff"></path><path d="M.167 2.592H22.39V9.72H.166z" fill="#da0000"></path><path fill="#fff9f9" d="M5.97 3.638h1.62c1.053 0 1.483.677 1.488 1.564.008.96-.6 1.564-1.492 1.564h-.644v1.66h-.977V3.64m.977.897v1.34h.542c.27 0 .596-.068.596-.673-.002-.6-.32-.667-.596-.667h-.542m3.8.036v2.92h.35c.933 0 1.223-.448 1.228-1.462.008-1.06-.316-1.45-1.23-1.45h-.347m-.977-.94h1.03c1.68 0 2.523.586 2.534 2.39.01 1.688-.607 2.4-2.534 2.4h-1.03V3.64m4.305 0h2.63v.934h-1.657v.894H16.6V6.4h-1.56v2.026h-.97V3.638"></path><path d="M19.462 13.46c.348 4.274-6.59 16.72-8.508 15.792-1.82-.85 1.53-3.317 2.92-4.366-2.864.894-5.394 3.252-3.837 3.93 2.113.895 7.048-9.25 9.41-15.394zM14.32 24.874c4.767-1.526 14.735-2.974 15.152-1.407.824-3.157-13.72-.37-15.153 1.407zm5.28-5.043c2.31 3.237 9.816 7.498 9.788 3.82-.306 2.046-6.66-1.097-8.925-4.164-4.087-5.534-2.39-8.772-1.682-8.732.917.047 1.074 1.307.67 2.442-.173-1.406-.58-2.44-1.224-2.415-1.835.067-1.905 4.46 1.37 9.065z" fill="#f91d0a"></path></svg><span class="anchor-text-container"><span class="anchor-text">View PDF</span></span></a><a class="anchor link anchor-primary" href="/science/article/pii/S0165168414000073" aria-describedby="ref-id-sbref0028"><span class="anchor-text-container"><span class="anchor-text">View article</span></span></a><a class="anchor link anchor-primary" href="https://www.scopus.com/inward/record.url?eid=2-s2.0-84893259710&amp;partnerID=10&amp;rel=R3.0.0" target="_blank" rel="noopener noreferrer" aria-describedby="ref-id-sbref0028"><span class="anchor-text-container"><span class="anchor-text">View in Scopus</span><svg focusable="false" viewBox="0 0 8 8" height="20" aria-label="Opens in new window" class="icon icon-arrow-up-right-tiny arrow-external-link"><path d="M1.12949 2.1072V1H7V6.85795H5.89111V2.90281L0.784057 8L0 7.21635L5.11902 2.1072H1.12949Z"></path></svg></span></a><a class="anchor link anchor-primary" href="https://scholar.google.com/scholar_lookup?title=Face-image%20retrieval%20based%20on%20singular%20values%20and%20potential-field%20representation&amp;publication_year=2014&amp;author=M.%20Jian&amp;author=K.M.%20Lam" target="_blank" rel="noopener noreferrer" aria-describedby="ref-id-sbref0028"><span class="anchor-text-container"><span class="anchor-text">Google Scholar</span><svg focusable="false" viewBox="0 0 8 8" height="20" aria-label="Opens in new window" class="icon icon-arrow-up-right-tiny arrow-external-link"><path d="M1.12949 2.1072V1H7V6.85795H5.89111V2.90281L0.784057 8L0 7.21635L5.11902 2.1072H1.12949Z"></path></svg></span></a></div></span></li><li><span class="label u-font-sans"><a class="anchor anchor-primary" href="#bbib0030" id="ref-id-bib0030" data-aa-button="sd:product:journal:article:location=references:type=anchor:name=citation-name"><span class="anchor-text-container"><span class="anchor-text">[30]</span></span></a></span><span class="reference" id="sbref0029"><div class="contribution"><div class="authors u-font-sans">Jian M., Lam K.M., Dong J.</div><div id="ref-id-sbref0029" class="title text-m">A novel face-hallucination scheme based on singular value decomposition</div></div><div class="host u-font-sans">Pattern Recognit., 46 (11) (2013), pp. 3091-3102</div><div class="ReferenceLinks u-font-sans"><a class="anchor pdf link anchor-primary anchor-icon-left anchor-with-icon" href="/science/article/pii/S0031320313001490/pdfft?md5=a11c4e24bb1991b7a79f026bf743b7af&amp;pid=1-s2.0-S0031320313001490-main.pdf" target="_blank" rel="nofollow" aria-describedby="ref-id-sbref0029"><svg focusable="false" viewBox="0 0 35 32" height="20" class="icon icon-pdf-multicolor"><path d="M7 .362h17.875l6.763 6.1V31.64H6.948V16z" stroke="#000" stroke-width=".703" fill="#fff"></path><path d="M.167 2.592H22.39V9.72H.166z" fill="#da0000"></path><path fill="#fff9f9" d="M5.97 3.638h1.62c1.053 0 1.483.677 1.488 1.564.008.96-.6 1.564-1.492 1.564h-.644v1.66h-.977V3.64m.977.897v1.34h.542c.27 0 .596-.068.596-.673-.002-.6-.32-.667-.596-.667h-.542m3.8.036v2.92h.35c.933 0 1.223-.448 1.228-1.462.008-1.06-.316-1.45-1.23-1.45h-.347m-.977-.94h1.03c1.68 0 2.523.586 2.534 2.39.01 1.688-.607 2.4-2.534 2.4h-1.03V3.64m4.305 0h2.63v.934h-1.657v.894H16.6V6.4h-1.56v2.026h-.97V3.638"></path><path d="M19.462 13.46c.348 4.274-6.59 16.72-8.508 15.792-1.82-.85 1.53-3.317 2.92-4.366-2.864.894-5.394 3.252-3.837 3.93 2.113.895 7.048-9.25 9.41-15.394zM14.32 24.874c4.767-1.526 14.735-2.974 15.152-1.407.824-3.157-13.72-.37-15.153 1.407zm5.28-5.043c2.31 3.237 9.816 7.498 9.788 3.82-.306 2.046-6.66-1.097-8.925-4.164-4.087-5.534-2.39-8.772-1.682-8.732.917.047 1.074 1.307.67 2.442-.173-1.406-.58-2.44-1.224-2.415-1.835.067-1.905 4.46 1.37 9.065z" fill="#f91d0a"></path></svg><span class="anchor-text-container"><span class="anchor-text">View PDF</span></span></a><a class="anchor link anchor-primary" href="/science/article/pii/S0031320313001490" aria-describedby="ref-id-sbref0029"><span class="anchor-text-container"><span class="anchor-text">View article</span></span></a><a class="anchor link anchor-primary" href="https://www.scopus.com/inward/record.url?eid=2-s2.0-84878834214&amp;partnerID=10&amp;rel=R3.0.0" target="_blank" rel="noopener noreferrer" aria-describedby="ref-id-sbref0029"><span class="anchor-text-container"><span class="anchor-text">View in Scopus</span><svg focusable="false" viewBox="0 0 8 8" height="20" aria-label="Opens in new window" class="icon icon-arrow-up-right-tiny arrow-external-link"><path d="M1.12949 2.1072V1H7V6.85795H5.89111V2.90281L0.784057 8L0 7.21635L5.11902 2.1072H1.12949Z"></path></svg></span></a><a class="anchor link anchor-primary" href="https://scholar.google.com/scholar_lookup?title=A%20novel%20face-hallucination%20scheme%20based%20on%20singular%20value%20decomposition&amp;publication_year=2013&amp;author=M.%20Jian&amp;author=K.M.%20Lam&amp;author=J.%20Dong" target="_blank" rel="noopener noreferrer" aria-describedby="ref-id-sbref0029"><span class="anchor-text-container"><span class="anchor-text">Google Scholar</span><svg focusable="false" viewBox="0 0 8 8" height="20" aria-label="Opens in new window" class="icon icon-arrow-up-right-tiny arrow-external-link"><path d="M1.12949 2.1072V1H7V6.85795H5.89111V2.90281L0.784057 8L0 7.21635L5.11902 2.1072H1.12949Z"></path></svg></span></a></div></span></li><li><span class="label u-font-sans"><a class="anchor anchor-primary" href="#bbib0031" id="ref-id-bib0031" data-aa-button="sd:product:journal:article:location=references:type=anchor:name=citation-name"><span class="anchor-text-container"><span class="anchor-text">[31]</span></span></a></span><span class="reference" id="sbref0030"><div class="contribution"><div class="authors u-font-sans">Jian M., Lam K.M.</div><div id="ref-id-sbref0030" class="title text-m">Simultaneous hallucination and recognition of low-resolution faces based on singular value decomposition</div></div><div class="host u-font-sans">IEEE Trans. Circuits Syst. Video Technol., 25 (11) (2015), pp. 1761-1772</div><div class="ReferenceLinks u-font-sans"><a class="anchor link anchor-primary" href="https://www.scopus.com/inward/record.url?eid=2-s2.0-84960481499&amp;partnerID=10&amp;rel=R3.0.0" target="_blank" rel="noopener noreferrer" aria-describedby="ref-id-sbref0030"><span class="anchor-text-container"><span class="anchor-text">View in Scopus</span><svg focusable="false" viewBox="0 0 8 8" height="20" aria-label="Opens in new window" class="icon icon-arrow-up-right-tiny arrow-external-link"><path d="M1.12949 2.1072V1H7V6.85795H5.89111V2.90281L0.784057 8L0 7.21635L5.11902 2.1072H1.12949Z"></path></svg></span></a><a class="anchor link anchor-primary" href="https://scholar.google.com/scholar_lookup?title=Simultaneous%20hallucination%20and%20recognition%20of%20low-resolution%20faces%20based%20on%20singular%20value%20decomposition&amp;publication_year=2015&amp;author=M.%20Jian&amp;author=K.M.%20Lam" target="_blank" rel="noopener noreferrer" aria-describedby="ref-id-sbref0030"><span class="anchor-text-container"><span class="anchor-text">Google Scholar</span><svg focusable="false" viewBox="0 0 8 8" height="20" aria-label="Opens in new window" class="icon icon-arrow-up-right-tiny arrow-external-link"><path d="M1.12949 2.1072V1H7V6.85795H5.89111V2.90281L0.784057 8L0 7.21635L5.11902 2.1072H1.12949Z"></path></svg></span></a></div></span></li><li><span class="label u-font-sans"><a class="anchor anchor-primary" href="#bbib0032" id="ref-id-bib0032" data-aa-button="sd:product:journal:article:location=references:type=anchor:name=citation-name"><span class="anchor-text-container"><span class="anchor-text">[32]</span></span></a></span><span class="reference" id="sbref0031"><div class="contribution"><div class="authors u-font-sans">A. Mollahosseini, Chan D., M.H. Mahoor</div><div id="ref-id-sbref0031" class="title text-m">Going deeper in facial expression recognition using deep neural networks</div></div><div class="host u-font-sans">Proceedings of the Applications of Computer Vision (2016), pp. 1-10</div><div class="ReferenceLinks u-font-sans"><a class="anchor link anchor-primary" href="https://scholar.google.com/scholar_lookup?title=Going%20deeper%20in%20facial%20expression%20recognition%20using%20deep%20neural%20networks&amp;publication_year=2016&amp;author=A.%20Mollahosseini&amp;author=D.%20Chan&amp;author=M.H.%20Mahoor" target="_blank" rel="noopener noreferrer" aria-describedby="ref-id-sbref0031"><span class="anchor-text-container"><span class="anchor-text">Google Scholar</span><svg focusable="false" viewBox="0 0 8 8" height="20" aria-label="Opens in new window" class="icon icon-arrow-up-right-tiny arrow-external-link"><path d="M1.12949 2.1072V1H7V6.85795H5.89111V2.90281L0.784057 8L0 7.21635L5.11902 2.1072H1.12949Z"></path></svg></span></a></div></span></li><li><span class="label u-font-sans"><a class="anchor anchor-primary" href="#bbib0033" id="ref-id-bib0033" data-aa-button="sd:product:journal:article:location=references:type=anchor:name=citation-name"><span class="anchor-text-container"><span class="anchor-text">[33]</span></span></a></span><span class="reference" id="sbref0032"><div class="contribution"><div class="authors u-font-sans">Liu M., Li S., Shan S., Chen X.</div><div id="ref-id-sbref0032" class="title text-m">Au-aware deep networks for facial expression recognition</div></div><div class="host u-font-sans">Proceedings of the IEEE International Conference and Workshops on Automatic Face and Gesture Recognition (2013), pp. 1-6</div><div class="ReferenceLinks u-font-sans"><a class="anchor link anchor-primary" href="https://www.scopus.com/inward/record.url?eid=2-s2.0-84877664416&amp;partnerID=10&amp;rel=R3.0.0" target="_blank" rel="noopener noreferrer" aria-describedby="ref-id-sbref0032"><span class="anchor-text-container"><span class="anchor-text">View in Scopus</span><svg focusable="false" viewBox="0 0 8 8" height="20" aria-label="Opens in new window" class="icon icon-arrow-up-right-tiny arrow-external-link"><path d="M1.12949 2.1072V1H7V6.85795H5.89111V2.90281L0.784057 8L0 7.21635L5.11902 2.1072H1.12949Z"></path></svg></span></a><a class="anchor link anchor-primary" href="https://scholar.google.com/scholar_lookup?title=Au-aware%20deep%20networks%20for%20facial%20expression%20recognition&amp;publication_year=2013&amp;author=M.%20Liu&amp;author=S.%20Li&amp;author=S.%20Shan&amp;author=X.%20Chen" target="_blank" rel="noopener noreferrer" aria-describedby="ref-id-sbref0032"><span class="anchor-text-container"><span class="anchor-text">Google Scholar</span><svg focusable="false" viewBox="0 0 8 8" height="20" aria-label="Opens in new window" class="icon icon-arrow-up-right-tiny arrow-external-link"><path d="M1.12949 2.1072V1H7V6.85795H5.89111V2.90281L0.784057 8L0 7.21635L5.11902 2.1072H1.12949Z"></path></svg></span></a></div></span></li><li><span class="label u-font-sans"><a class="anchor anchor-primary" href="#bbib0034" id="ref-id-bib0034" data-aa-button="sd:product:journal:article:location=references:type=anchor:name=citation-name"><span class="anchor-text-container"><span class="anchor-text">[34]</span></span></a></span><span class="reference" id="sbref0033"><div class="contribution"><div class="authors u-font-sans">Zhang T., Zheng W., Cui Z., Zong Y., Yan J., Yan K.</div><div id="ref-id-sbref0033" class="title text-m">A deep neural network driven feature learning method for multi-view facial expression recognition</div></div><div class="host u-font-sans">IEEE Trans. Multimed., 18 (12) (2016), pp. 2528-2536</div><div class="ReferenceLinks u-font-sans"><a class="anchor link anchor-primary" href="https://www.scopus.com/inward/record.url?eid=2-s2.0-85000786081&amp;partnerID=10&amp;rel=R3.0.0" target="_blank" rel="noopener noreferrer" aria-describedby="ref-id-sbref0033"><span class="anchor-text-container"><span class="anchor-text">View in Scopus</span><svg focusable="false" viewBox="0 0 8 8" height="20" aria-label="Opens in new window" class="icon icon-arrow-up-right-tiny arrow-external-link"><path d="M1.12949 2.1072V1H7V6.85795H5.89111V2.90281L0.784057 8L0 7.21635L5.11902 2.1072H1.12949Z"></path></svg></span></a><a class="anchor link anchor-primary" href="https://scholar.google.com/scholar_lookup?title=A%20deep%20neural%20network%20driven%20feature%20learning%20method%20for%20multi-view%20facial%20expression%20recognition&amp;publication_year=2016&amp;author=T.%20Zhang&amp;author=W.%20Zheng&amp;author=Z.%20Cui&amp;author=Y.%20Zong&amp;author=J.%20Yan&amp;author=K.%20Yan" target="_blank" rel="noopener noreferrer" aria-describedby="ref-id-sbref0033"><span class="anchor-text-container"><span class="anchor-text">Google Scholar</span><svg focusable="false" viewBox="0 0 8 8" height="20" aria-label="Opens in new window" class="icon icon-arrow-up-right-tiny arrow-external-link"><path d="M1.12949 2.1072V1H7V6.85795H5.89111V2.90281L0.784057 8L0 7.21635L5.11902 2.1072H1.12949Z"></path></svg></span></a></div></span></li><li><span class="label u-font-sans"><a class="anchor anchor-primary" href="#bbib0035" id="ref-id-bib0035" data-aa-button="sd:product:journal:article:location=references:type=anchor:name=citation-name"><span class="anchor-text-container"><span class="anchor-text">[35]</span></span></a></span><span class="reference" id="sbref0034"><div class="contribution"><div class="authors u-font-sans">Jung H., Lee S., Yim J., S. Park, Kim J.</div><div id="ref-id-sbref0034" class="title text-m">Joint fine-tuning in deep neural networks for facial expression recognition</div></div><div class="host u-font-sans">Proceedings of the IEEE International Conference on Computer Vision (2015), pp. 2983-2991</div><div class="ReferenceLinks u-font-sans"><a class="anchor link anchor-primary" href="https://www.scopus.com/inward/record.url?eid=2-s2.0-84973917824&amp;partnerID=10&amp;rel=R3.0.0" target="_blank" rel="noopener noreferrer" aria-describedby="ref-id-sbref0034"><span class="anchor-text-container"><span class="anchor-text">View in Scopus</span><svg focusable="false" viewBox="0 0 8 8" height="20" aria-label="Opens in new window" class="icon icon-arrow-up-right-tiny arrow-external-link"><path d="M1.12949 2.1072V1H7V6.85795H5.89111V2.90281L0.784057 8L0 7.21635L5.11902 2.1072H1.12949Z"></path></svg></span></a><a class="anchor link anchor-primary" href="https://scholar.google.com/scholar_lookup?title=Joint%20fine-tuning%20in%20deep%20neural%20networks%20for%20facial%20expression%20recognition&amp;publication_year=2015&amp;author=H.%20Jung&amp;author=S.%20Lee&amp;author=J.%20Yim&amp;author=S.%20Park&amp;author=J.%20Kim" target="_blank" rel="noopener noreferrer" aria-describedby="ref-id-sbref0034"><span class="anchor-text-container"><span class="anchor-text">Google Scholar</span><svg focusable="false" viewBox="0 0 8 8" height="20" aria-label="Opens in new window" class="icon icon-arrow-up-right-tiny arrow-external-link"><path d="M1.12949 2.1072V1H7V6.85795H5.89111V2.90281L0.784057 8L0 7.21635L5.11902 2.1072H1.12949Z"></path></svg></span></a></div></span></li><li><span class="label u-font-sans"><a class="anchor anchor-primary" href="#bbib0036" id="ref-id-bib0036" data-aa-button="sd:product:journal:article:location=references:type=anchor:name=citation-name"><span class="anchor-text-container"><span class="anchor-text">[36]</span></span></a></span><span class="reference" id="sbref0035"><div class="contribution"><div class="authors u-font-sans">A.T. Lopes, E.D. Aguiar, A.F.D. Souza, T. Oliveira-Santos</div><div id="ref-id-sbref0035" class="title text-m">Facial expression recognition with convolutional neural networks: coping with few data and the training sample order</div></div><div class="host u-font-sans">Pattern Recognit., 61 (2017), pp. 610-628</div><div class="ReferenceLinks u-font-sans"><a class="anchor pdf link anchor-primary anchor-icon-left anchor-with-icon" href="/science/article/pii/S0031320316301753/pdfft?md5=3652c422d2874205c7eb2b753a3aa71b&amp;pid=1-s2.0-S0031320316301753-main.pdf" target="_blank" rel="nofollow" aria-describedby="ref-id-sbref0035"><svg focusable="false" viewBox="0 0 35 32" height="20" class="icon icon-pdf-multicolor"><path d="M7 .362h17.875l6.763 6.1V31.64H6.948V16z" stroke="#000" stroke-width=".703" fill="#fff"></path><path d="M.167 2.592H22.39V9.72H.166z" fill="#da0000"></path><path fill="#fff9f9" d="M5.97 3.638h1.62c1.053 0 1.483.677 1.488 1.564.008.96-.6 1.564-1.492 1.564h-.644v1.66h-.977V3.64m.977.897v1.34h.542c.27 0 .596-.068.596-.673-.002-.6-.32-.667-.596-.667h-.542m3.8.036v2.92h.35c.933 0 1.223-.448 1.228-1.462.008-1.06-.316-1.45-1.23-1.45h-.347m-.977-.94h1.03c1.68 0 2.523.586 2.534 2.39.01 1.688-.607 2.4-2.534 2.4h-1.03V3.64m4.305 0h2.63v.934h-1.657v.894H16.6V6.4h-1.56v2.026h-.97V3.638"></path><path d="M19.462 13.46c.348 4.274-6.59 16.72-8.508 15.792-1.82-.85 1.53-3.317 2.92-4.366-2.864.894-5.394 3.252-3.837 3.93 2.113.895 7.048-9.25 9.41-15.394zM14.32 24.874c4.767-1.526 14.735-2.974 15.152-1.407.824-3.157-13.72-.37-15.153 1.407zm5.28-5.043c2.31 3.237 9.816 7.498 9.788 3.82-.306 2.046-6.66-1.097-8.925-4.164-4.087-5.534-2.39-8.772-1.682-8.732.917.047 1.074 1.307.67 2.442-.173-1.406-.58-2.44-1.224-2.415-1.835.067-1.905 4.46 1.37 9.065z" fill="#f91d0a"></path></svg><span class="anchor-text-container"><span class="anchor-text">View PDF</span></span></a><a class="anchor link anchor-primary" href="/science/article/pii/S0031320316301753" aria-describedby="ref-id-sbref0035"><span class="anchor-text-container"><span class="anchor-text">View article</span></span></a><a class="anchor link anchor-primary" href="https://www.scopus.com/inward/record.url?eid=2-s2.0-84991821737&amp;partnerID=10&amp;rel=R3.0.0" target="_blank" rel="noopener noreferrer" aria-describedby="ref-id-sbref0035"><span class="anchor-text-container"><span class="anchor-text">View in Scopus</span><svg focusable="false" viewBox="0 0 8 8" height="20" aria-label="Opens in new window" class="icon icon-arrow-up-right-tiny arrow-external-link"><path d="M1.12949 2.1072V1H7V6.85795H5.89111V2.90281L0.784057 8L0 7.21635L5.11902 2.1072H1.12949Z"></path></svg></span></a><a class="anchor link anchor-primary" href="https://scholar.google.com/scholar_lookup?title=Facial%20expression%20recognition%20with%20convolutional%20neural%20networks%3A%20coping%20with%20few%20data%20and%20the%20training%20sample%20order&amp;publication_year=2017&amp;author=A.T.%20Lopes&amp;author=E.D.%20Aguiar&amp;author=A.F.D.%20Souza&amp;author=T.%20Oliveira-Santos" target="_blank" rel="noopener noreferrer" aria-describedby="ref-id-sbref0035"><span class="anchor-text-container"><span class="anchor-text">Google Scholar</span><svg focusable="false" viewBox="0 0 8 8" height="20" aria-label="Opens in new window" class="icon icon-arrow-up-right-tiny arrow-external-link"><path d="M1.12949 2.1072V1H7V6.85795H5.89111V2.90281L0.784057 8L0 7.21635L5.11902 2.1072H1.12949Z"></path></svg></span></a></div></span></li><li><span class="label u-font-sans"><a class="anchor anchor-primary" href="#bbib0037" id="ref-id-bib0037" data-aa-button="sd:product:journal:article:location=references:type=anchor:name=citation-name"><span class="anchor-text-container"><span class="anchor-text">[37]</span></span></a></span><span class="reference" id="sbref0036"><div class="contribution"><div class="authors u-font-sans">A. Majumder, L. Behera, V.K. Subramanian</div><div id="ref-id-sbref0036" class="title text-m">Automatic facial expression recognition system using deep network-based data fusion</div></div><div class="host u-font-sans">IEEE Trans. Cybern., 48 (1) (2017), pp. 103-114</div><div class="ReferenceLinks u-font-sans"><a class="anchor link anchor-primary" href="https://scholar.google.com/scholar_lookup?title=Automatic%20facial%20expression%20recognition%20system%20using%20deep%20network-based%20data%20fusion&amp;publication_year=2017&amp;author=A.%20Majumder&amp;author=L.%20Behera&amp;author=V.K.%20Subramanian" target="_blank" rel="noopener noreferrer" aria-describedby="ref-id-sbref0036"><span class="anchor-text-container"><span class="anchor-text">Google Scholar</span><svg focusable="false" viewBox="0 0 8 8" height="20" aria-label="Opens in new window" class="icon icon-arrow-up-right-tiny arrow-external-link"><path d="M1.12949 2.1072V1H7V6.85795H5.89111V2.90281L0.784057 8L0 7.21635L5.11902 2.1072H1.12949Z"></path></svg></span></a></div></span></li><li><span class="label u-font-sans"><a class="anchor anchor-primary" href="#bbib0038" id="ref-id-bib0038" data-aa-button="sd:product:journal:article:location=references:type=anchor:name=citation-name"><span class="anchor-text-container"><span class="anchor-text">[38]</span></span></a></span><span class="reference" id="sbref0037"><div class="contribution"><div class="authors u-font-sans">D. Hamester, P. Barros, S. Wermter</div><div id="ref-id-sbref0037" class="title text-m">Face expression recognition with a 2-channel convolutional neural network</div></div><div class="host u-font-sans">Proceedings of the International Joint Conference on Neural Networks (2015), pp. 1-8</div><div class="ReferenceLinks u-font-sans"><a class="anchor link anchor-primary" href="https://www.scopus.com/inward/record.url?eid=2-s2.0-85132587813&amp;partnerID=10&amp;rel=R3.0.0" target="_blank" rel="noopener noreferrer" aria-describedby="ref-id-sbref0037"><span class="anchor-text-container"><span class="anchor-text">View in Scopus</span><svg focusable="false" viewBox="0 0 8 8" height="20" aria-label="Opens in new window" class="icon icon-arrow-up-right-tiny arrow-external-link"><path d="M1.12949 2.1072V1H7V6.85795H5.89111V2.90281L0.784057 8L0 7.21635L5.11902 2.1072H1.12949Z"></path></svg></span></a><a class="anchor link anchor-primary" href="https://scholar.google.com/scholar_lookup?title=Face%20expression%20recognition%20with%20a%202-channel%20convolutional%20neural%20network&amp;publication_year=2015&amp;author=D.%20Hamester&amp;author=P.%20Barros&amp;author=S.%20Wermter" target="_blank" rel="noopener noreferrer" aria-describedby="ref-id-sbref0037"><span class="anchor-text-container"><span class="anchor-text">Google Scholar</span><svg focusable="false" viewBox="0 0 8 8" height="20" aria-label="Opens in new window" class="icon icon-arrow-up-right-tiny arrow-external-link"><path d="M1.12949 2.1072V1H7V6.85795H5.89111V2.90281L0.784057 8L0 7.21635L5.11902 2.1072H1.12949Z"></path></svg></span></a></div></span></li><li><span class="label u-font-sans"><a class="anchor anchor-primary" href="#bbib0039" id="ref-id-bib0039" data-aa-button="sd:product:journal:article:location=references:type=anchor:name=citation-name"><span class="anchor-text-container"><span class="anchor-text">[39]</span></span></a></span><span class="reference" id="sbref0038"><div class="contribution"><div class="authors u-font-sans">S. Alizadeh, A. Fazel</div><div id="ref-id-sbref0038" class="title text-m">Convolutional neural networks for facial expression recognition</div></div><div class="host u-font-sans"> (2016)</div><div class="comment">, arXiv preprint arXiv:<a class="anchor anchor-primary" href="http://arxiv.org/abs/1704.06756" target="_blank"><span class="anchor-text-container"><span class="anchor-text">1704.06756</span><svg focusable="false" viewBox="0 0 8 8" height="20" aria-label="Opens in new window" class="icon icon-arrow-up-right-tiny arrow-external-link"><path d="M1.12949 2.1072V1H7V6.85795H5.89111V2.90281L0.784057 8L0 7.21635L5.11902 2.1072H1.12949Z"></path></svg></span></a></div><div class="ReferenceLinks u-font-sans"><a class="anchor link anchor-primary" href="https://scholar.google.com/scholar_lookup?title=Convolutional%20neural%20networks%20for%20facial%20expression%20recognition&amp;publication_year=2016&amp;author=S.%20Alizadeh&amp;author=A.%20Fazel" target="_blank" rel="noopener noreferrer" aria-describedby="ref-id-sbref0038"><span class="anchor-text-container"><span class="anchor-text">Google Scholar</span><svg focusable="false" viewBox="0 0 8 8" height="20" aria-label="Opens in new window" class="icon icon-arrow-up-right-tiny arrow-external-link"><path d="M1.12949 2.1072V1H7V6.85795H5.89111V2.90281L0.784057 8L0 7.21635L5.11902 2.1072H1.12949Z"></path></svg></span></a></div></span></li><li><span class="label u-font-sans"><a class="anchor anchor-primary" href="#bbib0040" id="ref-id-bib0040" data-aa-button="sd:product:journal:article:location=references:type=anchor:name=citation-name"><span class="anchor-text-container"><span class="anchor-text">[40]</span></span></a></span><span class="reference" id="sbref0039"><div class="contribution"><div class="authors u-font-sans">J. Donahue, Y. Jia, O. Vinyals, J. Hoffman, Zhang N., Tzeng E., T. Darrell</div><div id="ref-id-sbref0039" class="title text-m">Decaf: a deep convolutional activation feature for generic visual recognition</div></div><div class="host u-font-sans">Proceedings of the International Conference on International Conference on Machine Learning (2014), pp. I-647</div><div class="ReferenceLinks u-font-sans"><a class="anchor link anchor-primary" href="https://scholar.google.com/scholar_lookup?title=Decaf%3A%20a%20deep%20convolutional%20activation%20feature%20for%20generic%20visual%20recognition&amp;publication_year=2014&amp;author=J.%20Donahue&amp;author=Y.%20Jia&amp;author=O.%20Vinyals&amp;author=J.%20Hoffman&amp;author=N.%20Zhang&amp;author=E.%20Tzeng&amp;author=T.%20Darrell" target="_blank" rel="noopener noreferrer" aria-describedby="ref-id-sbref0039"><span class="anchor-text-container"><span class="anchor-text">Google Scholar</span><svg focusable="false" viewBox="0 0 8 8" height="20" aria-label="Opens in new window" class="icon icon-arrow-up-right-tiny arrow-external-link"><path d="M1.12949 2.1072V1H7V6.85795H5.89111V2.90281L0.784057 8L0 7.21635L5.11902 2.1072H1.12949Z"></path></svg></span></a></div></span></li><li><span class="label u-font-sans"><a class="anchor anchor-primary" href="#bbib0041" id="ref-id-bib0041" data-aa-button="sd:product:journal:article:location=references:type=anchor:name=citation-name"><span class="anchor-text-container"><span class="anchor-text">[41]</span></span></a></span><span class="reference" id="sbref0040"><div class="contribution"><div class="authors u-font-sans">A. Ruiz-Garcia, M. Elshaw, A. Altahhan, V. Palade</div><div id="ref-id-sbref0040" class="title text-m">Stacked deep convolutional auto-encoders for emotion recognition from facial expressions</div></div><div class="host u-font-sans">Proceedings of the International Joint Conference on Neural Networks (2017), pp. 1586-1593</div><div class="ReferenceLinks u-font-sans"><a class="anchor link anchor-primary" href="https://www.scopus.com/inward/record.url?eid=2-s2.0-85031041686&amp;partnerID=10&amp;rel=R3.0.0" target="_blank" rel="noopener noreferrer" aria-describedby="ref-id-sbref0040"><span class="anchor-text-container"><span class="anchor-text">View in Scopus</span><svg focusable="false" viewBox="0 0 8 8" height="20" aria-label="Opens in new window" class="icon icon-arrow-up-right-tiny arrow-external-link"><path d="M1.12949 2.1072V1H7V6.85795H5.89111V2.90281L0.784057 8L0 7.21635L5.11902 2.1072H1.12949Z"></path></svg></span></a><a class="anchor link anchor-primary" href="https://scholar.google.com/scholar_lookup?title=Stacked%20deep%20convolutional%20auto-encoders%20for%20emotion%20recognition%20from%20facial%20expressions&amp;publication_year=2017&amp;author=A.%20Ruiz-Garcia&amp;author=M.%20Elshaw&amp;author=A.%20Altahhan&amp;author=V.%20Palade" target="_blank" rel="noopener noreferrer" aria-describedby="ref-id-sbref0040"><span class="anchor-text-container"><span class="anchor-text">Google Scholar</span><svg focusable="false" viewBox="0 0 8 8" height="20" aria-label="Opens in new window" class="icon icon-arrow-up-right-tiny arrow-external-link"><path d="M1.12949 2.1072V1H7V6.85795H5.89111V2.90281L0.784057 8L0 7.21635L5.11902 2.1072H1.12949Z"></path></svg></span></a></div></span></li><li><span class="label u-font-sans"><a class="anchor anchor-primary" href="#bbib0042" id="ref-id-bib0042" data-aa-button="sd:product:journal:article:location=references:type=anchor:name=citation-name"><span class="anchor-text-container"><span class="anchor-text">[42]</span></span></a></span><span class="reference" id="sbref0041"><div class="contribution"><div class="authors u-font-sans">Yanai K., Y. Kawano</div><div id="ref-id-sbref0041" class="title text-m">Food image recognition using deep convolutional network with pre-training and fine-tuning</div></div><div class="host u-font-sans">Proceedings of the IEEE International Conference on Multimedia &amp; Expo Workshops (2015), pp. 1-6</div><div class="ReferenceLinks u-font-sans"><a class="anchor link anchor-primary" href="https://scholar.google.com/scholar_lookup?title=Food%20image%20recognition%20using%20deep%20convolutional%20network%20with%20pre-training%20and%20fine-tuning&amp;publication_year=2015&amp;author=K.%20Yanai&amp;author=Y.%20Kawano" target="_blank" rel="noopener noreferrer" aria-describedby="ref-id-sbref0041"><span class="anchor-text-container"><span class="anchor-text">Google Scholar</span><svg focusable="false" viewBox="0 0 8 8" height="20" aria-label="Opens in new window" class="icon icon-arrow-up-right-tiny arrow-external-link"><path d="M1.12949 2.1072V1H7V6.85795H5.89111V2.90281L0.784057 8L0 7.21635L5.11902 2.1072H1.12949Z"></path></svg></span></a></div></span></li><li><span class="label u-font-sans"><a class="anchor anchor-primary" href="#bbib0043" id="ref-id-bib0043" data-aa-button="sd:product:journal:article:location=references:type=anchor:name=citation-name"><span class="anchor-text-container"><span class="anchor-text">[43]</span></span></a></span><span class="reference" id="sbref0042"><div class="contribution"><div class="authors u-font-sans">He K., Zhang X., Ren S., Sun J.</div><div id="ref-id-sbref0042" class="title text-m">Deep residual learning for image recognition</div></div><div class="host u-font-sans">Proceedings of the 2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR) (2016), pp. 770-778, <a class="anchor anchor-primary" href="https://doi.org/10.1109/CVPR.2016.90" target="_blank"><span class="anchor-text-container"><span class="anchor-text">10.1109/CVPR.2016.90</span><svg focusable="false" viewBox="0 0 8 8" height="20" aria-label="Opens in new window" class="icon icon-arrow-up-right-tiny arrow-external-link"><path d="M1.12949 2.1072V1H7V6.85795H5.89111V2.90281L0.784057 8L0 7.21635L5.11902 2.1072H1.12949Z"></path></svg></span></a></div><div class="ReferenceLinks u-font-sans"><span class="link lazy-third-party-pdf-link"><span></span></span><a class="anchor link anchor-primary" href="https://scholar.google.com/scholar_lookup?title=Deep%20residual%20learning%20for%20image%20recognition&amp;publication_year=2016&amp;author=K.%20He&amp;author=X.%20Zhang&amp;author=S.%20Ren&amp;author=J.%20Sun" target="_blank" rel="noopener noreferrer" aria-describedby="ref-id-sbref0042"><span class="anchor-text-container"><span class="anchor-text">Google Scholar</span><svg focusable="false" viewBox="0 0 8 8" height="20" aria-label="Opens in new window" class="icon icon-arrow-up-right-tiny arrow-external-link"><path d="M1.12949 2.1072V1H7V6.85795H5.89111V2.90281L0.784057 8L0 7.21635L5.11902 2.1072H1.12949Z"></path></svg></span></a></div></span></li><li><span class="label u-font-sans"><a class="anchor anchor-primary" href="#bbib0044" id="ref-id-bib0044" data-aa-button="sd:product:journal:article:location=references:type=anchor:name=citation-name"><span class="anchor-text-container"><span class="anchor-text">[44]</span></span></a></span><span class="reference" id="sbref0043"><div class="contribution"><div class="authors u-font-sans">O. Russakovsky, Deng J., Su H., J. Krause, S. Satheesh, Ma S., Huang Z., A. Karpathy, A. Khosla, M. Bernstein</div><div id="ref-id-sbref0043" class="title text-m">Imagenet large scale visual recognition challenge</div></div><div class="host u-font-sans">Int. J. Comput. Vis., 115 (3) (2015), pp. 211-252</div><div class="ReferenceLinks u-font-sans"><span class="link lazy-third-party-pdf-link"><span></span></span><a class="anchor link anchor-primary" href="https://doi.org/10.1007/s11263-015-0816-y" target="_blank" rel="noopener noreferrer" aria-describedby="ref-id-sbref0043"><span class="anchor-text-container"><span class="anchor-text">Crossref</span><svg focusable="false" viewBox="0 0 8 8" height="20" aria-label="Opens in new window" class="icon icon-arrow-up-right-tiny arrow-external-link"><path d="M1.12949 2.1072V1H7V6.85795H5.89111V2.90281L0.784057 8L0 7.21635L5.11902 2.1072H1.12949Z"></path></svg></span></a><a class="anchor link anchor-primary" href="https://scholar.google.com/scholar_lookup?title=Imagenet%20large%20scale%20visual%20recognition%20challenge&amp;publication_year=2015&amp;author=O.%20Russakovsky&amp;author=J.%20Deng&amp;author=H.%20Su&amp;author=J.%20Krause&amp;author=S.%20Satheesh&amp;author=S.%20Ma&amp;author=Z.%20Huang&amp;author=A.%20Karpathy&amp;author=A.%20Khosla&amp;author=M.%20Bernstein" target="_blank" rel="noopener noreferrer" aria-describedby="ref-id-sbref0043"><span class="anchor-text-container"><span class="anchor-text">Google Scholar</span><svg focusable="false" viewBox="0 0 8 8" height="20" aria-label="Opens in new window" class="icon icon-arrow-up-right-tiny arrow-external-link"><path d="M1.12949 2.1072V1H7V6.85795H5.89111V2.90281L0.784057 8L0 7.21635L5.11902 2.1072H1.12949Z"></path></svg></span></a></div></span></li><li><span class="label u-font-sans"><a class="anchor anchor-primary" href="#bbib0045" id="ref-id-bib0045" data-aa-button="sd:product:journal:article:location=references:type=anchor:name=citation-name"><span class="anchor-text-container"><span class="anchor-text">[45]</span></span></a></span><span class="reference" id="sbref0044"><div class="contribution"><div class="authors u-font-sans">P. Lucey, J.F. Cohn, T. Kanade, J. Saragih</div><div id="ref-id-sbref0044" class="title text-m">The extended cohn-kanade dataset (ck+): a complete dataset for action unit and emotion-specified expression</div></div><div class="host u-font-sans">Proceedings of the Computer Vision and Pattern Recognition Workshops (2010), pp. 94-101</div><div class="ReferenceLinks u-font-sans"><a class="anchor link anchor-primary" href="https://www.scopus.com/inward/record.url?eid=2-s2.0-77956509035&amp;partnerID=10&amp;rel=R3.0.0" target="_blank" rel="noopener noreferrer" aria-describedby="ref-id-sbref0044"><span class="anchor-text-container"><span class="anchor-text">View in Scopus</span><svg focusable="false" viewBox="0 0 8 8" height="20" aria-label="Opens in new window" class="icon icon-arrow-up-right-tiny arrow-external-link"><path d="M1.12949 2.1072V1H7V6.85795H5.89111V2.90281L0.784057 8L0 7.21635L5.11902 2.1072H1.12949Z"></path></svg></span></a><a class="anchor link anchor-primary" href="https://scholar.google.com/scholar_lookup?title=The%20extended%20cohn-kanade%20dataset%20%3A%20a%20complete%20dataset%20for%20action%20unit%20and%20emotion-specified%20expression&amp;publication_year=2010&amp;author=P.%20Lucey&amp;author=J.F.%20Cohn&amp;author=T.%20Kanade&amp;author=J.%20Saragih" target="_blank" rel="noopener noreferrer" aria-describedby="ref-id-sbref0044"><span class="anchor-text-container"><span class="anchor-text">Google Scholar</span><svg focusable="false" viewBox="0 0 8 8" height="20" aria-label="Opens in new window" class="icon icon-arrow-up-right-tiny arrow-external-link"><path d="M1.12949 2.1072V1H7V6.85795H5.89111V2.90281L0.784057 8L0 7.21635L5.11902 2.1072H1.12949Z"></path></svg></span></a></div></span></li><li><span class="label u-font-sans"><a class="anchor anchor-primary" href="#bbib0046" id="ref-id-bib0046" data-aa-button="sd:product:journal:article:location=references:type=anchor:name=citation-name"><span class="anchor-text-container"><span class="anchor-text">[46]</span></span></a></span><span class="reference" id="sbref0045"><div class="contribution"><div class="authors u-font-sans">Yin L., Wei X., Sun Y., Wang J., M.J. Rosato</div><div id="ref-id-sbref0045" class="title text-m">A 3D facial expression database for facial behavior research</div></div><div class="host u-font-sans">Proceedings of the International Conference on Automatic Face and Gesture Recognition (2006), pp. 211-216</div><div class="ReferenceLinks u-font-sans"><a class="anchor link anchor-primary" href="https://www.scopus.com/inward/record.url?eid=2-s2.0-33750814056&amp;partnerID=10&amp;rel=R3.0.0" target="_blank" rel="noopener noreferrer" aria-describedby="ref-id-sbref0045"><span class="anchor-text-container"><span class="anchor-text">View in Scopus</span><svg focusable="false" viewBox="0 0 8 8" height="20" aria-label="Opens in new window" class="icon icon-arrow-up-right-tiny arrow-external-link"><path d="M1.12949 2.1072V1H7V6.85795H5.89111V2.90281L0.784057 8L0 7.21635L5.11902 2.1072H1.12949Z"></path></svg></span></a><a class="anchor link anchor-primary" href="https://scholar.google.com/scholar_lookup?title=A%203D%20facial%20expression%20database%20for%20facial%20behavior%20research&amp;publication_year=2006&amp;author=L.%20Yin&amp;author=X.%20Wei&amp;author=Y.%20Sun&amp;author=J.%20Wang&amp;author=M.J.%20Rosato" target="_blank" rel="noopener noreferrer" aria-describedby="ref-id-sbref0045"><span class="anchor-text-container"><span class="anchor-text">Google Scholar</span><svg focusable="false" viewBox="0 0 8 8" height="20" aria-label="Opens in new window" class="icon icon-arrow-up-right-tiny arrow-external-link"><path d="M1.12949 2.1072V1H7V6.85795H5.89111V2.90281L0.784057 8L0 7.21635L5.11902 2.1072H1.12949Z"></path></svg></span></a></div></span></li><li><span class="label u-font-sans"><a class="anchor anchor-primary" href="#bbib0047" id="ref-id-bib0047" data-aa-button="sd:product:journal:article:location=references:type=anchor:name=citation-name"><span class="anchor-text-container"><span class="anchor-text">[47]</span></span></a></span><span class="reference" id="sbref0046"><div class="contribution"><div class="authors u-font-sans">I.J. Goodfellow, D. Erhan, C.P. Luc, A. Courville, M. Mirza, B. Hamner, W. Cukierski, Tang Y., D. Thaler, Lee D.H.</div><div id="ref-id-sbref0046" class="title text-m">Challenges in representation learning: a report on three machine learning contests.</div></div><div class="host u-font-sans">Neural Netw, 64 (2015), pp. 59-63</div><div class="ReferenceLinks u-font-sans"><a class="anchor pdf link anchor-primary anchor-icon-left anchor-with-icon" href="/science/article/pii/S0893608014002159/pdfft?md5=1f6d3fa94ea723c2357fa1140e25d747&amp;pid=1-s2.0-S0893608014002159-main.pdf" target="_blank" rel="nofollow" aria-describedby="ref-id-sbref0046"><svg focusable="false" viewBox="0 0 35 32" height="20" class="icon icon-pdf-multicolor"><path d="M7 .362h17.875l6.763 6.1V31.64H6.948V16z" stroke="#000" stroke-width=".703" fill="#fff"></path><path d="M.167 2.592H22.39V9.72H.166z" fill="#da0000"></path><path fill="#fff9f9" d="M5.97 3.638h1.62c1.053 0 1.483.677 1.488 1.564.008.96-.6 1.564-1.492 1.564h-.644v1.66h-.977V3.64m.977.897v1.34h.542c.27 0 .596-.068.596-.673-.002-.6-.32-.667-.596-.667h-.542m3.8.036v2.92h.35c.933 0 1.223-.448 1.228-1.462.008-1.06-.316-1.45-1.23-1.45h-.347m-.977-.94h1.03c1.68 0 2.523.586 2.534 2.39.01 1.688-.607 2.4-2.534 2.4h-1.03V3.64m4.305 0h2.63v.934h-1.657v.894H16.6V6.4h-1.56v2.026h-.97V3.638"></path><path d="M19.462 13.46c.348 4.274-6.59 16.72-8.508 15.792-1.82-.85 1.53-3.317 2.92-4.366-2.864.894-5.394 3.252-3.837 3.93 2.113.895 7.048-9.25 9.41-15.394zM14.32 24.874c4.767-1.526 14.735-2.974 15.152-1.407.824-3.157-13.72-.37-15.153 1.407zm5.28-5.043c2.31 3.237 9.816 7.498 9.788 3.82-.306 2.046-6.66-1.097-8.925-4.164-4.087-5.534-2.39-8.772-1.682-8.732.917.047 1.074 1.307.67 2.442-.173-1.406-.58-2.44-1.224-2.415-1.835.067-1.905 4.46 1.37 9.065z" fill="#f91d0a"></path></svg><span class="anchor-text-container"><span class="anchor-text">View PDF</span></span></a><a class="anchor link anchor-primary" href="/science/article/pii/S0893608014002159" aria-describedby="ref-id-sbref0046"><span class="anchor-text-container"><span class="anchor-text">View article</span></span></a><a class="anchor link anchor-primary" href="https://www.scopus.com/inward/record.url?eid=2-s2.0-84922350769&amp;partnerID=10&amp;rel=R3.0.0" target="_blank" rel="noopener noreferrer" aria-describedby="ref-id-sbref0046"><span class="anchor-text-container"><span class="anchor-text">View in Scopus</span><svg focusable="false" viewBox="0 0 8 8" height="20" aria-label="Opens in new window" class="icon icon-arrow-up-right-tiny arrow-external-link"><path d="M1.12949 2.1072V1H7V6.85795H5.89111V2.90281L0.784057 8L0 7.21635L5.11902 2.1072H1.12949Z"></path></svg></span></a><a class="anchor link anchor-primary" href="https://scholar.google.com/scholar_lookup?title=Challenges%20in%20representation%20learning%3A%20a%20report%20on%20three%20machine%20learning%20contests.&amp;publication_year=2015&amp;author=I.J.%20Goodfellow&amp;author=D.%20Erhan&amp;author=C.P.%20Luc&amp;author=A.%20Courville&amp;author=M.%20Mirza&amp;author=B.%20Hamner&amp;author=W.%20Cukierski&amp;author=Y.%20Tang&amp;author=D.%20Thaler&amp;author=D.H.%20Lee" target="_blank" rel="noopener noreferrer" aria-describedby="ref-id-sbref0046"><span class="anchor-text-container"><span class="anchor-text">Google Scholar</span><svg focusable="false" viewBox="0 0 8 8" height="20" aria-label="Opens in new window" class="icon icon-arrow-up-right-tiny arrow-external-link"><path d="M1.12949 2.1072V1H7V6.85795H5.89111V2.90281L0.784057 8L0 7.21635L5.11902 2.1072H1.12949Z"></path></svg></span></a></div></span></li><li><span class="label u-font-sans"><a class="anchor anchor-primary" href="#bbib0048" id="ref-id-bib0048" data-aa-button="sd:product:journal:article:location=references:type=anchor:name=citation-name"><span class="anchor-text-container"><span class="anchor-text">[48]</span></span></a></span><span class="reference" id="sbref0047"><div class="contribution"><div class="authors u-font-sans">Xiang J., Zhu G.</div><div id="ref-id-sbref0047" class="title text-m">Joint face detection and facial expression recognition with mtcnn</div></div><div class="host u-font-sans">Proceedings of the International Conference on Information Science and Control Engineering (2017), pp. 424-427</div><div class="ReferenceLinks u-font-sans"><span class="link lazy-third-party-pdf-link"><span></span></span><a class="anchor link anchor-primary" href="https://doi.org/10.1109/ICISCE.2017.95" target="_blank" rel="noopener noreferrer" aria-describedby="ref-id-sbref0047"><span class="anchor-text-container"><span class="anchor-text">Crossref</span><svg focusable="false" viewBox="0 0 8 8" height="20" aria-label="Opens in new window" class="icon icon-arrow-up-right-tiny arrow-external-link"><path d="M1.12949 2.1072V1H7V6.85795H5.89111V2.90281L0.784057 8L0 7.21635L5.11902 2.1072H1.12949Z"></path></svg></span></a><a class="anchor link anchor-primary" href="https://www.scopus.com/inward/record.url?eid=2-s2.0-85040557555&amp;partnerID=10&amp;rel=R3.0.0" target="_blank" rel="noopener noreferrer" aria-describedby="ref-id-sbref0047"><span class="anchor-text-container"><span class="anchor-text">View in Scopus</span><svg focusable="false" viewBox="0 0 8 8" height="20" aria-label="Opens in new window" class="icon icon-arrow-up-right-tiny arrow-external-link"><path d="M1.12949 2.1072V1H7V6.85795H5.89111V2.90281L0.784057 8L0 7.21635L5.11902 2.1072H1.12949Z"></path></svg></span></a><a class="anchor link anchor-primary" href="https://scholar.google.com/scholar_lookup?title=Joint%20face%20detection%20and%20facial%20expression%20recognition%20with%20mtcnn&amp;publication_year=2017&amp;author=J.%20Xiang&amp;author=G.%20Zhu" target="_blank" rel="noopener noreferrer" aria-describedby="ref-id-sbref0047"><span class="anchor-text-container"><span class="anchor-text">Google Scholar</span><svg focusable="false" viewBox="0 0 8 8" height="20" aria-label="Opens in new window" class="icon icon-arrow-up-right-tiny arrow-external-link"><path d="M1.12949 2.1072V1H7V6.85795H5.89111V2.90281L0.784057 8L0 7.21635L5.11902 2.1072H1.12949Z"></path></svg></span></a></div></span></li><li><span class="label u-font-sans"><a class="anchor anchor-primary" href="#bbib0049" id="ref-id-bib0049" data-aa-button="sd:product:journal:article:location=references:type=anchor:name=citation-name"><span class="anchor-text-container"><span class="anchor-text">[49]</span></span></a></span><span class="reference" id="sbref0048"><div class="contribution"><div class="authors u-font-sans">L. Perez, Wang J.</div><div id="ref-id-sbref0048" class="title text-m">The effectiveness of data augmentation in image classification using deep learning</div></div><div class="host u-font-sans"> (2017)</div><div class="comment">, arXiv preprint arXiv:<a class="anchor anchor-primary" href="http://arxiv.org/abs/1712.04621" target="_blank"><span class="anchor-text-container"><span class="anchor-text">1712.04621</span><svg focusable="false" viewBox="0 0 8 8" height="20" aria-label="Opens in new window" class="icon icon-arrow-up-right-tiny arrow-external-link"><path d="M1.12949 2.1072V1H7V6.85795H5.89111V2.90281L0.784057 8L0 7.21635L5.11902 2.1072H1.12949Z"></path></svg></span></a></div><div class="ReferenceLinks u-font-sans"><a class="anchor link anchor-primary" href="https://scholar.google.com/scholar_lookup?title=The%20effectiveness%20of%20data%20augmentation%20in%20image%20classification%20using%20deep%20learning&amp;publication_year=2017&amp;author=L.%20Perez&amp;author=J.%20Wang" target="_blank" rel="noopener noreferrer" aria-describedby="ref-id-sbref0048"><span class="anchor-text-container"><span class="anchor-text">Google Scholar</span><svg focusable="false" viewBox="0 0 8 8" height="20" aria-label="Opens in new window" class="icon icon-arrow-up-right-tiny arrow-external-link"><path d="M1.12949 2.1072V1H7V6.85795H5.89111V2.90281L0.784057 8L0 7.21635L5.11902 2.1072H1.12949Z"></path></svg></span></a></div></span></li><li><span class="label u-font-sans"><a class="anchor anchor-primary" href="#bbib0050" id="ref-id-bib0050" data-aa-button="sd:product:journal:article:location=references:type=anchor:name=citation-name"><span class="anchor-text-container"><span class="anchor-text">[50]</span></span></a></span><span class="reference" id="sbref0049"><div class="contribution"><div class="authors u-font-sans">M. Stewart, B.G. Littlewort, I. Fasel, J.R. Movellan</div><div id="ref-id-sbref0049" class="title text-m">Real time face detection and facial expression recognition: Development and</div></div><div class="host u-font-sans">Proceedings of the Computer Vision and Pattern Recognition Workshop, 2003. CVPRW â€™03. Conference on (2003)</div><div class="comment">53â€“53</div><div class="ReferenceLinks u-font-sans"><a class="anchor link anchor-primary" href="https://scholar.google.com/scholar_lookup?title=Real%20time%20face%20detection%20and%20facial%20expression%20recognition%3A%20Development%20and&amp;publication_year=2003&amp;author=M.%20Stewart&amp;author=B.G.%20Littlewort&amp;author=I.%20Fasel&amp;author=J.R.%20Movellan" target="_blank" rel="noopener noreferrer" aria-describedby="ref-id-sbref0049"><span class="anchor-text-container"><span class="anchor-text">Google Scholar</span><svg focusable="false" viewBox="0 0 8 8" height="20" aria-label="Opens in new window" class="icon icon-arrow-up-right-tiny arrow-external-link"><path d="M1.12949 2.1072V1H7V6.85795H5.89111V2.90281L0.784057 8L0 7.21635L5.11902 2.1072H1.12949Z"></path></svg></span></a></div></span></li><li><span class="label u-font-sans"><a class="anchor anchor-primary" href="#bbib0051" id="ref-id-bib0051" data-aa-button="sd:product:journal:article:location=references:type=anchor:name=citation-name"><span class="anchor-text-container"><span class="anchor-text">[51]</span></span></a></span><span class="reference" id="sbref0050"><div class="contribution"><div class="authors u-font-sans">A. Poursaberi, H.A. Noubari, M. Gavrilova, S.N. Yanushkevich</div><div id="ref-id-sbref0050" class="title text-m">Gaussâ€“Laguerre wavelet textural feature fusion with geometrical information for facial expression identification</div></div><div class="host u-font-sans">EURASIP J. Image Video Process., 2012 (1) (2012), pp. 1-13</div><div class="ReferenceLinks u-font-sans"><a class="anchor link anchor-primary" href="https://scholar.google.com/scholar_lookup?title=GaussLaguerre%20wavelet%20textural%20feature%20fusion%20with%20geometrical%20information%20for%20facial%20expression%20identification&amp;publication_year=2012&amp;author=A.%20Poursaberi&amp;author=H.A.%20Noubari&amp;author=M.%20Gavrilova&amp;author=S.N.%20Yanushkevich" target="_blank" rel="noopener noreferrer" aria-describedby="ref-id-sbref0050"><span class="anchor-text-container"><span class="anchor-text">Google Scholar</span><svg focusable="false" viewBox="0 0 8 8" height="20" aria-label="Opens in new window" class="icon icon-arrow-up-right-tiny arrow-external-link"><path d="M1.12949 2.1072V1H7V6.85795H5.89111V2.90281L0.784057 8L0 7.21635L5.11902 2.1072H1.12949Z"></path></svg></span></a></div></span></li><li><span class="label u-font-sans"><a class="anchor anchor-primary" href="#bbib0052" id="ref-id-bib0052" data-aa-button="sd:product:journal:article:location=references:type=anchor:name=citation-name"><span class="anchor-text-container"><span class="anchor-text">[52]</span></span></a></span><span class="reference" id="sbref0051"><div class="contribution"><div class="authors u-font-sans">D. Ghimire, Jeong S., Yoon S., Choi J., Lee J.</div><div id="ref-id-sbref0051" class="title text-m">Facial expression recognition based on region specific appearance and geometric features</div></div><div class="host u-font-sans">Proceedings of the Tenth International Conference on Digital Information Management (2016), pp. 142-147</div><div class="ReferenceLinks u-font-sans"><a class="anchor link anchor-primary" href="https://scholar.google.com/scholar_lookup?title=Facial%20expression%20recognition%20based%20on%20region%20specific%20appearance%20and%20geometric%20features&amp;publication_year=2016&amp;author=D.%20Ghimire&amp;author=S.%20Jeong&amp;author=S.%20Yoon&amp;author=J.%20Choi&amp;author=J.%20Lee" target="_blank" rel="noopener noreferrer" aria-describedby="ref-id-sbref0051"><span class="anchor-text-container"><span class="anchor-text">Google Scholar</span><svg focusable="false" viewBox="0 0 8 8" height="20" aria-label="Opens in new window" class="icon icon-arrow-up-right-tiny arrow-external-link"><path d="M1.12949 2.1072V1H7V6.85795H5.89111V2.90281L0.784057 8L0 7.21635L5.11902 2.1072H1.12949Z"></path></svg></span></a></div></span></li><li><span class="label u-font-sans"><a class="anchor anchor-primary" href="#bbib0053" id="ref-id-bib0053" data-aa-button="sd:product:journal:article:location=references:type=anchor:name=citation-name"><span class="anchor-text-container"><span class="anchor-text">[53]</span></span></a></span><span class="reference" id="sbref0052"><div class="contribution"><div class="authors u-font-sans">Hu Y., Zeng Z., Yin L., Wei X.</div><div id="ref-id-sbref0052" class="title text-m">Multi-view facial expression recognition</div></div><div class="host u-font-sans">Proceedings of the IEEE International Conference on Automatic Face &amp; Gesture Recognition (2008), pp. 1-6</div><div class="ReferenceLinks u-font-sans"><a class="anchor link anchor-primary" href="https://scholar.google.com/scholar_lookup?title=Multi-view%20facial%20expression%20recognition&amp;publication_year=2008&amp;author=Y.%20Hu&amp;author=Z.%20Zeng&amp;author=L.%20Yin&amp;author=X.%20Wei" target="_blank" rel="noopener noreferrer" aria-describedby="ref-id-sbref0052"><span class="anchor-text-container"><span class="anchor-text">Google Scholar</span><svg focusable="false" viewBox="0 0 8 8" height="20" aria-label="Opens in new window" class="icon icon-arrow-up-right-tiny arrow-external-link"><path d="M1.12949 2.1072V1H7V6.85795H5.89111V2.90281L0.784057 8L0 7.21635L5.11902 2.1072H1.12949Z"></path></svg></span></a></div></span></li><li><span class="label u-font-sans"><a class="anchor anchor-primary" href="#bbib0054" id="ref-id-bib0054" data-aa-button="sd:product:journal:article:location=references:type=anchor:name=citation-name"><span class="anchor-text-container"><span class="anchor-text">[54]</span></span></a></span><span class="reference" id="sbref0053"><div class="contribution"><div class="authors u-font-sans">S. Moore, R. Bowden</div><div id="ref-id-sbref0053" class="title text-m">Local binary patterns for multi-view facial expression recognition</div></div><div class="host u-font-sans">Comput. Vis. Image Underst., 115 (4) (2011), pp. 541-558</div><div class="ReferenceLinks u-font-sans"><a class="anchor pdf link anchor-primary anchor-icon-left anchor-with-icon" href="/science/article/pii/S1077314210002511/pdfft?md5=8a66db13811eef9b092e86768465481a&amp;pid=1-s2.0-S1077314210002511-main.pdf" target="_blank" rel="nofollow" aria-describedby="ref-id-sbref0053"><svg focusable="false" viewBox="0 0 35 32" height="20" class="icon icon-pdf-multicolor"><path d="M7 .362h17.875l6.763 6.1V31.64H6.948V16z" stroke="#000" stroke-width=".703" fill="#fff"></path><path d="M.167 2.592H22.39V9.72H.166z" fill="#da0000"></path><path fill="#fff9f9" d="M5.97 3.638h1.62c1.053 0 1.483.677 1.488 1.564.008.96-.6 1.564-1.492 1.564h-.644v1.66h-.977V3.64m.977.897v1.34h.542c.27 0 .596-.068.596-.673-.002-.6-.32-.667-.596-.667h-.542m3.8.036v2.92h.35c.933 0 1.223-.448 1.228-1.462.008-1.06-.316-1.45-1.23-1.45h-.347m-.977-.94h1.03c1.68 0 2.523.586 2.534 2.39.01 1.688-.607 2.4-2.534 2.4h-1.03V3.64m4.305 0h2.63v.934h-1.657v.894H16.6V6.4h-1.56v2.026h-.97V3.638"></path><path d="M19.462 13.46c.348 4.274-6.59 16.72-8.508 15.792-1.82-.85 1.53-3.317 2.92-4.366-2.864.894-5.394 3.252-3.837 3.93 2.113.895 7.048-9.25 9.41-15.394zM14.32 24.874c4.767-1.526 14.735-2.974 15.152-1.407.824-3.157-13.72-.37-15.153 1.407zm5.28-5.043c2.31 3.237 9.816 7.498 9.788 3.82-.306 2.046-6.66-1.097-8.925-4.164-4.087-5.534-2.39-8.772-1.682-8.732.917.047 1.074 1.307.67 2.442-.173-1.406-.58-2.44-1.224-2.415-1.835.067-1.905 4.46 1.37 9.065z" fill="#f91d0a"></path></svg><span class="anchor-text-container"><span class="anchor-text">View PDF</span></span></a><a class="anchor link anchor-primary" href="/science/article/pii/S1077314210002511" aria-describedby="ref-id-sbref0053"><span class="anchor-text-container"><span class="anchor-text">View article</span></span></a><a class="anchor link anchor-primary" href="https://www.scopus.com/inward/record.url?eid=2-s2.0-79851512378&amp;partnerID=10&amp;rel=R3.0.0" target="_blank" rel="noopener noreferrer" aria-describedby="ref-id-sbref0053"><span class="anchor-text-container"><span class="anchor-text">View in Scopus</span><svg focusable="false" viewBox="0 0 8 8" height="20" aria-label="Opens in new window" class="icon icon-arrow-up-right-tiny arrow-external-link"><path d="M1.12949 2.1072V1H7V6.85795H5.89111V2.90281L0.784057 8L0 7.21635L5.11902 2.1072H1.12949Z"></path></svg></span></a><a class="anchor link anchor-primary" href="https://scholar.google.com/scholar_lookup?title=Local%20binary%20patterns%20for%20multi-view%20facial%20expression%20recognition&amp;publication_year=2011&amp;author=S.%20Moore&amp;author=R.%20Bowden" target="_blank" rel="noopener noreferrer" aria-describedby="ref-id-sbref0053"><span class="anchor-text-container"><span class="anchor-text">Google Scholar</span><svg focusable="false" viewBox="0 0 8 8" height="20" aria-label="Opens in new window" class="icon icon-arrow-up-right-tiny arrow-external-link"><path d="M1.12949 2.1072V1H7V6.85795H5.89111V2.90281L0.784057 8L0 7.21635L5.11902 2.1072H1.12949Z"></path></svg></span></a></div></span></li><li><span class="label u-font-sans"><a class="anchor anchor-primary" href="#bbib0055" id="ref-id-bib0055" data-aa-button="sd:product:journal:article:location=references:type=anchor:name=citation-name"><span class="anchor-text-container"><span class="anchor-text">[55]</span></span></a></span><span class="reference" id="sbref0054"><div class="contribution"><div class="authors u-font-sans">A. Dapogny, K. Bailly, S. Dubuisson</div><div id="ref-id-sbref0054" class="title text-m">Dynamic pose-robust facial expression recognition by multi-view pairwise conditional random forests</div></div><div class="host u-font-sans">IEEE Trans. Affect. Comput., PP (99) (2016)</div><div class="comment">1â€“1</div><div class="ReferenceLinks u-font-sans"><a class="anchor link anchor-primary" href="https://scholar.google.com/scholar_lookup?title=Dynamic%20pose-robust%20facial%20expression%20recognition%20by%20multi-view%20pairwise%20conditional%20random%20forests&amp;publication_year=2016&amp;author=A.%20Dapogny&amp;author=K.%20Bailly&amp;author=S.%20Dubuisson" target="_blank" rel="noopener noreferrer" aria-describedby="ref-id-sbref0054"><span class="anchor-text-container"><span class="anchor-text">Google Scholar</span><svg focusable="false" viewBox="0 0 8 8" height="20" aria-label="Opens in new window" class="icon icon-arrow-up-right-tiny arrow-external-link"><path d="M1.12949 2.1072V1H7V6.85795H5.89111V2.90281L0.784057 8L0 7.21635L5.11902 2.1072H1.12949Z"></path></svg></span></a></div></span></li><li><span class="label u-font-sans"><a class="anchor anchor-primary" href="#bbib0056" id="ref-id-bib0056" data-aa-button="sd:product:journal:article:location=references:type=anchor:name=citation-name"><span class="anchor-text-container"><span class="anchor-text">[56]</span></span></a></span><span class="reference" id="sbref0055"><div class="contribution"><div class="authors u-font-sans">Zheng W.</div><div id="ref-id-sbref0055" class="title text-m">Multi-view facial expression recognition based on group sparse reduced-rank regression</div></div><div class="host u-font-sans">IEEE Trans. Affect. Comput., 5 (1) (2014), pp. 71-85</div><div class="ReferenceLinks u-font-sans"><a class="anchor link anchor-primary" href="https://www.scopus.com/inward/record.url?eid=2-s2.0-84903643888&amp;partnerID=10&amp;rel=R3.0.0" target="_blank" rel="noopener noreferrer" aria-describedby="ref-id-sbref0055"><span class="anchor-text-container"><span class="anchor-text">View in Scopus</span><svg focusable="false" viewBox="0 0 8 8" height="20" aria-label="Opens in new window" class="icon icon-arrow-up-right-tiny arrow-external-link"><path d="M1.12949 2.1072V1H7V6.85795H5.89111V2.90281L0.784057 8L0 7.21635L5.11902 2.1072H1.12949Z"></path></svg></span></a><a class="anchor link anchor-primary" href="https://scholar.google.com/scholar_lookup?title=Multi-view%20facial%20expression%20recognition%20based%20on%20group%20sparse%20reduced-rank%20regression&amp;publication_year=2014&amp;author=W.%20Zheng" target="_blank" rel="noopener noreferrer" aria-describedby="ref-id-sbref0055"><span class="anchor-text-container"><span class="anchor-text">Google Scholar</span><svg focusable="false" viewBox="0 0 8 8" height="20" aria-label="Opens in new window" class="icon icon-arrow-up-right-tiny arrow-external-link"><path d="M1.12949 2.1072V1H7V6.85795H5.89111V2.90281L0.784057 8L0 7.21635L5.11902 2.1072H1.12949Z"></path></svg></span></a></div></span></li><li><span class="label u-font-sans"><a class="anchor anchor-primary" href="#bbib0057" id="ref-id-bib0057" data-aa-button="sd:product:journal:article:location=references:type=anchor:name=citation-name"><span class="anchor-text-container"><span class="anchor-text">[57]</span></span></a></span><span class="reference" id="sbref0056"><div class="contribution"><div class="authors u-font-sans">O. Rudovic, I. Patras, M. Pantic</div><div id="ref-id-sbref0056" class="title text-m">Coupled gaussian process regression for pose-invariant facial expression recognition</div></div><div class="host u-font-sans">Proceedings of the European Conference on Computer Vision (2010), pp. 350-363</div><div class="ReferenceLinks u-font-sans"><span class="link lazy-third-party-pdf-link"><span></span></span><a class="anchor link anchor-primary" href="https://doi.org/10.1007/978-3-642-15552-9_26" target="_blank" rel="noopener noreferrer" aria-describedby="ref-id-sbref0056"><span class="anchor-text-container"><span class="anchor-text">Crossref</span><svg focusable="false" viewBox="0 0 8 8" height="20" aria-label="Opens in new window" class="icon icon-arrow-up-right-tiny arrow-external-link"><path d="M1.12949 2.1072V1H7V6.85795H5.89111V2.90281L0.784057 8L0 7.21635L5.11902 2.1072H1.12949Z"></path></svg></span></a><a class="anchor link anchor-primary" href="https://www.scopus.com/inward/record.url?eid=2-s2.0-78149302175&amp;partnerID=10&amp;rel=R3.0.0" target="_blank" rel="noopener noreferrer" aria-describedby="ref-id-sbref0056"><span class="anchor-text-container"><span class="anchor-text">View in Scopus</span><svg focusable="false" viewBox="0 0 8 8" height="20" aria-label="Opens in new window" class="icon icon-arrow-up-right-tiny arrow-external-link"><path d="M1.12949 2.1072V1H7V6.85795H5.89111V2.90281L0.784057 8L0 7.21635L5.11902 2.1072H1.12949Z"></path></svg></span></a><a class="anchor link anchor-primary" href="https://scholar.google.com/scholar_lookup?title=Coupled%20gaussian%20process%20regression%20for%20pose-invariant%20facial%20expression%20recognition&amp;publication_year=2010&amp;author=O.%20Rudovic&amp;author=I.%20Patras&amp;author=M.%20Pantic" target="_blank" rel="noopener noreferrer" aria-describedby="ref-id-sbref0056"><span class="anchor-text-container"><span class="anchor-text">Google Scholar</span><svg focusable="false" viewBox="0 0 8 8" height="20" aria-label="Opens in new window" class="icon icon-arrow-up-right-tiny arrow-external-link"><path d="M1.12949 2.1072V1H7V6.85795H5.89111V2.90281L0.784057 8L0 7.21635L5.11902 2.1072H1.12949Z"></path></svg></span></a></div></span></li><li><span class="label u-font-sans"><a class="anchor anchor-primary" href="#bbib0058" id="ref-id-bib0058" data-aa-button="sd:product:journal:article:location=references:type=anchor:name=citation-name"><span class="anchor-text-container"><span class="anchor-text">[58]</span></span></a></span><span class="reference" id="sbref0057"><div class="contribution"><div class="authors u-font-sans">Tang Y.</div><div id="ref-id-sbref0057" class="title text-m">Deep learning using linear support vector machines</div></div><div class="host u-font-sans"> (2013)</div><div class="comment">, arXiv preprint arXiv:<a class="anchor anchor-primary" href="http://arxiv.org/abs/1306.0239" target="_blank"><span class="anchor-text-container"><span class="anchor-text">1306.0239</span><svg focusable="false" viewBox="0 0 8 8" height="20" aria-label="Opens in new window" class="icon icon-arrow-up-right-tiny arrow-external-link"><path d="M1.12949 2.1072V1H7V6.85795H5.89111V2.90281L0.784057 8L0 7.21635L5.11902 2.1072H1.12949Z"></path></svg></span></a></div><div class="ReferenceLinks u-font-sans"><a class="anchor link anchor-primary" href="https://scholar.google.com/scholar_lookup?title=Deep%20learning%20using%20linear%20support%20vector%20machines&amp;publication_year=2013&amp;author=Y.%20Tang" target="_blank" rel="noopener noreferrer" aria-describedby="ref-id-sbref0057"><span class="anchor-text-container"><span class="anchor-text">Google Scholar</span><svg focusable="false" viewBox="0 0 8 8" height="20" aria-label="Opens in new window" class="icon icon-arrow-up-right-tiny arrow-external-link"><path d="M1.12949 2.1072V1H7V6.85795H5.89111V2.90281L0.784057 8L0 7.21635L5.11902 2.1072H1.12949Z"></path></svg></span></a></div></span></li><li><span class="label u-font-sans"><a class="anchor anchor-primary" href="#bbib0059" id="ref-id-bib0059" data-aa-button="sd:product:journal:article:location=references:type=anchor:name=citation-name"><span class="anchor-text-container"><span class="anchor-text">[59]</span></span></a></span><span class="reference" id="sbref0058"><div class="contribution"><div class="authors u-font-sans">Kim B.K., Roh J., Dong S.Y., Lee S.Y.</div><div id="ref-id-sbref0058" class="title text-m">Hierarchical committee of deep convolutional neural networks for robust facial expression recognition</div></div><div class="host u-font-sans">J. Multimod. User Interfaces, 10 (2) (2016), pp. 1-17</div><div class="ReferenceLinks u-font-sans"><a class="anchor link anchor-primary" href="https://www.scopus.com/inward/record.url?eid=2-s2.0-85075737403&amp;partnerID=10&amp;rel=R3.0.0" target="_blank" rel="noopener noreferrer" aria-describedby="ref-id-sbref0058"><span class="anchor-text-container"><span class="anchor-text">View in Scopus</span><svg focusable="false" viewBox="0 0 8 8" height="20" aria-label="Opens in new window" class="icon icon-arrow-up-right-tiny arrow-external-link"><path d="M1.12949 2.1072V1H7V6.85795H5.89111V2.90281L0.784057 8L0 7.21635L5.11902 2.1072H1.12949Z"></path></svg></span></a><a class="anchor link anchor-primary" href="https://scholar.google.com/scholar_lookup?title=Hierarchical%20committee%20of%20deep%20convolutional%20neural%20networks%20for%20robust%20facial%20expression%20recognition&amp;publication_year=2016&amp;author=B.K.%20Kim&amp;author=J.%20Roh&amp;author=S.Y.%20Dong&amp;author=S.Y.%20Lee" target="_blank" rel="noopener noreferrer" aria-describedby="ref-id-sbref0058"><span class="anchor-text-container"><span class="anchor-text">Google Scholar</span><svg focusable="false" viewBox="0 0 8 8" height="20" aria-label="Opens in new window" class="icon icon-arrow-up-right-tiny arrow-external-link"><path d="M1.12949 2.1072V1H7V6.85795H5.89111V2.90281L0.784057 8L0 7.21635L5.11902 2.1072H1.12949Z"></path></svg></span></a></div></span></li><li><span class="label u-font-sans"><a class="anchor anchor-primary" href="#bbib0060" id="ref-id-bib0060" data-aa-button="sd:product:journal:article:location=references:type=anchor:name=citation-name"><span class="anchor-text-container"><span class="anchor-text">[60]</span></span></a></span><span class="reference" id="sbref0059"><div class="contribution"><div class="authors u-font-sans">Jeon J., J.-C. Park, Jo Y., Nam C., Bae K.-H., Hwang Y., Kim D.-S.</div><div id="ref-id-sbref0059" class="title text-m">A real-time facial expression recognizer using deep neural network</div></div><div class="host u-font-sans">Proceedings of the International Conference on Ubiquitous Information Management &amp; Communication (2016), pp. 1-4, <a class="anchor anchor-primary" href="https://doi.org/10.1145/2857546.2857642" target="_blank"><span class="anchor-text-container"><span class="anchor-text">10.1145/2857546.2857642</span><svg focusable="false" viewBox="0 0 8 8" height="20" aria-label="Opens in new window" class="icon icon-arrow-up-right-tiny arrow-external-link"><path d="M1.12949 2.1072V1H7V6.85795H5.89111V2.90281L0.784057 8L0 7.21635L5.11902 2.1072H1.12949Z"></path></svg></span></a></div><div class="ReferenceLinks u-font-sans"><span class="link lazy-third-party-pdf-link"><span></span></span><a class="anchor link anchor-primary" href="https://scholar.google.com/scholar_lookup?title=A%20real-time%20facial%20expression%20recognizer%20using%20deep%20neural%20network&amp;publication_year=2016&amp;author=J.%20Jeon&amp;author=J.-C.%20Park&amp;author=Y.%20Jo&amp;author=C.%20Nam&amp;author=K.-H.%20Bae&amp;author=Y.%20Hwang&amp;author=D.-S.%20Kim" target="_blank" rel="noopener noreferrer" aria-describedby="ref-id-sbref0059"><span class="anchor-text-container"><span class="anchor-text">Google Scholar</span><svg focusable="false" viewBox="0 0 8 8" height="20" aria-label="Opens in new window" class="icon icon-arrow-up-right-tiny arrow-external-link"><path d="M1.12949 2.1072V1H7V6.85795H5.89111V2.90281L0.784057 8L0 7.21635L5.11902 2.1072H1.12949Z"></path></svg></span></a></div></span></li><li><span class="label u-font-sans"><a class="anchor anchor-primary" href="#bbib0061" id="ref-id-bib0061" data-aa-button="sd:product:journal:article:location=references:type=anchor:name=citation-name"><span class="anchor-text-container"><span class="anchor-text">[61]</span></span></a></span><span class="reference" id="sbref0060"><div class="contribution"><div class="authors u-font-sans">T. Devries, K. Biswaranjan, G. W. Taylor</div><div id="ref-id-sbref0060" class="title text-m">Multi-task learning of facial landmarks and expression</div></div><div class="host u-font-sans">Proceedings of the Computer &amp; Robot Vision (2014), pp. 98-103, <a class="anchor anchor-primary" href="https://doi.org/10.1109/CRV.2014.21" target="_blank"><span class="anchor-text-container"><span class="anchor-text">10.1109/CRV.2014.21</span><svg focusable="false" viewBox="0 0 8 8" height="20" aria-label="Opens in new window" class="icon icon-arrow-up-right-tiny arrow-external-link"><path d="M1.12949 2.1072V1H7V6.85795H5.89111V2.90281L0.784057 8L0 7.21635L5.11902 2.1072H1.12949Z"></path></svg></span></a></div><div class="ReferenceLinks u-font-sans"><span class="link lazy-third-party-pdf-link"><span></span></span><a class="anchor link anchor-primary" href="https://www.scopus.com/inward/record.url?eid=2-s2.0-84902245243&amp;partnerID=10&amp;rel=R3.0.0" target="_blank" rel="noopener noreferrer" aria-describedby="ref-id-sbref0060"><span class="anchor-text-container"><span class="anchor-text">View in Scopus</span><svg focusable="false" viewBox="0 0 8 8" height="20" aria-label="Opens in new window" class="icon icon-arrow-up-right-tiny arrow-external-link"><path d="M1.12949 2.1072V1H7V6.85795H5.89111V2.90281L0.784057 8L0 7.21635L5.11902 2.1072H1.12949Z"></path></svg></span></a><a class="anchor link anchor-primary" href="https://scholar.google.com/scholar_lookup?title=Multi-task%20learning%20of%20facial%20landmarks%20and%20expression&amp;publication_year=2014&amp;author=T.%20Devries&amp;author=K.%20Biswaranjan&amp;author=G.%20W.%20Taylor" target="_blank" rel="noopener noreferrer" aria-describedby="ref-id-sbref0060"><span class="anchor-text-container"><span class="anchor-text">Google Scholar</span><svg focusable="false" viewBox="0 0 8 8" height="20" aria-label="Opens in new window" class="icon icon-arrow-up-right-tiny arrow-external-link"><path d="M1.12949 2.1072V1H7V6.85795H5.89111V2.90281L0.784057 8L0 7.21635L5.11902 2.1072H1.12949Z"></path></svg></span></a></div></span></li><li><span class="label u-font-sans"><a class="anchor anchor-primary" href="#bbib0062" id="ref-id-bib0062" data-aa-button="sd:product:journal:article:location=references:type=anchor:name=citation-name"><span class="anchor-text-container"><span class="anchor-text">[62]</span></span></a></span><span class="reference" id="sbref0061"><div class="contribution"><div class="authors u-font-sans">Liu K., Zhang M., Pan Z.</div><div id="ref-id-sbref0061" class="title text-m">Facial expression recognition with CNN ensemble</div></div><div class="host u-font-sans">Proceedings of the International Conference on Cyberworlds (2016), pp. 163-166</div><div class="ReferenceLinks u-font-sans"><span class="link lazy-third-party-pdf-link"><span></span></span><a class="anchor link anchor-primary" href="https://doi.org/10.1109/CW.2016.34" target="_blank" rel="noopener noreferrer" aria-describedby="ref-id-sbref0061"><span class="anchor-text-container"><span class="anchor-text">Crossref</span><svg focusable="false" viewBox="0 0 8 8" height="20" aria-label="Opens in new window" class="icon icon-arrow-up-right-tiny arrow-external-link"><path d="M1.12949 2.1072V1H7V6.85795H5.89111V2.90281L0.784057 8L0 7.21635L5.11902 2.1072H1.12949Z"></path></svg></span></a><a class="anchor link anchor-primary" href="https://www.scopus.com/inward/record.url?eid=2-s2.0-85006912356&amp;partnerID=10&amp;rel=R3.0.0" target="_blank" rel="noopener noreferrer" aria-describedby="ref-id-sbref0061"><span class="anchor-text-container"><span class="anchor-text">View in Scopus</span><svg focusable="false" viewBox="0 0 8 8" height="20" aria-label="Opens in new window" class="icon icon-arrow-up-right-tiny arrow-external-link"><path d="M1.12949 2.1072V1H7V6.85795H5.89111V2.90281L0.784057 8L0 7.21635L5.11902 2.1072H1.12949Z"></path></svg></span></a><a class="anchor link anchor-primary" href="https://scholar.google.com/scholar_lookup?title=Facial%20expression%20recognition%20with%20CNN%20ensemble&amp;publication_year=2016&amp;author=K.%20Liu&amp;author=M.%20Zhang&amp;author=Z.%20Pan" target="_blank" rel="noopener noreferrer" aria-describedby="ref-id-sbref0061"><span class="anchor-text-container"><span class="anchor-text">Google Scholar</span><svg focusable="false" viewBox="0 0 8 8" height="20" aria-label="Opens in new window" class="icon icon-arrow-up-right-tiny arrow-external-link"><path d="M1.12949 2.1072V1H7V6.85795H5.89111V2.90281L0.784057 8L0 7.21635L5.11902 2.1072H1.12949Z"></path></svg></span></a></div></span></li><li><span class="label u-font-sans"><a class="anchor anchor-primary" href="#bbib0063" id="ref-id-bib0063" data-aa-button="sd:product:journal:article:location=references:type=anchor:name=citation-name"><span class="anchor-text-container"><span class="anchor-text">[63]</span></span></a></span><span class="reference" id="sbref0062"><div class="contribution"><div class="authors u-font-sans">Zeng G., Zhou J., Jia X., Xie W., Shen L.</div><div id="ref-id-sbref0062" class="title text-m">Hand-crafted feature guided deep learning for facial expression recognition</div></div><div class="host u-font-sans">Proceedings of the 2018 13th IEEE International Conference on Automatic Face Gesture Recognition (FG 2018) (2018), pp. 423-430, <a class="anchor anchor-primary" href="https://doi.org/10.1109/FG.2018.00068" target="_blank"><span class="anchor-text-container"><span class="anchor-text">10.1109/FG.2018.00068</span><svg focusable="false" viewBox="0 0 8 8" height="20" aria-label="Opens in new window" class="icon icon-arrow-up-right-tiny arrow-external-link"><path d="M1.12949 2.1072V1H7V6.85795H5.89111V2.90281L0.784057 8L0 7.21635L5.11902 2.1072H1.12949Z"></path></svg></span></a></div><div class="ReferenceLinks u-font-sans"><span class="link lazy-third-party-pdf-link"><span></span></span><a class="anchor link anchor-primary" href="https://www.scopus.com/inward/record.url?eid=2-s2.0-85049414285&amp;partnerID=10&amp;rel=R3.0.0" target="_blank" rel="noopener noreferrer" aria-describedby="ref-id-sbref0062"><span class="anchor-text-container"><span class="anchor-text">View in Scopus</span><svg focusable="false" viewBox="0 0 8 8" height="20" aria-label="Opens in new window" class="icon icon-arrow-up-right-tiny arrow-external-link"><path d="M1.12949 2.1072V1H7V6.85795H5.89111V2.90281L0.784057 8L0 7.21635L5.11902 2.1072H1.12949Z"></path></svg></span></a><a class="anchor link anchor-primary" href="https://scholar.google.com/scholar_lookup?title=Hand-crafted%20feature%20guided%20deep%20learning%20for%20facial%20expression%20recognition&amp;publication_year=2018&amp;author=G.%20Zeng&amp;author=J.%20Zhou&amp;author=X.%20Jia&amp;author=W.%20Xie&amp;author=L.%20Shen" target="_blank" rel="noopener noreferrer" aria-describedby="ref-id-sbref0062"><span class="anchor-text-container"><span class="anchor-text">Google Scholar</span><svg focusable="false" viewBox="0 0 8 8" height="20" aria-label="Opens in new window" class="icon icon-arrow-up-right-tiny arrow-external-link"><path d="M1.12949 2.1072V1H7V6.85795H5.89111V2.90281L0.784057 8L0 7.21635L5.11902 2.1072H1.12949Z"></path></svg></span></a></div></span></li><li><span class="label u-font-sans"><a class="anchor anchor-primary" href="#bbib0064" id="ref-id-bib0064" data-aa-button="sd:product:journal:article:location=references:type=anchor:name=citation-name"><span class="anchor-text-container"><span class="anchor-text">[64]</span></span></a></span><span class="reference" id="sbref0063"><div class="contribution"><div class="authors u-font-sans">V. Tumen, O.F. Soylemez, B. Ergen</div><div id="ref-id-sbref0063" class="title text-m">Facial emotion recognition on a dataset using convolutional neural network</div></div><div class="host u-font-sans">Proceedings of the Artificial Intelligence and Data Processing Symposium (2017), pp. 1-5</div><div class="ReferenceLinks u-font-sans"><a class="anchor link anchor-primary" href="https://scholar.google.com/scholar_lookup?title=Facial%20emotion%20recognition%20on%20a%20dataset%20using%20convolutional%20neural%20network&amp;publication_year=2017&amp;author=V.%20Tumen&amp;author=O.F.%20Soylemez&amp;author=B.%20Ergen" target="_blank" rel="noopener noreferrer" aria-describedby="ref-id-sbref0063"><span class="anchor-text-container"><span class="anchor-text">Google Scholar</span><svg focusable="false" viewBox="0 0 8 8" height="20" aria-label="Opens in new window" class="icon icon-arrow-up-right-tiny arrow-external-link"><path d="M1.12949 2.1072V1H7V6.85795H5.89111V2.90281L0.784057 8L0 7.21635L5.11902 2.1072H1.12949Z"></path></svg></span></a></div></span></li></ol></section></section></div><div id="section-cited-by"><section aria-label="Cited by" class="ListArticles preview"><div class="PageDivider"></div><header id="citing-articles-header"><h2 class="u-h4 u-margin-l-ver u-font-serif">Cited by (149)</h2></header><div aria-describedby="citing-articles-header"><div class="citing-articles u-margin-l-bottom"><ul><li class="ListArticleItem u-margin-l-bottom"><div class="sub-heading u-margin-xs-bottom"><h3 class="u-font-serif" id="citing-articles-article-0-title"><a class="anchor anchor-primary" href="/science/article/pii/S0020025521008495"><span class="anchor-text-container"><span class="anchor-text">Facial expression recognition with grid-wise attention and visual transformer</span></span></a></h3><div>2021, Information Sciences</div></div><div class="buttons"><button class="button-link button-link-primary button-link-icon-right" data-aa-button="sd:product:journal:article:location=citing-articles:type=view-details" aria-describedby="citing-articles-article-0-title" aria-controls="citing-articles-article-0" aria-expanded="false" type="button"><span class="button-link-text-container"><span class="button-link-text">Show abstract</span></span><svg focusable="false" viewBox="0 0 92 128" height="20" class="icon icon-navigate-down"><path d="M1 51l7-7 38 38 38-38 7 7-45 45z"></path></svg></button></div><div class="u-display-none" aria-hidden="true"><div class="abstract u-margin-xs-top u-margin-m-bottom u-font-serif" id="reference-abstract"><div class="u-margin-ver-m"><div class="u-margin-s-bottom" id="sp005"><u>F</u>acial <u>E</u>xpression <u>R</u>ecognition (FER) has achieved remarkable progress as a result of using <u>C</u>onvolutional <u>N</u>eural <u>N</u>etworks (CNN). Relying on the spatial locality, convolutional filters in CNN, however, fail to learn long-range inductive biases between different facial regions in most neural layers. As such, the performance of a CNN-based model for FER is still limited. To address this problem, this paper introduces a novel FER framework with two attention mechanisms for CNN-based models, and these two attention mechanisms are used for the low-level feature learning the high-level semantic representation, respectively. In particular, in the low-level feature learning, a grid-wise attention mechanism is proposed to capture the dependencies of different regions from a facial expression image such that the parameter update of convolutional filters in low-level feature learning is regularized. In the high-level semantic representation, a visual transformer attention mechanism uses a sequence of visual semantic tokens (generated from pyramid features of high convolutional layer blocks) to learn the global representation. Extensive experiments have been conducted on three public facial expression datasets, CK+, FER+, and RAF-DB. The results show that our FER-VT has achieved state-of-the-art performance on these datasets, especially with a 100% accuracy on CKâ€¯+â€¯datasets without any extra training data.</div></div></div></div></li><li class="ListArticleItem u-margin-l-bottom"><div class="sub-heading u-margin-xs-bottom"><h3 class="u-font-serif" id="citing-articles-article-1-title"><a class="anchor anchor-primary" href="/science/article/pii/S0925231220309838"><span class="anchor-text-container"><span class="anchor-text">Attention mechanism-based CNN for facial expression recognition</span></span></a></h3><div>2020, Neurocomputing</div><div class="CitedSection u-margin-s-top"><div class="u-margin-s-left"><div class="cite-header u-text-italic u-font-sans">Citation Excerpt :</div><p class="u-font-serif text-xs">From Table 8, we can find that our method outperforms the others on our dataset. The recognition results of [33,30,34] on NCUFE are 91.58%, 81.3% and 82.5%, respectively. This paper presents a novel convolutional neural network with attention mechanism for facial expression recognition.</p></div></div></div><div class="buttons"><button class="button-link button-link-primary button-link-icon-right" data-aa-button="sd:product:journal:article:location=citing-articles:type=view-details" aria-describedby="citing-articles-article-1-title" aria-controls="citing-articles-article-1" aria-expanded="false" type="button"><span class="button-link-text-container"><span class="button-link-text">Show abstract</span></span><svg focusable="false" viewBox="0 0 92 128" height="20" class="icon icon-navigate-down"><path d="M1 51l7-7 38 38 38-38 7 7-45 45z"></path></svg></button></div><div class="u-display-none" aria-hidden="true"><div class="abstract u-margin-xs-top u-margin-m-bottom u-font-serif" id="reference-abstract"><div class="u-margin-ver-m"><div class="u-margin-s-bottom" id="sp0005">Facial expression recognition is a hot research topic and can be applied in many computer vision fields, such as humanâ€“computer interaction, affective computing and so on. In this paper, we propose a novel end-to-end network with attention mechanism for automatic facial expression recognition. The new network architecture consists of four parts, i.e., the feature extraction module, the attention module, the reconstruction module and the classification module. The LBP features extract image texture information and then catch the small movements of the faces, which can improve the network performance. Attention mechanism can make the neural network pay more attention to useful features. We combine LBP features and attention mechanism to enhance the attention model to obtain better results. In addition, we collected and labelled a new facial expression dataset of seven expressions from 35 subjects aged from 20 to 25. For each subject, we captured both RGB images and depth images with a Microsoft Kinect sensor. For each image type, there are 245 image sequences, each of which contains 110 images, resulting in 26,950 images in total. We apply the newly proposed method to our own dataset and four representative expression datasets, i.e., JAFFE, CK+, FER2013 and Oulu-CASIA. The experimental results demonstrate the feasibility and effectiveness of the proposed method.</div></div></div></div></li><li class="ListArticleItem u-margin-l-bottom"><div class="sub-heading u-margin-xs-bottom"><h3 class="u-font-serif" id="citing-articles-article-2-title"><a class="anchor anchor-primary" href="/science/article/pii/S0925231220300783"><span class="anchor-text-container"><span class="anchor-text">Deep convolution network based emotion analysis towards mental health care</span></span></a></h3><div>2020, Neurocomputing</div><div class="CitedSection u-margin-s-top"><div class="u-margin-s-left"><div class="cite-header u-text-italic u-font-sans">Citation Excerpt :</div><p class="u-font-serif text-xs">For instance, deep CNN approaches often need to determine large amount of weights in the training phase. Consequently it is observed that such approaches suffer from performance decrements when being trained on a small image dataset [8]. A second important issue is ecological validity, in that most of the existing systems use lab-posed facial expressions images.</p></div></div></div><div class="buttons"><button class="button-link button-link-primary button-link-icon-right" data-aa-button="sd:product:journal:article:location=citing-articles:type=view-details" aria-describedby="citing-articles-article-2-title" aria-controls="citing-articles-article-2" aria-expanded="false" type="button"><span class="button-link-text-container"><span class="button-link-text">Show abstract</span></span><svg focusable="false" viewBox="0 0 92 128" height="20" class="icon icon-navigate-down"><path d="M1 51l7-7 38 38 38-38 7 7-45 45z"></path></svg></button></div><div class="u-display-none" aria-hidden="true"><div class="abstract u-margin-xs-top u-margin-m-bottom u-font-serif" id="reference-abstract"><div class="u-margin-ver-m"><div class="u-margin-s-bottom" id="spara024">Facial expressions play an important role during communications, allowing information regarding the emotional state of an individual to be conveyed and inferred. Research suggests that automatic facial expression recognition is a promising avenue of enquiry in mental healthcare, as facial expressions can also reflect an individual's mental state. In order to develop user-friendly, low-cost and effective facial expression analysis systems for mental health care, this paper presents a novel deep convolution network based emotion analysis framework to support mental state detection and diagnosis. The proposed system is able to process facial images and interpret the temporal evolution of emotions through a new solution in which deep features are extracted from the Fully Connected Layer 6 of the AlexNet, with a standard Linear Discriminant Analysis Classifier exploited to obtain the final classification outcome. It is tested against 5 benchmarking databases, including JAFFE, KDEF,CK+, and databases with the images obtained â€˜in the wildâ€™ such as FER2013 and AffectNet. Compared with the other state-of-the-art methods, we observe that our method has overall higher accuracy of facial expression recognition. Additionally, when compared to the state-of-the-art deep learning algorithms such as Vgg16, GoogleNet, ResNet and AlexNet, the proposed method demonstrated better efficiency and has less device requirements. The experiments presented in this paper demonstrate that the proposed method outperforms the other methods in terms of accuracy and efficiency which suggests it could act as a smart, low-cost, user-friendly cognitive aid to detect, monitor, and diagnose the mental health of a patient through automatic facial expression analysis.</div></div></div></div></li><li class="ListArticleItem u-margin-l-bottom"><div class="sub-heading u-margin-xs-bottom"><h3 class="u-font-serif" id="citing-articles-article-3-title"><a class="anchor anchor-primary" href="https://doi.org/10.1109/TAFFC.2021.3122146" target="_blank"><span class="anchor-text-container"><span class="anchor-text">Facial Expression Recognition With Visual Transformers and Attentional Selective Fusion</span><svg focusable="false" viewBox="0 0 8 8" height="20" aria-label="Opens in new window" class="icon icon-arrow-up-right-tiny arrow-external-link"><path d="M1.12949 2.1072V1H7V6.85795H5.89111V2.90281L0.784057 8L0 7.21635L5.11902 2.1072H1.12949Z"></path></svg></span></a></h3><div>2023, IEEE Transactions on Affective Computing</div></div><div class="buttons"></div><div class="u-display-none" aria-hidden="true"><div class="abstract u-margin-xs-top u-margin-m-bottom u-font-serif" id="reference-abstract"></div></div></li><li class="ListArticleItem u-margin-l-bottom"><div class="sub-heading u-margin-xs-bottom"><h3 class="u-font-serif" id="citing-articles-article-4-title"><a class="anchor anchor-primary" href="https://doi.org/10.1109/ACCESS.2022.3156598" target="_blank"><span class="anchor-text-container"><span class="anchor-text">Ad-Corre: Adaptive Correlation-Based Loss for Facial Expression Recognition in the Wild</span><svg focusable="false" viewBox="0 0 8 8" height="20" aria-label="Opens in new window" class="icon icon-arrow-up-right-tiny arrow-external-link"><path d="M1.12949 2.1072V1H7V6.85795H5.89111V2.90281L0.784057 8L0 7.21635L5.11902 2.1072H1.12949Z"></path></svg></span></a></h3><div>2022, IEEE Access</div></div><div class="buttons"></div><div class="u-display-none" aria-hidden="true"><div class="abstract u-margin-xs-top u-margin-m-bottom u-font-serif" id="reference-abstract"></div></div></li><li class="ListArticleItem u-margin-l-bottom"><div class="sub-heading u-margin-xs-bottom"><h3 class="u-font-serif" id="citing-articles-article-5-title"><a class="anchor anchor-primary" href="https://doi.org/10.1007/s00521-020-05676-y" target="_blank"><span class="anchor-text-container"><span class="anchor-text">FER-net: facial expression recognition using deep neural net</span><svg focusable="false" viewBox="0 0 8 8" height="20" aria-label="Opens in new window" class="icon icon-arrow-up-right-tiny arrow-external-link"><path d="M1.12949 2.1072V1H7V6.85795H5.89111V2.90281L0.784057 8L0 7.21635L5.11902 2.1072H1.12949Z"></path></svg></span></a></h3><div>2021, Neural Computing and Applications</div></div><div class="buttons"></div><div class="u-display-none" aria-hidden="true"><div class="abstract u-margin-xs-top u-margin-m-bottom u-font-serif" id="reference-abstract"></div></div></li></ul><a class="button-alternative button-alternative-secondary large-alternative button-alternative-icon-left" href="http://www.scopus.com/scopus/inward/citedby.url?partnerID=10&amp;rel=3.0.0&amp;eid=2-s2.0-85065595874&amp;md5=8f3deef7712eb2355010d1b190efbdda" target="_blank" id="citing-articles-view-all-btn"><svg focusable="false" viewBox="0 0 54 128" height="20" class="icon icon-navigate-right"><path d="M1 99l38-38L1 23l7-7 45 45-45 45z"></path></svg><span class="button-alternative-text-container"><span class="button-alternative-text">View all citing articles on Scopus</span></span><svg focusable="false" viewBox="0 0 8 8" height="20" aria-label="Opens in new window" class="icon icon-arrow-up-right-tiny arrow-external-link"><path d="M1.12949 2.1072V1H7V6.85795H5.89111V2.90281L0.784057 8L0 7.21635L5.11902 2.1072H1.12949Z"></path></svg></a></div></div></section></div><div class="article-biography article-biography-has-image" id="b1"><div class="article-biography-image"><img src="https://ars.els-cdn.com/content/image/1-s2.0-S0925231219306137-fx1.jpg" height="150" alt=""></div><div class="article-biography-text"><div class="u-margin-s-bottom" id="sp0001"><strong>Jie Shao</strong> received the B.S. and M.S. degree in Nanjing University of Aeronauticsand Astronautics. Thenshe got her Ph.D. in Tongji University. At present, she is an associate professor in Shanghai University of Electric Power. Her currentresearch interest includes computer vision, video surveillance, and human emotion analysis.</div></div></div><div class="article-biography article-biography-has-image" id="b2"><div class="article-biography-image"><img src="https://ars.els-cdn.com/content/image/1-s2.0-S0925231219306137-fx2.jpg" height="151" alt=""></div><div class="article-biography-text"><div class="u-margin-s-bottom" id="sp0002"><strong>Yongsheng Qian</strong> received his bachelorâ€™s degree in electrical engineering and automation from Hubei University for Nationalities in 2015. He is currently a graduate student in the department of electronics and information engineering in Shanghai University of Electric Power, Shanghai, China. His research interest includes facial expression recognition and deep learning.</div></div></div><a class="anchor abstract-link anchor-primary" href="/science/article/abs/pii/S0925231219306137"><span class="anchor-text-container"><span class="anchor-text">View Abstract</span></span></a><div class="Copyright"><span class="copyright-line">Â© 2019 Elsevier B.V. All rights reserved.</span></div></article><div class="u-display-block-from-md col-lg-6 col-md-8 pad-right u-padding-s-top"><aside class="RelatedContent u-clr-grey8" aria-label="Related content"><section class="RelatedContentPanel u-margin-s-bottom"><header id="recommended-articles-header" class="related-content-panel-header u-margin-s-bottom"><button class="button-link button-link-secondary related-content-panel-toggle is-up button-link-icon-right button-link-has-colored-icon" aria-expanded="true" data-aa-button="sd:product:journal:article:location=recommended-articles:type=close" type="button"><span class="button-link-text-container"><span class="button-link-text"><h2 class="section-title u-h4"><span class="related-content-panel-title-text">Recommended articles</span></h2></span></span><svg focusable="false" viewBox="0 0 92 128" height="20" class="icon icon-navigate-down"><path d="M1 51l7-7 38 38 38-38 7 7-45 45z"></path></svg></button></header><div class="" aria-hidden="false" aria-describedby="recommended-articles-header"><div id="recommended-articles" class="text-xs"><ul><li class="RelatedContentPanelItem u-display-block"><div class="sub-heading u-padding-xs-bottom"><h3 class="related-content-panel-list-entry-outline-padding text-s u-font-serif" id="recommended-articles-article0-title"><a class="anchor u-clamp-2-lines anchor-primary" href="/science/article/pii/S104732031830364X" title="Video facial emotion recognition based on local enhanced motion history image and CNN-CTSLSTM networks"><span class="anchor-text-container"><span class="anchor-text"><span>Video facial emotion recognition based on local enhanced motion history image and CNN-CTSLSTM networks</span></span></span></a></h3><div class="article-source u-clr-grey6"><div class="source">Journal of Visual Communication and Image Representation, Volume 59, 2019, pp. 176-185</div></div><div class="authors"><span>Min</span> <span>Hu</span>, â€¦, <span>Ronggui</span> <span>Wang</span></div></div><div class="buttons"><a class="anchor anchor-primary anchor-icon-left anchor-with-icon" href="/science/article/pii/S104732031830364X/pdfft?md5=5b48aab76034073d90ecc95fabeca2d4&amp;pid=1-s2.0-S104732031830364X-main.pdf" target="_blank" rel="nofollow" aria-describedby="recommended-articles-article0-title"><svg focusable="false" viewBox="0 0 35 32" height="20" class="icon icon-pdf-multicolor"><path d="M7 .362h17.875l6.763 6.1V31.64H6.948V16z" stroke="#000" stroke-width=".703" fill="#fff"></path><path d="M.167 2.592H22.39V9.72H.166z" fill="#da0000"></path><path fill="#fff9f9" d="M5.97 3.638h1.62c1.053 0 1.483.677 1.488 1.564.008.96-.6 1.564-1.492 1.564h-.644v1.66h-.977V3.64m.977.897v1.34h.542c.27 0 .596-.068.596-.673-.002-.6-.32-.667-.596-.667h-.542m3.8.036v2.92h.35c.933 0 1.223-.448 1.228-1.462.008-1.06-.316-1.45-1.23-1.45h-.347m-.977-.94h1.03c1.68 0 2.523.586 2.534 2.39.01 1.688-.607 2.4-2.534 2.4h-1.03V3.64m4.305 0h2.63v.934h-1.657v.894H16.6V6.4h-1.56v2.026h-.97V3.638"></path><path d="M19.462 13.46c.348 4.274-6.59 16.72-8.508 15.792-1.82-.85 1.53-3.317 2.92-4.366-2.864.894-5.394 3.252-3.837 3.93 2.113.895 7.048-9.25 9.41-15.394zM14.32 24.874c4.767-1.526 14.735-2.974 15.152-1.407.824-3.157-13.72-.37-15.153 1.407zm5.28-5.043c2.31 3.237 9.816 7.498 9.788 3.82-.306 2.046-6.66-1.097-8.925-4.164-4.087-5.534-2.39-8.772-1.682-8.732.917.047 1.074 1.307.67 2.442-.173-1.406-.58-2.44-1.224-2.415-1.835.067-1.905 4.46 1.37 9.065z" fill="#f91d0a"></path></svg><span class="anchor-text-container"><span class="anchor-text">View PDF</span></span></a></div></li><li class="RelatedContentPanelItem u-display-block"><div class="sub-heading u-padding-xs-bottom"><h3 class="related-content-panel-list-entry-outline-padding text-s u-font-serif" id="recommended-articles-article1-title"><a class="anchor u-clamp-2-lines anchor-primary" href="/science/article/pii/S0923596518306556" title="Facial expression recognition with local prominent directional pattern"><span class="anchor-text-container"><span class="anchor-text"><span>Facial expression recognition with local prominent directional pattern</span></span></span></a></h3><div class="article-source u-clr-grey6"><div class="source">Signal Processing: Image Communication, Volume 74, 2019, pp. 1-12</div></div><div class="authors"><span>Farkhod</span> <span>Makhmudkhujaev</span>, â€¦, <span>Oksam</span> <span>Chae</span></div></div><div class="buttons"><a class="anchor anchor-primary anchor-icon-left anchor-with-icon" href="/science/article/pii/S0923596518306556/pdfft?md5=23b9947fd05942cc1b0046c026f5e50d&amp;pid=1-s2.0-S0923596518306556-main.pdf" target="_blank" rel="nofollow" aria-describedby="recommended-articles-article1-title"><svg focusable="false" viewBox="0 0 35 32" height="20" class="icon icon-pdf-multicolor"><path d="M7 .362h17.875l6.763 6.1V31.64H6.948V16z" stroke="#000" stroke-width=".703" fill="#fff"></path><path d="M.167 2.592H22.39V9.72H.166z" fill="#da0000"></path><path fill="#fff9f9" d="M5.97 3.638h1.62c1.053 0 1.483.677 1.488 1.564.008.96-.6 1.564-1.492 1.564h-.644v1.66h-.977V3.64m.977.897v1.34h.542c.27 0 .596-.068.596-.673-.002-.6-.32-.667-.596-.667h-.542m3.8.036v2.92h.35c.933 0 1.223-.448 1.228-1.462.008-1.06-.316-1.45-1.23-1.45h-.347m-.977-.94h1.03c1.68 0 2.523.586 2.534 2.39.01 1.688-.607 2.4-2.534 2.4h-1.03V3.64m4.305 0h2.63v.934h-1.657v.894H16.6V6.4h-1.56v2.026h-.97V3.638"></path><path d="M19.462 13.46c.348 4.274-6.59 16.72-8.508 15.792-1.82-.85 1.53-3.317 2.92-4.366-2.864.894-5.394 3.252-3.837 3.93 2.113.895 7.048-9.25 9.41-15.394zM14.32 24.874c4.767-1.526 14.735-2.974 15.152-1.407.824-3.157-13.72-.37-15.153 1.407zm5.28-5.043c2.31 3.237 9.816 7.498 9.788 3.82-.306 2.046-6.66-1.097-8.925-4.164-4.087-5.534-2.39-8.772-1.682-8.732.917.047 1.074 1.307.67 2.442-.173-1.406-.58-2.44-1.224-2.415-1.835.067-1.905 4.46 1.37 9.065z" fill="#f91d0a"></path></svg><span class="anchor-text-container"><span class="anchor-text">View PDF</span></span></a></div></li><li class="RelatedContentPanelItem u-display-block"><div class="sub-heading u-padding-xs-bottom"><h3 class="related-content-panel-list-entry-outline-padding text-s u-font-serif" id="recommended-articles-article2-title"><a class="anchor u-clamp-2-lines anchor-primary" href="/science/article/pii/S0925231221011619" title="MiniExpNet: A small and effective facial expression recognition network based on facial local regions"><span class="anchor-text-container"><span class="anchor-text"><span>MiniExpNet: A small and effective facial expression recognition network based on facial local regions</span></span></span></a></h3><div class="article-source u-clr-grey6"><div class="source">Neurocomputing, Volume 462, 2021, pp. 353-364</div></div><div class="authors"><span>Xing</span> <span>Jin</span>, <span>Zhong</span> <span>Jin</span></div></div><div class="buttons"><a class="anchor anchor-primary anchor-icon-left anchor-with-icon" href="/science/article/pii/S0925231221011619/pdfft?md5=09ba47a75557794ed9f67f1dae801822&amp;pid=1-s2.0-S0925231221011619-main.pdf" target="_blank" rel="nofollow" aria-describedby="recommended-articles-article2-title"><svg focusable="false" viewBox="0 0 35 32" height="20" class="icon icon-pdf-multicolor"><path d="M7 .362h17.875l6.763 6.1V31.64H6.948V16z" stroke="#000" stroke-width=".703" fill="#fff"></path><path d="M.167 2.592H22.39V9.72H.166z" fill="#da0000"></path><path fill="#fff9f9" d="M5.97 3.638h1.62c1.053 0 1.483.677 1.488 1.564.008.96-.6 1.564-1.492 1.564h-.644v1.66h-.977V3.64m.977.897v1.34h.542c.27 0 .596-.068.596-.673-.002-.6-.32-.667-.596-.667h-.542m3.8.036v2.92h.35c.933 0 1.223-.448 1.228-1.462.008-1.06-.316-1.45-1.23-1.45h-.347m-.977-.94h1.03c1.68 0 2.523.586 2.534 2.39.01 1.688-.607 2.4-2.534 2.4h-1.03V3.64m4.305 0h2.63v.934h-1.657v.894H16.6V6.4h-1.56v2.026h-.97V3.638"></path><path d="M19.462 13.46c.348 4.274-6.59 16.72-8.508 15.792-1.82-.85 1.53-3.317 2.92-4.366-2.864.894-5.394 3.252-3.837 3.93 2.113.895 7.048-9.25 9.41-15.394zM14.32 24.874c4.767-1.526 14.735-2.974 15.152-1.407.824-3.157-13.72-.37-15.153 1.407zm5.28-5.043c2.31 3.237 9.816 7.498 9.788 3.82-.306 2.046-6.66-1.097-8.925-4.164-4.087-5.534-2.39-8.772-1.682-8.732.917.047 1.074 1.307.67 2.442-.173-1.406-.58-2.44-1.224-2.415-1.835.067-1.905 4.46 1.37 9.065z" fill="#f91d0a"></path></svg><span class="anchor-text-container"><span class="anchor-text">View PDF</span></span></a></div></li><li class="RelatedContentPanelItem u-display-none"><div class="sub-heading u-padding-xs-bottom"><h3 class="related-content-panel-list-entry-outline-padding text-s u-font-serif" id="recommended-articles-article3-title"><a class="anchor u-clamp-2-lines anchor-primary" href="/science/article/pii/S0035378721007645" title="Anatomical and neurophysiological basis of face recognition"><span class="anchor-text-container"><span class="anchor-text"><span>Anatomical and neurophysiological basis of face recognition</span></span></span></a></h3><div class="article-source u-clr-grey6"><div class="source">Revue Neurologique, Volume 178, Issue 7, 2022, pp. 649-653</div></div><div class="authors"><span>F.</span> <span>Sellal</span></div></div><div class="buttons"><a class="anchor anchor-primary anchor-icon-left anchor-with-icon" href="/science/article/pii/S0035378721007645/pdfft?md5=68b542ddf8ae54c4c8bbc6497c84ed45&amp;pid=1-s2.0-S0035378721007645-main.pdf" target="_blank" rel="nofollow" aria-describedby="recommended-articles-article3-title"><svg focusable="false" viewBox="0 0 35 32" height="20" class="icon icon-pdf-multicolor"><path d="M7 .362h17.875l6.763 6.1V31.64H6.948V16z" stroke="#000" stroke-width=".703" fill="#fff"></path><path d="M.167 2.592H22.39V9.72H.166z" fill="#da0000"></path><path fill="#fff9f9" d="M5.97 3.638h1.62c1.053 0 1.483.677 1.488 1.564.008.96-.6 1.564-1.492 1.564h-.644v1.66h-.977V3.64m.977.897v1.34h.542c.27 0 .596-.068.596-.673-.002-.6-.32-.667-.596-.667h-.542m3.8.036v2.92h.35c.933 0 1.223-.448 1.228-1.462.008-1.06-.316-1.45-1.23-1.45h-.347m-.977-.94h1.03c1.68 0 2.523.586 2.534 2.39.01 1.688-.607 2.4-2.534 2.4h-1.03V3.64m4.305 0h2.63v.934h-1.657v.894H16.6V6.4h-1.56v2.026h-.97V3.638"></path><path d="M19.462 13.46c.348 4.274-6.59 16.72-8.508 15.792-1.82-.85 1.53-3.317 2.92-4.366-2.864.894-5.394 3.252-3.837 3.93 2.113.895 7.048-9.25 9.41-15.394zM14.32 24.874c4.767-1.526 14.735-2.974 15.152-1.407.824-3.157-13.72-.37-15.153 1.407zm5.28-5.043c2.31 3.237 9.816 7.498 9.788 3.82-.306 2.046-6.66-1.097-8.925-4.164-4.087-5.534-2.39-8.772-1.682-8.732.917.047 1.074 1.307.67 2.442-.173-1.406-.58-2.44-1.224-2.415-1.835.067-1.905 4.46 1.37 9.065z" fill="#f91d0a"></path></svg><span class="anchor-text-container"><span class="anchor-text">View PDF</span></span></a></div></li><li class="RelatedContentPanelItem u-display-none"><div class="sub-heading u-padding-xs-bottom"><h3 class="related-content-panel-list-entry-outline-padding text-s u-font-serif" id="recommended-articles-article4-title"><a class="anchor u-clamp-2-lines anchor-primary" href="/science/article/pii/S0957417419305561" title="Low resolution face recognition using a two-branch deep convolutional neural network architecture"><span class="anchor-text-container"><span class="anchor-text"><span>Low resolution face recognition using a two-branch deep convolutional neural network architecture</span></span></span></a></h3><div class="article-source u-clr-grey6"><div class="source">Expert Systems with Applications, Volume 139, 2020, Article 112854</div></div><div class="authors"><span>Erfan</span> <span>Zangeneh</span>, â€¦, <span>Yalda</span> <span>Mohsenzadeh</span></div></div><div class="buttons"><a class="anchor anchor-primary anchor-icon-left anchor-with-icon" href="/science/article/pii/S0957417419305561/pdfft?md5=7f588c86dd66d99499d9102836b80255&amp;pid=1-s2.0-S0957417419305561-main.pdf" target="_blank" rel="nofollow" aria-describedby="recommended-articles-article4-title"><svg focusable="false" viewBox="0 0 35 32" height="20" class="icon icon-pdf-multicolor"><path d="M7 .362h17.875l6.763 6.1V31.64H6.948V16z" stroke="#000" stroke-width=".703" fill="#fff"></path><path d="M.167 2.592H22.39V9.72H.166z" fill="#da0000"></path><path fill="#fff9f9" d="M5.97 3.638h1.62c1.053 0 1.483.677 1.488 1.564.008.96-.6 1.564-1.492 1.564h-.644v1.66h-.977V3.64m.977.897v1.34h.542c.27 0 .596-.068.596-.673-.002-.6-.32-.667-.596-.667h-.542m3.8.036v2.92h.35c.933 0 1.223-.448 1.228-1.462.008-1.06-.316-1.45-1.23-1.45h-.347m-.977-.94h1.03c1.68 0 2.523.586 2.534 2.39.01 1.688-.607 2.4-2.534 2.4h-1.03V3.64m4.305 0h2.63v.934h-1.657v.894H16.6V6.4h-1.56v2.026h-.97V3.638"></path><path d="M19.462 13.46c.348 4.274-6.59 16.72-8.508 15.792-1.82-.85 1.53-3.317 2.92-4.366-2.864.894-5.394 3.252-3.837 3.93 2.113.895 7.048-9.25 9.41-15.394zM14.32 24.874c4.767-1.526 14.735-2.974 15.152-1.407.824-3.157-13.72-.37-15.153 1.407zm5.28-5.043c2.31 3.237 9.816 7.498 9.788 3.82-.306 2.046-6.66-1.097-8.925-4.164-4.087-5.534-2.39-8.772-1.682-8.732.917.047 1.074 1.307.67 2.442-.173-1.406-.58-2.44-1.224-2.415-1.835.067-1.905 4.46 1.37 9.065z" fill="#f91d0a"></path></svg><span class="anchor-text-container"><span class="anchor-text">View PDF</span></span></a></div></li><li class="RelatedContentPanelItem u-display-none"><div class="sub-heading u-padding-xs-bottom"><h3 class="related-content-panel-list-entry-outline-padding text-s u-font-serif" id="recommended-articles-article5-title"><a class="anchor u-clamp-2-lines anchor-primary" href="/science/article/pii/S0028393215302268" title="Facial identity and facial expression are initially integrated at visual perceptual stages of face processing"><span class="anchor-text-container"><span class="anchor-text"><span>Facial identity and facial expression are initially integrated at visual perceptual stages of face processing</span></span></span></a></h3><div class="article-source u-clr-grey6"><div class="source">Neuropsychologia, Volume 80, 2016, pp. 115-125</div></div><div class="authors"><span>Katie</span> <span>Fisher</span>, â€¦, <span>Martin</span> <span>Eimer</span></div></div><div class="buttons"><a class="anchor anchor-primary anchor-icon-left anchor-with-icon" href="/science/article/pii/S0028393215302268/pdfft?md5=aa94614752c60525d50892f493d73e94&amp;pid=1-s2.0-S0028393215302268-main.pdf" target="_blank" rel="nofollow" aria-describedby="recommended-articles-article5-title"><svg focusable="false" viewBox="0 0 35 32" height="20" class="icon icon-pdf-multicolor"><path d="M7 .362h17.875l6.763 6.1V31.64H6.948V16z" stroke="#000" stroke-width=".703" fill="#fff"></path><path d="M.167 2.592H22.39V9.72H.166z" fill="#da0000"></path><path fill="#fff9f9" d="M5.97 3.638h1.62c1.053 0 1.483.677 1.488 1.564.008.96-.6 1.564-1.492 1.564h-.644v1.66h-.977V3.64m.977.897v1.34h.542c.27 0 .596-.068.596-.673-.002-.6-.32-.667-.596-.667h-.542m3.8.036v2.92h.35c.933 0 1.223-.448 1.228-1.462.008-1.06-.316-1.45-1.23-1.45h-.347m-.977-.94h1.03c1.68 0 2.523.586 2.534 2.39.01 1.688-.607 2.4-2.534 2.4h-1.03V3.64m4.305 0h2.63v.934h-1.657v.894H16.6V6.4h-1.56v2.026h-.97V3.638"></path><path d="M19.462 13.46c.348 4.274-6.59 16.72-8.508 15.792-1.82-.85 1.53-3.317 2.92-4.366-2.864.894-5.394 3.252-3.837 3.93 2.113.895 7.048-9.25 9.41-15.394zM14.32 24.874c4.767-1.526 14.735-2.974 15.152-1.407.824-3.157-13.72-.37-15.153 1.407zm5.28-5.043c2.31 3.237 9.816 7.498 9.788 3.82-.306 2.046-6.66-1.097-8.925-4.164-4.087-5.534-2.39-8.772-1.682-8.732.917.047 1.074 1.307.67 2.442-.173-1.406-.58-2.44-1.224-2.415-1.835.067-1.905 4.46 1.37 9.065z" fill="#f91d0a"></path></svg><span class="anchor-text-container"><span class="anchor-text">View PDF</span></span></a></div></li></ul></div><button class="button-link more-recommendations-button u-margin-s-bottom button-link-primary button-link-icon-right" type="button"><span class="button-link-text-container"><span class="button-link-text">Show 3 more articles</span></span><svg focusable="false" viewBox="0 0 92 128" height="20" class="icon icon-navigate-down"><path d="M1 51l7-7 38 38 38-38 7 7-45 45z"></path></svg></button></div></section><section class="RelatedContentPanel u-margin-s-bottom"><header id="metrics-header" class="related-content-panel-header u-margin-s-bottom"><button class="button-link button-link-secondary related-content-panel-toggle is-up button-link-icon-right button-link-has-colored-icon" aria-expanded="true" type="button"><span class="button-link-text-container"><span class="button-link-text"><h2 class="section-title u-h4"><span class="related-content-panel-title-text">Article Metrics</span></h2></span></span><svg focusable="false" viewBox="0 0 92 128" height="20" class="icon icon-navigate-down"><path d="M1 51l7-7 38 38 38-38 7 7-45 45z"></path></svg></button></header><div class="" aria-hidden="false" aria-describedby="metrics-header"><div class="plum-sciencedirect-theme"><div class="PlumX-Summary"><div class="pps-container pps-container-vertical plx-no-print"><div class="pps-branding pps-branding-top"><img alt="plumX logo" src="//cdn.plu.mx/3ba727faf225e19d2c759f6ebffc511d/plumx-inverse-logo.png" class="plx-logo"></div><div class="pps-cols"><div class="pps-col plx-citation"><div class="plx-citation"><div class="pps-title">Citations</div><ul><li class="plx-citation"><span class="pps-label">Citation Indexes: </span><span class="pps-count">148</span></li></ul></div></div><div class="pps-col plx-capture"><div class="plx-capture"><div class="pps-title">Captures</div><ul><li class="plx-capture"><span class="pps-label">Readers: </span><span class="pps-count">137</span></li></ul></div></div><div class="pps-col plx-mention"><div class="plx-mention"><div class="pps-title">Mentions</div><ul><li class="plx-mention"><span class="pps-label">News Mentions: </span><span class="pps-count">1</span></li></ul></div></div></div><div><div class="pps-branding pps-branding-bottom"><img alt="plumX logo" src="//cdn.plu.mx/3ba727faf225e19d2c759f6ebffc511d/plumx-logo.png" class="plx-logo"></div><a target="_blank" href="https://plu.mx/plum/a/?doi=10.1016/j.neucom.2019.05.005&amp;theme=plum-sciencedirect-theme&amp;hideUsage=true" class="pps-seemore" title="PlumX Metrics Detail Page">View details<svg fill="currentColor" tabindex="-1" focusable="false" width="16" height="16" viewBox="0 0 16 16" class="svg-arrow"><path d="M16 4.452l-1.26-1.26L8 9.932l-6.74-6.74L0 4.452l8 8 8-8z"></path></svg></a></div></div></div></div></div></section></aside></div></div></div></div><footer role="contentinfo" class="els-footer u-bg-white text-xs u-padding-s-hor u-padding-m-hor-from-sm u-padding-l-hor-from-md u-padding-l-ver u-margin-l-top u-margin-xl-top-from-sm u-margin-l-top-from-md"><div class="els-footer-elsevier u-margin-m-bottom u-margin-0-bottom-from-md u-margin-s-right u-margin-m-right-from-md u-margin-l-right-from-lg"><a class="anchor anchor-primary anchor-icon-left anchor-with-icon" href="https://www.elsevier.com/" target="_blank" aria-label="Elsevier home page (opens in a new tab)" rel="nofollow"><img class="footer-logo" src="https://sdfestaticassets-eu-west-1.sciencedirectassets.com/shared-assets/47/images/elsevier-non-solus-new-with-wordmark.svg" alt="Elsevier logo with wordmark" height="64" width="58" loading="lazy"></a></div><div class="els-footer-content"><div class="u-remove-if-print"><ul class="els-footer-links u-margin-xs-bottom" style="list-style:none"><li><a class="anchor u-display-flex u-clr-grey8 u-margin-s-bottom u-margin-0-bottom-from-sm u-margin-m-right-from-sm u-margin-l-right-from-md anchor-primary anchor-small" href="https://www.elsevier.com/solutions/sciencedirect" target="_blank" id="els-footer-about-science-direct" rel="nofollow"><span class="anchor-text-container"><span class="anchor-text">About ScienceDirect</span><svg focusable="false" viewBox="0 0 8 8" height="20" aria-label="Opens in new window" class="icon icon-arrow-up-right-tiny arrow-external-link"><path d="M1.12949 2.1072V1H7V6.85795H5.89111V2.90281L0.784057 8L0 7.21635L5.11902 2.1072H1.12949Z"></path></svg></span></a></li><li><a class="anchor u-display-flex u-clr-grey8 u-margin-s-bottom u-margin-0-bottom-from-sm u-margin-m-right-from-sm u-margin-l-right-from-md anchor-primary anchor-small" href="/user/institution/login?targetURL=%2Fscience%2Farticle%2Fpii%2FS0925231219306137" id="els-footer-remote-access" rel="nofollow"><span class="anchor-text-container"><span class="anchor-text">Remote access</span></span></a></li><li><a class="anchor u-display-flex u-clr-grey8 u-margin-s-bottom u-margin-0-bottom-from-sm u-margin-m-right-from-sm u-margin-l-right-from-md anchor-primary anchor-small" href="https://sd-cart.elsevier.com/?" target="_blank" id="els-footer-shopping-cart" rel="nofollow"><span class="anchor-text-container"><span class="anchor-text">Shopping cart</span><svg focusable="false" viewBox="0 0 8 8" height="20" aria-label="Opens in new window" class="icon icon-arrow-up-right-tiny arrow-external-link"><path d="M1.12949 2.1072V1H7V6.85795H5.89111V2.90281L0.784057 8L0 7.21635L5.11902 2.1072H1.12949Z"></path></svg></span></a></li><li><a class="anchor u-display-flex u-clr-grey8 u-margin-s-bottom u-margin-0-bottom-from-sm u-margin-m-right-from-sm u-margin-l-right-from-md anchor-primary anchor-small" href="https://www.elsmediakits.com" target="_blank" id="els-footer-advertise" rel="nofollow"><span class="anchor-text-container"><span class="anchor-text">Advertise</span><svg focusable="false" viewBox="0 0 8 8" height="20" aria-label="Opens in new window" class="icon icon-arrow-up-right-tiny arrow-external-link"><path d="M1.12949 2.1072V1H7V6.85795H5.89111V2.90281L0.784057 8L0 7.21635L5.11902 2.1072H1.12949Z"></path></svg></span></a></li><li><a class="anchor u-display-flex u-clr-grey8 u-margin-s-bottom u-margin-0-bottom-from-sm u-margin-m-right-from-sm u-margin-l-right-from-md anchor-primary anchor-small" href="https://service.elsevier.com/ci/pta/login/redirect/contact/supporthub/sciencedirect/p_li/xyhJEXWoHAMsz8VQOu3h2LHHIekBL3hT38urfpOCxeAty3TF61ibE7vsQPaZh4C6srqm9MNOxus2v65ykDkikA4MoWWax9xsxmy7qS6Jhq1MDk8fC~ZGE1crT~IU0fB88KgH29YS658ka3vhWTqW3QsF38M7JrWC3EPvnlMgTGg39gl1xRqh4DNloSU9hGNUBWmK_Teu~5LuRZ6Al86jUzFxO7CiLa3WIvaVAP5f3g900Gfh5TZfq33GuKqA9hfimBRbW0fFzY3a21RwOu4PLn_qOj_4DdmDZC5TLAXDZVY*" target="_blank" id="els-footer-contact-support" rel="nofollow"><span class="anchor-text-container"><span class="anchor-text">Contact and support</span><svg focusable="false" viewBox="0 0 8 8" height="20" aria-label="Opens in new window" class="icon icon-arrow-up-right-tiny arrow-external-link"><path d="M1.12949 2.1072V1H7V6.85795H5.89111V2.90281L0.784057 8L0 7.21635L5.11902 2.1072H1.12949Z"></path></svg></span></a></li><li><a class="anchor u-display-flex u-clr-grey8 u-margin-s-bottom u-margin-0-bottom-from-sm u-margin-m-right-from-sm u-margin-l-right-from-md anchor-primary anchor-small" href="https://www.elsevier.com/legal/elsevier-website-terms-and-conditions" target="_blank" id="els-footer-terms-condition" rel="nofollow"><span class="anchor-text-container"><span class="anchor-text">Terms and conditions</span><svg focusable="false" viewBox="0 0 8 8" height="20" aria-label="Opens in new window" class="icon icon-arrow-up-right-tiny arrow-external-link"><path d="M1.12949 2.1072V1H7V6.85795H5.89111V2.90281L0.784057 8L0 7.21635L5.11902 2.1072H1.12949Z"></path></svg></span></a></li><li><a class="anchor u-display-flex u-clr-grey8 u-margin-s-bottom u-margin-0-bottom-from-sm u-margin-m-right-from-sm u-margin-l-right-from-md anchor-primary anchor-small" href="https://www.elsevier.com/legal/privacy-policy" target="_blank" id="els-footer-privacy-policy" rel="nofollow"><span class="anchor-text-container"><span class="anchor-text">Privacy policy</span><svg focusable="false" viewBox="0 0 8 8" height="20" aria-label="Opens in new window" class="icon icon-arrow-up-right-tiny arrow-external-link"><path d="M1.12949 2.1072V1H7V6.85795H5.89111V2.90281L0.784057 8L0 7.21635L5.11902 2.1072H1.12949Z"></path></svg></span></a></li></ul></div><p id="els-footer-cookie-message" class="u-remove-if-print">Cookies are used by this site. <!-- --> <button class="button-link ot-sdk-show-settings cookie-btn button-link-primary button-link-small" id="ot-sdk-btn" type="button">Cookie Settings</button></p><p id="els-footer-copyright">All content on this site: Copyright Â© <!-- -->2024<!-- --> Elsevier B.V., its licensors, and contributors. All rights are reserved, including those for text and data mining, AI training, and similar technologies. For all open access content, the Creative Commons licensing terms apply.</p></div><div class="els-footer-relx u-margin-0-top u-margin-m-top-from-xs u-margin-0-top-from-md"><a class="anchor anchor-primary anchor-icon-left anchor-with-icon" href="https://www.relx.com/" target="_blank" aria-label="RELX home page (opens in a new tab)" id="els-footer-relx" rel="nofollow"><img loading="lazy" src="https://sdfestaticassets-eu-west-1.sciencedirectassets.com/shared-assets/60/images/logo-relx-tm.svg" width="93" height="20" alt="RELX group home page"></a></div></footer></div></div></div></div>
      <div id="floating-ui-node" class="floating-ui-node" data-sd-ui-floating-ui="true"></div>
      
      <script async="" src="https://assets.adobedtm.com/4a848ae9611a/032db4f73473/launch-a6263b31083f.min.js" type="text/javascript"></script>
      
<script type="text/javascript">
    window.pageData = {"content":[{"contentType":"JL","format":"MIME-XHTML","id":"sd:article:pii:S0925231219306137","type":"sd:article:JL:scope-full","detail":"sd:article:subtype:fla","publicationType":"journal","issn":"0925-2312","volumeNumber":"355","suppl":"C","provider":"elsevier","entitlementType":"package"}],"page":{"businessUnit":"ELS:RP:ST","language":"en","name":"product:journal:article","noTracking":"false","productAppVersion":"full-direct","productName":"SD","type":"CP-CA","environment":"prod","loadTimestamp":1730203939981,"loadTime":""},"visitor":{"accessType":"ae:REG_SHIBBOLETH","accountId":"ae:50401","accountName":"ae:IT University of Copenhagen","loginStatus":"logged in","userId":"ae:71970787","ipAddress":"130.225.244.206","appSessionId":"d803021f-cf0c-4303-a9ac-edd1111de6ef"}};
    window.pageData.page.loadTime = performance ? Math.round(performance.now()).toString() : '';

    try {
      appData.push({
      event: 'pageLoad',
      page: pageData.page,
      visitor: pageData.visitor,
      content: pageData.content
      })
    } catch(e) {
        console.warn("There was an error loading or running Adobe DTM: ", e);
    }
</script>
      <script nomodule="" src="https://sdfestaticassets-eu-west-1.sciencedirectassets.com/shared-assets/73/js/core-js/3.20.2/core-js.es.minified.js" type="text/javascript"></script>
      <script src="https://sdfestaticassets-eu-west-1.sciencedirectassets.com/shared-assets/108/js/react/18.3.1/react.production.min.js" type="text/javascript"></script>
      <script src="https://sdfestaticassets-eu-west-1.sciencedirectassets.com/shared-assets/108/js/react-dom/18.3.1/react-dom.production.min.js" type="text/javascript"></script>
      <script async="" src="https://sdfestaticassets-eu-west-1.sciencedirectassets.com/prod/562c52f0a29e84041e12a6c3286c1d8a5b89ba0b/arp.js" type="text/javascript"></script>
      <script type="text/javascript">
    const pendoData = {"visitor":{"pageName":"SD:product:journal:article","pageType":"CP-CA","pageProduct":"SD","pageLanguage":"en","pageEnvironment":"prod","accessType":"ae:REG_SHIBBOLETH","countryCode":"DK"},"account":{"id":"ae:50401","name":"ae:IT University of Copenhagen"},"events":{}};;
    pendoData.events = {
      ready: function () {
        pendo.addAltText();
      },
    };
    function runPendo(data, options) {
  const {
    firstDelay,
    maxRetries,
    urlPrefix,
    urlSuffix,
    apiKey
  } = options;
  (function (apiKey) {
    (function (p, e, n, d, o) {
      var v, w, x, y, z;
      o = p[d] = p[d] || {};
      o._q = [];
      v = ['initialize', 'identify', 'updateOptions', 'pageLoad'];
      for (w = 0, x = v.length; w < x; ++w) (function (m) {
        o[m] = o[m] || function () {
          o._q[m === v[0] ? 'unshift' : 'push']([m].concat([].slice.call(arguments, 0)));
        };
      })(v[w]);
      y = e.createElement(n);
      y.async = !0;
      y.src = urlPrefix + apiKey + urlSuffix;
      z = e.getElementsByTagName(n)[0];
      z.parentNode.insertBefore(y, z);
    })(window, document, 'script', 'pendo');
    pendo.addAltText = function () {
      var target = document.querySelector('body');
      var observer = new MutationObserver(function (mutations) {
        mutations.forEach(function (mutation) {
          if (mutation?.addedNodes?.length) {
            if (mutation.addedNodes[0]?.className?.includes("_pendo-badge")) {
              const badge = mutation.addedNodes[0];
              const altText = badge?.attributes['aria-label'].value ? badge?.attributes['aria-label'].value : 'Feedback';
              const pendoBadgeImage = pendo.dom(`#${badge?.attributes?.id.value} img`);
              if (pendoBadgeImage.length) {
                pendoBadgeImage[0]?.setAttribute('alt', altText);
              }
            }
          }
        });
      });
      var config = {
        attributeFilter: ['data-layout'],
        attributes: true,
        childList: true,
        characterData: true,
        subtree: false
      };
      observer.observe(target, config);
    };
  })(apiKey);
  (function watchAndSetPendo(nextDelay, retryAttempt) {
    if (typeof pageDataTracker === 'object' && typeof pageDataTracker.getVisitorId === 'function' && pageDataTracker.getVisitorId()) {
      data.visitor.id = pageDataTracker.getVisitorId();
      console.debug(`initializing pendo`);
      pendo.initialize(data);
    } else {
      if (retryAttempt > 0) {
        return setTimeout(function () {
          watchAndSetPendo(nextDelay * 2, retryAttempt - 1);
        }, nextDelay);
      }
      pendo.initialize(data);
      console.debug(`gave up ... pendo initialized`);
    }
  })(firstDelay, maxRetries);
}
    runPendo(pendoData, {
      firstDelay: 100,
      maxRetries: 5,
      urlPrefix: 'https://cdn.pendo.io/agent/static/',
      urlSuffix: '/pendo.js',
      apiKey: 'd6c1d995-bc7e-4e53-77f1-2ea4ecbb9565',
    });
  </script>
      <span id="pendo-answer-rating"></span>
      <script type="text/x-mathjax-config;executed=true">
        MathJax.Hub.Config({
          displayAlign: 'left',
          "fast-preview": {
            disabled: true
          },
          CommonHTML: { linebreaks: { automatic: true } },
          PreviewHTML: { linebreaks: { automatic: true } },
          'HTML-CSS': { linebreaks: { automatic: true } },
          SVG: {
            scale: 90,
            linebreaks: { automatic: true }
          }
        });
      </script>
      <script async="" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=MML_SVG" type="text/javascript"></script>
      <script async="" src="https://www.googletagservices.com/tag/js/gpt.js" type="text/javascript"></script>
      <script async="" src="https://scholar.google.com/scholar_js/casa.js" type="text/javascript"></script>
      <script data-cfasync="false">
      (function initOneTrust()  {
        const monitor = {
  init: () => {},
  loaded: () => {},
};
        function enableGroup(group) {
  document.querySelectorAll(`script[type*="ot-${group}"]`).forEach(script => {
    script.type = 'text/javascript';
    document.head.appendChild(script);
  });
}
        function runOneTrustCookies(doClear, monitor) {
  const oneTrustConsentSdkId = 'onetrust-consent-sdk';
  const emptyNodeSelectors = 'h3.ot-host-name, h4.ot-host-desc, button.ot-host-box';
  const ariaLabelledByButtonNodes = 'div.ot-accordion-layout > button';
  const ariaAttribute = 'aria-labelledby';
  function adjustOneTrustDOM() {
    const oneTrustRoot = document.getElementById('onetrust-consent-sdk');

    /* remove empty nodes */
    [...(oneTrustRoot?.querySelectorAll(emptyNodeSelectors) ?? [])].filter(e => e.textContent === '').forEach(e => e.remove());

    /* remove invalid aria-labelledby values */
    oneTrustRoot?.querySelectorAll(ariaLabelledByButtonNodes).forEach(e => {
      const presentIdValue = e.getAttribute(ariaAttribute)?.split(' ').filter(label => document.getElementById(label)).join(' ');
      if (presentIdValue) {
        e.setAttribute(ariaAttribute, presentIdValue);
      }
    });
  }
  function observeOneTrustLoaded(shouldSetOTDefaults, isConsentPresent) {
    const cb = (mutationList, observer) => {
      const oneTrustRoot = mutationList.filter(mutationRecord => mutationRecord.type === 'childList' && mutationRecord.addedNodes.length).map(mutationRecord => [...mutationRecord.addedNodes]).flat().find(e => e.id === oneTrustConsentSdkId);
      if (oneTrustRoot && typeof OneTrust !== 'undefined') {
        monitor.loaded(true);
        OneTrust.OnConsentChanged(() => {
          const perfAllowed = decodeURIComponent(document.cookie.match('(^| )OptanonConsent=([^;]+)')?.[2])?.match('groups=([0-9:0|1,?]+)&?')?.[1]?.match('2:([0|1])')[1] === '1';
          if (perfAllowed) {
            enableGroup('performance');
          }
        });
        if (!isConsentPresent && (shouldSetOTDefaults || OneTrust.GetDomainData().ConsentModel.Name === 'implied consent')) {
          OneTrust.AllowAll();
        }
        document.dispatchEvent(new CustomEvent('@sdtech/onetrust/loaded', {}));
        observer.disconnect();
        adjustOneTrustDOM();
      }
    };
    const observer = new MutationObserver(cb);
    observer.observe(document.querySelector('body'), {
      childList: true
    });
  }
  if (doClear) {
    document.cookie = 'OptanonAlertBoxClosed=; expires=Thu, 01 Jan 1970 00:00:00 UTC; samesite=lax; path=/';
  }
  const isConsentPresent = !!decodeURIComponent(document.cookie.match('(^| )OptanonConsent=([^;]+)')?.[2])?.match('groups=([0-9:0|1,?]+)&?')?.[1];
  const shouldSetOTDefaults = 'false' === 'false' && !document.cookie?.match('OptanonAlertBoxClosed=');
  if (shouldSetOTDefaults) {
    const date = new Date();
    date.setFullYear(date.getFullYear() + 1);
    document.cookie = `OptanonAlertBoxClosed=${new Date().toISOString()}; expires=${date.toUTCString()}; samesite=lax; path=/; domain=sciencedirect.com`;
  }
  observeOneTrustLoaded(shouldSetOTDefaults, isConsentPresent, monitor);
  window.addOTScript = () => {
    const otSDK = document.createElement('script');
    otSDK.setAttribute('data-cfasync', 'false');
    otSDK.setAttribute('src', 'https://cdn.cookielaw.org/scripttemplates/otSDKStub.js');
    otSDK.setAttribute('data-document-language', 'true');
    otSDK.setAttribute('data-domain-script', '865ea198-88cc-4e41-8952-1df75d554d02');
    window.addOTScript = () => {};
    document.head.appendChild(otSDK);
    monitor.init();
  };
  window.addEventListener('load', () => window.addOTScript());
}
        if (document.location.host.match(/.sciencedirect.com$/)) {
          runOneTrustCookies(true, monitor);
        }
        else {
          window.addEventListener('load', (event) => {
            enableGroup('performance');
          });
        }
      }());
    </script>
    
  <script>
var pageDataTracker = {
    eventCookieName: 'eventTrack',
    debugCookie: 'els-aa-debugmode',
    debugCounter: 1,
    warnings: [],
    measures: {},
    timeoffset: 0

    ,trackPageLoad: function(data) {
        if (window.pageData && ((pageData.page && pageData.page.noTracking == 'true') || window.pageData_isLoaded)) {
            return false;
        }

        this.updatePageData(data);

        this.initWarnings();
        if(!(window.pageData && pageData.page && pageData.page.name)) {
            console.error('pageDataTracker.trackPageLoad() called without pageData.page.name being defined!');
            return;
        }

        this.processIdPlusData(window.pageData);

        if(window.pageData && pageData.page && !pageData.page.loadTime) {
          pageData.page.loadTime = performance ? Math.round((performance.now())).toString() : '';
        }

        if(window.pageData && pageData.page) {
            var localTime = new Date().getTime();
            if(pageData.page.loadTimestamp) {
                // calculate timeoffset
                var serverTime = parseInt(pageData.page.loadTimestamp);
                if(!isNaN(serverTime)) {
                    this.timeoffset = pageData.page.loadTimestamp - localTime;
                }
            } else {
                pageData.page.loadTimestamp = localTime;
            }
        }

        this.validateData(window.pageData);

        try {
            var cookieTest = 'aa-cookie-test';
            this.setCookie(cookieTest, cookieTest);
            if(this.getCookie(cookieTest) != cookieTest) {
                this.warnings.push('dtm5');
            }
            this.deleteCookie(cookieTest);
        } catch(e){
            this.warnings.push('dtm5');
        }

        this.registerCallbacks();
        this.setAnalyticsData();

        // handle any cookied event data
        this.getEvents();

        window.pageData_isLoaded = true;

        this.debugMessage('Init - trackPageLoad()', window.pageData);

        _satellite.track('eventDispatcher', JSON.stringify({
          eventName: 'newPage',
          eventData: {eventName: 'newPage'},
          pageData: window.pageData
        }));
    }

    ,trackEvent: function(event, data, callback) {
        if (window.pageData && pageData.page && pageData.page.noTracking == 'true') {
            return false;
        }
        
        if(!window.pageData_isLoaded) {
            if(this.isDebugEnabled()) {
                console.log('[AA] pageDataTracker.trackEvent() called without calling trackPageLoad() first.');
            }
            return false;
        }

        if (event) {
            this.initWarnings();
            if(event === 'newPage') {
                // auto fillings
                if(data && data.page && !data.page.loadTimestamp) {
                    data.page.loadTimestamp = ''+(new Date().getTime() + this.timeoffset);
                }
                this.processIdPlusData(data);
            }

            window.eventData = data ? data : {};
            window.eventData.eventName = event;
            if(!_satellite.getVar('blacklisted')) {
                this.handleEventData(event, data);
    
                if(event === 'newPage') {
                    this.validateData(window.pageData);
                }
                this.debugMessage('Event: ' + event, data);
    
                _satellite.track('eventDispatcher', JSON.stringify({
                  eventName: event,
                  eventData: window.eventData,
                  pageData: window.pageData
                }));
            } else {
                this.debugMessage('!! Blocked Event: ' + event, data);
            }
        }

        if (typeof(callback) == 'function') {
            callback.call();
        }
    }

    ,processIdPlusData: function(data) {
        if(data && data.visitor && data.visitor.idPlusData) {
            var idPlusFields = ['userId', 'accessType', 'accountId', 'accountName'];
            for(var i=0; i < idPlusFields.length; i++) {
                if(typeof data.visitor.idPlusData[idPlusFields[i]] !== 'undefined') {
                    data.visitor[idPlusFields[i]] = data.visitor.idPlusData[idPlusFields[i]];
                }
            }
            data.visitor.idPlusData = undefined;
        }
    }

    ,validateData: function(data) {
        if(!data) {
            this.warnings.push('dv0');
            return;
        }

        // top 5
        if(!(data.visitor && data.visitor.accessType)) {
            this.warnings.push('dv1');
        }
        if(data.visitor && (data.visitor.accountId || data.visitor.accountName)) {
            if(!data.visitor.accountName) {
                this.warnings.push('dv2');
            }
            if(!data.visitor.accountId) {
                this.warnings.push('dv3');
            }
        }
        if(!(data.page && data.page.productName)) {
            this.warnings.push('dv4');
        }
        if(!(data.page && data.page.businessUnit)) {
            this.warnings.push('dv5');
        }
        if(!(data.page && data.page.name)) {
            this.warnings.push('dv6');
        }

        // rp mandatory
        if(data.page && data.page.businessUnit && (data.page.businessUnit.toLowerCase().indexOf('els:rp:') !== -1 || data.page.businessUnit.toLowerCase().indexOf('els:rap:') !== -1)) {
            if(!(data.page && data.page.loadTimestamp)) {
                this.warnings.push('dv7');
            }
            if(!(data.page && data.page.loadTime)) {
                this.warnings.push('dv8');
            }
            if(!(data.visitor && data.visitor.ipAddress)) {
                this.warnings.push('dv9');
            }
            if(!(data.page && data.page.type)) {
                this.warnings.push('dv10');
            }
            if(!(data.page && data.page.language)) {
                this.warnings.push('dv11');
            }
        }

        // other
        if(data.page && data.page.environment) {
            var env = data.page.environment.toLowerCase();
            if(!(env === 'dev' || env === 'cert' || env === 'prod')) {
                this.warnings.push('dv12');
            }
        }
        if(data.content && data.content.constructor !== Array) {
            this.warnings.push('dv13');
        }

        if(data.visitor && data.visitor.accountId && data.visitor.accountId.indexOf(':') == -1) {
            this.warnings.push('dv14');
            data.visitor.accountId = "data violation"
        }
    }

    ,initWarnings: function() {
        this.warnings = [];
        try {
            var hdn = document.head.childNodes;
            var libf = false;
            for(var i=0; i<hdn.length; i++) {
                if(hdn[i].src && (hdn[i].src.indexOf('satelliteLib') !== -1 || hdn[i].src.indexOf('launch') !== -1)) {
                    libf = true;
                    break;
                }
            }
            if(!libf) {
                this.warnings.push('dtm1');
            }
        } catch(e) {}

        try {
            for (let element of document.querySelectorAll('*')) {
                // Check if the element has a src attribute and if it meets the criteria
                if (element.src && element.src.includes('assets.adobedtm.com') && element.src.includes('launch')) {
                    if (element.tagName.toLowerCase() !== 'script') {
                        this.warnings.push('dtm5');
                    }
                    if (!element.hasAttribute('async')) {
                        this.warnings.push('dtm4');
                    }
                }
            }
        } catch (e) { }
    }

    ,getMessages: function() {
        return ['v1'].concat(this.warnings).join('|');
    }
    ,addMessage: function(message) {
        this.warnings.push(message);
    }

    ,getPerformance: function() {
        var copy = {};
        for (var attr in this.measures) {
            if(this.measures.hasOwnProperty(attr)) {
                copy[attr] = this.measures[attr];
            }
        }

        this.measures = {};
        return copy;
    }

    ,dtmCodeDesc: {
        dtm1: 'satellite-lib must be placed in the <head> section',
        dtm2: 'trackPageLoad() must be placed and called before the closing </body> tag',
        dtm3: 'trackEvent() must be called at a stage where Document.readyState=complete (e.g. on the load event or a user event)',
        dtm4: 'Embed codes need to be loaded in async mode',
        dtm5: 'Embed codes not in type script',
        dv1: 'visitor.accessType not set but mandatory',
        dv2: 'visitor.accountName not set but mandatory',
        dv3: 'visitor.accountId not set but mandatory',
        dv4: 'page.productName not set but mandatory',
        dv5: 'page.businessUnit not set but mandatory',
        dv6: 'page.name not set but mandatory',
        dv7: 'page.loadTimestamp not set but mandatory',
        dv8: 'page.loadTime not set but mandatory',
        dv9: 'visitor.ipAddress not set but mandatory',
        dv10: 'page.type not set but mandatory',
        dv11: 'page.language not set but mandatory',
        dv12: 'page.environment must be set to \'prod\', \'cert\' or \'dev\'',
        dv13: 'content must be of type array of objects',
        dv14: 'account number must contain at least one \':\', e.g. \'ae:12345\''
    }

    ,debugMessage: function(event, data) {
        if(this.isDebugEnabled()) {
            console.log('[AA] --------- [' + (this.debugCounter++) + '] Web Analytics Data ---------');
            console.log('[AA] ' + event);
            console.groupCollapsed("[AA] AA Data: ");
            if(window.eventData) {
                console.log("[AA] eventData:\n" + JSON.stringify(window.eventData, true, 2));
            }
            if(window.pageData) {
                console.log("[AA] pageData:\n" + JSON.stringify(window.pageData, true, 2));
            }
            console.groupEnd();
            if(this.warnings.length > 0) {
                console.groupCollapsed("[AA] Warnings ("+this.warnings.length+"): ");
                for(var i=0; i<this.warnings.length; i++) {
                    var error = this.dtmCodeDesc[this.warnings[i]] ? this.dtmCodeDesc[this.warnings[i]] : 'Error Code: ' + this.warnings[i];
                    console.log('[AA] ' + error);
                }
                console.log('[AA] More can be found here: https://confluence.cbsels.com/display/AA/AA+Error+Catalog');
                console.groupEnd();
            }
            console.log("This mode can be disabled by calling 'pageDataTracker.disableDebug()'");
        }
    }

    ,getTrackingCode: function() {
      var campaign = _satellite.getVar('Campaign - ID');
      if(!campaign) {
        campaign = window.sessionStorage ? sessionStorage.getItem('dgcid') : '';
      }
      return campaign;
    }

    ,isDebugEnabled: function() {
        if(typeof this.debug === 'undefined') {
            this.debug = (document.cookie.indexOf(this.debugCookie) !== -1) || (window.pageData && pageData.page && pageData.page.environment && pageData.page.environment.toLowerCase() === 'dev');
            //this.debug = (document.cookie.indexOf(this.debugCookie) !== -1);
        }
        return this.debug;
    }

    ,enableDebug: function(expire) {
        if (typeof expire === 'undefined') {
            expire = 86400;
        }
        console.log('You just enabled debug mode for Adobe Analytics tracking. This mode will persist for 24h.');
        console.log("This mode can be disabled by calling 'pageDataTracker.disableDebug()'");
        this.setCookie(this.debugCookie, 'true', expire, document.location.hostname);
        this.debug = true;
    }

    ,disableDebug: function() {
        console.log('Debug mode is now disabled.');
        this.deleteCookie(this.debugCookie);
        this.debug = false;
    }

    ,setAnalyticsData: function() {
        if(!(window.pageData && pageData.page && pageData.page.productName && pageData.page.name)) {
            return;
        }
        pageData.page.analyticsPagename = pageData.page.productName + ':' + pageData.page.name;

        var pageEls = pageData.page.name.indexOf(':') > -1 ? pageData.page.name.split(':') : [pageData.page.name];
        pageData.page.sectionName = pageData.page.productName + ':' + pageEls[0];
    }

    ,getEvents: function() {
        pageData.savedEvents = {};
        pageData.eventList = [];

        var val = this.getCookie(this.eventCookieName);
        if (val) {
            pageData.savedEvents = val;
        }

        this.deleteCookie(this.eventCookieName);
    }

    ,updatePageData(data) {
        window.pageData = window.pageData || {};
        if (data && typeof(data) === 'object') {
            for (var x in data) {
                if(data.hasOwnProperty(x) && data[x] instanceof Array) {
                    pageData[x] = data[x];
                } else if(data.hasOwnProperty(x) && typeof(data[x]) === 'object') {
                    if(!pageData[x]) {
                        pageData[x] = {};
                    }
                    for (var y in data[x]) {
                        if(data[x].hasOwnProperty(y)) {
                            pageData[x][y] = data[x][y];
                        }
                    }
                }
            }
        }
    }

    ,handleEventData: function(event, data) {
        var val;
        switch(event) {
            case 'newPage':
                this.updatePageData(data);
                this.setAnalyticsData();
            case 'saveSearch':
            case 'searchResultsUpdated':
                if (data) {
                    // overwrite page-load object
                    if (data.search && typeof(data.search) == 'object') {
                        window.eventData.search.resultsPosition = '';
                        pageData.search = pageData.search || {};
                        var fields = ['advancedCriteria', 'criteria', 'currentPage', 'dataFormCriteria', 'facets', 'resultsByType', 'resultsPerPage', 'sortType', 'totalResults', 'type', 'database',
                        'suggestedClickPosition','suggestedLetterCount','suggestedResultCount', 'autoSuggestCategory', 'autoSuggestDetails','typedTerm','selectedTerm', 'channel',
                        'facetOperation', 'details'];
                        for (var i=0; i<fields.length; i++) {
                            if (data.search[fields[i]]) {
                                pageData.search[fields[i]] = data.search[fields[i]];
                            }
                        }
                    }
                }
                this.setAnalyticsData();
                break;
            case 'navigationClick':
                if (data && data.link) {
                    window.eventData.navigationLink = {
                        name: ((data.link.location || 'no location') + ':' + (data.link.name || 'no name'))
                    };
                }
                break;
            case 'autoSuggestClick':
                if (data && data.search) {
                    val = {
                        autoSuggestSearchData: (
                            'letterct:' + (data.search.suggestedLetterCount || 'none') +
                            '|resultct:' + (data.search.suggestedResultCount || 'none') +
                            '|clickpos:' + (data.search.suggestedClickPosition || 'none')
                        ).toLowerCase(),
                        autoSuggestSearchTerm: (data.search.typedTerm || ''),
                        autoSuggestTypedTerm: (data.search.typedTerm || ''),
                        autoSuggestSelectedTerm: (data.search.selectedTerm || ''),
                        autoSuggestCategory: (data.search.autoSuggestCategory || ''),
                        autoSuggestDetails: (data.search.autoSuggestDetails || '')
                    };
                }
                break;
            case 'linkOut':
                if (data && data.content && data.content.length > 0) {
                    window.eventData.linkOut = data.content[0].linkOut;
                    window.eventData.referringProduct = _satellite.getVar('Page - Product Name') + ':' + data.content[0].id;
                }
                break;
            case 'socialShare':
                if (data && data.social) {
                    window.eventData.sharePlatform = data.social.sharePlatform || '';
                }
                break;
            case 'contentInteraction':
                if (data && data.action) {
                    window.eventData.action.name = pageData.page.productName + ':' + data.action.name;
                }
                break;
            case 'searchWithinContent':
                if (data && data.search) {
                    window.pageData.search = window.pageData.search || {};
                    pageData.search.withinContentCriteria = data.search.withinContentCriteria;
                }
                break;
            case 'contentShare':
                if (data && data.content) {
                    window.eventData.sharePlatform = data.content[0].sharePlatform;
                }
                break;
            case 'contentLinkClick':
                if (data && data.link) {
                    window.eventData.action = { name: pageData.page.productName + ':' + (data.link.type || 'no link type') + ':' + (data.link.name || 'no link name') };
                }
                break;
            case 'contentWindowLoad':
            case 'contentTabClick':
                if (data && data.content) {
                    window.eventData.tabName = data.content[0].tabName || '';
                    window.eventData.windowName = data.content[0].windowName || '';
                }
                break;
            case 'userProfileUpdate':
                if (data && data.user) {
                    if (Object.prototype.toString.call(data.user) === "[object Array]") {
                        window.eventData.user = data.user[0];
                    }
                }
                break;
            case 'videoStart':
                if (data.video) {
                    data.video.length = parseFloat(data.video.length || '0');
                    data.video.position = parseFloat(data.video.position || '0');
                    s.Media.open(data.video.id, data.video.length, s.Media.playerName);
                    s.Media.play(data.video.id, data.video.position);
                }
                break;
            case 'videoPlay':
                if (data.video) {
                    data.video.position = parseFloat(data.video.position || '0');
                    s.Media.play(data.video.id, data.video.position);
                }
                break;
            case 'videoStop':
                if (data.video) {
                    data.video.position = parseFloat(data.video.position || '0');
                    s.Media.stop(data.video.id, data.video.position);
                }
                break;
            case 'videoComplete':
                if (data.video) {
                    data.video.position = parseFloat(data.video.position || '0');
                    s.Media.stop(data.video.id, data.video.position);
                    s.Media.close(data.video.id);
                }
                break;
            case 'addWebsiteExtension':
                if(data && data.page) {
                    val = {
                        wx: data.page.websiteExtension
                    }
                }
                break;
        }

        if (val) {
            this.setCookie(this.eventCookieName, val);
        }
    }

    ,registerCallbacks: function() {
        var self = this;
        if(window.usabilla_live) {
            window.usabilla_live('setEventCallback', function(category, action, label, value) {
                if(action == 'Campaign:Open') {
                    self.trackEvent('ctaImpression', {
                        cta: {
                            ids: ['usabillaid:' + label]
                        }
                    });
                } else if(action == 'Campaign:Success') {
                    self.trackEvent('ctaClick', {
                        cta: {
                            ids: ['usabillaid:' + label]
                        }
                    });
                }
            });
        }
    }

    ,getConsortiumAccountId: function() {
        var id = '';
        if (window.pageData && pageData.visitor && (pageData.visitor.consortiumId || pageData.visitor.accountId)) {
            id = (pageData.visitor.consortiumId || 'no consortium ID') + '|' + (pageData.visitor.accountId || 'no account ID');
        }

        return id;
    }

    ,getSearchClickPosition: function() {
        if (window.eventData && eventData.search && eventData.search.resultsPosition) {
            var pos = parseInt(eventData.search.resultsPosition), clickPos;
            if (!isNaN(pos)) {
                var page = pageData.search.currentPage ? parseInt(pageData.search.currentPage) : '', perPage = pageData.search.resultsPerPage ? parseInt(pageData.search.resultsPerPage) : '';
                if (!isNaN(page) && !isNaN(perPage)) {
                    clickPos = pos + ((page - 1) * perPage);
                }
            }
            return clickPos ? clickPos.toString() : eventData.search.resultsPosition;
        }
        return '';
    }

    ,getSearchFacets: function() {
        var facetList = '';
        if (window.pageData && pageData.search && pageData.search.facets) {
            if (typeof(pageData.search.facets) == 'object') {
                for (var i=0; i<pageData.search.facets.length; i++) {
                    var f = pageData.search.facets[i];
                    facetList += (facetList ? '|' : '') + f.name + '=' + f.values.join('^');
                }
            }
        }
        return facetList;
    }

    ,getSearchResultsByType: function() {
        var resultTypes = '';
        if (window.pageData && pageData.search && pageData.search.resultsByType) {
            for (var i=0; i<pageData.search.resultsByType.length; i++) {
                var r = pageData.search.resultsByType[i];
                resultTypes += (resultTypes ? '|' : '') + r.name + (r.results || r.values ? '=' + (r.results || r.values) : '');
            }
        }
        return resultTypes;
    }

    ,getJournalInfo: function() {
        var info = '';
        if (window.pageData && pageData.journal && (pageData.journal.name || pageData.journal.specialty || pageData.journal.section || pageData.journal.issn || pageData.journal.issueNumber || pageData.journal.volumeNumber || pageData.journal.family || pageData.journal.publisher)) {
            var journal = pageData.journal;
            info = (journal.name || 'no name') 
            + '|' + (journal.specialty || 'no specialty') 
            + '|' + (journal.section || 'no section') 
            + '|' + (journal.issn || 'no issn') 
            + '|' + (journal.issueNumber || 'no issue #') 
            + '|' + (journal.volumeNumber || 'no volume #')
            + '|' + (journal.family || 'no family')
            + '|' + (journal.publisher || 'no publisher');

        }
        return info;
    }

    ,getBibliographicInfo: function(doc) {
        if (!doc || !(doc.publisher || doc.indexTerms || doc.publicationType || doc.publicationRights || doc.volumeNumber || doc.issueNumber || doc.subjectAreas || doc.isbn)) {
            return '';
        }

        var terms = doc.indexTerms ? doc.indexTerms.split('+') : '';
        if (terms) {
            terms = terms.slice(0, 5).join('+');
            terms = terms.length > 100 ? terms.substring(0, 100) : terms;
        }

        var areas = doc.subjectAreas ? doc.subjectAreas.split('>') : '';
        if (areas) {
            areas = areas.slice(0, 5).join('>');
            areas = areas.length > 100 ? areas.substring(0, 100) : areas;
        }

        var biblio	= (doc.publisher || 'none')
            + '^' + (doc.publicationType || 'none')
            + '^' + (doc.publicationRights || 'none')
            + '^' + (terms || 'none')
            + '^' + (doc.volumeNumber || 'none')
            + '^' + (doc.issueNumber || 'none')
            + '^' + (areas || 'none')
            + '^' + (doc.isbn || 'none');

        return this.stripProductDelimiters(biblio).toLowerCase();
    }

    ,getContentItem: function() {
        var docs = window.eventData && eventData.content ? eventData.content : pageData.content;
        if (docs && docs.length > 0) {
            return docs[0];
        }
    }

    ,getFormattedDate: function(ts) {
        if (!ts) {
            return '';
        }

        var d = new Date(parseInt(ts) * 1000);

        // now do formatting
        var year = d.getFullYear()
            ,month = ((d.getMonth() + 1) < 10 ? '0' : '') + (d.getMonth() + 1)
            ,date = (d.getDate() < 10 ? '0' : '') + d.getDate()
            ,hours = d.getHours() > 12 ? d.getHours() - 12 : d.getHours()
            ,mins = (d.getMinutes() < 10 ? '0' : '') + d.getMinutes()
            ,ampm = d.getHours() > 12 ? 'pm' : 'am';

        hours = (hours < 10 ? '0' : '') + hours;
        return year + '-' + month + '-' + date;
    }

    ,getVisitorId: function() {
        var orgId = '4D6368F454EC41940A4C98A6@AdobeOrg';
        if(Visitor && Visitor.getInstance(orgId)) {
            return Visitor.getInstance(orgId).getMarketingCloudVisitorID();
        } else {
            return ''
        }
    }

    ,setProductsVariable: function() {
        var prodList = window.eventData && eventData.content ? eventData.content : pageData.content
            ,prods = [];
        if (prodList) {
            for (var i=0; i<prodList.length; i++) {
                if (prodList[i].id || prodList[i].type || prodList[i].publishDate || prodList[i].onlineDate) {
                    if (!prodList[i].id) {
                        prodList[i].id = 'no id';
                    }
                    var prodName = (pageData.page.productName || 'xx').toLowerCase();
                    if (prodList[i].id.indexOf(prodName + ':') != 0) {
                        prodList[i].id = prodName + ':' + prodList[i].id;
                    }
                    prodList[i].id = this.stripProductDelimiters(prodList[i].id);
                    var merch = [];
                    if (prodList[i].format) {
                        merch.push('evar17=' + this.stripProductDelimiters(prodList[i].format.toLowerCase()));
                    }
                    if (prodList[i].type) {
                        var type = prodList[i].type;
                        if (prodList[i].accessType) {
                            type += ':' + prodList[i].accessType;
                        }
                        merch.push('evar20=' + this.stripProductDelimiters(type.toLowerCase()));

                        if(type.indexOf(':manuscript') > 0) {
                            /*
                            var regex = /[a-z]+:manuscript:id:([a-z]+-[a-z]-[0-9]+-[0-9]+)/gmi;
                            var m = regex.exec(prodList[i].id);
                            if(m) {
                                merch.push('evar200=' + m[1]);
                            }
                            merch.push('evar200=' + prodList[i].id);
                            */
                            a = prodList[i].id.lastIndexOf(':');
                            if(a>0) {
                                merch.push('evar200=' + prodList[i].id.substring(a+1).toUpperCase());
                            }
                        } else if(type.indexOf(':submission') > 0) {
                            merch.push('evar200=' + prodList[i].id);
                        }
                    }
                    if(!prodList[i].title) {
                        prodList[i].title = prodList[i].name;
                    }
                    if (prodList[i].title) {
                        merch.push('evar75=' + this.stripProductDelimiters(prodList[i].title.toLowerCase()));
                    }
                    if (prodList[i].breadcrumb) {
                        merch.push('evar63=' + this.stripProductDelimiters(prodList[i].breadcrumb).toLowerCase());
                    }
                    var nowTs = new Date().getTime()/1000;
                    if (prodList[i].onlineDate && !isNaN(prodList[i].onlineDate)) {
                        if(prodList[i].onlineDate > 32503680000) {
                            prodList[i].onlineDate = prodList[i].onlineDate/1000;
                        }
                        merch.push('evar122=' + this.stripProductDelimiters(pageDataTracker.getFormattedDate(prodList[i].onlineDate)));
                        var onlineAge = Math.floor((nowTs - prodList[i].onlineDate) / 86400);
                        onlineAge = (onlineAge === 0) ? 'zero' : onlineAge;
                        merch.push('evar128=' + onlineAge);
                    }
                    if (prodList[i].publishDate && !isNaN(prodList[i].publishDate)) {
                        if(prodList[i].publishDate > 32503680000) {
                            prodList[i].publishDate = prodList[i].publishDate/1000;
                        }
                        merch.push('evar123=' + this.stripProductDelimiters(pageDataTracker.getFormattedDate(prodList[i].publishDate)));
                        var publishAge = Math.floor((nowTs - prodList[i].publishDate) / 86400);
                        publishAge = (publishAge === 0) ? 'zero' : publishAge;
                        merch.push('evar127=' + publishAge);
                    }
                    if (prodList[i].onlineDate && prodList[i].publishDate) {
                        merch.push('evar38=' + this.stripProductDelimiters(pageDataTracker.getFormattedDate(prodList[i].onlineDate) + '^' + pageDataTracker.getFormattedDate(prodList[i].publishDate)));
                    }
                    if (prodList[i].mapId) {
                        merch.push('evar70=' + this.stripProductDelimiters(prodList[i].mapId));
                    }
					if (prodList[i].relevancyScore) {
						merch.push('evar71=' + this.stripProductDelimiters(prodList[i].relevancyScore));
					}
                    if (prodList[i].status) {
                        merch.push('evar73=' + this.stripProductDelimiters(prodList[i].status));
                    }
                    if (prodList[i].previousStatus) {
                        merch.push('evar111=' + this.stripProductDelimiters(prodList[i].previousStatus));
                    }
                    if (prodList[i].entitlementType) {
                        merch.push('evar80=' + this.stripProductDelimiters(prodList[i].entitlementType));
                    }
                    if (prodList[i].recordType) {
                        merch.push('evar93=' + this.stripProductDelimiters(prodList[i].recordType));
                    }
                    if (prodList[i].exportType) {
                        merch.push('evar99=' + this.stripProductDelimiters(prodList[i].exportType));
                    }
                    if (prodList[i].importType) {
                        merch.push('evar142=' + this.stripProductDelimiters(prodList[i].importType));
                    }
                    if (prodList[i].section) {
                        merch.push('evar100=' + this.stripProductDelimiters(prodList[i].section));
                    }
                    if (prodList[i].detail) {
                        merch.push('evar104=' + this.stripProductDelimiters(prodList[i].detail.toLowerCase()));
                    } else if(prodList[i].details) {
                        merch.push('evar104=' + this.stripProductDelimiters(prodList[i].details.toLowerCase()));
                    }
                    if (prodList[i].position) {
                        merch.push('evar116=' + this.stripProductDelimiters(prodList[i].position));
                    }
                    if (prodList[i].publicationTitle) {
                        merch.push('evar129=' + this.stripProductDelimiters(prodList[i].publicationTitle));
                    }
                    if (prodList[i].specialIssueTitle) {
                        merch.push('evar130=' + this.stripProductDelimiters(prodList[i].specialIssueTitle));
                    }
                    if (prodList[i].specialIssueNumber) {
                        merch.push('evar131=' + this.stripProductDelimiters(prodList[i].specialIssueNumber));
                    }
                    if (prodList[i].referenceModuleTitle) {
                        merch.push('evar139=' + this.stripProductDelimiters(prodList[i].referenceModuleTitle));
                    }
                    if (prodList[i].referenceModuleISBN) {
                        merch.push('evar140=' + this.stripProductDelimiters(prodList[i].referenceModuleISBN));
                    }
                    if (prodList[i].volumeTitle) {
                        merch.push('evar132=' + this.stripProductDelimiters(prodList[i].volumeTitle));
                    }
                    if (prodList[i].publicationSection) {
                        merch.push('evar133=' + this.stripProductDelimiters(prodList[i].publicationSection));
                    }
                    if (prodList[i].publicationSpecialty) {
                        merch.push('evar134=' + this.stripProductDelimiters(prodList[i].publicationSpecialty));
                    }
                    if (prodList[i].issn) {
                        merch.push('evar135=' + this.stripProductDelimiters(prodList[i].issn));
                    }
                    if (prodList[i].id2) {
                        merch.push('evar159=' + this.stripProductDelimiters(prodList[i].id2));
                    }
                    if (prodList[i].id3) {
                        merch.push('evar160=' + this.stripProductDelimiters(prodList[i].id3));
                    }
                    if (prodList[i].provider) {
                        merch.push('evar164=' + this.stripProductDelimiters(prodList[i].provider));
                    }
                    if (prodList[i].citationStyle) {
                        merch.push('evar170=' + this.stripProductDelimiters(prodList[i].citationStyle));
                    }

                    var biblio = this.getBibliographicInfo(prodList[i]);
                    if (biblio) {
                        merch.push('evar28=' + biblio);
                    }

                    if (prodList[i].turnawayId) {
                        pageData.eventList.push('product turnaway');
                    }

                    var price = prodList[i].price || '', qty = prodList[i].quantity || '', evts = [];
                    if (price && qty) {
                        qty = parseInt(qty || '1');
                        price = parseFloat(price || '0');
                        price = (price * qty).toFixed(2);

                        if (window.eventData && eventData.eventName && eventData.eventName == 'cartAdd') {
                            evts.push('event20=' + price);
                        }
                    }

                    var type = window.pageData && pageData.page && pageData.page.type ? pageData.page.type : '', evt = window.eventData && eventData.eventName ? eventData.eventName : '';
                    if (type.match(/^CP\-/gi) !== null && (!evt || evt == 'newPage' || evt == 'contentView')) {
                        evts.push('event181=1');
                    }
                    if (evt == 'contentDownload' || type.match(/^CP\-DL/gi) !== null) {
                        evts.push('event182=1');
                    }
                    if (evt == 'contentDownloadRequest') {
                        evts.push('event319=1');
                    }
                    if (evt == 'contentExport') {
                        evts.push('event184=1');
                    }
                    if (this.eventFires('recommendationViews')) {
                        evts.push('event264=1');
                    }

                    if(prodList[i].datapoints) {
                        evts.push('event239=' + prodList[i].datapoints);
                    }
                    if(prodList[i].documents) {
                        evts.push('event240=' + prodList[i].documents);
                    }
                    if(prodList[i].size) {
                        evts.push('event335=' + prodList[i].size);
                        evts.push('event336=1')
                    }

                    prods.push([
                        ''					// empty category
                        ,prodList[i].id		// id
                        ,qty				// qty
                        ,price				// price
                        ,evts.join('|')		// events
                        ,merch.join('|')	// merchandising eVars
                    ].join(';'));
                }
            }
        }

        return prods.join(',');
    }
    ,eventFires: function(eventName) {
      var evt = window.eventData && eventData.eventName ? eventData.eventName : '';
      if(evt == eventName) {
        return true;
      }
      // initial pageload and new pages
      if((!window.eventData || evt == 'newPage') && window.pageData && window.pageData.trackEvents) {
        var tEvents = window.pageData.trackEvents;
        for(var i=0; i<tEvents.length; i++) {
          if(tEvents[i] == eventName) {
            return true;
          }
        }
      }
      return false;
    }

    ,md5: function(s){function L(k,d){return(k<<d)|(k>>>(32-d))}function K(G,k){var I,d,F,H,x;F=(G&2147483648);H=(k&2147483648);I=(G&1073741824);d=(k&1073741824);x=(G&1073741823)+(k&1073741823);if(I&d){return(x^2147483648^F^H)}if(I|d){if(x&1073741824){return(x^3221225472^F^H)}else{return(x^1073741824^F^H)}}else{return(x^F^H)}}function r(d,F,k){return(d&F)|((~d)&k)}function q(d,F,k){return(d&k)|(F&(~k))}function p(d,F,k){return(d^F^k)}function n(d,F,k){return(F^(d|(~k)))}function u(G,F,aa,Z,k,H,I){G=K(G,K(K(r(F,aa,Z),k),I));return K(L(G,H),F)}function f(G,F,aa,Z,k,H,I){G=K(G,K(K(q(F,aa,Z),k),I));return K(L(G,H),F)}function D(G,F,aa,Z,k,H,I){G=K(G,K(K(p(F,aa,Z),k),I));return K(L(G,H),F)}function t(G,F,aa,Z,k,H,I){G=K(G,K(K(n(F,aa,Z),k),I));return K(L(G,H),F)}function e(G){var Z;var F=G.length;var x=F+8;var k=(x-(x%64))/64;var I=(k+1)*16;var aa=Array(I-1);var d=0;var H=0;while(H<F){Z=(H-(H%4))/4;d=(H%4)*8;aa[Z]=(aa[Z]| (G.charCodeAt(H)<<d));H++}Z=(H-(H%4))/4;d=(H%4)*8;aa[Z]=aa[Z]|(128<<d);aa[I-2]=F<<3;aa[I-1]=F>>>29;return aa}function B(x){var k="",F="",G,d;for(d=0;d<=3;d++){G=(x>>>(d*8))&255;F="0"+G.toString(16);k=k+F.substr(F.length-2,2)}return k}function J(k){k=k.replace(/rn/g,"n");var d="";for(var F=0;F<k.length;F++){var x=k.charCodeAt(F);if(x<128){d+=String.fromCharCode(x)}else{if((x>127)&&(x<2048)){d+=String.fromCharCode((x>>6)|192);d+=String.fromCharCode((x&63)|128)}else{d+=String.fromCharCode((x>>12)|224);d+=String.fromCharCode(((x>>6)&63)|128);d+=String.fromCharCode((x&63)|128)}}}return d}var C=Array();var P,h,E,v,g,Y,X,W,V;var S=7,Q=12,N=17,M=22;var A=5,z=9,y=14,w=20;var o=4,m=11,l=16,j=23;var U=6,T=10,R=15,O=21;s=J(s);C=e(s);Y=1732584193;X=4023233417;W=2562383102;V=271733878;for(P=0;P<C.length;P+=16){h=Y;E=X;v=W;g=V;Y=u(Y,X,W,V,C[P+0],S,3614090360);V=u(V,Y,X,W,C[P+1],Q,3905402710);W=u(W,V,Y,X,C[P+2],N,606105819);X=u(X,W,V,Y,C[P+3],M,3250441966);Y=u(Y,X,W,V,C[P+4],S,4118548399);V=u(V,Y,X,W,C[P+5],Q,1200080426);W=u(W,V,Y,X,C[P+6],N,2821735955);X=u(X,W,V,Y,C[P+7],M,4249261313);Y=u(Y,X,W,V,C[P+8],S,1770035416);V=u(V,Y,X,W,C[P+9],Q,2336552879);W=u(W,V,Y,X,C[P+10],N,4294925233);X=u(X,W,V,Y,C[P+11],M,2304563134);Y=u(Y,X,W,V,C[P+12],S,1804603682);V=u(V,Y,X,W,C[P+13],Q,4254626195);W=u(W,V,Y,X,C[P+14],N,2792965006);X=u(X,W,V,Y,C[P+15],M,1236535329);Y=f(Y,X,W,V,C[P+1],A,4129170786);V=f(V,Y,X,W,C[P+6],z,3225465664);W=f(W,V,Y,X,C[P+11],y,643717713);X=f(X,W,V,Y,C[P+0],w,3921069994);Y=f(Y,X,W,V,C[P+5],A,3593408605);V=f(V,Y,X,W,C[P+10],z,38016083);W=f(W,V,Y,X,C[P+15],y,3634488961);X=f(X,W,V,Y,C[P+4],w,3889429448);Y=f(Y,X,W,V,C[P+9],A,568446438);V=f(V,Y,X,W,C[P+14],z,3275163606);W=f(W,V,Y,X,C[P+3],y,4107603335);X=f(X,W,V,Y,C[P+8],w,1163531501);Y=f(Y,X,W,V,C[P+13],A,2850285829);V=f(V,Y,X,W,C[P+2],z,4243563512);W=f(W,V,Y,X,C[P+7],y,1735328473);X=f(X,W,V,Y,C[P+12],w,2368359562);Y=D(Y,X,W,V,C[P+5],o,4294588738);V=D(V,Y,X,W,C[P+8],m,2272392833);W=D(W,V,Y,X,C[P+11],l,1839030562);X=D(X,W,V,Y,C[P+14],j,4259657740);Y=D(Y,X,W,V,C[P+1],o,2763975236);V=D(V,Y,X,W,C[P+4],m,1272893353);W=D(W,V,Y,X,C[P+7],l,4139469664);X=D(X,W,V,Y,C[P+10],j,3200236656);Y=D(Y,X,W,V,C[P+13],o,681279174);V=D(V,Y,X,W,C[P+0],m,3936430074);W=D(W,V,Y,X,C[P+3],l,3572445317);X=D(X,W,V,Y,C[P+6],j,76029189);Y=D(Y,X,W,V,C[P+9],o,3654602809);V=D(V,Y,X,W,C[P+12],m,3873151461);W=D(W,V,Y,X,C[P+15],l,530742520);X=D(X,W,V,Y,C[P+2],j,3299628645);Y=t(Y,X,W,V,C[P+0],U,4096336452);V=t(V,Y,X,W,C[P+7],T,1126891415);W=t(W,V,Y,X,C[P+14],R,2878612391);X=t(X,W,V,Y,C[P+5],O,4237533241);Y=t(Y,X,W,V,C[P+12],U,1700485571);V=t(V,Y,X,W,C[P+3],T,2399980690);W=t(W,V,Y,X,C[P+10],R,4293915773);X=t(X,W,V,Y,C[P+1],O,2240044497);Y=t(Y,X,W,V,C[P+8],U,1873313359);V=t(V,Y,X,W,C[P+15],T,4264355552);W=t(W,V,Y,X,C[P+6],R,2734768916);X=t(X,W,V,Y,C[P+13],O,1309151649);Y=t(Y,X,W,V,C[P+4],U,4149444226);V=t(V,Y,X,W,C[P+11],T,3174756917);W=t(W,V,Y,X,C[P+2],R,718787259);X=t(X,W,V,Y,C[P+9],O,3951481745);Y=K(Y,h);X=K(X,E);W=K(W,v);V=K(V,g)}var i=B(Y)+B(X)+B(W)+B(V);return i.toLowerCase()}
    ,stripProductDelimiters: function(val) {
        if (val) {
            return val.replace(/\;|\||\,/gi, '-');
        }
    }

    ,setCookie: function(name, value, seconds, domain) {
        domain = document.location.hostname;
        var expires = '';
        var expiresNow = '';
        var date = new Date();
        date.setTime(date.getTime() + (-1 * 1000));
        expiresNow = "; expires=" + date.toGMTString();

        if (typeof(seconds) != 'undefined') {
            date.setTime(date.getTime() + (seconds * 1000));
            expires = '; expires=' + date.toGMTString();
        }

        var type = typeof(value);
        type = type.toLowerCase();
        if (type != 'undefined' && type != 'string') {
            value = JSON.stringify(value);
        }

        // fix scoping issues
        // keep writing the old cookie, but make it expire
        document.cookie = name + '=' + value + expiresNow + '; path=/';

        // now just set the right one
        document.cookie = name + '=' + value + expires + '; path=/; domain=' + domain;
    }

    ,getCookie: function(name) {
        name = name + '=';
        var carray = document.cookie.split(';'), value;

        for (var i=0; i<carray.length; i++) {
            var c = carray[i];
            while (c.charAt(0) == ' ') {
                c = c.substring(1, c.length);
            }
            if (c.indexOf(name) == 0) {
                value = c.substring(name.length, c.length);
                try {
                    value = JSON.parse(value);
                } catch(ex) {}

                return value;
            }
        }

        return null;
    }

    ,deleteCookie: function(name) {
        this.setCookie(name, '', -1);
        this.setCookie(name, '', -1, document.location.hostname);
    }

    ,mapAdobeVars: function(s) {
        var vars = {
            pageName		: 'Page - Analytics Pagename'
            ,channel		: 'Page - Section Name'
            ,campaign		: 'Campaign - ID'
            ,currencyCode	: 'Page - Currency Code'
            ,purchaseID		: 'Order - ID'
            ,prop1			: 'Visitor - Account ID'
            ,prop2			: 'Page - Product Name'
            ,prop4			: 'Page - Type'
            ,prop6			: 'Search - Type'
            ,prop7			: 'Search - Facet List'
            ,prop8			: 'Search - Feature Used'
            ,prop12			: 'Visitor - User ID'
            ,prop13			: 'Search - Sort Type'
            ,prop14			: 'Page - Load Time'
            ,prop15         : 'Support - Topic Name'
            ,prop16			: 'Page - Business Unit'
            ,prop21			: 'Search - Criteria'
            ,prop24			: 'Page - Language'
            ,prop25			: 'Page - Product Feature'
            ,prop28         : 'Support - Search Criteria'
            ,prop30			: 'Visitor - IP Address'
            ,prop33         : 'Page - Product Application Version'
            ,prop34         : 'Page - Website Extensions'
            ,prop60			: 'Search - Data Form Criteria'
            ,prop63			: 'Page - Extended Page Name'
            ,prop65         : 'Page - Online State'
            ,prop67         : 'Research Networks'
            ,prop40: 'Page - UX Properties'

            ,eVar3			: 'Search - Total Results'
            ,eVar7			: 'Visitor - Account Name'
            ,eVar15			: 'Event - Search Results Click Position'
            ,eVar19			: 'Search - Advanced Criteria'
            ,eVar21			: 'Promo - Clicked ID'
            ,eVar22			: 'Page - Test ID'
            ,eVar27			: 'Event - AutoSuggest Search Data'
            ,eVar157		: 'Event - AutoSuggest Search Typed Term'
            ,eVar156		: 'Event - AutoSuggest Search Selected Term'
            ,eVar162		: 'Event - AutoSuggest Search Category'
            ,eVar163		: 'Event - AutoSuggest Search Details'
            ,eVar33			: 'Visitor - Access Type'
            ,eVar34			: 'Order - Promo Code'
            ,eVar39			: 'Order - Payment Method'
            ,eVar41			: 'Visitor - Industry'
            ,eVar42			: 'Visitor - SIS ID'
            ,eVar43			: 'Page - Error Type'
            ,eVar44			: 'Event - Updated User Fields'
            ,eVar48			: 'Email - Recipient ID'
            ,eVar51			: 'Email - Message ID'
            ,eVar52			: 'Visitor - Department ID'
            ,eVar53			: 'Visitor - Department Name'
            ,eVar60			: 'Search - Within Content Criteria'
            ,eVar61			: 'Search - Within Results Criteria'
            ,eVar62			: 'Search - Result Types'
            ,eVar74			: 'Page - Journal Info'
            ,eVar59			: 'Page - Journal Publisher'
            ,eVar76			: 'Email - Broadlog ID'
            ,eVar78			: 'Visitor - Details'
            ,eVar80         : 'Visitor - Usage Path Info'
            ,eVar102		: 'Form - Name'
            ,eVar103        : 'Event - Conversion Driver'
            ,eVar105        : 'Search - Current Page'
            ,eVar106        : 'Visitor - App Session ID'
            ,eVar107        : 'Page - Secondary Product Name'
            ,eVar117        : 'Search - Database'
            ,eVar126        : 'Page - Environment'
            ,eVar141        : 'Search - Criteria Original'
            ,eVar143        : 'Page - Tabs'
            ,eVar161        : 'Search - Channel'
            ,eVar169        : 'Search - Facet Operation'
            ,eVar173        : 'Search - Details'
            ,eVar174        : 'Campaign - Spredfast ID'
            ,eVar175        : 'Visitor - TMX Device ID'
            ,eVar176        : 'Visitor - TMX Request ID'
            ,eVar148        : 'Visitor - Platform Name'
            ,eVar149        : 'Visitor - Platform ID'
            ,eVar152        : 'Visitor - Product ID'
            ,eVar153        : 'Visitor - Superaccount ID'
            ,eVar154        : 'Visitor - Superaccount Name'
            ,eVar177        : 'Page - Context Domain'
            ,eVar189    : 'Page - Experimentation User Id'
            ,eVar190    : 'Page - Identity User'
            ,eVar199    : 'Page - ID+ Parameters'

            ,list2			: 'Page - Widget Names'
            ,list3			: 'Promo - IDs'
        };

        for (var i in vars) {
            s[i] = s[i] ? s[i] : _satellite.getVar(vars[i]);
        }
    }
};

// async support fallback
(function(w) {
	var eventBuffer = [];
	if(w.appData) {
		if(Array.isArray(w.appData)) {
			eventBuffer = w.appData;
		} else {
			console.error('Elsevier DataLayer "window.appData" must be specified as array');
			return;
		}
    }

	w.appData = [];

	var oldPush = w.appData.push;

	var appDataPush = function() {
        oldPush.apply(w.appData, arguments);
        for(var i=0; i<arguments.length; i++) {
            var data = arguments[i];
            if(data.event) {
                if(data.event == 'pageLoad') {
                    w.pageDataTracker.trackPageLoad(data);
                } else {
                    w.pageDataTracker.trackEvent(data.event, data);
                }
            }
        }
	};

	w.appData.push = appDataPush;
	for(var i=0; i<eventBuffer.length; i++) {
	    var data = eventBuffer[i];
	    w.appData.push(data);
	}
})(window);

</script><script>_satellite["_runScript1"](function(event, target, Promise) {
_satellite.logger.log("eventDispatcher: clearing tracking state");try{s.events="",s.linkTrackVars="",s.linkTrackEvents=""}catch(e){_satellite.logger.log("eventDispatcher: s object - could not reset state.")}try{dispatcherData=JSON.parse(event.detail),window.ddqueue=window.ddqueue||[],window.ddqueue.push(dispatcherData),window.eventData=dispatcherData.eventData,window.pageData=dispatcherData.pageData,_satellite.track(dispatcherData.eventName)}catch(e){_satellite.logger.log("eventDispatcher: exception"),_satellite.logger.log(e)}
});</script><script src="https://cdn.plu.mx/widget-summary.js" async=""></script><script>_satellite["_runScript2"](function(event, target, Promise) {
_satellite.logger.log("eventDispatcher: clearing tracking state");try{s.events="",s.linkTrackVars="",s.linkTrackEvents=""}catch(e){_satellite.logger.log("eventDispatcher: s object - could not reset state.")}try{dispatcherData=JSON.parse(event.detail),window.ddqueue=window.ddqueue||[],window.ddqueue.push(dispatcherData),window.eventData=dispatcherData.eventData,window.pageData=dispatcherData.pageData,_satellite.track(dispatcherData.eventName)}catch(e){_satellite.logger.log("eventDispatcher: exception"),_satellite.logger.log(e)}
});</script><div class="js-react-modal"></div><div class="js-react-modal"></div><div class="js-react-modal"></div><div class="js-react-modal"></div><div class="js-react-modal"></div><div class="js-react-modal"></div><div class="js-react-modal"></div><div id="onetrust-consent-sdk"><div class="onetrust-pc-dark-filter ot-hide ot-fade-in"></div><div id="onetrust-pc-sdk" class="otPcCenter ot-hide ot-fade-in" lang="en" aria-label="Preference center" role="region"><div role="alertdialog" aria-modal="true" aria-describedby="ot-pc-desc" style="height: 100%;" aria-label="Cookie Preference Center"><!-- Close Button --><div class="ot-pc-header"><!-- Logo Tag --><div class="ot-pc-logo" role="img" aria-label="Company Logo"><img alt="Company Logo" src="https://cdn.cookielaw.org/logos/static/ot_company_logo.png"></div></div><!-- Close Button --><div id="ot-pc-content" class="ot-pc-scrollbar"><div class="ot-optout-signal ot-hide"><div class="ot-optout-icon"><svg xmlns="http://www.w3.org/2000/svg"><path class="ot-floating-button__svg-fill" d="M14.588 0l.445.328c1.807 1.303 3.961 2.533 6.461 3.688 2.015.93 4.576 1.746 7.682 2.446 0 14.178-4.73 24.133-14.19 29.864l-.398.236C4.863 30.87 0 20.837 0 6.462c3.107-.7 5.668-1.516 7.682-2.446 2.709-1.251 5.01-2.59 6.906-4.016zm5.87 13.88a.75.75 0 00-.974.159l-5.475 6.625-3.005-2.997-.077-.067a.75.75 0 00-.983 1.13l4.172 4.16 6.525-7.895.06-.083a.75.75 0 00-.16-.973z" fill="#FFF" fill-rule="evenodd"></path></svg></div><span></span></div><h2 id="ot-pc-title">Cookie Preference Center</h2><div id="ot-pc-desc">We use cookies which are necessary to make our site work. We may also use additional cookies to analyse, improve and personalise our content and your digital experience. For more information, see our <a href="https://www.elsevier.com/legal/cookienotice/_nocache" target="_blank">Cookie Policy</a> and the list of <a href="https://support.google.com/admanager/answer/9012903" target="_blank">Google Ad-Tech Vendors</a>.
<br>
<br>
You may choose not to allow some types of cookies. However, blocking some types may impact your experience of our site and the services we are able to offer. See the different category headings below to find out more or change your settings.
<br>
</div><button id="accept-recommended-btn-handler">Allow all</button><section class="ot-sdk-row ot-cat-grp"><h3 id="ot-category-title"> Manage Consent Preferences</h3><div class="ot-accordion-layout ot-cat-item ot-vs-config" data-optanongroupid="1"><button aria-expanded="false" ot-accordion="true" aria-controls="ot-desc-id-1" aria-labelledby="ot-header-id-1 ot-status-id-1"></button><!-- Accordion header --><div class="ot-acc-hdr ot-always-active-group"><div class="ot-plus-minus"><span></span><span></span></div><h4 class="ot-cat-header" id="ot-header-id-1">Strictly Necessary Cookies</h4><div id="ot-status-id-1" class="ot-always-active">Always active</div></div><!-- accordion detail --><div class="ot-acc-grpcntr ot-acc-txt"><p class="ot-acc-grpdesc ot-category-desc" id="ot-desc-id-1">These cookies are necessary for the website to function and cannot be switched off in our systems. They are usually only set in response to actions made by you which amount to a request for services, such as setting your privacy preferences, logging in or filling in forms. You can set your browser to block or alert you about these cookies, but some parts of the site will not then work. These cookies do not store any personally identifiable information.
<br><br></p><div class="ot-hlst-cntr"><button class="ot-link-btn category-host-list-handler" aria-label="Cookie Details List" data-parent-id="1">Cookie Details Listâ€Ž</button></div></div></div><div class="ot-accordion-layout ot-cat-item ot-vs-config" data-optanongroupid="3"><button aria-expanded="false" ot-accordion="true" aria-controls="ot-desc-id-3" aria-labelledby="ot-header-id-3"></button><!-- Accordion header --><div class="ot-acc-hdr"><div class="ot-plus-minus"><span></span><span></span></div><h4 class="ot-cat-header" id="ot-header-id-3">Functional Cookies</h4><div class="ot-tgl"><input type="checkbox" name="ot-group-id-3" id="ot-group-id-3" role="switch" class="category-switch-handler" data-optanongroupid="3" checked="" aria-labelledby="ot-header-id-3"> <label class="ot-switch" for="ot-group-id-3"><span class="ot-switch-nob" aria-checked="true" role="switch" aria-label="Functional Cookies"></span> <span class="ot-label-txt">Functional Cookies</span></label> </div></div><!-- accordion detail --><div class="ot-acc-grpcntr ot-acc-txt"><p class="ot-acc-grpdesc ot-category-desc" id="ot-desc-id-3">These cookies enable the website to provide enhanced functionality and personalisation. They may be set by us or by third party providers whose services we have added to our pages. If you do not allow these cookies then some or all of these services may not function properly.</p><div class="ot-hlst-cntr"><button class="ot-link-btn category-host-list-handler" aria-label="Cookie Details List" data-parent-id="3">Cookie Details Listâ€Ž</button></div></div></div><div class="ot-accordion-layout ot-cat-item ot-vs-config" data-optanongroupid="2"><button aria-expanded="false" ot-accordion="true" aria-controls="ot-desc-id-2" aria-labelledby="ot-header-id-2"></button><!-- Accordion header --><div class="ot-acc-hdr"><div class="ot-plus-minus"><span></span><span></span></div><h4 class="ot-cat-header" id="ot-header-id-2">Performance Cookies</h4><div class="ot-tgl"><input type="checkbox" name="ot-group-id-2" id="ot-group-id-2" role="switch" class="category-switch-handler" data-optanongroupid="2" checked="" aria-labelledby="ot-header-id-2"> <label class="ot-switch" for="ot-group-id-2"><span class="ot-switch-nob" aria-checked="true" role="switch" aria-label="Performance Cookies"></span> <span class="ot-label-txt">Performance Cookies</span></label> </div></div><!-- accordion detail --><div class="ot-acc-grpcntr ot-acc-txt"><p class="ot-acc-grpdesc ot-category-desc" id="ot-desc-id-2">These cookies allow us to count visits and traffic sources so we can measure and improve the performance of our site. They help us to know which pages are the most and least popular and see how visitors move around the site.</p><div class="ot-hlst-cntr"><button class="ot-link-btn category-host-list-handler" aria-label="Cookie Details List" data-parent-id="2">Cookie Details Listâ€Ž</button></div></div></div><div class="ot-accordion-layout ot-cat-item ot-vs-config" data-optanongroupid="4"><button aria-expanded="false" ot-accordion="true" aria-controls="ot-desc-id-4" aria-labelledby="ot-header-id-4"></button><!-- Accordion header --><div class="ot-acc-hdr"><div class="ot-plus-minus"><span></span><span></span></div><h4 class="ot-cat-header" id="ot-header-id-4">Targeting Cookies</h4><div class="ot-tgl"><input type="checkbox" name="ot-group-id-4" id="ot-group-id-4" role="switch" class="category-switch-handler" data-optanongroupid="4" checked="" aria-labelledby="ot-header-id-4"> <label class="ot-switch" for="ot-group-id-4"><span class="ot-switch-nob" aria-checked="true" role="switch" aria-label="Targeting Cookies"></span> <span class="ot-label-txt">Targeting Cookies</span></label> </div></div><!-- accordion detail --><div class="ot-acc-grpcntr ot-acc-txt"><p class="ot-acc-grpdesc ot-category-desc" id="ot-desc-id-4">These cookies may be set through our site by our advertising partners. They may be used by those companies to build a profile of your interests and show you relevant adverts on other sites. If you do not allow these cookies, you will experience less targeted advertising.</p><div class="ot-hlst-cntr"><button class="ot-link-btn category-host-list-handler" aria-label="Cookie Details List" data-parent-id="4">Cookie Details Listâ€Ž</button></div></div></div><!-- Groups sections starts --><!-- Group section ends --><!-- Accordion Group section starts --><!-- Accordion Group section ends --></section></div><section id="ot-pc-lst" class="ot-hide ot-hosts-ui ot-pc-scrollbar"><div id="ot-pc-hdr"><div id="ot-lst-title"><button class="ot-link-btn back-btn-handler" aria-label="Back"><svg id="ot-back-arw" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" x="0px" y="0px" viewBox="0 0 444.531 444.531" xml:space="preserve"><title>Back Button</title><g><path fill="#656565" d="M213.13,222.409L351.88,83.653c7.05-7.043,10.567-15.657,10.567-25.841c0-10.183-3.518-18.793-10.567-25.835
                    l-21.409-21.416C323.432,3.521,314.817,0,304.637,0s-18.791,3.521-25.841,10.561L92.649,196.425
                    c-7.044,7.043-10.566,15.656-10.566,25.841s3.521,18.791,10.566,25.837l186.146,185.864c7.05,7.043,15.66,10.564,25.841,10.564
                    s18.795-3.521,25.834-10.564l21.409-21.412c7.05-7.039,10.567-15.604,10.567-25.697c0-10.085-3.518-18.746-10.567-25.978
                    L213.13,222.409z"></path></g></svg></button><h3>Cookie List</h3></div><div class="ot-lst-subhdr"><div class="ot-search-cntr"><p role="status" class="ot-scrn-rdr"></p><input id="vendor-search-handler" type="text" name="vendor-search-handler" placeholder="Searchâ€¦" aria-label="Cookie list search"> <svg xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" x="0px" y="0px" viewBox="0 -30 110 110" aria-hidden="true"><title>Search Icon</title><path fill="#2e3644" d="M55.146,51.887L41.588,37.786c3.486-4.144,5.396-9.358,5.396-14.786c0-12.682-10.318-23-23-23s-23,10.318-23,23
            s10.318,23,23,23c4.761,0,9.298-1.436,13.177-4.162l13.661,14.208c0.571,0.593,1.339,0.92,2.162,0.92
            c0.779,0,1.518-0.297,2.079-0.837C56.255,54.982,56.293,53.08,55.146,51.887z M23.984,6c9.374,0,17,7.626,17,17s-7.626,17-17,17
            s-17-7.626-17-17S14.61,6,23.984,6z"></path></svg></div><div class="ot-fltr-cntr"><button id="filter-btn-handler" aria-label="Filter" aria-haspopup="true"><svg role="presentation" aria-hidden="true" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" x="0px" y="0px" viewBox="0 0 402.577 402.577" xml:space="preserve"><title>Filter Icon</title><g><path fill="#fff" d="M400.858,11.427c-3.241-7.421-8.85-11.132-16.854-11.136H18.564c-7.993,0-13.61,3.715-16.846,11.136
      c-3.234,7.801-1.903,14.467,3.999,19.985l140.757,140.753v138.755c0,4.955,1.809,9.232,5.424,12.854l73.085,73.083
      c3.429,3.614,7.71,5.428,12.851,5.428c2.282,0,4.66-0.479,7.135-1.43c7.426-3.238,11.14-8.851,11.14-16.845V172.166L396.861,31.413
      C402.765,25.895,404.093,19.231,400.858,11.427z"></path></g></svg></button></div><div id="ot-anchor"></div><section id="ot-fltr-modal"><div id="ot-fltr-cnt"><button id="clear-filters-handler">Clear</button><div class="ot-fltr-scrlcnt ot-pc-scrollbar"><div class="ot-fltr-opts"><div class="ot-fltr-opt"><div class="ot-chkbox"><input id="chkbox-id" type="checkbox" class="category-filter-handler"> <label for="chkbox-id"><span class="ot-label-txt">checkbox label</span></label> <span class="ot-label-status">label</span></div></div></div><div class="ot-fltr-btns"><button id="filter-apply-handler">Apply</button> <button id="filter-cancel-handler">Cancel</button></div></div></div></section></div></div><section id="ot-lst-cnt" class="ot-host-cnt ot-pc-scrollbar"><div id="ot-sel-blk"><div class="ot-sel-all"><div class="ot-sel-all-hdr"><span class="ot-consent-hdr">Consent</span> <span class="ot-li-hdr">Leg.Interest</span></div><div class="ot-sel-all-chkbox"><div class="ot-chkbox" id="ot-selall-hostcntr"><input id="select-all-hosts-groups-handler" type="checkbox"> <label for="select-all-hosts-groups-handler"><span class="ot-label-txt">checkbox label</span></label> <span class="ot-label-status">label</span></div><div class="ot-chkbox" id="ot-selall-vencntr"><input id="select-all-vendor-groups-handler" type="checkbox"> <label for="select-all-vendor-groups-handler"><span class="ot-label-txt">checkbox label</span></label> <span class="ot-label-status">label</span></div><div class="ot-chkbox" id="ot-selall-licntr"><input id="select-all-vendor-leg-handler" type="checkbox"> <label for="select-all-vendor-leg-handler"><span class="ot-label-txt">checkbox label</span></label> <span class="ot-label-status">label</span></div></div></div></div><div class="ot-sdk-row"><div class="ot-sdk-column"><ul id="ot-host-lst"></ul></div></div></section></section><div class="ot-pc-footer ot-pc-scrollbar"><div class="ot-btn-container"> <button class="save-preference-btn-handler onetrust-close-btn-handler">Confirm my choices</button></div><!-- Footer logo --><div class="ot-pc-footer-logo"><a href="https://www.onetrust.com/products/cookie-consent/" target="_blank" rel="noopener noreferrer" aria-label="Powered by OneTrust Opens in a new Tab"><img alt="Powered by Onetrust" src="https://cdn.cookielaw.org/logos/static/powered_by_logo.svg" title="Powered by OneTrust Opens in a new Tab"></a></div></div><!-- Cookie subgroup container --><!-- Vendor list link --><!-- Cookie lost link --><!-- Toggle HTML element --><!-- Checkbox HTML --><!-- plus minus--><!-- Arrow SVG element --><!-- Accordion basic element --><span class="ot-scrn-rdr" aria-atomic="true" aria-live="polite"></span><!-- Vendor Service container and item template --></div><iframe class="ot-text-resize" sandbox="allow-same-origin" title="onetrust-text-resize" style="position: absolute; top: -50000px; width: 100em;" aria-hidden="true"></iframe></div></div><button aria-label="Feedback" type="button" id="_pendo-badge_9BcFvkCLLiElWp6hocDK3ZG6Z4E" data-layout="badgeBlank" class="_pendo-badge _pendo-badge_" style="z-index: 19000; margin: 0px; height: 32px; width: 128px; font-size: 0px; background: rgba(255, 255, 255, 0); padding: 0px; line-height: 1; min-width: auto; box-shadow: rgb(136, 136, 136) 0px 0px 0px 0px; border: 0px; float: none; vertical-align: baseline; cursor: pointer; position: absolute; top: 33665px; left: 912px;"><img id="pendo-image-badge-19b66351" src="https://pendo-static-5661679399600128.storage.googleapis.com/D_T2uHq_M1r-XQq8htU6Z3GjHfE/guide-media-75af8ddc-3c43-49fd-8836-cfc7e2c3ea60" alt="Feedback" data-_pendo-image-1="" class="_pendo-image _pendo-badge-image" style="display: block; height: 32px; width: 128px; box-shadow: rgb(136, 136, 136) 0px 0px 0px 0px; float: none; vertical-align: baseline;"></button></body></html>