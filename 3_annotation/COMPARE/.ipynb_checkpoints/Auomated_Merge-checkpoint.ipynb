{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "08ad8688",
   "metadata": {},
   "source": [
    "# Load Automated Annotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a1eeca19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded AffectNet - Test_face_analysis_results_anger with shape (1718, 5)\n",
      "Loaded AffectNet - Test_face_analysis_results_contempt with shape (1312, 5)\n",
      "Loaded AffectNet - Test_face_analysis_results_disgust with shape (1248, 5)\n",
      "Loaded AffectNet - Test_face_analysis_results_fear with shape (1664, 5)\n",
      "Loaded AffectNet - Test_face_analysis_results_happy with shape (2704, 5)\n",
      "Loaded AffectNet - Test_face_analysis_results_neutral with shape (2368, 5)\n",
      "Loaded AffectNet - Test_face_analysis_results_sad with shape (1584, 5)\n",
      "Loaded AffectNet - Test_face_analysis_results_surprise with shape (1920, 5)\n",
      "Loaded CK_face_analysis_results_anger_ck with shape (135, 5)\n",
      "Loaded CK_face_analysis_results_contempt_ck with shape (54, 5)\n",
      "Loaded CK_face_analysis_results_disgust_ck with shape (177, 5)\n",
      "Loaded CK_face_analysis_results_fear_ck with shape (75, 5)\n",
      "Loaded CK_face_analysis_results_happy_ck with shape (207, 5)\n",
      "Loaded CK_face_analysis_results_sadness_ck with shape (84, 5)\n",
      "Loaded CK_face_analysis_results_surprise_ck with shape (249, 5)\n",
      "Loaded FER2013_face_analysis_results_angry_fer with shape (958, 5)\n",
      "Loaded FER2013_face_analysis_results_disgust_fer with shape (111, 5)\n",
      "Loaded FER2013_face_analysis_results_fear_fer with shape (1024, 5)\n",
      "Loaded FER2013_face_analysis_results_happy_fer with shape (1774, 5)\n",
      "Loaded FER2013_face_analysis_results_neutral_fer with shape (1233, 5)\n",
      "Loaded FER2013_face_analysis_results_sad_fer with shape (1247, 5)\n",
      "Loaded FER2013_face_analysis_results_surprise_fer with shape (831, 5)\n",
      "Loaded JAFFE_face_analysis_results__jaffe with shape (213, 5)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# Dictionary to store DataFrames\n",
    "dataframes = {}\n",
    "\n",
    "# Root path where the results are stored\n",
    "root_path = \"../results\"\n",
    "\n",
    "# Walk through each subfolder and file in the root path\n",
    "for subdir, _, files in os.walk(root_path):\n",
    "    for file in files:\n",
    "        if file.endswith(\".csv\"):\n",
    "            # Create a unique name for each DataFrame based on subfolder and file name\n",
    "            relative_path = os.path.relpath(subdir, root_path)  # Get relative path for subfolder\n",
    "            df_name = f\"{relative_path}_{file.replace('.csv', '')}\".replace(os.sep, \"_\")\n",
    "            \n",
    "            # Read the CSV file into a DataFrame\n",
    "            file_path = os.path.join(subdir, file)\n",
    "            dataframes[df_name] = pd.read_csv(file_path)\n",
    "            \n",
    "            print(f\"Loaded {df_name} with shape {dataframes[df_name].shape}\")\n",
    "\n",
    "# Now each DataFrame can be accessed by its unique key in the dataframes dictionary\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a88a43d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Image</th>\n",
       "      <th>Age</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Race</th>\n",
       "      <th>Emotion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>_-_KA.AN1.39.tiff</td>\n",
       "      <td>25</td>\n",
       "      <td>Man</td>\n",
       "      <td>asian</td>\n",
       "      <td>disgust</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>_-_KA.AN2.40.tiff</td>\n",
       "      <td>25</td>\n",
       "      <td>Man</td>\n",
       "      <td>asian</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>_-_KA.AN3.41.tiff</td>\n",
       "      <td>25</td>\n",
       "      <td>Man</td>\n",
       "      <td>asian</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>_-_KA.DI1.42.tiff</td>\n",
       "      <td>26</td>\n",
       "      <td>Man</td>\n",
       "      <td>asian</td>\n",
       "      <td>sad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>_-_KA.DI2.43.tiff</td>\n",
       "      <td>26</td>\n",
       "      <td>Man</td>\n",
       "      <td>asian</td>\n",
       "      <td>sad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>208</th>\n",
       "      <td>_-_YM.SA2.56.tiff</td>\n",
       "      <td>30</td>\n",
       "      <td>Man</td>\n",
       "      <td>asian</td>\n",
       "      <td>sad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>209</th>\n",
       "      <td>_-_YM.SA3.57.tiff</td>\n",
       "      <td>30</td>\n",
       "      <td>Man</td>\n",
       "      <td>asian</td>\n",
       "      <td>sad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>210</th>\n",
       "      <td>_-_YM.SU1.58.tiff</td>\n",
       "      <td>28</td>\n",
       "      <td>Man</td>\n",
       "      <td>asian</td>\n",
       "      <td>surprise</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>211</th>\n",
       "      <td>_-_YM.SU2.59.tiff</td>\n",
       "      <td>30</td>\n",
       "      <td>Man</td>\n",
       "      <td>asian</td>\n",
       "      <td>surprise</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>212</th>\n",
       "      <td>_-_YM.SU3.60.tiff</td>\n",
       "      <td>30</td>\n",
       "      <td>Man</td>\n",
       "      <td>asian</td>\n",
       "      <td>surprise</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>213 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Image  Age Gender   Race   Emotion\n",
       "0    _-_KA.AN1.39.tiff   25    Man  asian   disgust\n",
       "1    _-_KA.AN2.40.tiff   25    Man  asian   neutral\n",
       "2    _-_KA.AN3.41.tiff   25    Man  asian   neutral\n",
       "3    _-_KA.DI1.42.tiff   26    Man  asian       sad\n",
       "4    _-_KA.DI2.43.tiff   26    Man  asian       sad\n",
       "..                 ...  ...    ...    ...       ...\n",
       "208  _-_YM.SA2.56.tiff   30    Man  asian       sad\n",
       "209  _-_YM.SA3.57.tiff   30    Man  asian       sad\n",
       "210  _-_YM.SU1.58.tiff   28    Man  asian  surprise\n",
       "211  _-_YM.SU2.59.tiff   30    Man  asian  surprise\n",
       "212  _-_YM.SU3.60.tiff   30    Man  asian  surprise\n",
       "\n",
       "[213 rows x 5 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataframes[\"JAFFE_face_analysis_results__jaffe\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7f73366c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Image</th>\n",
       "      <th>Age</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Race</th>\n",
       "      <th>Emotion</th>\n",
       "      <th>folderName</th>\n",
       "      <th>imageName</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>anger_-_image0000006.jpg</td>\n",
       "      <td>30</td>\n",
       "      <td>Woman</td>\n",
       "      <td>white</td>\n",
       "      <td>neutral</td>\n",
       "      <td>anger</td>\n",
       "      <td>image0000006.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>anger_-_image0000060.jpg</td>\n",
       "      <td>34</td>\n",
       "      <td>Man</td>\n",
       "      <td>white</td>\n",
       "      <td>neutral</td>\n",
       "      <td>anger</td>\n",
       "      <td>image0000060.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>anger_-_image0000061.jpg</td>\n",
       "      <td>44</td>\n",
       "      <td>Man</td>\n",
       "      <td>white</td>\n",
       "      <td>happy</td>\n",
       "      <td>anger</td>\n",
       "      <td>image0000061.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>anger_-_image0000066.jpg</td>\n",
       "      <td>49</td>\n",
       "      <td>Man</td>\n",
       "      <td>white</td>\n",
       "      <td>sad</td>\n",
       "      <td>anger</td>\n",
       "      <td>image0000066.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>anger_-_image0000106.jpg</td>\n",
       "      <td>30</td>\n",
       "      <td>Man</td>\n",
       "      <td>black</td>\n",
       "      <td>angry</td>\n",
       "      <td>anger</td>\n",
       "      <td>image0000106.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22885</th>\n",
       "      <td>_-_YM.SA2.56.tiff</td>\n",
       "      <td>30</td>\n",
       "      <td>Man</td>\n",
       "      <td>asian</td>\n",
       "      <td>sad</td>\n",
       "      <td></td>\n",
       "      <td>YM.SA2.56.tiff</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22886</th>\n",
       "      <td>_-_YM.SA3.57.tiff</td>\n",
       "      <td>30</td>\n",
       "      <td>Man</td>\n",
       "      <td>asian</td>\n",
       "      <td>sad</td>\n",
       "      <td></td>\n",
       "      <td>YM.SA3.57.tiff</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22887</th>\n",
       "      <td>_-_YM.SU1.58.tiff</td>\n",
       "      <td>28</td>\n",
       "      <td>Man</td>\n",
       "      <td>asian</td>\n",
       "      <td>surprise</td>\n",
       "      <td></td>\n",
       "      <td>YM.SU1.58.tiff</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22888</th>\n",
       "      <td>_-_YM.SU2.59.tiff</td>\n",
       "      <td>30</td>\n",
       "      <td>Man</td>\n",
       "      <td>asian</td>\n",
       "      <td>surprise</td>\n",
       "      <td></td>\n",
       "      <td>YM.SU2.59.tiff</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22889</th>\n",
       "      <td>_-_YM.SU3.60.tiff</td>\n",
       "      <td>30</td>\n",
       "      <td>Man</td>\n",
       "      <td>asian</td>\n",
       "      <td>surprise</td>\n",
       "      <td></td>\n",
       "      <td>YM.SU3.60.tiff</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>22890 rows Ã— 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                          Image  Age Gender   Race   Emotion folderName  \\\n",
       "0      anger_-_image0000006.jpg   30  Woman  white   neutral      anger   \n",
       "1      anger_-_image0000060.jpg   34    Man  white   neutral      anger   \n",
       "2      anger_-_image0000061.jpg   44    Man  white     happy      anger   \n",
       "3      anger_-_image0000066.jpg   49    Man  white       sad      anger   \n",
       "4      anger_-_image0000106.jpg   30    Man  black     angry      anger   \n",
       "...                         ...  ...    ...    ...       ...        ...   \n",
       "22885         _-_YM.SA2.56.tiff   30    Man  asian       sad              \n",
       "22886         _-_YM.SA3.57.tiff   30    Man  asian       sad              \n",
       "22887         _-_YM.SU1.58.tiff   28    Man  asian  surprise              \n",
       "22888         _-_YM.SU2.59.tiff   30    Man  asian  surprise              \n",
       "22889         _-_YM.SU3.60.tiff   30    Man  asian  surprise              \n",
       "\n",
       "              imageName  \n",
       "0      image0000006.jpg  \n",
       "1      image0000060.jpg  \n",
       "2      image0000061.jpg  \n",
       "3      image0000066.jpg  \n",
       "4      image0000106.jpg  \n",
       "...                 ...  \n",
       "22885    YM.SA2.56.tiff  \n",
       "22886    YM.SA3.57.tiff  \n",
       "22887    YM.SU1.58.tiff  \n",
       "22888    YM.SU2.59.tiff  \n",
       "22889    YM.SU3.60.tiff  \n",
       "\n",
       "[22890 rows x 7 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Create an empty list to hold modified DataFrames\n",
    "modified_dfs = []\n",
    "\n",
    "# Iterate over each DataFrame in the dictionary\n",
    "for df_name, df in dataframes.items():\n",
    "    # Split the 'Image' column at the first occurrence of \"_-_\" into 'folderName' and 'imageName'\n",
    "    split_image = df['Image'].str.split('_-_', n=1, expand=True)\n",
    "    df['folderName'] = split_image[0]\n",
    "    df['imageName'] = split_image[1]\n",
    "    \n",
    "    # Append the modified DataFrame to the list\n",
    "    modified_dfs.append(df)\n",
    "\n",
    "# Concatenate all modified DataFrames into a single DataFrame\n",
    "combined_df = pd.concat(modified_dfs, ignore_index=True)\n",
    "\n",
    "# Display the first few rows of the combined DataFrame to verify\n",
    "combined_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd0c3571",
   "metadata": {},
   "source": [
    "# 22890 all\n",
    "\n",
    "### AffectNet Test: 14,518 images\n",
    "### FER2013 Test: 7,178 images - Black and white (grayscale) images only.\n",
    "### CK (all images included): 981 images - Black and white (grayscale) images only.\n",
    "\n",
    "### JAFFE (all images) 213 images\n",
    "\n",
    "The JAFFE dataset was collected for controlled expression analysis rather than demographic diversity, so it lacks explicit demographic variability in age and ethnicity. This is a limitation when using JAFFE for tasks requiring diverse demographic information.\n",
    "\n",
    "Age: The JAFFE dataset generally includes images of adult women, but specific ages are not provided within the dataset itself. Itâ€™s often assumed that the subjects are adults, typically ranging from young to middle-aged.\n",
    "\n",
    "Gender: All individuals in the JAFFE dataset are female, as the dataset name itself specifies (\"Japanese Female Facial Expression\").\n",
    "\n",
    "Ethnicity: All subjects in the JAFFE dataset are of Japanese ethnicity, making the dataset homogeneous in terms of ethnicity."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1be041b",
   "metadata": {},
   "source": [
    "### Why Grayscale Images Are Unsuitable for Age, Gender, and Ethnicity Annotation\n",
    "\n",
    "Annotating age, gender, and ethnicity from grayscale (black and white) images is challenging and often unreliable due to the lack of color information. Color plays a crucial role in accurately assessing demographic attributes:\n",
    "\n",
    "Age Estimation: Age-related features like skin texture, wrinkles, and hair color are harder to discern without color. Grayscale images obscure these details, making it difficult to differentiate between similar age groups accurately.\n",
    "\n",
    "Gender Identification: Indicators such as makeup, lip color, and hair color, which can subtly signal gender, are lost in grayscale, reducing the accuracy of gender annotations.\n",
    "\n",
    "Ethnicity Identification: Ethnicity often relies on skin tone and undertones, which are absent in grayscale images. This makes it nearly impossible to distinguish between certain ethnic groups, leading to unreliable results.\n",
    "\n",
    "In summary, grayscale images lack the necessary detail to make accurate annotations of age, gender, and ethnicity, and attempting to do so may introduce significant bias and error into the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf82e614",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
