{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "texts = pd.read_csv('FullText_ALL.csv')\n",
    "texts.columns\n",
    "texts = texts[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                             Full_Text  \\\n",
      "1    3D Facial Expression Recognition Based on Auto...   \n",
      "2    3D Facial Expression Recognition Based on Prim...   \n",
      "6    BREUER,KIMMEL:ADEEPLEARNINGPERSPECTIVEONFACIAL...   \n",
      "7    1\\nA Deeper Look at Facial Expression Dataset ...   \n",
      "8    ## Title: BP4D-Spontaneous: a high-resolution ...   \n",
      "..                                                 ...   \n",
      "218  The Elements of End-to-end Deep Face Recogniti...   \n",
      "222  ## Title: Three convolutional neural network m...   \n",
      "224  TorontoCity: Seeing the World with a Million E...   \n",
      "225  AcceptedasaworkshopcontributionatICLR2015\\nTRA...   \n",
      "228  1\\nUtilizing Deep Learning Towards Multi-modal...   \n",
      "\n",
      "                                        Metric_Context  f1 score  accuracy  \\\n",
      "1    [An attractive scheme is that we have\\na large...         0         1   \n",
      "2    [v1,v2are the principal directions at\\npointp....         0         1   \n",
      "6    [We\\nuseOpenCV[4]forallimageoperations.\\n3 Res...         0         1   \n",
      "7    [However, as a byproduct trained\\nto express m...         0         1   \n",
      "8    [As a result, the lost-track error of pose is ...         0         1   \n",
      "..                                                 ...       ...       ...   \n",
      "218  [From the multi-task routine, we\\ncan see that...         0         1   \n",
      "222  [Other features, including Histograms of Orien...         0         1   \n",
      "224  [Left: panoramicview;right: top-downview. (TP:...         0         0   \n",
      "225  [Inallexperimentswefirstextractedspatial-pyram...         0         1   \n",
      "228  [There is also no baseline data present in\\nth...         0         1   \n",
      "\n",
      "     precision  recall  auc  mean squared error  r2 score  mae  \n",
      "1            0       0    0                   0         0    0  \n",
      "2            0       0    0                   0         0    0  \n",
      "6            0       0    0                   0         0    0  \n",
      "7            0       0    0                   0         0    0  \n",
      "8            0       0    1                   0         0    0  \n",
      "..         ...     ...  ...                 ...       ...  ...  \n",
      "218          0       0    1                   0         0    0  \n",
      "222          0       0    0                   0         0    0  \n",
      "224          1       1    0                   0         0    0  \n",
      "225          1       1    0                   0         0    0  \n",
      "228          0       0    0                   0         0    0  \n",
      "\n",
      "[115 rows x 10 columns]\n"
     ]
    }
   ],
   "source": [
    "# Define the list of metric keywords to search for\n",
    "metrics = [\"f1 score\", \"accuracy\", \"precision\", \"recall\", \"auc\", \"mean squared error\", \"r2 score\", \"mae\"]\n",
    "\n",
    "# Compile a regex pattern to search for any of the metric keywords, case insensitive\n",
    "pattern = re.compile(r'\\b(' + '|'.join(metrics) + r')\\b', re.IGNORECASE)\n",
    "\n",
    "# Function to extract surrounding sentences and detect presence of metrics\n",
    "def extract_context_and_detect_metrics(text):\n",
    "    # Return empty list and dictionary with zeros if text is NaN\n",
    "    if pd.isna(text):\n",
    "        return [], {metric: 0 for metric in metrics}\n",
    "    \n",
    "    # Split the text into sentences\n",
    "    sentences = re.split(r'(?<=[.!?]) +', text)\n",
    "    matches = []\n",
    "    metric_presence = {metric: 0 for metric in metrics}  # Dictionary to store 0 or 1 for each metric\n",
    "    \n",
    "    for i, sentence in enumerate(sentences):\n",
    "        # If the sentence contains any of the metrics\n",
    "        if pattern.search(sentence):\n",
    "            # Extract two sentences before and after\n",
    "            context = sentences[max(0, i - 2):min(len(sentences), i + 3)]\n",
    "            matches.append(\" \".join(context))\n",
    "            \n",
    "            # Check for each metric and mark as present (1)\n",
    "            for metric in metrics:\n",
    "                if re.search(r'\\b' + re.escape(metric) + r'\\b', sentence, re.IGNORECASE):\n",
    "                    metric_presence[metric] = 1\n",
    "    \n",
    "    return matches, metric_presence\n",
    "\n",
    "# Apply the function to the \"Full_Text\" column\n",
    "texts[['Metric_Context', 'Metric_Presence']] = texts['Full_Text'].apply(\n",
    "    lambda x: pd.Series(extract_context_and_detect_metrics(x))\n",
    ")\n",
    "\n",
    "# Split the Metric_Presence dictionary into individual columns\n",
    "metric_columns = pd.DataFrame(texts['Metric_Presence'].tolist(), index=texts.index)\n",
    "texts = pd.concat([texts, metric_columns], axis=1).drop(columns=['Metric_Presence'])\n",
    "\n",
    "# Filter out rows with no matches and display the resulting dataframe\n",
    "texts_with_context = texts[texts['Metric_Context'].apply(bool)]\n",
    "print(texts_with_context[['Full_Text', 'Metric_Context'] + metrics])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Unnamed: 0', 'ID', 'Title', 'Authors', 'Year', 'Cited By',\n",
      "       'Detected_Dataset', 'Detected_Topic', 'Abstract', 'Journal', 'URL',\n",
      "       'Full_Text', 'Metric_Context', 'f1 score', 'accuracy', 'precision',\n",
      "       'recall', 'auc', 'mean squared error', 'r2 score', 'mae'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(texts_with_context.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "texts_with_context.to_csv('full_text_with_metrics.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
