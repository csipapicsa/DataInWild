### TO Run:
1) Run the 6 notebooks in "data_collection" in ascending order and then the merge notebook. This creates 'Scrapes_All.csv' in the 1_scraping folder.
2) Run the notebooks in "full_text_extraction" in ascending order. This will produce 3 files in the "results" which contain the full texts from each source.
3) Run the "AllFullTextsTOCSV" notebook to merge the 3 files produced in the previous step into "FullText_ALL.csv" which will be under the "/1_scraping/" folder





### Folder structure

`dataset_finding`
- Has the notebooks and the data to produce the table of how many papers were found relating to our topic, 'Scrapes_All.csv'

`x_research_papers_save`
- Contains the notebooks and all the data in order to get the full texts from the papers we found in 'Scrapes_All.csv'

 `x_research_papers_save\1_raw_files`
 - contains papers in html from science direct


```
 ðŸ“¦1_scraping
 â”£ ðŸ“‚1_scrapers
 â”£ ðŸ“‚xx_results
 â”ƒ â”— ðŸ“œ01_scraped_papers.csv
 â”£ ðŸ“‚x_research_papers_save
 â”ƒ â”£ ðŸ“‚1_raw_files
 â”ƒ â”£ ðŸ“œ01_scraper_science_direct.ipynb
 â”ƒ â”£ ðŸ“œheaders.py
 â”ƒ â”— ðŸ“œsciencedirect_papers_status.csv
 â”£ ðŸ“œnothing.txt
 â”— ðŸ“œREADME.md
```
