{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "39c2f167",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd452b32",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = 'FullText_ALL.csv'\n",
    "FullText_df = pd.read_csv(file_path)\n",
    "FullText_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91184e47",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample dataframe containing the text data\n",
    "# Replace this with the actual dataframe column as per your case\n",
    "df = FullText_df.copy()\n",
    "\n",
    "def clean_text(text):\n",
    "    # Return NaN if text is empty or placeholder\n",
    "    if text is np.nan or text == \"Nothing found\":\n",
    "        return np.nan\n",
    "\n",
    "    # Remove common metadata patterns and unwanted sections\n",
    "    # Adjust regex patterns based on your files' content\n",
    "    text = re.sub(r'\\b(References|Cited by|Acknowledgments|Table of Contents|Outline|Figure \\d+|Table \\d+|DOI: .*)', '', text, flags=re.IGNORECASE)\n",
    "    text = re.sub(r'##?\\s?Title:.*?\\n', '', text)  # Remove lines that start with '## Title:'\n",
    "    text = re.sub(r'https?://\\S+|www\\.\\S+', '', text)  # Remove URLs\n",
    "\n",
    "    # Remove special characters and multiple spaces\n",
    "    text = re.sub(r'\\n+', ' ', text)  # Replace newlines with space\n",
    "    text = re.sub(r'\\s+', ' ', text)  # Replace multiple spaces with a single space\n",
    "    text = re.sub(r'\\s*Figure\\s*\\d+\\s*', '', text)  # Remove figure references\n",
    "    text = re.sub(r'\\s*Table\\s*\\d+\\s*', '', text)  # Remove table references\n",
    "\n",
    "    # Trim any leading or trailing whitespace\n",
    "    text = text.strip()\n",
    "    \n",
    "    # Remove line breaks and excessive whitespace\n",
    "    text = re.sub(r'\\s+', ' ', text)\n",
    "\n",
    "    return text\n",
    "\n",
    "# Apply the cleaning function to the Full_Text column\n",
    "df['Full_Text'] = df['Full_Text'].apply(clean_text)\n",
    "\n",
    "# Display the cleaned texts\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13aec349",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_no_nan = df.dropna(subset=['Full_Text'])\n",
    "df_no_nan['Text_Length'] = df_no_nan['Full_Text'].apply(len)\n",
    "\n",
    "# Plotting\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(df_no_nan.index, df_no_nan['Text_Length'], marker='o', linestyle='-')\n",
    "plt.title('Length of Full Text Entries (Non-NaN Only)')\n",
    "plt.xlabel('Row Index')\n",
    "plt.ylabel('Text Length (in characters)')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef947a0d",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Filter rows in df_no_nan where the length of 'Full_Text' is zero\n",
    "empty_text_rows = df_no_nan[df_no_nan['Text_Length'] <= 10000]\n",
    "\n",
    "# Display the filtered rows\n",
    "empty_text_rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8b35c46",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_no_nan.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f861b22",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Filter to find rows from each source by looking at URL patterns\n",
    "ieee_examples = df_no_nan[df_no_nan['URL'].str.contains(\"ieee\", case=False)]['Full_Text'].dropna().iloc[:1].tolist()\n",
    "arxiv_examples = df_no_nan[df_no_nan['URL'].str.contains(\"arxiv\", case=False)]['Full_Text'].dropna().iloc[:1].tolist()\n",
    "sd_examples = df_no_nan[df_no_nan['URL'].str.contains(\"sciencedirect\", case=False)]['Full_Text'].dropna().iloc[:1].tolist()\n",
    "\n",
    "# Create a new dataframe to show examples side-by-side\n",
    "examples_df = pd.DataFrame({\n",
    "    'IEEE Texts': ieee_examples,\n",
    "    'Arxiv Texts': arxiv_examples,\n",
    "    'ScienceDirect Texts': sd_examples\n",
    "})\n",
    "\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "\n",
    "examples_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89e27dee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the list of metric keywords to search for\n",
    "metrics = [\"f1 score\", \"accuracy\", \"precision\", \"recall\", \"auc\", \"mean squared error\", \"r2 score\", \"mae\"]\n",
    "\n",
    "# Compile a regex pattern to search for any of the metric keywords, case insensitive\n",
    "pattern = re.compile(r'\\b(' + '|'.join(metrics) + r')\\b', re.IGNORECASE)\n",
    "\n",
    "# Function to extract surrounding sentences and detect presence of metrics\n",
    "def extract_context_and_detect_metrics(text):\n",
    "    # Return empty list and dictionary with zeros if text is NaN\n",
    "    if pd.isna(text):\n",
    "        return [], {metric: 0 for metric in metrics}\n",
    "    \n",
    "    # Split the text into sentences\n",
    "    sentences = re.split(r'(?<=[.!?]) +', text)\n",
    "    matches = []\n",
    "    metric_presence = {metric: 0 for metric in metrics}  # Dictionary to store 0 or 1 for each metric\n",
    "    \n",
    "    for i, sentence in enumerate(sentences):\n",
    "        # If the sentence contains any of the metrics\n",
    "        if pattern.search(sentence):\n",
    "            # Extract two sentences before and after\n",
    "            context = sentences[max(0, i - 2):min(len(sentences), i + 3)]\n",
    "            matches.append(\" \".join(context))\n",
    "            \n",
    "            # Check for each metric and mark as present (1)\n",
    "            for metric in metrics:\n",
    "                if re.search(r'\\b' + re.escape(metric) + r'\\b', sentence, re.IGNORECASE):\n",
    "                    metric_presence[metric] = 1\n",
    "    \n",
    "    return matches, metric_presence\n",
    "\n",
    "# Apply the function to the \"Full_Text\" column\n",
    "FullText_df[['Metric_Context', 'Metric_Presence']] = FullText_df['Full_Text'].apply(\n",
    "    lambda x: pd.Series(extract_context_and_detect_metrics(x))\n",
    ")\n",
    "\n",
    "# Split the Metric_Presence dictionary into individual columns\n",
    "metric_columns = pd.DataFrame(FullText_df['Metric_Presence'].tolist(), index=FullText_df.index)\n",
    "texts = pd.concat([FullText_df, metric_columns], axis=1).drop(columns=['Metric_Presence'])\n",
    "\n",
    "# Filter out rows with no matches and display the resulting dataframe\n",
    "texts_with_context = texts[texts['Metric_Context'].apply(bool)]\n",
    "print(texts_with_context[['Full_Text', 'Metric_Context'] + metrics])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9685f696",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b27d1234",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
