<html lang="en-US"><head>
<meta name="citation_pii" content="S0925231220309838">
<meta name="citation_issn" content="0925-2312">
<meta name="citation_volume" content="411">
<meta name="citation_lastpage" content="350">
<meta name="citation_publisher" content="Elsevier">
<meta name="citation_firstpage" content="340">
<meta name="citation_journal_title" content="Neurocomputing">
<meta name="citation_type" content="JOUR">
<meta name="citation_doi" content="10.1016/j.neucom.2020.06.014">
<meta name="dc.identifier" content="10.1016/j.neucom.2020.06.014">
<meta name="citation_article_type" content="Full-length article">
<meta property="og:description" content="Facial expression recognition is a hot research topic and can be applied in many computer vision fields, such as human–computer interaction, affective…">
<meta property="og:image" content="https://ars.els-cdn.com/content/image/1-s2.0-S0925231220X00336-cov150h.gif">
<meta name="citation_title" content="Attention mechanism-based CNN for facial expression recognition">
<meta property="og:title" content="Attention mechanism-based CNN for facial expression recognition">
<meta name="citation_publication_date" content="2020/10/21">
<meta name="citation_online_date" content="2020/06/12">
<meta name="robots" content="INDEX,FOLLOW,NOARCHIVE,NOCACHE,NOODP,NOYDIR">
<title>Attention mechanism-based CNN for facial expression recognition - ScienceDirect</title>
<link rel="canonical" href="https://www.sciencedirect.com/science/article/pii/S0925231220309838">
<meta property="og:type" content="article">
<meta name="viewport" content="initial-scale=1">
<meta name="SDTech" content="Proudly brought to you by the SD Technology team">
<script async="" src="https://cdn.pendo.io/agent/static/d6c1d995-bc7e-4e53-77f1-2ea4ecbb9565/pendo.js"></script><script type="text/javascript">(function newRelicBrowserProSPA() {
  ;
  window.NREUM || (NREUM = {});
  NREUM.init = {
    privacy: {
      cookies_enabled: true
    },
    ajax: {
      deny_list: ["bam-cell.nr-data.net"]
    }
  };
  ;
  NREUM.loader_config = {
    accountID: "2128461",
    trustKey: "2038175",
    agentID: "1118783207",
    licenseKey: "7ac4127487",
    applicationID: "814813181"
  };
  ;
  NREUM.info = {
    beacon: "bam.nr-data.net",
    errorBeacon: "bam.nr-data.net",
    licenseKey: "7ac4127487",
    applicationID: "814813181",
    sa: 1
  };
  ; /*! For license information please see nr-loader-spa-1.238.0.min.js.LICENSE.txt */
  (() => {
    "use strict";

    var e,
      t,
      r = {
        5763: (e, t, r) => {
          r.d(t, {
            P_: () => f,
            Mt: () => p,
            C5: () => s,
            DL: () => v,
            OP: () => T,
            lF: () => D,
            Yu: () => y,
            Dg: () => h,
            CX: () => c,
            GE: () => b,
            sU: () => _
          });
          var n = r(8632),
            i = r(9567);
          const o = {
              beacon: n.ce.beacon,
              errorBeacon: n.ce.errorBeacon,
              licenseKey: void 0,
              applicationID: void 0,
              sa: void 0,
              queueTime: void 0,
              applicationTime: void 0,
              ttGuid: void 0,
              user: void 0,
              account: void 0,
              product: void 0,
              extra: void 0,
              jsAttributes: {},
              userAttributes: void 0,
              atts: void 0,
              transactionName: void 0,
              tNamePlain: void 0
            },
            a = {};
          function s(e) {
            if (!e) throw new Error("All info objects require an agent identifier!");
            if (!a[e]) throw new Error("Info for ".concat(e, " was never set"));
            return a[e];
          }
          function c(e, t) {
            if (!e) throw new Error("All info objects require an agent identifier!");
            a[e] = (0, i.D)(t, o), (0, n.Qy)(e, a[e], "info");
          }
          var u = r(7056);
          const d = () => {
              const e = {
                blockSelector: "[data-nr-block]",
                maskInputOptions: {
                  password: !0
                }
              };
              return {
                allow_bfcache: !0,
                privacy: {
                  cookies_enabled: !0
                },
                ajax: {
                  deny_list: void 0,
                  block_internal: !0,
                  enabled: !0,
                  harvestTimeSeconds: 10
                },
                distributed_tracing: {
                  enabled: void 0,
                  exclude_newrelic_header: void 0,
                  cors_use_newrelic_header: void 0,
                  cors_use_tracecontext_headers: void 0,
                  allowed_origins: void 0
                },
                session: {
                  domain: void 0,
                  expiresMs: u.oD,
                  inactiveMs: u.Hb
                },
                ssl: void 0,
                obfuscate: void 0,
                jserrors: {
                  enabled: !0,
                  harvestTimeSeconds: 10
                },
                metrics: {
                  enabled: !0
                },
                page_action: {
                  enabled: !0,
                  harvestTimeSeconds: 30
                },
                page_view_event: {
                  enabled: !0
                },
                page_view_timing: {
                  enabled: !0,
                  harvestTimeSeconds: 30,
                  long_task: !1
                },
                session_trace: {
                  enabled: !0,
                  harvestTimeSeconds: 10
                },
                harvest: {
                  tooManyRequestsDelay: 60
                },
                session_replay: {
                  enabled: !1,
                  harvestTimeSeconds: 60,
                  sampleRate: .1,
                  errorSampleRate: .1,
                  maskTextSelector: "*",
                  maskAllInputs: !0,
                  get blockClass() {
                    return "nr-block";
                  },
                  get ignoreClass() {
                    return "nr-ignore";
                  },
                  get maskTextClass() {
                    return "nr-mask";
                  },
                  get blockSelector() {
                    return e.blockSelector;
                  },
                  set blockSelector(t) {
                    e.blockSelector += ",".concat(t);
                  },
                  get maskInputOptions() {
                    return e.maskInputOptions;
                  },
                  set maskInputOptions(t) {
                    e.maskInputOptions = {
                      ...t,
                      password: !0
                    };
                  }
                },
                spa: {
                  enabled: !0,
                  harvestTimeSeconds: 10
                }
              };
            },
            l = {};
          function f(e) {
            if (!e) throw new Error("All configuration objects require an agent identifier!");
            if (!l[e]) throw new Error("Configuration for ".concat(e, " was never set"));
            return l[e];
          }
          function h(e, t) {
            if (!e) throw new Error("All configuration objects require an agent identifier!");
            l[e] = (0, i.D)(t, d()), (0, n.Qy)(e, l[e], "config");
          }
          function p(e, t) {
            if (!e) throw new Error("All configuration objects require an agent identifier!");
            var r = f(e);
            if (r) {
              for (var n = t.split("."), i = 0; i < n.length - 1; i++) if ("object" != typeof (r = r[n[i]])) return;
              r = r[n[n.length - 1]];
            }
            return r;
          }
          const g = {
              accountID: void 0,
              trustKey: void 0,
              agentID: void 0,
              licenseKey: void 0,
              applicationID: void 0,
              xpid: void 0
            },
            m = {};
          function v(e) {
            if (!e) throw new Error("All loader-config objects require an agent identifier!");
            if (!m[e]) throw new Error("LoaderConfig for ".concat(e, " was never set"));
            return m[e];
          }
          function b(e, t) {
            if (!e) throw new Error("All loader-config objects require an agent identifier!");
            m[e] = (0, i.D)(t, g), (0, n.Qy)(e, m[e], "loader_config");
          }
          const y = (0, n.mF)().o;
          var w = r(385),
            A = r(6818);
          const x = {
              buildEnv: A.Re,
              bytesSent: {},
              queryBytesSent: {},
              customTransaction: void 0,
              disabled: !1,
              distMethod: A.gF,
              isolatedBacklog: !1,
              loaderType: void 0,
              maxBytes: 3e4,
              offset: Math.floor(w._A?.performance?.timeOrigin || w._A?.performance?.timing?.navigationStart || Date.now()),
              onerror: void 0,
              origin: "" + w._A.location,
              ptid: void 0,
              releaseIds: {},
              session: void 0,
              xhrWrappable: "function" == typeof w._A.XMLHttpRequest?.prototype?.addEventListener,
              version: A.q4,
              denyList: void 0
            },
            E = {};
          function T(e) {
            if (!e) throw new Error("All runtime objects require an agent identifier!");
            if (!E[e]) throw new Error("Runtime for ".concat(e, " was never set"));
            return E[e];
          }
          function _(e, t) {
            if (!e) throw new Error("All runtime objects require an agent identifier!");
            E[e] = (0, i.D)(t, x), (0, n.Qy)(e, E[e], "runtime");
          }
          function D(e) {
            return function (e) {
              try {
                const t = s(e);
                return !!t.licenseKey && !!t.errorBeacon && !!t.applicationID;
              } catch (e) {
                return !1;
              }
            }(e);
          }
        },
        9567: (e, t, r) => {
          r.d(t, {
            D: () => i
          });
          var n = r(50);
          function i(e, t) {
            try {
              if (!e || "object" != typeof e) return (0, n.Z)("Setting a Configurable requires an object as input");
              if (!t || "object" != typeof t) return (0, n.Z)("Setting a Configurable requires a model to set its initial properties");
              const r = Object.create(Object.getPrototypeOf(t), Object.getOwnPropertyDescriptors(t)),
                o = 0 === Object.keys(r).length ? e : r;
              for (let a in o) if (void 0 !== e[a]) try {
                "object" == typeof e[a] && "object" == typeof t[a] ? r[a] = i(e[a], t[a]) : r[a] = e[a];
              } catch (e) {
                (0, n.Z)("An error occurred while setting a property of a Configurable", e);
              }
              return r;
            } catch (e) {
              (0, n.Z)("An error occured while setting a Configurable", e);
            }
          }
        },
        6818: (e, t, r) => {
          r.d(t, {
            Re: () => i,
            gF: () => o,
            q4: () => n
          });
          const n = "1.238.0",
            i = "PROD",
            o = "CDN";
        },
        385: (e, t, r) => {
          r.d(t, {
            FN: () => a,
            IF: () => u,
            Nk: () => l,
            Tt: () => s,
            _A: () => o,
            il: () => n,
            pL: () => c,
            v6: () => i,
            w1: () => d
          });
          const n = "undefined" != typeof window && !!window.document,
            i = "undefined" != typeof WorkerGlobalScope && ("undefined" != typeof self && self instanceof WorkerGlobalScope && self.navigator instanceof WorkerNavigator || "undefined" != typeof globalThis && globalThis instanceof WorkerGlobalScope && globalThis.navigator instanceof WorkerNavigator),
            o = n ? window : "undefined" != typeof WorkerGlobalScope && ("undefined" != typeof self && self instanceof WorkerGlobalScope && self || "undefined" != typeof globalThis && globalThis instanceof WorkerGlobalScope && globalThis),
            a = "" + o?.location,
            s = /iPad|iPhone|iPod/.test(navigator.userAgent),
            c = s && "undefined" == typeof SharedWorker,
            u = (() => {
              const e = navigator.userAgent.match(/Firefox[/\s](\d+\.\d+)/);
              return Array.isArray(e) && e.length >= 2 ? +e[1] : 0;
            })(),
            d = Boolean(n && window.document.documentMode),
            l = !!navigator.sendBeacon;
        },
        1117: (e, t, r) => {
          r.d(t, {
            w: () => o
          });
          var n = r(50);
          const i = {
            agentIdentifier: "",
            ee: void 0
          };
          class o {
            constructor(e) {
              try {
                if ("object" != typeof e) return (0, n.Z)("shared context requires an object as input");
                this.sharedContext = {}, Object.assign(this.sharedContext, i), Object.entries(e).forEach(e => {
                  let [t, r] = e;
                  Object.keys(i).includes(t) && (this.sharedContext[t] = r);
                });
              } catch (e) {
                (0, n.Z)("An error occured while setting SharedContext", e);
              }
            }
          }
        },
        8e3: (e, t, r) => {
          r.d(t, {
            L: () => d,
            R: () => c
          });
          var n = r(8325),
            i = r(1284),
            o = r(4322),
            a = r(3325);
          const s = {};
          function c(e, t) {
            const r = {
              staged: !1,
              priority: a.p[t] || 0
            };
            u(e), s[e].get(t) || s[e].set(t, r);
          }
          function u(e) {
            e && (s[e] || (s[e] = new Map()));
          }
          function d() {
            let e = arguments.length > 0 && void 0 !== arguments[0] ? arguments[0] : "",
              t = arguments.length > 1 && void 0 !== arguments[1] ? arguments[1] : "feature";
            if (u(e), !e || !s[e].get(t)) return a(t);
            s[e].get(t).staged = !0;
            const r = [...s[e]];
            function a(t) {
              const r = e ? n.ee.get(e) : n.ee,
                a = o.X.handlers;
              if (r.backlog && a) {
                var s = r.backlog[t],
                  c = a[t];
                if (c) {
                  for (var u = 0; s && u < s.length; ++u) l(s[u], c);
                  (0, i.D)(c, function (e, t) {
                    (0, i.D)(t, function (t, r) {
                      r[0].on(e, r[1]);
                    });
                  });
                }
                delete a[t], r.backlog[t] = null, r.emit("drain-" + t, []);
              }
            }
            r.every(e => {
              let [t, r] = e;
              return r.staged;
            }) && (r.sort((e, t) => e[1].priority - t[1].priority), r.forEach(e => {
              let [t] = e;
              a(t);
            }));
          }
          function l(e, t) {
            var r = e[1];
            (0, i.D)(t[r], function (t, r) {
              var n = e[0];
              if (r[0] === n) {
                var i = r[1],
                  o = e[3],
                  a = e[2];
                i.apply(o, a);
              }
            });
          }
        },
        8325: (e, t, r) => {
          r.d(t, {
            A: () => c,
            ee: () => u
          });
          var n = r(8632),
            i = r(2210),
            o = r(5763);
          class a {
            constructor(e) {
              this.contextId = e;
            }
          }
          var s = r(3117);
          const c = "nr@context:".concat(s.a),
            u = function e(t, r) {
              var n = {},
                s = {},
                d = {},
                f = !1;
              try {
                f = 16 === r.length && (0, o.OP)(r).isolatedBacklog;
              } catch (e) {}
              var h = {
                on: g,
                addEventListener: g,
                removeEventListener: function (e, t) {
                  var r = n[e];
                  if (!r) return;
                  for (var i = 0; i < r.length; i++) r[i] === t && r.splice(i, 1);
                },
                emit: function (e, r, n, i, o) {
                  !1 !== o && (o = !0);
                  if (u.aborted && !i) return;
                  t && o && t.emit(e, r, n);
                  for (var a = p(n), c = m(e), d = c.length, l = 0; l < d; l++) c[l].apply(a, r);
                  var f = b()[s[e]];
                  f && f.push([h, e, r, a]);
                  return a;
                },
                get: v,
                listeners: m,
                context: p,
                buffer: function (e, t) {
                  const r = b();
                  if (t = t || "feature", h.aborted) return;
                  Object.entries(e || {}).forEach(e => {
                    let [n, i] = e;
                    s[i] = t, t in r || (r[t] = []);
                  });
                },
                abort: l,
                aborted: !1,
                isBuffering: function (e) {
                  return !!b()[s[e]];
                },
                debugId: r,
                backlog: f ? {} : t && "object" == typeof t.backlog ? t.backlog : {}
              };
              return h;
              function p(e) {
                return e && e instanceof a ? e : e ? (0, i.X)(e, c, () => new a(c)) : new a(c);
              }
              function g(e, t) {
                n[e] = m(e).concat(t);
              }
              function m(e) {
                return n[e] || [];
              }
              function v(t) {
                return d[t] = d[t] || e(h, t);
              }
              function b() {
                return h.backlog;
              }
            }(void 0, "globalEE"),
            d = (0, n.fP)();
          function l() {
            u.aborted = !0, u.backlog = {};
          }
          d.ee || (d.ee = u);
        },
        5546: (e, t, r) => {
          r.d(t, {
            E: () => n,
            p: () => i
          });
          var n = r(8325).ee.get("handle");
          function i(e, t, r, i, o) {
            o ? (o.buffer([e], i), o.emit(e, t, r)) : (n.buffer([e], i), n.emit(e, t, r));
          }
        },
        4322: (e, t, r) => {
          r.d(t, {
            X: () => o
          });
          var n = r(5546);
          o.on = a;
          var i = o.handlers = {};
          function o(e, t, r, o) {
            a(o || n.E, i, e, t, r);
          }
          function a(e, t, r, i, o) {
            o || (o = "feature"), e || (e = n.E);
            var a = t[o] = t[o] || {};
            (a[r] = a[r] || []).push([e, i]);
          }
        },
        3239: (e, t, r) => {
          r.d(t, {
            bP: () => s,
            iz: () => c,
            m$: () => a
          });
          var n = r(385);
          let i = !1,
            o = !1;
          try {
            const e = {
              get passive() {
                return i = !0, !1;
              },
              get signal() {
                return o = !0, !1;
              }
            };
            n._A.addEventListener("test", null, e), n._A.removeEventListener("test", null, e);
          } catch (e) {}
          function a(e, t) {
            return i || o ? {
              capture: !!e,
              passive: i,
              signal: t
            } : !!e;
          }
          function s(e, t) {
            let r = arguments.length > 2 && void 0 !== arguments[2] && arguments[2],
              n = arguments.length > 3 ? arguments[3] : void 0;
            window.addEventListener(e, t, a(r, n));
          }
          function c(e, t) {
            let r = arguments.length > 2 && void 0 !== arguments[2] && arguments[2],
              n = arguments.length > 3 ? arguments[3] : void 0;
            document.addEventListener(e, t, a(r, n));
          }
        },
        3117: (e, t, r) => {
          r.d(t, {
            a: () => n
          });
          const n = (0, r(4402).Rl)();
        },
        4402: (e, t, r) => {
          r.d(t, {
            Ht: () => u,
            M: () => c,
            Rl: () => a,
            ky: () => s
          });
          var n = r(385);
          const i = "xxxxxxxx-xxxx-4xxx-yxxx-xxxxxxxxxxxx";
          function o(e, t) {
            return e ? 15 & e[t] : 16 * Math.random() | 0;
          }
          function a() {
            const e = n._A?.crypto || n._A?.msCrypto;
            let t,
              r = 0;
            return e && e.getRandomValues && (t = e.getRandomValues(new Uint8Array(31))), i.split("").map(e => "x" === e ? o(t, ++r).toString(16) : "y" === e ? (3 & o() | 8).toString(16) : e).join("");
          }
          function s(e) {
            const t = n._A?.crypto || n._A?.msCrypto;
            let r,
              i = 0;
            t && t.getRandomValues && (r = t.getRandomValues(new Uint8Array(31)));
            const a = [];
            for (var s = 0; s < e; s++) a.push(o(r, ++i).toString(16));
            return a.join("");
          }
          function c() {
            return s(16);
          }
          function u() {
            return s(32);
          }
        },
        7056: (e, t, r) => {
          r.d(t, {
            Bq: () => n,
            Hb: () => o,
            oD: () => i
          });
          const n = "NRBA",
            i = 144e5,
            o = 18e5;
        },
        7894: (e, t, r) => {
          function n() {
            return Math.round(performance.now());
          }
          r.d(t, {
            z: () => n
          });
        },
        7243: (e, t, r) => {
          r.d(t, {
            e: () => o
          });
          var n = r(385),
            i = {};
          function o(e) {
            if (e in i) return i[e];
            if (0 === (e || "").indexOf("data:")) return {
              protocol: "data"
            };
            let t;
            var r = n._A?.location,
              o = {};
            if (n.il) t = document.createElement("a"), t.href = e;else try {
              t = new URL(e, r.href);
            } catch (e) {
              return o;
            }
            o.port = t.port;
            var a = t.href.split("://");
            !o.port && a[1] && (o.port = a[1].split("/")[0].split("@").pop().split(":")[1]), o.port && "0" !== o.port || (o.port = "https" === a[0] ? "443" : "80"), o.hostname = t.hostname || r.hostname, o.pathname = t.pathname, o.protocol = a[0], "/" !== o.pathname.charAt(0) && (o.pathname = "/" + o.pathname);
            var s = !t.protocol || ":" === t.protocol || t.protocol === r.protocol,
              c = t.hostname === r.hostname && t.port === r.port;
            return o.sameOrigin = s && (!t.hostname || c), "/" === o.pathname && (i[e] = o), o;
          }
        },
        50: (e, t, r) => {
          function n(e, t) {
            "function" == typeof console.warn && (console.warn("New Relic: ".concat(e)), t && console.warn(t));
          }
          r.d(t, {
            Z: () => n
          });
        },
        2587: (e, t, r) => {
          r.d(t, {
            N: () => c,
            T: () => u
          });
          var n = r(8325),
            i = r(5546),
            o = r(8e3),
            a = r(3325);
          const s = {
            stn: [a.D.sessionTrace],
            err: [a.D.jserrors, a.D.metrics],
            ins: [a.D.pageAction],
            spa: [a.D.spa],
            sr: [a.D.sessionReplay, a.D.sessionTrace]
          };
          function c(e, t) {
            const r = n.ee.get(t);
            e && "object" == typeof e && (Object.entries(e).forEach(e => {
              let [t, n] = e;
              void 0 === u[t] && (s[t] ? s[t].forEach(e => {
                n ? (0, i.p)("feat-" + t, [], void 0, e, r) : (0, i.p)("block-" + t, [], void 0, e, r), (0, i.p)("rumresp-" + t, [Boolean(n)], void 0, e, r);
              }) : n && (0, i.p)("feat-" + t, [], void 0, void 0, r), u[t] = Boolean(n));
            }), Object.keys(s).forEach(e => {
              void 0 === u[e] && (s[e]?.forEach(t => (0, i.p)("rumresp-" + e, [!1], void 0, t, r)), u[e] = !1);
            }), (0, o.L)(t, a.D.pageViewEvent));
          }
          const u = {};
        },
        2210: (e, t, r) => {
          r.d(t, {
            X: () => i
          });
          var n = Object.prototype.hasOwnProperty;
          function i(e, t, r) {
            if (n.call(e, t)) return e[t];
            var i = r();
            if (Object.defineProperty && Object.keys) try {
              return Object.defineProperty(e, t, {
                value: i,
                writable: !0,
                enumerable: !1
              }), i;
            } catch (e) {}
            return e[t] = i, i;
          }
        },
        1284: (e, t, r) => {
          r.d(t, {
            D: () => n
          });
          const n = (e, t) => Object.entries(e || {}).map(e => {
            let [r, n] = e;
            return t(r, n);
          });
        },
        4351: (e, t, r) => {
          r.d(t, {
            P: () => o
          });
          var n = r(8325);
          const i = () => {
            const e = new WeakSet();
            return (t, r) => {
              if ("object" == typeof r && null !== r) {
                if (e.has(r)) return;
                e.add(r);
              }
              return r;
            };
          };
          function o(e) {
            try {
              return JSON.stringify(e, i());
            } catch (e) {
              try {
                n.ee.emit("internal-error", [e]);
              } catch (e) {}
            }
          }
        },
        3960: (e, t, r) => {
          r.d(t, {
            K: () => a,
            b: () => o
          });
          var n = r(3239);
          function i() {
            return "undefined" == typeof document || "complete" === document.readyState;
          }
          function o(e, t) {
            if (i()) return e();
            (0, n.bP)("load", e, t);
          }
          function a(e) {
            if (i()) return e();
            (0, n.iz)("DOMContentLoaded", e);
          }
        },
        8632: (e, t, r) => {
          r.d(t, {
            EZ: () => u,
            Qy: () => c,
            ce: () => o,
            fP: () => a,
            gG: () => d,
            mF: () => s
          });
          var n = r(7894),
            i = r(385);
          const o = {
            beacon: "bam.nr-data.net",
            errorBeacon: "bam.nr-data.net"
          };
          function a() {
            return i._A.NREUM || (i._A.NREUM = {}), void 0 === i._A.newrelic && (i._A.newrelic = i._A.NREUM), i._A.NREUM;
          }
          function s() {
            let e = a();
            return e.o || (e.o = {
              ST: i._A.setTimeout,
              SI: i._A.setImmediate,
              CT: i._A.clearTimeout,
              XHR: i._A.XMLHttpRequest,
              REQ: i._A.Request,
              EV: i._A.Event,
              PR: i._A.Promise,
              MO: i._A.MutationObserver,
              FETCH: i._A.fetch
            }), e;
          }
          function c(e, t, r) {
            let i = a();
            const o = i.initializedAgents || {},
              s = o[e] || {};
            return Object.keys(s).length || (s.initializedAt = {
              ms: (0, n.z)(),
              date: new Date()
            }), i.initializedAgents = {
              ...o,
              [e]: {
                ...s,
                [r]: t
              }
            }, i;
          }
          function u(e, t) {
            a()[e] = t;
          }
          function d() {
            return function () {
              let e = a();
              const t = e.info || {};
              e.info = {
                beacon: o.beacon,
                errorBeacon: o.errorBeacon,
                ...t
              };
            }(), function () {
              let e = a();
              const t = e.init || {};
              e.init = {
                ...t
              };
            }(), s(), function () {
              let e = a();
              const t = e.loader_config || {};
              e.loader_config = {
                ...t
              };
            }(), a();
          }
        },
        7956: (e, t, r) => {
          r.d(t, {
            N: () => i
          });
          var n = r(3239);
          function i(e) {
            let t = arguments.length > 1 && void 0 !== arguments[1] && arguments[1],
              r = arguments.length > 2 ? arguments[2] : void 0,
              i = arguments.length > 3 ? arguments[3] : void 0;
            return void (0, n.iz)("visibilitychange", function () {
              if (t) return void ("hidden" == document.visibilityState && e());
              e(document.visibilityState);
            }, r, i);
          }
        },
        1214: (e, t, r) => {
          r.d(t, {
            em: () => b,
            u5: () => j,
            QU: () => O,
            _L: () => I,
            Gm: () => H,
            Lg: () => L,
            BV: () => G,
            Kf: () => K
          });
          var n = r(8325),
            i = r(3117);
          const o = "nr@original:".concat(i.a);
          var a = Object.prototype.hasOwnProperty,
            s = !1;
          function c(e, t) {
            return e || (e = n.ee), r.inPlace = function (e, t, n, i, o) {
              n || (n = "");
              const a = "-" === n.charAt(0);
              for (let s = 0; s < t.length; s++) {
                const c = t[s],
                  u = e[c];
                d(u) || (e[c] = r(u, a ? c + n : n, i, c, o));
              }
            }, r.flag = o, r;
            function r(t, r, n, s, c) {
              return d(t) ? t : (r || (r = ""), nrWrapper[o] = t, function (e, t, r) {
                if (Object.defineProperty && Object.keys) try {
                  return Object.keys(e).forEach(function (r) {
                    Object.defineProperty(t, r, {
                      get: function () {
                        return e[r];
                      },
                      set: function (t) {
                        return e[r] = t, t;
                      }
                    });
                  }), t;
                } catch (e) {
                  u([e], r);
                }
                for (var n in e) a.call(e, n) && (t[n] = e[n]);
              }(t, nrWrapper, e), nrWrapper);
              function nrWrapper() {
                var o, a, d, l;
                try {
                  a = this, o = [...arguments], d = "function" == typeof n ? n(o, a) : n || {};
                } catch (t) {
                  u([t, "", [o, a, s], d], e);
                }
                i(r + "start", [o, a, s], d, c);
                try {
                  return l = t.apply(a, o);
                } catch (e) {
                  throw i(r + "err", [o, a, e], d, c), e;
                } finally {
                  i(r + "end", [o, a, l], d, c);
                }
              }
            }
            function i(r, n, i, o) {
              if (!s || t) {
                var a = s;
                s = !0;
                try {
                  e.emit(r, n, i, t, o);
                } catch (t) {
                  u([t, r, n, i], e);
                }
                s = a;
              }
            }
          }
          function u(e, t) {
            t || (t = n.ee);
            try {
              t.emit("internal-error", e);
            } catch (e) {}
          }
          function d(e) {
            return !(e && e instanceof Function && e.apply && !e[o]);
          }
          var l = r(2210),
            f = r(385);
          const h = {},
            p = f._A.XMLHttpRequest,
            g = "addEventListener",
            m = "removeEventListener",
            v = "nr@wrapped:".concat(n.A);
          function b(e) {
            var t = function (e) {
              return (e || n.ee).get("events");
            }(e);
            if (h[t.debugId]++) return t;
            h[t.debugId] = 1;
            var r = c(t, !0);
            function i(e) {
              r.inPlace(e, [g, m], "-", o);
            }
            function o(e, t) {
              return e[1];
            }
            return "getPrototypeOf" in Object && (f.il && y(document, i), y(f._A, i), y(p.prototype, i)), t.on(g + "-start", function (e, t) {
              var n = e[1];
              if (null !== n && ("function" == typeof n || "object" == typeof n)) {
                var i = (0, l.X)(n, v, function () {
                  var e = {
                    object: function () {
                      if ("function" != typeof n.handleEvent) return;
                      return n.handleEvent.apply(n, arguments);
                    },
                    function: n
                  }[typeof n];
                  return e ? r(e, "fn-", null, e.name || "anonymous") : n;
                });
                this.wrapped = e[1] = i;
              }
            }), t.on(m + "-start", function (e) {
              e[1] = this.wrapped || e[1];
            }), t;
          }
          function y(e, t) {
            let r = e;
            for (; "object" == typeof r && !Object.prototype.hasOwnProperty.call(r, g);) r = Object.getPrototypeOf(r);
            for (var n = arguments.length, i = new Array(n > 2 ? n - 2 : 0), o = 2; o < n; o++) i[o - 2] = arguments[o];
            r && t(r, ...i);
          }
          var w = "fetch-",
            A = w + "body-",
            x = ["arrayBuffer", "blob", "json", "text", "formData"],
            E = f._A.Request,
            T = f._A.Response,
            _ = "prototype";
          const D = {};
          function j(e) {
            const t = function (e) {
              return (e || n.ee).get("fetch");
            }(e);
            if (!(E && T && f._A.fetch)) return t;
            if (D[t.debugId]++) return t;
            function r(e, r, i) {
              var o = e[r];
              "function" == typeof o && (e[r] = function () {
                var e,
                  r = [...arguments],
                  a = {};
                t.emit(i + "before-start", [r], a), a[n.A] && a[n.A].dt && (e = a[n.A].dt);
                var s = o.apply(this, r);
                return t.emit(i + "start", [r, e], s), s.then(function (e) {
                  return t.emit(i + "end", [null, e], s), e;
                }, function (e) {
                  throw t.emit(i + "end", [e], s), e;
                });
              });
            }
            return D[t.debugId] = 1, x.forEach(e => {
              r(E[_], e, A), r(T[_], e, A);
            }), r(f._A, "fetch", w), t.on(w + "end", function (e, r) {
              var n = this;
              if (r) {
                var i = r.headers.get("content-length");
                null !== i && (n.rxSize = i), t.emit(w + "done", [null, r], n);
              } else t.emit(w + "done", [e], n);
            }), t;
          }
          const C = {},
            N = ["pushState", "replaceState"];
          function O(e) {
            const t = function (e) {
              return (e || n.ee).get("history");
            }(e);
            return !f.il || C[t.debugId]++ || (C[t.debugId] = 1, c(t).inPlace(window.history, N, "-")), t;
          }
          var S = r(3239);
          const P = {},
            R = ["appendChild", "insertBefore", "replaceChild"];
          function I(e) {
            const t = function (e) {
              return (e || n.ee).get("jsonp");
            }(e);
            if (!f.il || P[t.debugId]) return t;
            P[t.debugId] = !0;
            var r = c(t),
              i = /[?&](?:callback|cb)=([^&#]+)/,
              o = /(.*)\.([^.]+)/,
              a = /^(\w+)(\.|$)(.*)$/;
            function s(e, t) {
              if (!e) return t;
              const r = e.match(a),
                n = r[1];
              return s(r[3], t[n]);
            }
            return r.inPlace(Node.prototype, R, "dom-"), t.on("dom-start", function (e) {
              !function (e) {
                if (!e || "string" != typeof e.nodeName || "script" !== e.nodeName.toLowerCase()) return;
                if ("function" != typeof e.addEventListener) return;
                var n = (a = e.src, c = a.match(i), c ? c[1] : null);
                var a, c;
                if (!n) return;
                var u = function (e) {
                  var t = e.match(o);
                  if (t && t.length >= 3) return {
                    key: t[2],
                    parent: s(t[1], window)
                  };
                  return {
                    key: e,
                    parent: window
                  };
                }(n);
                if ("function" != typeof u.parent[u.key]) return;
                var d = {};
                function l() {
                  t.emit("jsonp-end", [], d), e.removeEventListener("load", l, (0, S.m$)(!1)), e.removeEventListener("error", f, (0, S.m$)(!1));
                }
                function f() {
                  t.emit("jsonp-error", [], d), t.emit("jsonp-end", [], d), e.removeEventListener("load", l, (0, S.m$)(!1)), e.removeEventListener("error", f, (0, S.m$)(!1));
                }
                r.inPlace(u.parent, [u.key], "cb-", d), e.addEventListener("load", l, (0, S.m$)(!1)), e.addEventListener("error", f, (0, S.m$)(!1)), t.emit("new-jsonp", [e.src], d);
              }(e[0]);
            }), t;
          }
          const k = {};
          function H(e) {
            const t = function (e) {
              return (e || n.ee).get("mutation");
            }(e);
            if (!f.il || k[t.debugId]) return t;
            k[t.debugId] = !0;
            var r = c(t),
              i = f._A.MutationObserver;
            return i && (window.MutationObserver = function (e) {
              return this instanceof i ? new i(r(e, "fn-")) : i.apply(this, arguments);
            }, MutationObserver.prototype = i.prototype), t;
          }
          const z = {};
          function L(e) {
            const t = function (e) {
              return (e || n.ee).get("promise");
            }(e);
            if (z[t.debugId]) return t;
            z[t.debugId] = !0;
            var r = t.context,
              i = c(t),
              a = f._A.Promise;
            return a && function () {
              function e(r) {
                var n = t.context(),
                  o = i(r, "executor-", n, null, !1);
                const s = Reflect.construct(a, [o], e);
                return t.context(s).getCtx = function () {
                  return n;
                }, s;
              }
              f._A.Promise = e, Object.defineProperty(e, "name", {
                value: "Promise"
              }), e.toString = function () {
                return a.toString();
              }, Object.setPrototypeOf(e, a), ["all", "race"].forEach(function (r) {
                const n = a[r];
                e[r] = function (e) {
                  let i = !1;
                  [...(e || [])].forEach(e => {
                    this.resolve(e).then(a("all" === r), a(!1));
                  });
                  const o = n.apply(this, arguments);
                  return o;
                  function a(e) {
                    return function () {
                      t.emit("propagate", [null, !i], o, !1, !1), i = i || !e;
                    };
                  }
                };
              }), ["resolve", "reject"].forEach(function (r) {
                const n = a[r];
                e[r] = function (e) {
                  const r = n.apply(this, arguments);
                  return e !== r && t.emit("propagate", [e, !0], r, !1, !1), r;
                };
              }), e.prototype = a.prototype;
              const n = a.prototype.then;
              a.prototype.then = function () {
                var e = this,
                  o = r(e);
                o.promise = e;
                for (var a = arguments.length, s = new Array(a), c = 0; c < a; c++) s[c] = arguments[c];
                s[0] = i(s[0], "cb-", o, null, !1), s[1] = i(s[1], "cb-", o, null, !1);
                const u = n.apply(this, s);
                return o.nextPromise = u, t.emit("propagate", [e, !0], u, !1, !1), u;
              }, a.prototype.then[o] = n, t.on("executor-start", function (e) {
                e[0] = i(e[0], "resolve-", this, null, !1), e[1] = i(e[1], "resolve-", this, null, !1);
              }), t.on("executor-err", function (e, t, r) {
                e[1](r);
              }), t.on("cb-end", function (e, r, n) {
                t.emit("propagate", [n, !0], this.nextPromise, !1, !1);
              }), t.on("propagate", function (e, r, n) {
                this.getCtx && !r || (this.getCtx = function () {
                  if (e instanceof Promise) var r = t.context(e);
                  return r && r.getCtx ? r.getCtx() : this;
                });
              });
            }(), t;
          }
          const M = {},
            B = "setTimeout",
            F = "setInterval",
            U = "clearTimeout",
            q = "-start",
            Z = "-",
            V = [B, "setImmediate", F, U, "clearImmediate"];
          function G(e) {
            const t = function (e) {
              return (e || n.ee).get("timer");
            }(e);
            if (M[t.debugId]++) return t;
            M[t.debugId] = 1;
            var r = c(t);
            return r.inPlace(f._A, V.slice(0, 2), B + Z), r.inPlace(f._A, V.slice(2, 3), F + Z), r.inPlace(f._A, V.slice(3), U + Z), t.on(F + q, function (e, t, n) {
              e[0] = r(e[0], "fn-", null, n);
            }), t.on(B + q, function (e, t, n) {
              this.method = n, this.timerDuration = isNaN(e[1]) ? 0 : +e[1], e[0] = r(e[0], "fn-", this, n);
            }), t;
          }
          var W = r(50);
          const X = {},
            Q = ["open", "send"];
          function K(e) {
            var t = e || n.ee;
            const r = function (e) {
              return (e || n.ee).get("xhr");
            }(t);
            if (X[r.debugId]++) return r;
            X[r.debugId] = 1, b(t);
            var i = c(r),
              o = f._A.XMLHttpRequest,
              a = f._A.MutationObserver,
              s = f._A.Promise,
              u = f._A.setInterval,
              d = "readystatechange",
              l = ["onload", "onerror", "onabort", "onloadstart", "onloadend", "onprogress", "ontimeout"],
              h = [],
              p = f._A.XMLHttpRequest = function (e) {
                const t = new o(e),
                  n = r.context(t);
                try {
                  r.emit("new-xhr", [t], n), t.addEventListener(d, (a = n, function () {
                    var e = this;
                    e.readyState > 3 && !a.resolved && (a.resolved = !0, r.emit("xhr-resolved", [], e)), i.inPlace(e, l, "fn-", A);
                  }), (0, S.m$)(!1));
                } catch (e) {
                  (0, W.Z)("An error occurred while intercepting XHR", e);
                  try {
                    r.emit("internal-error", [e]);
                  } catch (e) {}
                }
                var a;
                return t;
              };
            function g(e, t) {
              i.inPlace(t, ["onreadystatechange"], "fn-", A);
            }
            if (function (e, t) {
              for (var r in e) t[r] = e[r];
            }(o, p), p.prototype = o.prototype, i.inPlace(p.prototype, Q, "-xhr-", A), r.on("send-xhr-start", function (e, t) {
              g(e, t), function (e) {
                h.push(e), a && (m ? m.then(w) : u ? u(w) : (v = -v, y.data = v));
              }(t);
            }), r.on("open-xhr-start", g), a) {
              var m = s && s.resolve();
              if (!u && !s) {
                var v = 1,
                  y = document.createTextNode(v);
                new a(w).observe(y, {
                  characterData: !0
                });
              }
            } else t.on("fn-end", function (e) {
              e[0] && e[0].type === d || w();
            });
            function w() {
              for (var e = 0; e < h.length; e++) g(0, h[e]);
              h.length && (h = []);
            }
            function A(e, t) {
              return t;
            }
            return r;
          }
        },
        7825: (e, t, r) => {
          r.d(t, {
            t: () => n
          });
          const n = r(3325).D.ajax;
        },
        6660: (e, t, r) => {
          r.d(t, {
            t: () => n
          });
          const n = r(3325).D.jserrors;
        },
        3081: (e, t, r) => {
          r.d(t, {
            gF: () => o,
            mY: () => i,
            t9: () => n,
            vz: () => s,
            xS: () => a
          });
          const n = r(3325).D.metrics,
            i = "sm",
            o = "cm",
            a = "storeSupportabilityMetrics",
            s = "storeEventMetrics";
        },
        4649: (e, t, r) => {
          r.d(t, {
            t: () => n
          });
          const n = r(3325).D.pageAction;
        },
        7633: (e, t, r) => {
          r.d(t, {
            Dz: () => i,
            OJ: () => a,
            qw: () => o,
            t9: () => n
          });
          const n = r(3325).D.pageViewEvent,
            i = "firstbyte",
            o = "domcontent",
            a = "windowload";
        },
        9251: (e, t, r) => {
          r.d(t, {
            t: () => n
          });
          const n = r(3325).D.pageViewTiming;
        },
        3614: (e, t, r) => {
          r.d(t, {
            BST_RESOURCE: () => i,
            END: () => s,
            FEATURE_NAME: () => n,
            FN_END: () => u,
            FN_START: () => c,
            PUSH_STATE: () => d,
            RESOURCE: () => o,
            START: () => a
          });
          const n = r(3325).D.sessionTrace,
            i = "bstResource",
            o = "resource",
            a = "-start",
            s = "-end",
            c = "fn" + a,
            u = "fn" + s,
            d = "pushState";
        },
        7836: (e, t, r) => {
          r.d(t, {
            BODY: () => x,
            CB_END: () => E,
            CB_START: () => u,
            END: () => A,
            FEATURE_NAME: () => i,
            FETCH: () => _,
            FETCH_BODY: () => v,
            FETCH_DONE: () => m,
            FETCH_START: () => g,
            FN_END: () => c,
            FN_START: () => s,
            INTERACTION: () => f,
            INTERACTION_API: () => d,
            INTERACTION_EVENTS: () => o,
            JSONP_END: () => b,
            JSONP_NODE: () => p,
            JS_TIME: () => T,
            MAX_TIMER_BUDGET: () => a,
            REMAINING: () => l,
            SPA_NODE: () => h,
            START: () => w,
            originalSetTimeout: () => y
          });
          var n = r(5763);
          const i = r(3325).D.spa,
            o = ["click", "submit", "keypress", "keydown", "keyup", "change"],
            a = 999,
            s = "fn-start",
            c = "fn-end",
            u = "cb-start",
            d = "api-ixn-",
            l = "remaining",
            f = "interaction",
            h = "spaNode",
            p = "jsonpNode",
            g = "fetch-start",
            m = "fetch-done",
            v = "fetch-body-",
            b = "jsonp-end",
            y = n.Yu.ST,
            w = "-start",
            A = "-end",
            x = "-body",
            E = "cb" + A,
            T = "jsTime",
            _ = "fetch";
        },
        5938: (e, t, r) => {
          r.d(t, {
            W: () => o
          });
          var n = r(5763),
            i = r(8325);
          class o {
            constructor(e, t, r) {
              this.agentIdentifier = e, this.aggregator = t, this.ee = i.ee.get(e, (0, n.OP)(this.agentIdentifier).isolatedBacklog), this.featureName = r, this.blocked = !1;
            }
          }
        },
        9144: (e, t, r) => {
          r.d(t, {
            j: () => m
          });
          var n = r(3325),
            i = r(5763),
            o = r(5546),
            a = r(8325),
            s = r(7894),
            c = r(8e3),
            u = r(3960),
            d = r(385),
            l = r(50),
            f = r(3081),
            h = r(8632);
          function p() {
            const e = (0, h.gG)();
            ["setErrorHandler", "finished", "addToTrace", "inlineHit", "addRelease", "addPageAction", "setCurrentRouteName", "setPageViewName", "setCustomAttribute", "interaction", "noticeError", "setUserId", "setApplicationVersion"].forEach(t => {
              e[t] = function () {
                for (var r = arguments.length, n = new Array(r), i = 0; i < r; i++) n[i] = arguments[i];
                return function (t) {
                  for (var r = arguments.length, n = new Array(r > 1 ? r - 1 : 0), i = 1; i < r; i++) n[i - 1] = arguments[i];
                  let o = [];
                  return Object.values(e.initializedAgents).forEach(e => {
                    e.exposed && e.api[t] && o.push(e.api[t](...n));
                  }), o.length > 1 ? o : o[0];
                }(t, ...n);
              };
            });
          }
          var g = r(2587);
          function m(e) {
            let t = arguments.length > 1 && void 0 !== arguments[1] ? arguments[1] : {},
              m = arguments.length > 2 ? arguments[2] : void 0,
              v = arguments.length > 3 ? arguments[3] : void 0,
              {
                init: b,
                info: y,
                loader_config: w,
                runtime: A = {
                  loaderType: m
                },
                exposed: x = !0
              } = t;
            const E = (0, h.gG)();
            y || (b = E.init, y = E.info, w = E.loader_config), (0, i.Dg)(e, b || {}), (0, i.GE)(e, w || {}), y.jsAttributes ??= {}, d.v6 && (y.jsAttributes.isWorker = !0), (0, i.CX)(e, y);
            const T = (0, i.P_)(e);
            A.denyList = [...(T.ajax?.deny_list || []), ...(T.ajax?.block_internal ? [y.beacon, y.errorBeacon] : [])], (0, i.sU)(e, A), p();
            const _ = function (e, t) {
              t || (0, c.R)(e, "api");
              const h = {};
              var p = a.ee.get(e),
                g = p.get("tracer"),
                m = "api-",
                v = m + "ixn-";
              function b(t, r, n, o) {
                const a = (0, i.C5)(e);
                return null === r ? delete a.jsAttributes[t] : (0, i.CX)(e, {
                  ...a,
                  jsAttributes: {
                    ...a.jsAttributes,
                    [t]: r
                  }
                }), A(m, n, !0, o || null === r ? "session" : void 0)(t, r);
              }
              function y() {}
              ["setErrorHandler", "finished", "addToTrace", "inlineHit", "addRelease"].forEach(e => h[e] = A(m, e, !0, "api")), h.addPageAction = A(m, "addPageAction", !0, n.D.pageAction), h.setCurrentRouteName = A(m, "routeName", !0, n.D.spa), h.setPageViewName = function (t, r) {
                if ("string" == typeof t) return "/" !== t.charAt(0) && (t = "/" + t), (0, i.OP)(e).customTransaction = (r || "http://custom.transaction") + t, A(m, "setPageViewName", !0)();
              }, h.setCustomAttribute = function (e, t) {
                let r = arguments.length > 2 && void 0 !== arguments[2] && arguments[2];
                if ("string" == typeof e) {
                  if (["string", "number"].includes(typeof t) || null === t) return b(e, t, "setCustomAttribute", r);
                  (0, l.Z)("Failed to execute setCustomAttribute.\nNon-null value must be a string or number type, but a type of <".concat(typeof t, "> was provided."));
                } else (0, l.Z)("Failed to execute setCustomAttribute.\nName must be a string type, but a type of <".concat(typeof e, "> was provided."));
              }, h.setUserId = function (e) {
                if ("string" == typeof e || null === e) return b("enduser.id", e, "setUserId", !0);
                (0, l.Z)("Failed to execute setUserId.\nNon-null value must be a string type, but a type of <".concat(typeof e, "> was provided."));
              }, h.setApplicationVersion = function (e) {
                if ("string" == typeof e || null === e) return b("application.version", e, "setApplicationVersion", !1);
                (0, l.Z)("Failed to execute setApplicationVersion. Expected <String | null>, but got <".concat(typeof e, ">."));
              }, h.interaction = function () {
                return new y().get();
              };
              var w = y.prototype = {
                createTracer: function (e, t) {
                  var r = {},
                    i = this,
                    a = "function" == typeof t;
                  return (0, o.p)(v + "tracer", [(0, s.z)(), e, r], i, n.D.spa, p), function () {
                    if (g.emit((a ? "" : "no-") + "fn-start", [(0, s.z)(), i, a], r), a) try {
                      return t.apply(this, arguments);
                    } catch (e) {
                      throw g.emit("fn-err", [arguments, this, e], r), e;
                    } finally {
                      g.emit("fn-end", [(0, s.z)()], r);
                    }
                  };
                }
              };
              function A(e, t, r, i) {
                return function () {
                  return (0, o.p)(f.xS, ["API/" + t + "/called"], void 0, n.D.metrics, p), i && (0, o.p)(e + t, [(0, s.z)(), ...arguments], r ? null : this, i, p), r ? void 0 : this;
                };
              }
              function x() {
                r.e(111).then(r.bind(r, 7438)).then(t => {
                  let {
                    setAPI: r
                  } = t;
                  r(e), (0, c.L)(e, "api");
                }).catch(() => (0, l.Z)("Downloading runtime APIs failed..."));
              }
              return ["actionText", "setName", "setAttribute", "save", "ignore", "onEnd", "getContext", "end", "get"].forEach(e => {
                w[e] = A(v, e, void 0, n.D.spa);
              }), h.noticeError = function (e, t) {
                "string" == typeof e && (e = new Error(e)), (0, o.p)(f.xS, ["API/noticeError/called"], void 0, n.D.metrics, p), (0, o.p)("err", [e, (0, s.z)(), !1, t], void 0, n.D.jserrors, p);
              }, d.il ? (0, u.b)(() => x(), !0) : x(), h;
            }(e, v);
            return (0, h.Qy)(e, _, "api"), (0, h.Qy)(e, x, "exposed"), (0, h.EZ)("activatedFeatures", g.T), _;
          }
        },
        3325: (e, t, r) => {
          r.d(t, {
            D: () => n,
            p: () => i
          });
          const n = {
              ajax: "ajax",
              jserrors: "jserrors",
              metrics: "metrics",
              pageAction: "page_action",
              pageViewEvent: "page_view_event",
              pageViewTiming: "page_view_timing",
              sessionReplay: "session_replay",
              sessionTrace: "session_trace",
              spa: "spa"
            },
            i = {
              [n.pageViewEvent]: 1,
              [n.pageViewTiming]: 2,
              [n.metrics]: 3,
              [n.jserrors]: 4,
              [n.ajax]: 5,
              [n.sessionTrace]: 6,
              [n.pageAction]: 7,
              [n.spa]: 8,
              [n.sessionReplay]: 9
            };
        }
      },
      n = {};
    function i(e) {
      var t = n[e];
      if (void 0 !== t) return t.exports;
      var o = n[e] = {
        exports: {}
      };
      return r[e](o, o.exports, i), o.exports;
    }
    i.m = r, i.d = (e, t) => {
      for (var r in t) i.o(t, r) && !i.o(e, r) && Object.defineProperty(e, r, {
        enumerable: !0,
        get: t[r]
      });
    }, i.f = {}, i.e = e => Promise.all(Object.keys(i.f).reduce((t, r) => (i.f[r](e, t), t), [])), i.u = e => "nr-spa.1097a448-1.238.0.min.js", i.o = (e, t) => Object.prototype.hasOwnProperty.call(e, t), e = {}, t = "NRBA-1.238.0.PROD:", i.l = (r, n, o, a) => {
      if (e[r]) e[r].push(n);else {
        var s, c;
        if (void 0 !== o) for (var u = document.getElementsByTagName("script"), d = 0; d < u.length; d++) {
          var l = u[d];
          if (l.getAttribute("src") == r || l.getAttribute("data-webpack") == t + o) {
            s = l;
            break;
          }
        }
        s || (c = !0, (s = document.createElement("script")).charset = "utf-8", s.timeout = 120, i.nc && s.setAttribute("nonce", i.nc), s.setAttribute("data-webpack", t + o), s.src = r), e[r] = [n];
        var f = (t, n) => {
            s.onerror = s.onload = null, clearTimeout(h);
            var i = e[r];
            if (delete e[r], s.parentNode && s.parentNode.removeChild(s), i && i.forEach(e => e(n)), t) return t(n);
          },
          h = setTimeout(f.bind(null, void 0, {
            type: "timeout",
            target: s
          }), 12e4);
        s.onerror = f.bind(null, s.onerror), s.onload = f.bind(null, s.onload), c && document.head.appendChild(s);
      }
    }, i.r = e => {
      "undefined" != typeof Symbol && Symbol.toStringTag && Object.defineProperty(e, Symbol.toStringTag, {
        value: "Module"
      }), Object.defineProperty(e, "__esModule", {
        value: !0
      });
    }, i.p = "https://js-agent.newrelic.com/", (() => {
      var e = {
        801: 0,
        92: 0
      };
      i.f.j = (t, r) => {
        var n = i.o(e, t) ? e[t] : void 0;
        if (0 !== n) if (n) r.push(n[2]);else {
          var o = new Promise((r, i) => n = e[t] = [r, i]);
          r.push(n[2] = o);
          var a = i.p + i.u(t),
            s = new Error();
          i.l(a, r => {
            if (i.o(e, t) && (0 !== (n = e[t]) && (e[t] = void 0), n)) {
              var o = r && ("load" === r.type ? "missing" : r.type),
                a = r && r.target && r.target.src;
              s.message = "Loading chunk " + t + " failed.\n(" + o + ": " + a + ")", s.name = "ChunkLoadError", s.type = o, s.request = a, n[1](s);
            }
          }, "chunk-" + t, t);
        }
      };
      var t = (t, r) => {
          var n,
            o,
            [a, s, c] = r,
            u = 0;
          if (a.some(t => 0 !== e[t])) {
            for (n in s) i.o(s, n) && (i.m[n] = s[n]);
            if (c) c(i);
          }
          for (t && t(r); u < a.length; u++) o = a[u], i.o(e, o) && e[o] && e[o][0](), e[o] = 0;
        },
        r = self["webpackChunk:NRBA-1.238.0.PROD"] = self["webpackChunk:NRBA-1.238.0.PROD"] || [];
      r.forEach(t.bind(null, 0)), r.push = t.bind(null, r.push.bind(r));
    })(), (() => {
      var e = i(50);
      class t {
        addPageAction(t, r) {
          (0, e.Z)("Call to agent api addPageAction failed. The session trace feature is not currently initialized.");
        }
        setPageViewName(t, r) {
          (0, e.Z)("Call to agent api setPageViewName failed. The page view feature is not currently initialized.");
        }
        setCustomAttribute(t, r, n) {
          (0, e.Z)("Call to agent api setCustomAttribute failed. The js errors feature is not currently initialized.");
        }
        noticeError(t, r) {
          (0, e.Z)("Call to agent api noticeError failed. The js errors feature is not currently initialized.");
        }
        setUserId(t) {
          (0, e.Z)("Call to agent api setUserId failed. The js errors feature is not currently initialized.");
        }
        setApplicationVersion(t) {
          (0, e.Z)("Call to agent api setApplicationVersion failed. The agent is not currently initialized.");
        }
        setErrorHandler(t) {
          (0, e.Z)("Call to agent api setErrorHandler failed. The js errors feature is not currently initialized.");
        }
        finished(t) {
          (0, e.Z)("Call to agent api finished failed. The page action feature is not currently initialized.");
        }
        addRelease(t, r) {
          (0, e.Z)("Call to agent api addRelease failed. The agent is not currently initialized.");
        }
      }
      var r = i(3325),
        n = i(5763);
      const o = Object.values(r.D);
      function a(e) {
        const t = {};
        return o.forEach(r => {
          t[r] = function (e, t) {
            return !1 !== (0, n.Mt)(t, "".concat(e, ".enabled"));
          }(r, e);
        }), t;
      }
      var s = i(9144);
      var c = i(5546),
        u = i(385),
        d = i(8e3),
        l = i(5938),
        f = i(3960);
      class h extends l.W {
        constructor(e, t, r) {
          let n = !(arguments.length > 3 && void 0 !== arguments[3]) || arguments[3];
          super(e, t, r), this.auto = n, this.abortHandler, this.featAggregate, this.onAggregateImported, n && (0, d.R)(e, r);
        }
        importAggregator() {
          let t = arguments.length > 0 && void 0 !== arguments[0] ? arguments[0] : {};
          if (this.featAggregate || !this.auto) return;
          const r = u.il && !0 === (0, n.Mt)(this.agentIdentifier, "privacy.cookies_enabled");
          let o;
          this.onAggregateImported = new Promise(e => {
            o = e;
          });
          const a = async () => {
            let n;
            try {
              if (r) {
                const {
                  setupAgentSession: e
                } = await i.e(111).then(i.bind(i, 3228));
                n = e(this.agentIdentifier);
              }
            } catch (t) {
              (0, e.Z)("A problem occurred when starting up session manager. This page will not start or extend any session.", t);
            }
            try {
              if (!this.shouldImportAgg(this.featureName, n)) return (0, d.L)(this.agentIdentifier, this.featureName), void o(!1);
              const {
                  lazyFeatureLoader: e
                } = await i.e(111).then(i.bind(i, 8582)),
                {
                  Aggregate: r
                } = await e(this.featureName, "aggregate");
              this.featAggregate = new r(this.agentIdentifier, this.aggregator, t), o(!0);
            } catch (t) {
              (0, e.Z)("Downloading and initializing ".concat(this.featureName, " failed..."), t), this.abortHandler?.(), o(!1);
            }
          };
          u.il ? (0, f.b)(() => a(), !0) : a();
        }
        shouldImportAgg(e, t) {
          return e !== r.D.sessionReplay || !!n.Yu.MO && !1 !== (0, n.Mt)(this.agentIdentifier, "session_trace.enabled") && (!!t?.isNew || !!t?.state.sessionReplay);
        }
      }
      var p = i(7633),
        g = i(7894);
      class m extends h {
        static featureName = p.t9;
        constructor(e, t) {
          let i = !(arguments.length > 2 && void 0 !== arguments[2]) || arguments[2];
          if (super(e, t, p.t9, i), ("undefined" == typeof PerformanceNavigationTiming || u.Tt) && "undefined" != typeof PerformanceTiming) {
            const t = (0, n.OP)(e);
            t[p.Dz] = Math.max(Date.now() - t.offset, 0), (0, f.K)(() => t[p.qw] = Math.max((0, g.z)() - t[p.Dz], 0)), (0, f.b)(() => {
              const e = (0, g.z)();
              t[p.OJ] = Math.max(e - t[p.Dz], 0), (0, c.p)("timing", ["load", e], void 0, r.D.pageViewTiming, this.ee);
            });
          }
          this.importAggregator();
        }
      }
      var v = i(1117),
        b = i(1284);
      class y extends v.w {
        constructor(e) {
          super(e), this.aggregatedData = {};
        }
        store(e, t, r, n, i) {
          var o = this.getBucket(e, t, r, i);
          return o.metrics = function (e, t) {
            t || (t = {
              count: 0
            });
            return t.count += 1, (0, b.D)(e, function (e, r) {
              t[e] = w(r, t[e]);
            }), t;
          }(n, o.metrics), o;
        }
        merge(e, t, r, n, i) {
          var o = this.getBucket(e, t, n, i);
          if (o.metrics) {
            var a = o.metrics;
            a.count += r.count, (0, b.D)(r, function (e, t) {
              if ("count" !== e) {
                var n = a[e],
                  i = r[e];
                i && !i.c ? a[e] = w(i.t, n) : a[e] = function (e, t) {
                  if (!t) return e;
                  t.c || (t = A(t.t));
                  return t.min = Math.min(e.min, t.min), t.max = Math.max(e.max, t.max), t.t += e.t, t.sos += e.sos, t.c += e.c, t;
                }(i, a[e]);
              }
            });
          } else o.metrics = r;
        }
        storeMetric(e, t, r, n) {
          var i = this.getBucket(e, t, r);
          return i.stats = w(n, i.stats), i;
        }
        getBucket(e, t, r, n) {
          this.aggregatedData[e] || (this.aggregatedData[e] = {});
          var i = this.aggregatedData[e][t];
          return i || (i = this.aggregatedData[e][t] = {
            params: r || {}
          }, n && (i.custom = n)), i;
        }
        get(e, t) {
          return t ? this.aggregatedData[e] && this.aggregatedData[e][t] : this.aggregatedData[e];
        }
        take(e) {
          for (var t = {}, r = "", n = !1, i = 0; i < e.length; i++) t[r = e[i]] = x(this.aggregatedData[r]), t[r].length && (n = !0), delete this.aggregatedData[r];
          return n ? t : null;
        }
      }
      function w(e, t) {
        return null == e ? function (e) {
          e ? e.c++ : e = {
            c: 1
          };
          return e;
        }(t) : t ? (t.c || (t = A(t.t)), t.c += 1, t.t += e, t.sos += e * e, e > t.max && (t.max = e), e < t.min && (t.min = e), t) : {
          t: e
        };
      }
      function A(e) {
        return {
          t: e,
          min: e,
          max: e,
          sos: e * e,
          c: 1
        };
      }
      function x(e) {
        return "object" != typeof e ? [] : (0, b.D)(e, E);
      }
      function E(e, t) {
        return t;
      }
      var T = i(8632),
        _ = i(4402),
        D = i(4351);
      var j = i(7956),
        C = i(3239),
        N = i(9251);
      class O extends h {
        static featureName = N.t;
        constructor(e, t) {
          let r = !(arguments.length > 2 && void 0 !== arguments[2]) || arguments[2];
          super(e, t, N.t, r), u.il && ((0, n.OP)(e).initHidden = Boolean("hidden" === document.visibilityState), (0, j.N)(() => (0, c.p)("docHidden", [(0, g.z)()], void 0, N.t, this.ee), !0), (0, C.bP)("pagehide", () => (0, c.p)("winPagehide", [(0, g.z)()], void 0, N.t, this.ee)), this.importAggregator());
        }
      }
      var S = i(3081);
      class P extends h {
        static featureName = S.t9;
        constructor(e, t) {
          let r = !(arguments.length > 2 && void 0 !== arguments[2]) || arguments[2];
          super(e, t, S.t9, r), this.importAggregator();
        }
      }
      var R = i(6660);
      class I {
        constructor(e, t, r, n) {
          this.name = "UncaughtError", this.message = e, this.sourceURL = t, this.line = r, this.column = n;
        }
      }
      class k extends h {
        static featureName = R.t;
        #e = new Set();
        constructor(e, t) {
          let n = !(arguments.length > 2 && void 0 !== arguments[2]) || arguments[2];
          super(e, t, R.t, n);
          try {
            this.removeOnAbort = new AbortController();
          } catch (e) {}
          this.ee.on("fn-err", (e, t, n) => {
            this.abortHandler && !this.#e.has(n) && (this.#e.add(n), (0, c.p)("err", [this.#t(n), (0, g.z)()], void 0, r.D.jserrors, this.ee));
          }), this.ee.on("internal-error", e => {
            this.abortHandler && (0, c.p)("ierr", [this.#t(e), (0, g.z)(), !0], void 0, r.D.jserrors, this.ee);
          }), u._A.addEventListener("unhandledrejection", e => {
            this.abortHandler && (0, c.p)("err", [this.#r(e), (0, g.z)(), !1, {
              unhandledPromiseRejection: 1
            }], void 0, r.D.jserrors, this.ee);
          }, (0, C.m$)(!1, this.removeOnAbort?.signal)), u._A.addEventListener("error", e => {
            this.abortHandler && (this.#e.has(e.error) ? this.#e.delete(e.error) : (0, c.p)("err", [this.#n(e), (0, g.z)()], void 0, r.D.jserrors, this.ee));
          }, (0, C.m$)(!1, this.removeOnAbort?.signal)), this.abortHandler = this.#i, this.importAggregator();
        }
        #i() {
          this.removeOnAbort?.abort(), this.#e.clear(), this.abortHandler = void 0;
        }
        #t(e) {
          return e instanceof Error ? e : void 0 !== e?.message ? new I(e.message, e.filename || e.sourceURL, e.lineno || e.line, e.colno || e.col) : new I("string" == typeof e ? e : (0, D.P)(e));
        }
        #r(e) {
          let t = "Unhandled Promise Rejection: ";
          if (e?.reason instanceof Error) try {
            return e.reason.message = t + e.reason.message, e.reason;
          } catch (t) {
            return e.reason;
          }
          if (void 0 === e.reason) return new I(t);
          const r = this.#t(e.reason);
          return r.message = t + r.message, r;
        }
        #n(e) {
          return e.error instanceof Error ? e.error : new I(e.message, e.filename, e.lineno, e.colno);
        }
      }
      var H = i(2210);
      let z = 1;
      const L = "nr@id";
      function M(e) {
        const t = typeof e;
        return !e || "object" !== t && "function" !== t ? -1 : e === u._A ? 0 : (0, H.X)(e, L, function () {
          return z++;
        });
      }
      function B(e) {
        if ("string" == typeof e && e.length) return e.length;
        if ("object" == typeof e) {
          if ("undefined" != typeof ArrayBuffer && e instanceof ArrayBuffer && e.byteLength) return e.byteLength;
          if ("undefined" != typeof Blob && e instanceof Blob && e.size) return e.size;
          if (!("undefined" != typeof FormData && e instanceof FormData)) try {
            return (0, D.P)(e).length;
          } catch (e) {
            return;
          }
        }
      }
      var F = i(1214),
        U = i(7243);
      class q {
        constructor(e) {
          this.agentIdentifier = e;
        }
        generateTracePayload(e) {
          if (!this.shouldGenerateTrace(e)) return null;
          var t = (0, n.DL)(this.agentIdentifier);
          if (!t) return null;
          var r = (t.accountID || "").toString() || null,
            i = (t.agentID || "").toString() || null,
            o = (t.trustKey || "").toString() || null;
          if (!r || !i) return null;
          var a = (0, _.M)(),
            s = (0, _.Ht)(),
            c = Date.now(),
            u = {
              spanId: a,
              traceId: s,
              timestamp: c
            };
          return (e.sameOrigin || this.isAllowedOrigin(e) && this.useTraceContextHeadersForCors()) && (u.traceContextParentHeader = this.generateTraceContextParentHeader(a, s), u.traceContextStateHeader = this.generateTraceContextStateHeader(a, c, r, i, o)), (e.sameOrigin && !this.excludeNewrelicHeader() || !e.sameOrigin && this.isAllowedOrigin(e) && this.useNewrelicHeaderForCors()) && (u.newrelicHeader = this.generateTraceHeader(a, s, c, r, i, o)), u;
        }
        generateTraceContextParentHeader(e, t) {
          return "00-" + t + "-" + e + "-01";
        }
        generateTraceContextStateHeader(e, t, r, n, i) {
          return i + "@nr=0-1-" + r + "-" + n + "-" + e + "----" + t;
        }
        generateTraceHeader(e, t, r, n, i, o) {
          if (!("function" == typeof u._A?.btoa)) return null;
          var a = {
            v: [0, 1],
            d: {
              ty: "Browser",
              ac: n,
              ap: i,
              id: e,
              tr: t,
              ti: r
            }
          };
          return o && n !== o && (a.d.tk = o), btoa((0, D.P)(a));
        }
        shouldGenerateTrace(e) {
          return this.isDtEnabled() && this.isAllowedOrigin(e);
        }
        isAllowedOrigin(e) {
          var t = !1,
            r = {};
          if ((0, n.Mt)(this.agentIdentifier, "distributed_tracing") && (r = (0, n.P_)(this.agentIdentifier).distributed_tracing), e.sameOrigin) t = !0;else if (r.allowed_origins instanceof Array) for (var i = 0; i < r.allowed_origins.length; i++) {
            var o = (0, U.e)(r.allowed_origins[i]);
            if (e.hostname === o.hostname && e.protocol === o.protocol && e.port === o.port) {
              t = !0;
              break;
            }
          }
          return t;
        }
        isDtEnabled() {
          var e = (0, n.Mt)(this.agentIdentifier, "distributed_tracing");
          return !!e && !!e.enabled;
        }
        excludeNewrelicHeader() {
          var e = (0, n.Mt)(this.agentIdentifier, "distributed_tracing");
          return !!e && !!e.exclude_newrelic_header;
        }
        useNewrelicHeaderForCors() {
          var e = (0, n.Mt)(this.agentIdentifier, "distributed_tracing");
          return !!e && !1 !== e.cors_use_newrelic_header;
        }
        useTraceContextHeadersForCors() {
          var e = (0, n.Mt)(this.agentIdentifier, "distributed_tracing");
          return !!e && !!e.cors_use_tracecontext_headers;
        }
      }
      var Z = i(7825),
        V = ["load", "error", "abort", "timeout"],
        G = V.length,
        W = n.Yu.REQ,
        X = n.Yu.XHR;
      class Q extends h {
        static featureName = Z.t;
        constructor(e, t) {
          let i = !(arguments.length > 2 && void 0 !== arguments[2]) || arguments[2];
          super(e, t, Z.t, i), (0, n.OP)(e).xhrWrappable && (this.dt = new q(e), this.handler = (e, t, r, n) => (0, c.p)(e, t, r, n, this.ee), (0, F.u5)(this.ee), (0, F.Kf)(this.ee), function (e, t, i, o) {
            function a(e) {
              var t = this;
              t.totalCbs = 0, t.called = 0, t.cbTime = 0, t.end = E, t.ended = !1, t.xhrGuids = {}, t.lastSize = null, t.loadCaptureCalled = !1, t.params = this.params || {}, t.metrics = this.metrics || {}, e.addEventListener("load", function (r) {
                _(t, e);
              }, (0, C.m$)(!1)), u.IF || e.addEventListener("progress", function (e) {
                t.lastSize = e.loaded;
              }, (0, C.m$)(!1));
            }
            function s(e) {
              this.params = {
                method: e[0]
              }, T(this, e[1]), this.metrics = {};
            }
            function c(t, r) {
              var i = (0, n.DL)(e);
              i.xpid && this.sameOrigin && r.setRequestHeader("X-NewRelic-ID", i.xpid);
              var a = o.generateTracePayload(this.parsedOrigin);
              if (a) {
                var s = !1;
                a.newrelicHeader && (r.setRequestHeader("newrelic", a.newrelicHeader), s = !0), a.traceContextParentHeader && (r.setRequestHeader("traceparent", a.traceContextParentHeader), a.traceContextStateHeader && r.setRequestHeader("tracestate", a.traceContextStateHeader), s = !0), s && (this.dt = a);
              }
            }
            function d(e, r) {
              var n = this.metrics,
                i = e[0],
                o = this;
              if (n && i) {
                var a = B(i);
                a && (n.txSize = a);
              }
              this.startTime = (0, g.z)(), this.listener = function (e) {
                try {
                  "abort" !== e.type || o.loadCaptureCalled || (o.params.aborted = !0), ("load" !== e.type || o.called === o.totalCbs && (o.onloadCalled || "function" != typeof r.onload) && "function" == typeof o.end) && o.end(r);
                } catch (e) {
                  try {
                    t.emit("internal-error", [e]);
                  } catch (e) {}
                }
              };
              for (var s = 0; s < G; s++) r.addEventListener(V[s], this.listener, (0, C.m$)(!1));
            }
            function l(e, t, r) {
              this.cbTime += e, t ? this.onloadCalled = !0 : this.called += 1, this.called !== this.totalCbs || !this.onloadCalled && "function" == typeof r.onload || "function" != typeof this.end || this.end(r);
            }
            function f(e, t) {
              var r = "" + M(e) + !!t;
              this.xhrGuids && !this.xhrGuids[r] && (this.xhrGuids[r] = !0, this.totalCbs += 1);
            }
            function h(e, t) {
              var r = "" + M(e) + !!t;
              this.xhrGuids && this.xhrGuids[r] && (delete this.xhrGuids[r], this.totalCbs -= 1);
            }
            function p() {
              this.endTime = (0, g.z)();
            }
            function m(e, r) {
              r instanceof X && "load" === e[0] && t.emit("xhr-load-added", [e[1], e[2]], r);
            }
            function v(e, r) {
              r instanceof X && "load" === e[0] && t.emit("xhr-load-removed", [e[1], e[2]], r);
            }
            function b(e, t, r) {
              t instanceof X && ("onload" === r && (this.onload = !0), ("load" === (e[0] && e[0].type) || this.onload) && (this.xhrCbStart = (0, g.z)()));
            }
            function y(e, r) {
              this.xhrCbStart && t.emit("xhr-cb-time", [(0, g.z)() - this.xhrCbStart, this.onload, r], r);
            }
            function w(e) {
              var t,
                r = e[1] || {};
              if ("string" == typeof e[0] ? 0 === (t = e[0]).length && u.il && (t = "" + u._A.location.href) : e[0] && e[0].url ? t = e[0].url : u._A?.URL && e[0] && e[0] instanceof URL ? t = e[0].href : "function" == typeof e[0].toString && (t = e[0].toString()), "string" == typeof t && 0 !== t.length) {
                t && (this.parsedOrigin = (0, U.e)(t), this.sameOrigin = this.parsedOrigin.sameOrigin);
                var n = o.generateTracePayload(this.parsedOrigin);
                if (n && (n.newrelicHeader || n.traceContextParentHeader)) if (e[0] && e[0].headers) s(e[0].headers, n) && (this.dt = n);else {
                  var i = {};
                  for (var a in r) i[a] = r[a];
                  i.headers = new Headers(r.headers || {}), s(i.headers, n) && (this.dt = n), e.length > 1 ? e[1] = i : e.push(i);
                }
              }
              function s(e, t) {
                var r = !1;
                return t.newrelicHeader && (e.set("newrelic", t.newrelicHeader), r = !0), t.traceContextParentHeader && (e.set("traceparent", t.traceContextParentHeader), t.traceContextStateHeader && e.set("tracestate", t.traceContextStateHeader), r = !0), r;
              }
            }
            function A(e, t) {
              this.params = {}, this.metrics = {}, this.startTime = (0, g.z)(), this.dt = t, e.length >= 1 && (this.target = e[0]), e.length >= 2 && (this.opts = e[1]);
              var r,
                n = this.opts || {},
                i = this.target;
              "string" == typeof i ? r = i : "object" == typeof i && i instanceof W ? r = i.url : u._A?.URL && "object" == typeof i && i instanceof URL && (r = i.href), T(this, r);
              var o = ("" + (i && i instanceof W && i.method || n.method || "GET")).toUpperCase();
              this.params.method = o, this.txSize = B(n.body) || 0;
            }
            function x(e, t) {
              var n;
              this.endTime = (0, g.z)(), this.params || (this.params = {}), this.params.status = t ? t.status : 0, "string" == typeof this.rxSize && this.rxSize.length > 0 && (n = +this.rxSize);
              var o = {
                txSize: this.txSize,
                rxSize: n,
                duration: (0, g.z)() - this.startTime
              };
              i("xhr", [this.params, o, this.startTime, this.endTime, "fetch"], this, r.D.ajax);
            }
            function E(e) {
              var t = this.params,
                n = this.metrics;
              if (!this.ended) {
                this.ended = !0;
                for (var o = 0; o < G; o++) e.removeEventListener(V[o], this.listener, !1);
                t.aborted || (n.duration = (0, g.z)() - this.startTime, this.loadCaptureCalled || 4 !== e.readyState ? null == t.status && (t.status = 0) : _(this, e), n.cbTime = this.cbTime, i("xhr", [t, n, this.startTime, this.endTime, "xhr"], this, r.D.ajax));
              }
            }
            function T(e, t) {
              var r = (0, U.e)(t),
                n = e.params;
              n.hostname = r.hostname, n.port = r.port, n.protocol = r.protocol, n.host = r.hostname + ":" + r.port, n.pathname = r.pathname, e.parsedOrigin = r, e.sameOrigin = r.sameOrigin;
            }
            function _(e, t) {
              e.params.status = t.status;
              var r = function (e, t) {
                var r = e.responseType;
                return "json" === r && null !== t ? t : "arraybuffer" === r || "blob" === r || "json" === r ? B(e.response) : "text" === r || "" === r || void 0 === r ? B(e.responseText) : void 0;
              }(t, e.lastSize);
              if (r && (e.metrics.rxSize = r), e.sameOrigin) {
                var n = t.getResponseHeader("X-NewRelic-App-Data");
                n && (e.params.cat = n.split(", ").pop());
              }
              e.loadCaptureCalled = !0;
            }
            t.on("new-xhr", a), t.on("open-xhr-start", s), t.on("open-xhr-end", c), t.on("send-xhr-start", d), t.on("xhr-cb-time", l), t.on("xhr-load-added", f), t.on("xhr-load-removed", h), t.on("xhr-resolved", p), t.on("addEventListener-end", m), t.on("removeEventListener-end", v), t.on("fn-end", y), t.on("fetch-before-start", w), t.on("fetch-start", A), t.on("fn-start", b), t.on("fetch-done", x);
          }(e, this.ee, this.handler, this.dt), this.importAggregator());
        }
      }
      var K = i(3614);
      const {
        BST_RESOURCE: Y,
        RESOURCE: J,
        START: ee,
        END: te,
        FEATURE_NAME: re,
        FN_END: ne,
        FN_START: ie,
        PUSH_STATE: oe
      } = K;
      var ae = i(7836);
      const {
        FEATURE_NAME: se,
        START: ce,
        END: ue,
        BODY: de,
        CB_END: le,
        JS_TIME: fe,
        FETCH: he,
        FN_START: pe,
        CB_START: ge,
        FN_END: me
      } = ae;
      var ve = i(4649);
      class be extends h {
        static featureName = ve.t;
        constructor(e, t) {
          let r = !(arguments.length > 2 && void 0 !== arguments[2]) || arguments[2];
          super(e, t, ve.t, r), this.importAggregator();
        }
      }
      new class extends t {
        constructor(t) {
          let r = arguments.length > 1 && void 0 !== arguments[1] ? arguments[1] : (0, _.ky)(16);
          super(), u._A ? (this.agentIdentifier = r, this.sharedAggregator = new y({
            agentIdentifier: this.agentIdentifier
          }), this.features = {}, this.desiredFeatures = new Set(t.features || []), this.desiredFeatures.add(m), Object.assign(this, (0, s.j)(this.agentIdentifier, t, t.loaderType || "agent")), this.start()) : (0, e.Z)("Failed to initial the agent. Could not determine the runtime environment.");
        }
        get config() {
          return {
            info: (0, n.C5)(this.agentIdentifier),
            init: (0, n.P_)(this.agentIdentifier),
            loader_config: (0, n.DL)(this.agentIdentifier),
            runtime: (0, n.OP)(this.agentIdentifier)
          };
        }
        start() {
          const t = "features";
          try {
            const n = a(this.agentIdentifier),
              i = [...this.desiredFeatures];
            i.sort((e, t) => r.p[e.featureName] - r.p[t.featureName]), i.forEach(t => {
              if (n[t.featureName] || t.featureName === r.D.pageViewEvent) {
                const i = function (e) {
                  switch (e) {
                    case r.D.ajax:
                      return [r.D.jserrors];
                    case r.D.sessionTrace:
                      return [r.D.ajax, r.D.pageViewEvent];
                    case r.D.sessionReplay:
                      return [r.D.sessionTrace];
                    case r.D.pageViewTiming:
                      return [r.D.pageViewEvent];
                    default:
                      return [];
                  }
                }(t.featureName);
                i.every(e => n[e]) || (0, e.Z)("".concat(t.featureName, " is enabled but one or more dependent features has been disabled (").concat((0, D.P)(i), "). This may cause unintended consequences or missing data...")), this.features[t.featureName] = new t(this.agentIdentifier, this.sharedAggregator);
              }
            }), (0, T.Qy)(this.agentIdentifier, this.features, t);
          } catch (r) {
            (0, e.Z)("Failed to initialize all enabled instrument classes (agent aborted) -", r);
            for (const e in this.features) this.features[e].abortHandler?.();
            const n = (0, T.fP)();
            return delete n.initializedAgents[this.agentIdentifier]?.api, delete n.initializedAgents[this.agentIdentifier]?.[t], delete this.sharedAggregator, n.ee?.abort(), delete n.ee?.get(this.agentIdentifier), !1;
          }
        }
        addToTrace(t) {
          (0, e.Z)("Call to agent api addToTrace failed. The page action feature is not currently initialized.");
        }
        setCurrentRouteName(t) {
          (0, e.Z)("Call to agent api setCurrentRouteName failed. The spa feature is not currently initialized.");
        }
        interaction() {
          (0, e.Z)("Call to agent api interaction failed. The spa feature is not currently initialized.");
        }
      }({
        features: [Q, m, O, class extends h {
          static featureName = re;
          constructor(e, t) {
            if (super(e, t, re, !(arguments.length > 2 && void 0 !== arguments[2]) || arguments[2]), !u.il) return;
            const n = this.ee;
            let i;
            (0, F.QU)(n), this.eventsEE = (0, F.em)(n), this.eventsEE.on(ie, function (e, t) {
              this.bstStart = (0, g.z)();
            }), this.eventsEE.on(ne, function (e, t) {
              (0, c.p)("bst", [e[0], t, this.bstStart, (0, g.z)()], void 0, r.D.sessionTrace, n);
            }), n.on(oe + ee, function (e) {
              this.time = (0, g.z)(), this.startPath = location.pathname + location.hash;
            }), n.on(oe + te, function (e) {
              (0, c.p)("bstHist", [location.pathname + location.hash, this.startPath, this.time], void 0, r.D.sessionTrace, n);
            });
            try {
              i = new PerformanceObserver(e => {
                const t = e.getEntries();
                (0, c.p)(Y, [t], void 0, r.D.sessionTrace, n);
              }), i.observe({
                type: J,
                buffered: !0
              });
            } catch (e) {}
            this.importAggregator({
              resourceObserver: i
            });
          }
        }, P, be, k, class extends h {
          static featureName = se;
          constructor(e, t) {
            if (super(e, t, se, !(arguments.length > 2 && void 0 !== arguments[2]) || arguments[2]), !u.il) return;
            if (!(0, n.OP)(e).xhrWrappable) return;
            try {
              this.removeOnAbort = new AbortController();
            } catch (e) {}
            let r,
              i = 0;
            const o = this.ee.get("tracer"),
              a = (0, F._L)(this.ee),
              s = (0, F.Lg)(this.ee),
              c = (0, F.BV)(this.ee),
              d = (0, F.Kf)(this.ee),
              l = this.ee.get("events"),
              f = (0, F.u5)(this.ee),
              h = (0, F.QU)(this.ee),
              p = (0, F.Gm)(this.ee);
            function m(e, t) {
              h.emit("newURL", ["" + window.location, t]);
            }
            function v() {
              i++, r = window.location.hash, this[pe] = (0, g.z)();
            }
            function b() {
              i--, window.location.hash !== r && m(0, !0);
              var e = (0, g.z)();
              this[fe] = ~~this[fe] + e - this[pe], this[me] = e;
            }
            function y(e, t) {
              e.on(t, function () {
                this[t] = (0, g.z)();
              });
            }
            this.ee.on(pe, v), s.on(ge, v), a.on(ge, v), this.ee.on(me, b), s.on(le, b), a.on(le, b), this.ee.buffer([pe, me, "xhr-resolved"], this.featureName), l.buffer([pe], this.featureName), c.buffer(["setTimeout" + ue, "clearTimeout" + ce, pe], this.featureName), d.buffer([pe, "new-xhr", "send-xhr" + ce], this.featureName), f.buffer([he + ce, he + "-done", he + de + ce, he + de + ue], this.featureName), h.buffer(["newURL"], this.featureName), p.buffer([pe], this.featureName), s.buffer(["propagate", ge, le, "executor-err", "resolve" + ce], this.featureName), o.buffer([pe, "no-" + pe], this.featureName), a.buffer(["new-jsonp", "cb-start", "jsonp-error", "jsonp-end"], this.featureName), y(f, he + ce), y(f, he + "-done"), y(a, "new-jsonp"), y(a, "jsonp-end"), y(a, "cb-start"), h.on("pushState-end", m), h.on("replaceState-end", m), window.addEventListener("hashchange", m, (0, C.m$)(!0, this.removeOnAbort?.signal)), window.addEventListener("load", m, (0, C.m$)(!0, this.removeOnAbort?.signal)), window.addEventListener("popstate", function () {
              m(0, i > 1);
            }, (0, C.m$)(!0, this.removeOnAbort?.signal)), this.abortHandler = this.#i, this.importAggregator();
          }
          #i() {
            this.removeOnAbort?.abort(), this.abortHandler = void 0;
          }
        }],
        loaderType: "spa"
      });
    })();
  })();
})()</script>
<link rel="shortcut icon" href="https://sdfestaticassets-eu-west-1.sciencedirectassets.com/shared-assets/103/images/favSD.ico" type="image/x-icon">
<link rel="icon" href="https://sdfestaticassets-eu-west-1.sciencedirectassets.com/shared-assets/103/images/favSD.ico" type="image/x-icon">
<link rel="stylesheet" href="https://sdfestaticassets-eu-west-1.sciencedirectassets.com/prod/fe5f1a9a67d6a2bd1341815211e4a5a7e50a5117/arp.css">
<link href="//cdn.pendo.io" rel="dns-prefetch">
<link href="https://cdn.pendo.io" rel="preconnect" crossorigin="anonymous">
<link rel="dns-prefetch" href="https://smetrics.elsevier.com">
<script async="" id="reading-assistant-script-tag" src="/feature/assets/ai-components/S0925231220309838?componentVersion=V10&amp;jwt=eyJ0eXAiOiJKV1QiLCJhbGciOiJIUzI1NiJ9.eyJhdWQiOiJnZW5BaUFwcHMiLCJzdWIiOiI1MDQwMSIsInBpaSI6IlMwOTI1MjMxMjIwMzA5ODM4IiwiaXNzIjoiYXJwIiwic2Vzc2lvbklkIjoiZDNlOTE2NTMxZGUwYzg0OTE2MGI3M2Y0NzkyNTBiODU5NGNhZ3hycWIiLCJleHAiOjE3Mjg5OTI1MjgsImlhdCI6MTcyODk5MDcyOCwidmVyc2lvbiI6MSwianRpIjoiM2U5MzM0MGQtYzM5MS00MDIzLThhNjUtMTRjOTlkNGFmMGU5In0.w3vWVh8EJR1q38kBN1_cFPKwML8Ax-7NfTcY87vfM08" type="text/javascript"></script>
<script type="text/javascript">
        var targetServerState = JSON.stringify({"4D6368F454EC41940A4C98A6@AdobeOrg":{"sdid":{"supplementalDataIDCurrent":"2188A14E692F4139-40C2A65B8EA0F3EB","supplementalDataIDCurrentConsumed":{"payload:target-global-mbox":true},"supplementalDataIDLastConsumed":{}}}});
        window.appData = window.appData || [];
        window.pageTargeting = {"region":"eu-west-1","platform":"sdtech","entitled":true,"crawler":"","journal":"Neurocomputing","auth":"AE"};
        window.arp = {
          config: {"adobeSuite":"elsevier-sd-prod","arsUrl":"https://ars.els-cdn.com","recommendationsFeedback":{"enabled":true,"url":"https://feedback.recs.d.elsevier.com/raw/events","timeout":60000},"googleMapsApiKey":"AIzaSyCBYU6I6lrbEU6wQXUEIte3NwGtm3jwHQc","mediaBaseUrl":"https://ars.els-cdn.com/content/image/","strictMode":false,"seamlessAccess":{"enableSeamlessAccess":true,"scriptUrl":"https://unpkg.com/@theidentityselector/thiss-ds@1.0.13/dist/thiss-ds.js","persistenceUrl":"https://service.seamlessaccess.org/ps/","persistenceContext":"seamlessaccess.org","scienceDirectUrl":"https://www.sciencedirect.com","shibAuthUrl":"https://auth.elsevier.com/ShibAuth/institutionLogin"},"reaxys":{"apiUrl":"https://reaxys-sdlc.reaxys.com","origin":"sciencedirect","queryBuilderHostPath":"https://www.reaxys.com/reaxys/secured/hopinto.do","url":"https://www.reaxys.com"},"oneTrustCookie":{"enabled":true},"ssrn":{"url":"https://papers.ssrn.com","path":"/sol3/papers.cfm"},"assetRoute":"https://sdfestaticassets-eu-west-1.sciencedirectassets.com/prod/fe5f1a9a67d6a2bd1341815211e4a5a7e50a5117"},
          subscriptions: [],
          subscribe: function(cb) {
            var self = this;
            var i = this.subscriptions.push(cb) - 1;
            return function unsubscribe() {
              self.subscriptions.splice(i, 1);
            }
          },
        };
        window.addEventListener('beforeprint', () => pendo.onGuideDismissed());
      </script>
<script data-cfasync="false" src="https://cdn.cookielaw.org/scripttemplates/otSDKStub.js" data-document-language="true" data-domain-script="865ea198-88cc-4e41-8952-1df75d554d02"></script><script src="https://assets.adobedtm.com/extensions/EP8757b503532a44a68eee17773f6f10a0/AppMeasurement.min.js" async=""></script><script src="https://assets.adobedtm.com/extensions/EP8757b503532a44a68eee17773f6f10a0/AppMeasurement_Module_ActivityMap.min.js" async=""></script><script src="https://assets.adobedtm.com/4a848ae9611a/032db4f73473/6a62c1bc1779/RCa16d232f95a944c0aabdea6621a2ef94-source.min.js" async=""></script><script src="https://cdn.cookielaw.org/scripttemplates/202402.1.0/otBannerSdk.js" async="" type="text/javascript"></script><meta http-equiv="origin-trial" content="AlK2UR5SkAlj8jjdEc9p3F3xuFYlF6LYjAML3EOqw1g26eCwWPjdmecULvBH5MVPoqKYrOfPhYVL71xAXI1IBQoAAAB8eyJvcmlnaW4iOiJodHRwczovL2RvdWJsZWNsaWNrLm5ldDo0NDMiLCJmZWF0dXJlIjoiV2ViVmlld1hSZXF1ZXN0ZWRXaXRoRGVwcmVjYXRpb24iLCJleHBpcnkiOjE3NTgwNjcxOTksImlzU3ViZG9tYWluIjp0cnVlfQ=="><meta http-equiv="origin-trial" content="Amm8/NmvvQfhwCib6I7ZsmUxiSCfOxWxHayJwyU1r3gRIItzr7bNQid6O8ZYaE1GSQTa69WwhPC9flq/oYkRBwsAAACCeyJvcmlnaW4iOiJodHRwczovL2dvb2dsZXN5bmRpY2F0aW9uLmNvbTo0NDMiLCJmZWF0dXJlIjoiV2ViVmlld1hSZXF1ZXN0ZWRXaXRoRGVwcmVjYXRpb24iLCJleHBpcnkiOjE3NTgwNjcxOTksImlzU3ViZG9tYWluIjp0cnVlfQ=="><meta http-equiv="origin-trial" content="A9wSqI5i0iwGdf6L1CERNdmsTPgVu44ewj8QxTBYgsv1LCPUVF7YmWOvTappqB1139jAymxUW/RO8zmMqo4zlAAAAACNeyJvcmlnaW4iOiJodHRwczovL2RvdWJsZWNsaWNrLm5ldDo0NDMiLCJmZWF0dXJlIjoiRmxlZGdlQmlkZGluZ0FuZEF1Y3Rpb25TZXJ2ZXIiLCJleHBpcnkiOjE3MzY4MTI4MDAsImlzU3ViZG9tYWluIjp0cnVlLCJpc1RoaXJkUGFydHkiOnRydWV9"><meta http-equiv="origin-trial" content="A+d7vJfYtay4OUbdtRPZA3y7bKQLsxaMEPmxgfhBGqKXNrdkCQeJlUwqa6EBbSfjwFtJWTrWIioXeMW+y8bWAgQAAACTeyJvcmlnaW4iOiJodHRwczovL2dvb2dsZXN5bmRpY2F0aW9uLmNvbTo0NDMiLCJmZWF0dXJlIjoiRmxlZGdlQmlkZGluZ0FuZEF1Y3Rpb25TZXJ2ZXIiLCJleHBpcnkiOjE3MzY4MTI4MDAsImlzU3ViZG9tYWluIjp0cnVlLCJpc1RoaXJkUGFydHkiOnRydWV9"><script src="https://securepubads.g.doubleclick.net/pagead/managed/js/gpt/m202410100101/pubads_impl.js" async=""></script><style type="text/css">.MathJax_Hover_Frame {border-radius: .25em; -webkit-border-radius: .25em; -moz-border-radius: .25em; -khtml-border-radius: .25em; box-shadow: 0px 0px 15px #83A; -webkit-box-shadow: 0px 0px 15px #83A; -moz-box-shadow: 0px 0px 15px #83A; -khtml-box-shadow: 0px 0px 15px #83A; border: 1px solid #A6D ! important; display: inline-block; position: absolute}
.MathJax_Menu_Button .MathJax_Hover_Arrow {position: absolute; cursor: pointer; display: inline-block; border: 2px solid #AAA; border-radius: 4px; -webkit-border-radius: 4px; -moz-border-radius: 4px; -khtml-border-radius: 4px; font-family: 'Courier New',Courier; font-size: 9px; color: #F0F0F0}
.MathJax_Menu_Button .MathJax_Hover_Arrow span {display: block; background-color: #AAA; border: 1px solid; border-radius: 3px; line-height: 0; padding: 4px}
.MathJax_Hover_Arrow:hover {color: white!important; border: 2px solid #CCC!important}
.MathJax_Hover_Arrow:hover span {background-color: #CCC!important}
</style><style type="text/css">#MathJax_About {position: fixed; left: 50%; width: auto; text-align: center; border: 3px outset; padding: 1em 2em; background-color: #DDDDDD; color: black; cursor: default; font-family: message-box; font-size: 120%; font-style: normal; text-indent: 0; text-transform: none; line-height: normal; letter-spacing: normal; word-spacing: normal; word-wrap: normal; white-space: nowrap; float: none; z-index: 201; border-radius: 15px; -webkit-border-radius: 15px; -moz-border-radius: 15px; -khtml-border-radius: 15px; box-shadow: 0px 10px 20px #808080; -webkit-box-shadow: 0px 10px 20px #808080; -moz-box-shadow: 0px 10px 20px #808080; -khtml-box-shadow: 0px 10px 20px #808080; filter: progid:DXImageTransform.Microsoft.dropshadow(OffX=2, OffY=2, Color='gray', Positive='true')}
#MathJax_About.MathJax_MousePost {outline: none}
.MathJax_Menu {position: absolute; background-color: white; color: black; width: auto; padding: 2px; border: 1px solid #CCCCCC; margin: 0; cursor: default; font: menu; text-align: left; text-indent: 0; text-transform: none; line-height: normal; letter-spacing: normal; word-spacing: normal; word-wrap: normal; white-space: nowrap; float: none; z-index: 201; box-shadow: 0px 10px 20px #808080; -webkit-box-shadow: 0px 10px 20px #808080; -moz-box-shadow: 0px 10px 20px #808080; -khtml-box-shadow: 0px 10px 20px #808080; filter: progid:DXImageTransform.Microsoft.dropshadow(OffX=2, OffY=2, Color='gray', Positive='true')}
.MathJax_MenuItem {padding: 2px 2em; background: transparent}
.MathJax_MenuArrow {position: absolute; right: .5em; padding-top: .25em; color: #666666; font-size: .75em}
.MathJax_MenuActive .MathJax_MenuArrow {color: white}
.MathJax_MenuArrow.RTL {left: .5em; right: auto}
.MathJax_MenuCheck {position: absolute; left: .7em}
.MathJax_MenuCheck.RTL {right: .7em; left: auto}
.MathJax_MenuRadioCheck {position: absolute; left: 1em}
.MathJax_MenuRadioCheck.RTL {right: 1em; left: auto}
.MathJax_MenuLabel {padding: 2px 2em 4px 1.33em; font-style: italic}
.MathJax_MenuRule {border-top: 1px solid #CCCCCC; margin: 4px 1px 0px}
.MathJax_MenuDisabled {color: GrayText}
.MathJax_MenuActive {background-color: Highlight; color: HighlightText}
.MathJax_MenuDisabled:focus, .MathJax_MenuLabel:focus {background-color: #E8E8E8}
.MathJax_ContextMenu:focus {outline: none}
.MathJax_ContextMenu .MathJax_MenuItem:focus {outline: none}
#MathJax_AboutClose {top: .2em; right: .2em}
.MathJax_Menu .MathJax_MenuClose {top: -10px; left: -10px}
.MathJax_MenuClose {position: absolute; cursor: pointer; display: inline-block; border: 2px solid #AAA; border-radius: 18px; -webkit-border-radius: 18px; -moz-border-radius: 18px; -khtml-border-radius: 18px; font-family: 'Courier New',Courier; font-size: 24px; color: #F0F0F0}
.MathJax_MenuClose span {display: block; background-color: #AAA; border: 1.5px solid; border-radius: 18px; -webkit-border-radius: 18px; -moz-border-radius: 18px; -khtml-border-radius: 18px; line-height: 0; padding: 8px 0 6px}
.MathJax_MenuClose:hover {color: white!important; border: 2px solid #CCC!important}
.MathJax_MenuClose:hover span {background-color: #CCC!important}
.MathJax_MenuClose:hover:focus {outline: none}
</style><style type="text/css">.MJX_Assistive_MathML {position: absolute!important; top: 0; left: 0; clip: rect(1px, 1px, 1px, 1px); padding: 1px 0 0 0!important; border: 0!important; height: 1px!important; width: 1px!important; overflow: hidden!important; display: block!important; -webkit-touch-callout: none; -webkit-user-select: none; -khtml-user-select: none; -moz-user-select: none; -ms-user-select: none; user-select: none}
.MJX_Assistive_MathML.MJX_Assistive_MathML_Block {width: 100%!important}
</style><style type="text/css">#MathJax_Zoom {position: absolute; background-color: #F0F0F0; overflow: auto; display: block; z-index: 301; padding: .5em; border: 1px solid black; margin: 0; font-weight: normal; font-style: normal; text-align: left; text-indent: 0; text-transform: none; line-height: normal; letter-spacing: normal; word-spacing: normal; word-wrap: normal; white-space: nowrap; float: none; -webkit-box-sizing: content-box; -moz-box-sizing: content-box; box-sizing: content-box; box-shadow: 5px 5px 15px #AAAAAA; -webkit-box-shadow: 5px 5px 15px #AAAAAA; -moz-box-shadow: 5px 5px 15px #AAAAAA; -khtml-box-shadow: 5px 5px 15px #AAAAAA; filter: progid:DXImageTransform.Microsoft.dropshadow(OffX=2, OffY=2, Color='gray', Positive='true')}
#MathJax_ZoomOverlay {position: absolute; left: 0; top: 0; z-index: 300; display: inline-block; width: 100%; height: 100%; border: 0; padding: 0; margin: 0; background-color: white; opacity: 0; filter: alpha(opacity=0)}
#MathJax_ZoomFrame {position: relative; display: inline-block; height: 0; width: 0}
#MathJax_ZoomEventTrap {position: absolute; left: 0; top: 0; z-index: 302; display: inline-block; border: 0; padding: 0; margin: 0; background-color: white; opacity: 0; filter: alpha(opacity=0)}
</style><style type="text/css">.MathJax_Preview {color: #888}
#MathJax_Message {position: fixed; left: 1em; bottom: 1.5em; background-color: #E6E6E6; border: 1px solid #959595; margin: 0px; padding: 2px 8px; z-index: 102; color: black; font-size: 80%; width: auto; white-space: nowrap}
#MathJax_MSIE_Frame {position: absolute; top: 0; left: 0; width: 0px; z-index: 101; border: 0px; margin: 0px; padding: 0px}
.MathJax_Error {color: #CC0000; font-style: italic}
</style><link id="plx-css-summary" type="text/css" rel="stylesheet" href="//cdn.plu.mx/summary.css"><script type="text/javascript" src="//ajax.googleapis.com/ajax/libs/jquery/1.10.2/jquery.min.js"></script><script type="text/javascript" src="//cdn.plu.mx/extjs/xss.js"></script><style type="text/css">.MJXp-script {font-size: .8em}
.MJXp-right {-webkit-transform-origin: right; -moz-transform-origin: right; -ms-transform-origin: right; -o-transform-origin: right; transform-origin: right}
.MJXp-bold {font-weight: bold}
.MJXp-italic {font-style: italic}
.MJXp-scr {font-family: MathJax_Script,'Times New Roman',Times,STIXGeneral,serif}
.MJXp-frak {font-family: MathJax_Fraktur,'Times New Roman',Times,STIXGeneral,serif}
.MJXp-sf {font-family: MathJax_SansSerif,'Times New Roman',Times,STIXGeneral,serif}
.MJXp-cal {font-family: MathJax_Caligraphic,'Times New Roman',Times,STIXGeneral,serif}
.MJXp-mono {font-family: MathJax_Typewriter,'Times New Roman',Times,STIXGeneral,serif}
.MJXp-largeop {font-size: 150%}
.MJXp-largeop.MJXp-int {vertical-align: -.2em}
.MJXp-math {display: inline-block; line-height: 1.2; text-indent: 0; font-family: 'Times New Roman',Times,STIXGeneral,serif; white-space: nowrap; border-collapse: collapse}
.MJXp-display {display: block; text-align: center; margin: 1em 0}
.MJXp-math span {display: inline-block}
.MJXp-box {display: block!important; text-align: center}
.MJXp-box:after {content: " "}
.MJXp-rule {display: block!important; margin-top: .1em}
.MJXp-char {display: block!important}
.MJXp-mo {margin: 0 .15em}
.MJXp-mfrac {margin: 0 .125em; vertical-align: .25em}
.MJXp-denom {display: inline-table!important; width: 100%}
.MJXp-denom > * {display: table-row!important}
.MJXp-surd {vertical-align: top}
.MJXp-surd > * {display: block!important}
.MJXp-script-box > *  {display: table!important; height: 50%}
.MJXp-script-box > * > * {display: table-cell!important; vertical-align: top}
.MJXp-script-box > *:last-child > * {vertical-align: bottom}
.MJXp-script-box > * > * > * {display: block!important}
.MJXp-mphantom {visibility: hidden}
.MJXp-munderover, .MJXp-munder {display: inline-table!important}
.MJXp-over {display: inline-block!important; text-align: center}
.MJXp-over > * {display: block!important}
.MJXp-munderover > *, .MJXp-munder > * {display: table-row!important}
.MJXp-mtable {vertical-align: .25em; margin: 0 .125em}
.MJXp-mtable > * {display: inline-table!important; vertical-align: middle}
.MJXp-mtr {display: table-row!important}
.MJXp-mtd {display: table-cell!important; text-align: center; padding: .5em 0 0 .5em}
.MJXp-mtr > .MJXp-mtd:first-child {padding-left: 0}
.MJXp-mtr:first-child > .MJXp-mtd {padding-top: 0}
.MJXp-mlabeledtr {display: table-row!important}
.MJXp-mlabeledtr > .MJXp-mtd:first-child {padding-left: 0}
.MJXp-mlabeledtr:first-child > .MJXp-mtd {padding-top: 0}
.MJXp-merror {background-color: #FFFF88; color: #CC0000; border: 1px solid #CC0000; padding: 1px 3px; font-style: normal; font-size: 90%}
.MJXp-scale0 {-webkit-transform: scaleX(.0); -moz-transform: scaleX(.0); -ms-transform: scaleX(.0); -o-transform: scaleX(.0); transform: scaleX(.0)}
.MJXp-scale1 {-webkit-transform: scaleX(.1); -moz-transform: scaleX(.1); -ms-transform: scaleX(.1); -o-transform: scaleX(.1); transform: scaleX(.1)}
.MJXp-scale2 {-webkit-transform: scaleX(.2); -moz-transform: scaleX(.2); -ms-transform: scaleX(.2); -o-transform: scaleX(.2); transform: scaleX(.2)}
.MJXp-scale3 {-webkit-transform: scaleX(.3); -moz-transform: scaleX(.3); -ms-transform: scaleX(.3); -o-transform: scaleX(.3); transform: scaleX(.3)}
.MJXp-scale4 {-webkit-transform: scaleX(.4); -moz-transform: scaleX(.4); -ms-transform: scaleX(.4); -o-transform: scaleX(.4); transform: scaleX(.4)}
.MJXp-scale5 {-webkit-transform: scaleX(.5); -moz-transform: scaleX(.5); -ms-transform: scaleX(.5); -o-transform: scaleX(.5); transform: scaleX(.5)}
.MJXp-scale6 {-webkit-transform: scaleX(.6); -moz-transform: scaleX(.6); -ms-transform: scaleX(.6); -o-transform: scaleX(.6); transform: scaleX(.6)}
.MJXp-scale7 {-webkit-transform: scaleX(.7); -moz-transform: scaleX(.7); -ms-transform: scaleX(.7); -o-transform: scaleX(.7); transform: scaleX(.7)}
.MJXp-scale8 {-webkit-transform: scaleX(.8); -moz-transform: scaleX(.8); -ms-transform: scaleX(.8); -o-transform: scaleX(.8); transform: scaleX(.8)}
.MJXp-scale9 {-webkit-transform: scaleX(.9); -moz-transform: scaleX(.9); -ms-transform: scaleX(.9); -o-transform: scaleX(.9); transform: scaleX(.9)}
</style><style id="onetrust-style">#onetrust-banner-sdk{-ms-text-size-adjust:100%;-webkit-text-size-adjust:100%}#onetrust-banner-sdk .onetrust-vendors-list-handler{cursor:pointer;color:#1f96db;font-size:inherit;font-weight:bold;text-decoration:none;margin-left:5px}#onetrust-banner-sdk .onetrust-vendors-list-handler:hover{color:#1f96db}#onetrust-banner-sdk:focus{outline:2px solid #000;outline-offset:-2px}#onetrust-banner-sdk a:focus{outline:2px solid #000}#onetrust-banner-sdk #onetrust-accept-btn-handler,#onetrust-banner-sdk #onetrust-reject-all-handler,#onetrust-banner-sdk #onetrust-pc-btn-handler{outline-offset:1px}#onetrust-banner-sdk.ot-bnr-w-logo .ot-bnr-logo{height:64px;width:64px}#onetrust-banner-sdk .ot-tcf2-vendor-count.ot-text-bold{font-weight:bold}#onetrust-banner-sdk .ot-close-icon,#onetrust-pc-sdk .ot-close-icon,#ot-sync-ntfy .ot-close-icon{background-size:contain;background-repeat:no-repeat;background-position:center;height:12px;width:12px}#onetrust-banner-sdk .powered-by-logo,#onetrust-banner-sdk .ot-pc-footer-logo a,#onetrust-pc-sdk .powered-by-logo,#onetrust-pc-sdk .ot-pc-footer-logo a,#ot-sync-ntfy .powered-by-logo,#ot-sync-ntfy .ot-pc-footer-logo a{background-size:contain;background-repeat:no-repeat;background-position:center;height:25px;width:152px;display:block;text-decoration:none;font-size:.75em}#onetrust-banner-sdk .powered-by-logo:hover,#onetrust-banner-sdk .ot-pc-footer-logo a:hover,#onetrust-pc-sdk .powered-by-logo:hover,#onetrust-pc-sdk .ot-pc-footer-logo a:hover,#ot-sync-ntfy .powered-by-logo:hover,#ot-sync-ntfy .ot-pc-footer-logo a:hover{color:#565656}#onetrust-banner-sdk h3 *,#onetrust-banner-sdk h4 *,#onetrust-banner-sdk h6 *,#onetrust-banner-sdk button *,#onetrust-banner-sdk a[data-parent-id] *,#onetrust-pc-sdk h3 *,#onetrust-pc-sdk h4 *,#onetrust-pc-sdk h6 *,#onetrust-pc-sdk button *,#onetrust-pc-sdk a[data-parent-id] *,#ot-sync-ntfy h3 *,#ot-sync-ntfy h4 *,#ot-sync-ntfy h6 *,#ot-sync-ntfy button *,#ot-sync-ntfy a[data-parent-id] *{font-size:inherit;font-weight:inherit;color:inherit}#onetrust-banner-sdk .ot-hide,#onetrust-pc-sdk .ot-hide,#ot-sync-ntfy .ot-hide{display:none !important}#onetrust-banner-sdk button.ot-link-btn:hover,#onetrust-pc-sdk button.ot-link-btn:hover,#ot-sync-ntfy button.ot-link-btn:hover{text-decoration:underline;opacity:1}#onetrust-pc-sdk .ot-sdk-row .ot-sdk-column{padding:0}#onetrust-pc-sdk .ot-sdk-container{padding-right:0}#onetrust-pc-sdk .ot-sdk-row{flex-direction:initial;width:100%}#onetrust-pc-sdk [type=checkbox]:checked,#onetrust-pc-sdk [type=checkbox]:not(:checked){pointer-events:initial}#onetrust-pc-sdk [type=checkbox]:disabled+label::before,#onetrust-pc-sdk [type=checkbox]:disabled+label:after,#onetrust-pc-sdk [type=checkbox]:disabled+label{pointer-events:none;opacity:.7}#onetrust-pc-sdk #vendor-list-content{transform:translate3d(0, 0, 0)}#onetrust-pc-sdk li input[type=checkbox]{z-index:1}#onetrust-pc-sdk li .ot-checkbox label{z-index:2}#onetrust-pc-sdk li .ot-checkbox input[type=checkbox]{height:auto;width:auto}#onetrust-pc-sdk li .host-title a,#onetrust-pc-sdk li .ot-host-name a,#onetrust-pc-sdk li .accordion-text,#onetrust-pc-sdk li .ot-acc-txt{z-index:2;position:relative}#onetrust-pc-sdk input{margin:3px .1ex}#onetrust-pc-sdk .pc-logo,#onetrust-pc-sdk .ot-pc-logo{height:60px;width:180px;background-position:center;background-size:contain;background-repeat:no-repeat;display:inline-flex;justify-content:center;align-items:center}#onetrust-pc-sdk .pc-logo img,#onetrust-pc-sdk .ot-pc-logo img{max-height:100%;max-width:100%}#onetrust-pc-sdk .screen-reader-only,#onetrust-pc-sdk .ot-scrn-rdr,.ot-sdk-cookie-policy .screen-reader-only,.ot-sdk-cookie-policy .ot-scrn-rdr{border:0;clip:rect(0 0 0 0);height:1px;margin:-1px;overflow:hidden;padding:0;position:absolute;width:1px}#onetrust-pc-sdk.ot-fade-in,.onetrust-pc-dark-filter.ot-fade-in,#onetrust-banner-sdk.ot-fade-in{animation-name:onetrust-fade-in;animation-duration:400ms;animation-timing-function:ease-in-out}#onetrust-pc-sdk.ot-hide{display:none !important}.onetrust-pc-dark-filter.ot-hide{display:none !important}#ot-sdk-btn.ot-sdk-show-settings,#ot-sdk-btn.optanon-show-settings{color:#68b631;border:1px solid #68b631;height:auto;white-space:normal;word-wrap:break-word;padding:.8em 2em;font-size:.8em;line-height:1.2;cursor:pointer;-moz-transition:.1s ease;-o-transition:.1s ease;-webkit-transition:1s ease;transition:.1s ease}#ot-sdk-btn.ot-sdk-show-settings:hover,#ot-sdk-btn.optanon-show-settings:hover{color:#fff;background-color:#68b631}.onetrust-pc-dark-filter{background:rgba(0,0,0,.5);z-index:2147483646;width:100%;height:100%;overflow:hidden;position:fixed;top:0;bottom:0;left:0}@keyframes onetrust-fade-in{0%{opacity:0}100%{opacity:1}}.ot-cookie-label{text-decoration:underline}@media only screen and (min-width: 426px)and (max-width: 896px)and (orientation: landscape){#onetrust-pc-sdk p{font-size:.75em}}#onetrust-banner-sdk .banner-option-input:focus+label{outline:1px solid #000;outline-style:auto}.category-vendors-list-handler+a:focus,.category-vendors-list-handler+a:focus-visible{outline:2px solid #000}#onetrust-pc-sdk .ot-userid-title{margin-top:10px}#onetrust-pc-sdk .ot-userid-title>span,#onetrust-pc-sdk .ot-userid-timestamp>span{font-weight:700}#onetrust-pc-sdk .ot-userid-desc{font-style:italic}#onetrust-pc-sdk .ot-host-desc a{pointer-events:initial}#onetrust-pc-sdk .ot-ven-hdr>p a{position:relative;z-index:2;pointer-events:initial}#onetrust-pc-sdk .ot-vnd-serv .ot-vnd-item .ot-vnd-info a,#onetrust-pc-sdk .ot-vs-list .ot-vnd-item .ot-vnd-info a{margin-right:auto}#onetrust-pc-sdk .ot-pc-footer-logo img{width:136px;height:16px}#onetrust-pc-sdk .ot-pur-vdr-count{font-weight:400;font-size:.7rem;padding-top:3px;display:block}#onetrust-banner-sdk .ot-optout-signal,#onetrust-pc-sdk .ot-optout-signal{border:1px solid #32ae88;border-radius:3px;padding:5px;margin-bottom:10px;background-color:#f9fffa;font-size:.85rem;line-height:2}#onetrust-banner-sdk .ot-optout-signal .ot-optout-icon,#onetrust-pc-sdk .ot-optout-signal .ot-optout-icon{display:inline;margin-right:5px}#onetrust-banner-sdk .ot-optout-signal svg,#onetrust-pc-sdk .ot-optout-signal svg{height:20px;width:30px;transform:scale(0.5)}#onetrust-banner-sdk .ot-optout-signal svg path,#onetrust-pc-sdk .ot-optout-signal svg path{fill:#32ae88}#onetrust-banner-sdk,#onetrust-pc-sdk,#ot-sdk-cookie-policy,#ot-sync-ntfy{font-size:16px}#onetrust-banner-sdk *,#onetrust-banner-sdk ::after,#onetrust-banner-sdk ::before,#onetrust-pc-sdk *,#onetrust-pc-sdk ::after,#onetrust-pc-sdk ::before,#ot-sdk-cookie-policy *,#ot-sdk-cookie-policy ::after,#ot-sdk-cookie-policy ::before,#ot-sync-ntfy *,#ot-sync-ntfy ::after,#ot-sync-ntfy ::before{-webkit-box-sizing:content-box;-moz-box-sizing:content-box;box-sizing:content-box}#onetrust-banner-sdk div,#onetrust-banner-sdk span,#onetrust-banner-sdk h1,#onetrust-banner-sdk h2,#onetrust-banner-sdk h3,#onetrust-banner-sdk h4,#onetrust-banner-sdk h5,#onetrust-banner-sdk h6,#onetrust-banner-sdk p,#onetrust-banner-sdk img,#onetrust-banner-sdk svg,#onetrust-banner-sdk button,#onetrust-banner-sdk section,#onetrust-banner-sdk a,#onetrust-banner-sdk label,#onetrust-banner-sdk input,#onetrust-banner-sdk ul,#onetrust-banner-sdk li,#onetrust-banner-sdk nav,#onetrust-banner-sdk table,#onetrust-banner-sdk thead,#onetrust-banner-sdk tr,#onetrust-banner-sdk td,#onetrust-banner-sdk tbody,#onetrust-banner-sdk .ot-main-content,#onetrust-banner-sdk .ot-toggle,#onetrust-banner-sdk #ot-content,#onetrust-banner-sdk #ot-pc-content,#onetrust-banner-sdk .checkbox,#onetrust-pc-sdk div,#onetrust-pc-sdk span,#onetrust-pc-sdk h1,#onetrust-pc-sdk h2,#onetrust-pc-sdk h3,#onetrust-pc-sdk h4,#onetrust-pc-sdk h5,#onetrust-pc-sdk h6,#onetrust-pc-sdk p,#onetrust-pc-sdk img,#onetrust-pc-sdk svg,#onetrust-pc-sdk button,#onetrust-pc-sdk section,#onetrust-pc-sdk a,#onetrust-pc-sdk label,#onetrust-pc-sdk input,#onetrust-pc-sdk ul,#onetrust-pc-sdk li,#onetrust-pc-sdk nav,#onetrust-pc-sdk table,#onetrust-pc-sdk thead,#onetrust-pc-sdk tr,#onetrust-pc-sdk td,#onetrust-pc-sdk tbody,#onetrust-pc-sdk .ot-main-content,#onetrust-pc-sdk .ot-toggle,#onetrust-pc-sdk #ot-content,#onetrust-pc-sdk #ot-pc-content,#onetrust-pc-sdk .checkbox,#ot-sdk-cookie-policy div,#ot-sdk-cookie-policy span,#ot-sdk-cookie-policy h1,#ot-sdk-cookie-policy h2,#ot-sdk-cookie-policy h3,#ot-sdk-cookie-policy h4,#ot-sdk-cookie-policy h5,#ot-sdk-cookie-policy h6,#ot-sdk-cookie-policy p,#ot-sdk-cookie-policy img,#ot-sdk-cookie-policy svg,#ot-sdk-cookie-policy button,#ot-sdk-cookie-policy section,#ot-sdk-cookie-policy a,#ot-sdk-cookie-policy label,#ot-sdk-cookie-policy input,#ot-sdk-cookie-policy ul,#ot-sdk-cookie-policy li,#ot-sdk-cookie-policy nav,#ot-sdk-cookie-policy table,#ot-sdk-cookie-policy thead,#ot-sdk-cookie-policy tr,#ot-sdk-cookie-policy td,#ot-sdk-cookie-policy tbody,#ot-sdk-cookie-policy .ot-main-content,#ot-sdk-cookie-policy .ot-toggle,#ot-sdk-cookie-policy #ot-content,#ot-sdk-cookie-policy #ot-pc-content,#ot-sdk-cookie-policy .checkbox,#ot-sync-ntfy div,#ot-sync-ntfy span,#ot-sync-ntfy h1,#ot-sync-ntfy h2,#ot-sync-ntfy h3,#ot-sync-ntfy h4,#ot-sync-ntfy h5,#ot-sync-ntfy h6,#ot-sync-ntfy p,#ot-sync-ntfy img,#ot-sync-ntfy svg,#ot-sync-ntfy button,#ot-sync-ntfy section,#ot-sync-ntfy a,#ot-sync-ntfy label,#ot-sync-ntfy input,#ot-sync-ntfy ul,#ot-sync-ntfy li,#ot-sync-ntfy nav,#ot-sync-ntfy table,#ot-sync-ntfy thead,#ot-sync-ntfy tr,#ot-sync-ntfy td,#ot-sync-ntfy tbody,#ot-sync-ntfy .ot-main-content,#ot-sync-ntfy .ot-toggle,#ot-sync-ntfy #ot-content,#ot-sync-ntfy #ot-pc-content,#ot-sync-ntfy .checkbox{font-family:inherit;font-weight:normal;-webkit-font-smoothing:auto;letter-spacing:normal;line-height:normal;padding:0;margin:0;height:auto;min-height:0;max-height:none;width:auto;min-width:0;max-width:none;border-radius:0;border:none;clear:none;float:none;position:static;bottom:auto;left:auto;right:auto;top:auto;text-align:left;text-decoration:none;text-indent:0;text-shadow:none;text-transform:none;white-space:normal;background:none;overflow:visible;vertical-align:baseline;visibility:visible;z-index:auto;box-shadow:none}#onetrust-banner-sdk label:before,#onetrust-banner-sdk label:after,#onetrust-banner-sdk .checkbox:after,#onetrust-banner-sdk .checkbox:before,#onetrust-pc-sdk label:before,#onetrust-pc-sdk label:after,#onetrust-pc-sdk .checkbox:after,#onetrust-pc-sdk .checkbox:before,#ot-sdk-cookie-policy label:before,#ot-sdk-cookie-policy label:after,#ot-sdk-cookie-policy .checkbox:after,#ot-sdk-cookie-policy .checkbox:before,#ot-sync-ntfy label:before,#ot-sync-ntfy label:after,#ot-sync-ntfy .checkbox:after,#ot-sync-ntfy .checkbox:before{content:"";content:none}#onetrust-banner-sdk .ot-sdk-container,#onetrust-pc-sdk .ot-sdk-container,#ot-sdk-cookie-policy .ot-sdk-container{position:relative;width:100%;max-width:100%;margin:0 auto;padding:0 20px;box-sizing:border-box}#onetrust-banner-sdk .ot-sdk-column,#onetrust-banner-sdk .ot-sdk-columns,#onetrust-pc-sdk .ot-sdk-column,#onetrust-pc-sdk .ot-sdk-columns,#ot-sdk-cookie-policy .ot-sdk-column,#ot-sdk-cookie-policy .ot-sdk-columns{width:100%;float:left;box-sizing:border-box;padding:0;display:initial}@media(min-width: 400px){#onetrust-banner-sdk .ot-sdk-container,#onetrust-pc-sdk .ot-sdk-container,#ot-sdk-cookie-policy .ot-sdk-container{width:90%;padding:0}}@media(min-width: 550px){#onetrust-banner-sdk .ot-sdk-container,#onetrust-pc-sdk .ot-sdk-container,#ot-sdk-cookie-policy .ot-sdk-container{width:100%}#onetrust-banner-sdk .ot-sdk-column,#onetrust-banner-sdk .ot-sdk-columns,#onetrust-pc-sdk .ot-sdk-column,#onetrust-pc-sdk .ot-sdk-columns,#ot-sdk-cookie-policy .ot-sdk-column,#ot-sdk-cookie-policy .ot-sdk-columns{margin-left:4%}#onetrust-banner-sdk .ot-sdk-column:first-child,#onetrust-banner-sdk .ot-sdk-columns:first-child,#onetrust-pc-sdk .ot-sdk-column:first-child,#onetrust-pc-sdk .ot-sdk-columns:first-child,#ot-sdk-cookie-policy .ot-sdk-column:first-child,#ot-sdk-cookie-policy .ot-sdk-columns:first-child{margin-left:0}#onetrust-banner-sdk .ot-sdk-two.ot-sdk-columns,#onetrust-pc-sdk .ot-sdk-two.ot-sdk-columns,#ot-sdk-cookie-policy .ot-sdk-two.ot-sdk-columns{width:13.3333333333%}#onetrust-banner-sdk .ot-sdk-three.ot-sdk-columns,#onetrust-pc-sdk .ot-sdk-three.ot-sdk-columns,#ot-sdk-cookie-policy .ot-sdk-three.ot-sdk-columns{width:22%}#onetrust-banner-sdk .ot-sdk-four.ot-sdk-columns,#onetrust-pc-sdk .ot-sdk-four.ot-sdk-columns,#ot-sdk-cookie-policy .ot-sdk-four.ot-sdk-columns{width:30.6666666667%}#onetrust-banner-sdk .ot-sdk-eight.ot-sdk-columns,#onetrust-pc-sdk .ot-sdk-eight.ot-sdk-columns,#ot-sdk-cookie-policy .ot-sdk-eight.ot-sdk-columns{width:65.3333333333%}#onetrust-banner-sdk .ot-sdk-nine.ot-sdk-columns,#onetrust-pc-sdk .ot-sdk-nine.ot-sdk-columns,#ot-sdk-cookie-policy .ot-sdk-nine.ot-sdk-columns{width:74%}#onetrust-banner-sdk .ot-sdk-ten.ot-sdk-columns,#onetrust-pc-sdk .ot-sdk-ten.ot-sdk-columns,#ot-sdk-cookie-policy .ot-sdk-ten.ot-sdk-columns{width:82.6666666667%}#onetrust-banner-sdk .ot-sdk-eleven.ot-sdk-columns,#onetrust-pc-sdk .ot-sdk-eleven.ot-sdk-columns,#ot-sdk-cookie-policy .ot-sdk-eleven.ot-sdk-columns{width:91.3333333333%}#onetrust-banner-sdk .ot-sdk-twelve.ot-sdk-columns,#onetrust-pc-sdk .ot-sdk-twelve.ot-sdk-columns,#ot-sdk-cookie-policy .ot-sdk-twelve.ot-sdk-columns{width:100%;margin-left:0}}#onetrust-banner-sdk h1,#onetrust-banner-sdk h2,#onetrust-banner-sdk h3,#onetrust-banner-sdk h4,#onetrust-banner-sdk h5,#onetrust-banner-sdk h6,#onetrust-pc-sdk h1,#onetrust-pc-sdk h2,#onetrust-pc-sdk h3,#onetrust-pc-sdk h4,#onetrust-pc-sdk h5,#onetrust-pc-sdk h6,#ot-sdk-cookie-policy h1,#ot-sdk-cookie-policy h2,#ot-sdk-cookie-policy h3,#ot-sdk-cookie-policy h4,#ot-sdk-cookie-policy h5,#ot-sdk-cookie-policy h6{margin-top:0;font-weight:600;font-family:inherit}#onetrust-banner-sdk h1,#onetrust-pc-sdk h1,#ot-sdk-cookie-policy h1{font-size:1.5rem;line-height:1.2}#onetrust-banner-sdk h2,#onetrust-pc-sdk h2,#ot-sdk-cookie-policy h2{font-size:1.5rem;line-height:1.25}#onetrust-banner-sdk h3,#onetrust-pc-sdk h3,#ot-sdk-cookie-policy h3{font-size:1.5rem;line-height:1.3}#onetrust-banner-sdk h4,#onetrust-pc-sdk h4,#ot-sdk-cookie-policy h4{font-size:1.5rem;line-height:1.35}#onetrust-banner-sdk h5,#onetrust-pc-sdk h5,#ot-sdk-cookie-policy h5{font-size:1.5rem;line-height:1.5}#onetrust-banner-sdk h6,#onetrust-pc-sdk h6,#ot-sdk-cookie-policy h6{font-size:1.5rem;line-height:1.6}@media(min-width: 550px){#onetrust-banner-sdk h1,#onetrust-pc-sdk h1,#ot-sdk-cookie-policy h1{font-size:1.5rem}#onetrust-banner-sdk h2,#onetrust-pc-sdk h2,#ot-sdk-cookie-policy h2{font-size:1.5rem}#onetrust-banner-sdk h3,#onetrust-pc-sdk h3,#ot-sdk-cookie-policy h3{font-size:1.5rem}#onetrust-banner-sdk h4,#onetrust-pc-sdk h4,#ot-sdk-cookie-policy h4{font-size:1.5rem}#onetrust-banner-sdk h5,#onetrust-pc-sdk h5,#ot-sdk-cookie-policy h5{font-size:1.5rem}#onetrust-banner-sdk h6,#onetrust-pc-sdk h6,#ot-sdk-cookie-policy h6{font-size:1.5rem}}#onetrust-banner-sdk p,#onetrust-pc-sdk p,#ot-sdk-cookie-policy p{margin:0 0 1em 0;font-family:inherit;line-height:normal}#onetrust-banner-sdk a,#onetrust-pc-sdk a,#ot-sdk-cookie-policy a{color:#565656;text-decoration:underline}#onetrust-banner-sdk a:hover,#onetrust-pc-sdk a:hover,#ot-sdk-cookie-policy a:hover{color:#565656;text-decoration:none}#onetrust-banner-sdk .ot-sdk-button,#onetrust-banner-sdk button,#onetrust-pc-sdk .ot-sdk-button,#onetrust-pc-sdk button,#ot-sdk-cookie-policy .ot-sdk-button,#ot-sdk-cookie-policy button{margin-bottom:1rem;font-family:inherit}#onetrust-banner-sdk .ot-sdk-button,#onetrust-banner-sdk button,#onetrust-pc-sdk .ot-sdk-button,#onetrust-pc-sdk button,#ot-sdk-cookie-policy .ot-sdk-button,#ot-sdk-cookie-policy button{display:inline-block;height:38px;padding:0 30px;color:#555;text-align:center;font-size:.9em;font-weight:400;line-height:38px;letter-spacing:.01em;text-decoration:none;white-space:nowrap;background-color:rgba(0,0,0,0);border-radius:2px;border:1px solid #bbb;cursor:pointer;box-sizing:border-box}#onetrust-banner-sdk .ot-sdk-button:hover,#onetrust-banner-sdk :not(.ot-leg-btn-container)>button:not(.ot-link-btn):hover,#onetrust-banner-sdk :not(.ot-leg-btn-container)>button:not(.ot-link-btn):focus,#onetrust-pc-sdk .ot-sdk-button:hover,#onetrust-pc-sdk :not(.ot-leg-btn-container)>button:not(.ot-link-btn):hover,#onetrust-pc-sdk :not(.ot-leg-btn-container)>button:not(.ot-link-btn):focus,#ot-sdk-cookie-policy .ot-sdk-button:hover,#ot-sdk-cookie-policy :not(.ot-leg-btn-container)>button:not(.ot-link-btn):hover,#ot-sdk-cookie-policy :not(.ot-leg-btn-container)>button:not(.ot-link-btn):focus{color:#333;border-color:#888;opacity:.7}#onetrust-banner-sdk .ot-sdk-button:focus,#onetrust-banner-sdk :not(.ot-leg-btn-container)>button:focus,#onetrust-pc-sdk .ot-sdk-button:focus,#onetrust-pc-sdk :not(.ot-leg-btn-container)>button:focus,#ot-sdk-cookie-policy .ot-sdk-button:focus,#ot-sdk-cookie-policy :not(.ot-leg-btn-container)>button:focus{outline:2px solid #000}#onetrust-banner-sdk .ot-sdk-button.ot-sdk-button-primary,#onetrust-banner-sdk button.ot-sdk-button-primary,#onetrust-banner-sdk input[type=submit].ot-sdk-button-primary,#onetrust-banner-sdk input[type=reset].ot-sdk-button-primary,#onetrust-banner-sdk input[type=button].ot-sdk-button-primary,#onetrust-pc-sdk .ot-sdk-button.ot-sdk-button-primary,#onetrust-pc-sdk button.ot-sdk-button-primary,#onetrust-pc-sdk input[type=submit].ot-sdk-button-primary,#onetrust-pc-sdk input[type=reset].ot-sdk-button-primary,#onetrust-pc-sdk input[type=button].ot-sdk-button-primary,#ot-sdk-cookie-policy .ot-sdk-button.ot-sdk-button-primary,#ot-sdk-cookie-policy button.ot-sdk-button-primary,#ot-sdk-cookie-policy input[type=submit].ot-sdk-button-primary,#ot-sdk-cookie-policy input[type=reset].ot-sdk-button-primary,#ot-sdk-cookie-policy input[type=button].ot-sdk-button-primary{color:#fff;background-color:#33c3f0;border-color:#33c3f0}#onetrust-banner-sdk .ot-sdk-button.ot-sdk-button-primary:hover,#onetrust-banner-sdk button.ot-sdk-button-primary:hover,#onetrust-banner-sdk input[type=submit].ot-sdk-button-primary:hover,#onetrust-banner-sdk input[type=reset].ot-sdk-button-primary:hover,#onetrust-banner-sdk input[type=button].ot-sdk-button-primary:hover,#onetrust-banner-sdk .ot-sdk-button.ot-sdk-button-primary:focus,#onetrust-banner-sdk button.ot-sdk-button-primary:focus,#onetrust-banner-sdk input[type=submit].ot-sdk-button-primary:focus,#onetrust-banner-sdk input[type=reset].ot-sdk-button-primary:focus,#onetrust-banner-sdk input[type=button].ot-sdk-button-primary:focus,#onetrust-pc-sdk .ot-sdk-button.ot-sdk-button-primary:hover,#onetrust-pc-sdk button.ot-sdk-button-primary:hover,#onetrust-pc-sdk input[type=submit].ot-sdk-button-primary:hover,#onetrust-pc-sdk input[type=reset].ot-sdk-button-primary:hover,#onetrust-pc-sdk input[type=button].ot-sdk-button-primary:hover,#onetrust-pc-sdk .ot-sdk-button.ot-sdk-button-primary:focus,#onetrust-pc-sdk button.ot-sdk-button-primary:focus,#onetrust-pc-sdk input[type=submit].ot-sdk-button-primary:focus,#onetrust-pc-sdk input[type=reset].ot-sdk-button-primary:focus,#onetrust-pc-sdk input[type=button].ot-sdk-button-primary:focus,#ot-sdk-cookie-policy .ot-sdk-button.ot-sdk-button-primary:hover,#ot-sdk-cookie-policy button.ot-sdk-button-primary:hover,#ot-sdk-cookie-policy input[type=submit].ot-sdk-button-primary:hover,#ot-sdk-cookie-policy input[type=reset].ot-sdk-button-primary:hover,#ot-sdk-cookie-policy input[type=button].ot-sdk-button-primary:hover,#ot-sdk-cookie-policy .ot-sdk-button.ot-sdk-button-primary:focus,#ot-sdk-cookie-policy button.ot-sdk-button-primary:focus,#ot-sdk-cookie-policy input[type=submit].ot-sdk-button-primary:focus,#ot-sdk-cookie-policy input[type=reset].ot-sdk-button-primary:focus,#ot-sdk-cookie-policy input[type=button].ot-sdk-button-primary:focus{color:#fff;background-color:#1eaedb;border-color:#1eaedb}#onetrust-banner-sdk input[type=text],#onetrust-pc-sdk input[type=text],#ot-sdk-cookie-policy input[type=text]{height:38px;padding:6px 10px;background-color:#fff;border:1px solid #d1d1d1;border-radius:4px;box-shadow:none;box-sizing:border-box}#onetrust-banner-sdk input[type=text],#onetrust-pc-sdk input[type=text],#ot-sdk-cookie-policy input[type=text]{-webkit-appearance:none;-moz-appearance:none;appearance:none}#onetrust-banner-sdk input[type=text]:focus,#onetrust-pc-sdk input[type=text]:focus,#ot-sdk-cookie-policy input[type=text]:focus{border:1px solid #000;outline:0}#onetrust-banner-sdk label,#onetrust-pc-sdk label,#ot-sdk-cookie-policy label{display:block;margin-bottom:.5rem;font-weight:600}#onetrust-banner-sdk input[type=checkbox],#onetrust-pc-sdk input[type=checkbox],#ot-sdk-cookie-policy input[type=checkbox]{display:inline}#onetrust-banner-sdk ul,#onetrust-pc-sdk ul,#ot-sdk-cookie-policy ul{list-style:circle inside}#onetrust-banner-sdk ul,#onetrust-pc-sdk ul,#ot-sdk-cookie-policy ul{padding-left:0;margin-top:0}#onetrust-banner-sdk ul ul,#onetrust-pc-sdk ul ul,#ot-sdk-cookie-policy ul ul{margin:1.5rem 0 1.5rem 3rem;font-size:90%}#onetrust-banner-sdk li,#onetrust-pc-sdk li,#ot-sdk-cookie-policy li{margin-bottom:1rem}#onetrust-banner-sdk th,#onetrust-banner-sdk td,#onetrust-pc-sdk th,#onetrust-pc-sdk td,#ot-sdk-cookie-policy th,#ot-sdk-cookie-policy td{padding:12px 15px;text-align:left;border-bottom:1px solid #e1e1e1}#onetrust-banner-sdk button,#onetrust-pc-sdk button,#ot-sdk-cookie-policy button{margin-bottom:1rem;font-family:inherit}#onetrust-banner-sdk .ot-sdk-container:after,#onetrust-banner-sdk .ot-sdk-row:after,#onetrust-pc-sdk .ot-sdk-container:after,#onetrust-pc-sdk .ot-sdk-row:after,#ot-sdk-cookie-policy .ot-sdk-container:after,#ot-sdk-cookie-policy .ot-sdk-row:after{content:"";display:table;clear:both}#onetrust-banner-sdk .ot-sdk-row,#onetrust-pc-sdk .ot-sdk-row,#ot-sdk-cookie-policy .ot-sdk-row{margin:0;max-width:none;display:block}#onetrust-banner-sdk{box-shadow:0 0 18px rgba(0,0,0,.2)}#onetrust-banner-sdk.otFlat{position:fixed;z-index:2147483645;bottom:0;right:0;left:0;background-color:#fff;max-height:90%;overflow-x:hidden;overflow-y:auto}#onetrust-banner-sdk.otFlat.top{top:0px;bottom:auto}#onetrust-banner-sdk.otRelFont{font-size:1rem}#onetrust-banner-sdk>.ot-sdk-container{overflow:hidden}#onetrust-banner-sdk::-webkit-scrollbar{width:11px}#onetrust-banner-sdk::-webkit-scrollbar-thumb{border-radius:10px;background:#c1c1c1}#onetrust-banner-sdk{scrollbar-arrow-color:#c1c1c1;scrollbar-darkshadow-color:#c1c1c1;scrollbar-face-color:#c1c1c1;scrollbar-shadow-color:#c1c1c1}#onetrust-banner-sdk #onetrust-policy{margin:1.25em 0 .625em 2em;overflow:hidden}#onetrust-banner-sdk #onetrust-policy .ot-gv-list-handler{float:left;font-size:.82em;padding:0;margin-bottom:0;border:0;line-height:normal;height:auto;width:auto}#onetrust-banner-sdk #onetrust-policy-title{font-size:1.2em;line-height:1.3;margin-bottom:10px}#onetrust-banner-sdk #onetrust-policy-text{clear:both;text-align:left;font-size:.88em;line-height:1.4}#onetrust-banner-sdk #onetrust-policy-text *{font-size:inherit;line-height:inherit}#onetrust-banner-sdk #onetrust-policy-text a{font-weight:bold;margin-left:5px}#onetrust-banner-sdk #onetrust-policy-title,#onetrust-banner-sdk #onetrust-policy-text{color:dimgray;float:left}#onetrust-banner-sdk #onetrust-button-group-parent{min-height:1px;text-align:center}#onetrust-banner-sdk #onetrust-button-group{display:inline-block}#onetrust-banner-sdk #onetrust-accept-btn-handler,#onetrust-banner-sdk #onetrust-reject-all-handler,#onetrust-banner-sdk #onetrust-pc-btn-handler{background-color:#68b631;color:#fff;border-color:#68b631;margin-right:1em;min-width:125px;height:auto;white-space:normal;word-break:break-word;word-wrap:break-word;padding:12px 10px;line-height:1.2;font-size:.813em;font-weight:600}#onetrust-banner-sdk #onetrust-pc-btn-handler.cookie-setting-link{background-color:#fff;border:none;color:#68b631;text-decoration:underline;padding-left:0;padding-right:0}#onetrust-banner-sdk .onetrust-close-btn-ui{width:44px;height:44px;background-size:12px;border:none;position:relative;margin:auto;padding:0}#onetrust-banner-sdk .banner_logo{display:none}#onetrust-banner-sdk.ot-bnr-w-logo .ot-bnr-logo{position:absolute;top:50%;transform:translateY(-50%);left:0px}#onetrust-banner-sdk.ot-bnr-w-logo #onetrust-policy{margin-left:65px}#onetrust-banner-sdk .ot-b-addl-desc{clear:both;float:left;display:block}#onetrust-banner-sdk #banner-options{float:left;display:table;margin-right:0;margin-left:1em;width:calc(100% - 1em)}#onetrust-banner-sdk .banner-option-input{cursor:pointer;width:auto;height:auto;border:none;padding:0;padding-right:3px;margin:0 0 10px;font-size:.82em;line-height:1.4}#onetrust-banner-sdk .banner-option-input *{pointer-events:none;font-size:inherit;line-height:inherit}#onetrust-banner-sdk .banner-option-input[aria-expanded=true]~.banner-option-details{display:block;height:auto}#onetrust-banner-sdk .banner-option-input[aria-expanded=true] .ot-arrow-container{transform:rotate(90deg)}#onetrust-banner-sdk .banner-option{margin-bottom:12px;margin-left:0;border:none;float:left;padding:0}#onetrust-banner-sdk .banner-option:first-child{padding-left:2px}#onetrust-banner-sdk .banner-option:not(:first-child){padding:0;border:none}#onetrust-banner-sdk .banner-option-header{cursor:pointer;display:inline-block}#onetrust-banner-sdk .banner-option-header :first-child{color:dimgray;font-weight:bold;float:left}#onetrust-banner-sdk .banner-option-header .ot-arrow-container{display:inline-block;border-top:6px solid rgba(0,0,0,0);border-bottom:6px solid rgba(0,0,0,0);border-left:6px solid dimgray;margin-left:10px;vertical-align:middle}#onetrust-banner-sdk .banner-option-details{display:none;font-size:.83em;line-height:1.5;padding:10px 0px 5px 10px;margin-right:10px;height:0px}#onetrust-banner-sdk .banner-option-details *{font-size:inherit;line-height:inherit;color:dimgray}#onetrust-banner-sdk .ot-arrow-container,#onetrust-banner-sdk .banner-option-details{transition:all 300ms ease-in 0s;-webkit-transition:all 300ms ease-in 0s;-moz-transition:all 300ms ease-in 0s;-o-transition:all 300ms ease-in 0s}#onetrust-banner-sdk .ot-dpd-container{float:left}#onetrust-banner-sdk .ot-dpd-title{margin-bottom:10px}#onetrust-banner-sdk .ot-dpd-title,#onetrust-banner-sdk .ot-dpd-desc{font-size:.88em;line-height:1.4;color:dimgray}#onetrust-banner-sdk .ot-dpd-title *,#onetrust-banner-sdk .ot-dpd-desc *{font-size:inherit;line-height:inherit}#onetrust-banner-sdk.ot-iab-2 #onetrust-policy-text *{margin-bottom:0}#onetrust-banner-sdk.ot-iab-2 .onetrust-vendors-list-handler{display:block;margin-left:0;margin-top:5px;clear:both;margin-bottom:0;padding:0;border:0;height:auto;width:auto}#onetrust-banner-sdk.ot-iab-2 #onetrust-button-group button{display:block}#onetrust-banner-sdk.ot-close-btn-link{padding-top:25px}#onetrust-banner-sdk.ot-close-btn-link #onetrust-close-btn-container{top:15px;transform:none;right:15px}#onetrust-banner-sdk.ot-close-btn-link #onetrust-close-btn-container button{padding:0;white-space:pre-wrap;border:none;height:auto;line-height:1.5;text-decoration:underline;font-size:.69em}#onetrust-banner-sdk #onetrust-policy-text,#onetrust-banner-sdk .ot-dpd-desc,#onetrust-banner-sdk .ot-b-addl-desc{font-size:.813em;line-height:1.5}#onetrust-banner-sdk .ot-dpd-desc{margin-bottom:10px}#onetrust-banner-sdk .ot-dpd-desc>.ot-b-addl-desc{margin-top:10px;margin-bottom:10px;font-size:1em}@media only screen and (max-width: 425px){#onetrust-banner-sdk #onetrust-close-btn-container{position:absolute;top:6px;right:2px}#onetrust-banner-sdk #onetrust-policy{margin-left:0;margin-top:3em}#onetrust-banner-sdk #onetrust-button-group{display:block}#onetrust-banner-sdk #onetrust-accept-btn-handler,#onetrust-banner-sdk #onetrust-reject-all-handler,#onetrust-banner-sdk #onetrust-pc-btn-handler{width:100%}#onetrust-banner-sdk .onetrust-close-btn-ui{top:auto;transform:none}#onetrust-banner-sdk #onetrust-policy-title{display:inline;float:none}#onetrust-banner-sdk #banner-options{margin:0;padding:0;width:100%}}@media only screen and (min-width: 426px)and (max-width: 896px){#onetrust-banner-sdk #onetrust-close-btn-container{position:absolute;top:0;right:0}#onetrust-banner-sdk #onetrust-policy{margin-left:1em;margin-right:1em}#onetrust-banner-sdk .onetrust-close-btn-ui{top:10px;right:10px}#onetrust-banner-sdk:not(.ot-iab-2) #onetrust-group-container{width:95%}#onetrust-banner-sdk.ot-iab-2 #onetrust-group-container{width:100%}#onetrust-banner-sdk.ot-bnr-w-logo #onetrust-button-group-parent{padding-left:50px}#onetrust-banner-sdk #onetrust-button-group-parent{width:100%;position:relative;margin-left:0}#onetrust-banner-sdk #onetrust-button-group button{display:inline-block}#onetrust-banner-sdk #onetrust-button-group{margin-right:0;text-align:center}#onetrust-banner-sdk .has-reject-all-button #onetrust-pc-btn-handler{float:left}#onetrust-banner-sdk .has-reject-all-button #onetrust-reject-all-handler,#onetrust-banner-sdk .has-reject-all-button #onetrust-accept-btn-handler{float:right}#onetrust-banner-sdk .has-reject-all-button #onetrust-button-group{width:calc(100% - 2em);margin-right:0}#onetrust-banner-sdk .has-reject-all-button #onetrust-pc-btn-handler.cookie-setting-link{padding-left:0px;text-align:left}#onetrust-banner-sdk.ot-buttons-fw .ot-sdk-three button{width:100%;text-align:center}#onetrust-banner-sdk.ot-buttons-fw #onetrust-button-group-parent button{float:none}#onetrust-banner-sdk.ot-buttons-fw #onetrust-pc-btn-handler.cookie-setting-link{text-align:center}}@media only screen and (min-width: 550px){#onetrust-banner-sdk .banner-option:not(:first-child){border-left:1px solid #d8d8d8;padding-left:25px}}@media only screen and (min-width: 425px)and (max-width: 550px){#onetrust-banner-sdk.ot-iab-2 #onetrust-button-group,#onetrust-banner-sdk.ot-iab-2 #onetrust-policy,#onetrust-banner-sdk.ot-iab-2 .banner-option{width:100%}#onetrust-banner-sdk.ot-iab-2 #onetrust-button-group #onetrust-accept-btn-handler,#onetrust-banner-sdk.ot-iab-2 #onetrust-button-group #onetrust-reject-all-handler,#onetrust-banner-sdk.ot-iab-2 #onetrust-button-group #onetrust-pc-btn-handler{width:100%}#onetrust-banner-sdk.ot-iab-2 #onetrust-button-group #onetrust-accept-btn-handler,#onetrust-banner-sdk.ot-iab-2 #onetrust-button-group #onetrust-reject-all-handler{float:left}}@media only screen and (min-width: 769px){#onetrust-banner-sdk #onetrust-button-group{margin-right:30%}#onetrust-banner-sdk #banner-options{margin-left:2em;margin-right:5em;margin-bottom:1.25em;width:calc(100% - 7em)}}@media only screen and (min-width: 897px)and (max-width: 1023px){#onetrust-banner-sdk.vertical-align-content #onetrust-button-group-parent{position:absolute;top:50%;left:75%;transform:translateY(-50%)}#onetrust-banner-sdk #onetrust-close-btn-container{top:50%;margin:auto;transform:translate(-50%, -50%);position:absolute;padding:0;right:0}#onetrust-banner-sdk #onetrust-close-btn-container button{position:relative;margin:0;right:-22px;top:2px}}@media only screen and (min-width: 1024px){#onetrust-banner-sdk #onetrust-close-btn-container{top:50%;margin:auto;transform:translate(-50%, -50%);position:absolute;right:0}#onetrust-banner-sdk #onetrust-close-btn-container button{right:-12px}#onetrust-banner-sdk #onetrust-policy{margin-left:2em}#onetrust-banner-sdk.vertical-align-content #onetrust-button-group-parent{position:absolute;top:50%;left:60%;transform:translateY(-50%)}#onetrust-banner-sdk .ot-optout-signal{width:50%}#onetrust-banner-sdk.ot-iab-2 #onetrust-policy-title{width:50%}#onetrust-banner-sdk.ot-iab-2 #onetrust-policy-text,#onetrust-banner-sdk.ot-iab-2 :not(.ot-dpd-desc)>.ot-b-addl-desc{margin-bottom:1em;width:50%;border-right:1px solid #d8d8d8;padding-right:1rem}#onetrust-banner-sdk.ot-iab-2 #onetrust-policy-text{margin-bottom:0;padding-bottom:1em}#onetrust-banner-sdk.ot-iab-2 :not(.ot-dpd-desc)>.ot-b-addl-desc{margin-bottom:0;padding-bottom:1em}#onetrust-banner-sdk.ot-iab-2 .ot-dpd-container{width:45%;padding-left:1rem;display:inline-block;float:none}#onetrust-banner-sdk.ot-iab-2 .ot-dpd-title{line-height:1.7}#onetrust-banner-sdk.ot-iab-2 #onetrust-button-group-parent{left:auto;right:4%;margin-left:0}#onetrust-banner-sdk.ot-iab-2 #onetrust-button-group button{display:block}#onetrust-banner-sdk:not(.ot-iab-2) #onetrust-button-group-parent{margin:auto;width:30%}#onetrust-banner-sdk:not(.ot-iab-2) #onetrust-group-container{width:60%}#onetrust-banner-sdk #onetrust-button-group{margin-right:auto}#onetrust-banner-sdk #onetrust-accept-btn-handler,#onetrust-banner-sdk #onetrust-reject-all-handler,#onetrust-banner-sdk #onetrust-pc-btn-handler{margin-top:1em}}@media only screen and (min-width: 890px){#onetrust-banner-sdk.ot-buttons-fw:not(.ot-iab-2) #onetrust-button-group-parent{padding-left:3%;padding-right:4%;margin-left:0}#onetrust-banner-sdk.ot-buttons-fw:not(.ot-iab-2) #onetrust-button-group{margin-right:0;margin-top:1.25em;width:100%}#onetrust-banner-sdk.ot-buttons-fw:not(.ot-iab-2) #onetrust-button-group button{width:100%;margin-bottom:5px;margin-top:5px}#onetrust-banner-sdk.ot-buttons-fw:not(.ot-iab-2) #onetrust-button-group button:last-of-type{margin-bottom:20px}}@media only screen and (min-width: 1280px){#onetrust-banner-sdk:not(.ot-iab-2) #onetrust-group-container{width:55%}#onetrust-banner-sdk:not(.ot-iab-2) #onetrust-button-group-parent{width:44%;padding-left:2%;padding-right:2%}#onetrust-banner-sdk:not(.ot-iab-2).vertical-align-content #onetrust-button-group-parent{position:absolute;left:55%}}
        #onetrust-consent-sdk #onetrust-banner-sdk {background-color: #FFF;}
            #onetrust-consent-sdk #onetrust-policy-title,
                    #onetrust-consent-sdk #onetrust-policy-text,
                    #onetrust-consent-sdk .ot-b-addl-desc,
                    #onetrust-consent-sdk .ot-dpd-desc,
                    #onetrust-consent-sdk .ot-dpd-title,
                    #onetrust-consent-sdk #onetrust-policy-text *:not(.onetrust-vendors-list-handler),
                    #onetrust-consent-sdk .ot-dpd-desc *:not(.onetrust-vendors-list-handler),
                    #onetrust-consent-sdk #onetrust-banner-sdk #banner-options *,
                    #onetrust-banner-sdk .ot-cat-header,
                    #onetrust-banner-sdk .ot-optout-signal
                    {
                        color: #2E2E2E;
                    }
            #onetrust-consent-sdk #onetrust-banner-sdk .banner-option-details {
                    background-color: #E9E9E9;}
             #onetrust-consent-sdk #onetrust-banner-sdk a[href],
                    #onetrust-consent-sdk #onetrust-banner-sdk a[href] font,
                    #onetrust-consent-sdk #onetrust-banner-sdk .ot-link-btn
                        {
                            color: #007398;
                        }#onetrust-consent-sdk #onetrust-accept-btn-handler,
                         #onetrust-banner-sdk #onetrust-reject-all-handler {
                            background-color: #007398;border-color: #007398;
                color: #FFF;
            }
            #onetrust-consent-sdk #onetrust-banner-sdk *:focus,
            #onetrust-consent-sdk #onetrust-banner-sdk:focus {
               outline-color: #000000;
               outline-width: 1px;
            }
            #onetrust-consent-sdk #onetrust-pc-btn-handler,
            #onetrust-consent-sdk #onetrust-pc-btn-handler.cookie-setting-link {
                color: #6CC04A; border-color: #6CC04A;
                background-color:
                #FFF;
            }/*! Extra code to blur out background */
.onetrust-pc-dark-filter{
background:rgba(0,0,0,.5);
z-index:2147483646;
width:100%;
height:100%;
overflow:hidden;
position:fixed;
top:0;
bottom:0;
left:0;
backdrop-filter: initial
}

/*! v6.12.0 2021-01-19 */
div#onetrust-consent-sdk #onetrust-banner-sdk{border-top:2px solid #eb6500!important;outline:1px solid transparent;box-shadow:none;padding:24px}div#onetrust-consent-sdk button{border-radius:0!important;box-shadow:none!important;box-sizing:border-box!important;font-size:20px!important;font-weight:400!important;letter-spacing:0!important;max-width:none!important;white-space:nowrap!important}div#onetrust-consent-sdk button:not(.ot-link-btn){background-color:#007398!important;border:2px solid #007398!important;color:#fff!important;height:48px!important;padding:0 1em!important;width:auto!important}div#onetrust-consent-sdk button:hover{background-color:#fff!important;border-color:#eb6500!important;color:#2e2e2e!important}div#onetrust-consent-sdk button.ot-link-btn{color:#007398!important;font-size:16px!important;text-decoration:underline}div#onetrust-consent-sdk button.ot-link-btn:hover{color:inherit!important;text-decoration-color:#eb6500!important}div#onetrust-consent-sdk a,div#onetrust-pc-sdk a{color:#007398!important;text-decoration:underline!important}div#onetrust-consent-sdk a,div#onetrust-consent-sdk button,div#onetrust-consent-sdk p:hover{opacity:1!important}div#onetrust-consent-sdk a:focus,div#onetrust-consent-sdk button:focus,div#onetrust-consent-sdk input:focus{outline:2px solid #eb6500!important;outline-offset:1px!important}div#onetrust-banner-sdk .ot-sdk-container{padding:0;width:auto}div#onetrust-banner-sdk .ot-sdk-row{align-items:flex-start;box-sizing:border-box;display:flex;flex-direction:column;justify-content:space-between;margin:auto;max-width:1152px}div#onetrust-banner-sdk .ot-sdk-row:after{display:none}div#onetrust-banner-sdk #onetrust-group-container,div#onetrust-banner-sdk.ot-bnr-flift:not(.ot-iab-2) #onetrust-group-container,div#onetrust-banner-sdk:not(.ot-iab-2) #onetrust-group-container{flex-grow:1;width:auto}div#onetrust-banner-sdk #onetrust-policy,div#onetrust-banner-sdk.ot-bnr-flift #onetrust-policy{margin:0;overflow:visible}div#onetrust-banner-sdk.ot-bnr-flift #onetrust-policy-text,div#onetrust-consent-sdk #onetrust-policy-text{font-size:16px;line-height:24px;max-width:44em;margin:0}div#onetrust-consent-sdk #onetrust-policy-text a[href]{font-weight:400;margin-left:8px}div#onetrust-banner-sdk #onetrust-button-group-parent{flex:0 0 auto;margin:32px 0 0;width:100%}div#onetrust-banner-sdk #onetrust-button-group{display:flex;flex-direction:row;flex-wrap:wrap;justify-content:flex-end;margin:-8px}div#onetrust-banner-sdk .banner-actions-container{display:flex;flex:1 0 auto}div#onetrust-banner-sdk.ot-buttons-fw:not(.ot-iab-2) #onetrust-button-group button:last-of-type,div#onetrust-consent-sdk #onetrust-accept-btn-handler,div#onetrust-consent-sdk #onetrust-pc-btn-handler{flex:1 0 auto;margin:8px;width:auto}div#onetrust-consent-sdk #onetrust-pc-btn-handler{background-color:#fff!important;color:inherit!important}div#onetrust-banner-sdk #onetrust-close-btn-container{display:none}@media only screen and (min-width:556px){div#onetrust-consent-sdk #onetrust-banner-sdk{padding:40px}div#onetrust-banner-sdk #onetrust-policy{margin:0 40px 0 0}div#onetrust-banner-sdk .ot-sdk-row{align-items:center;flex-direction:row}div#onetrust-banner-sdk #onetrust-button-group-parent,div#onetrust-banner-sdk.ot-bnr-flift:not(.ot-iab-2) #onetrust-button-group-parent,div#onetrust-banner-sdk:not(.ot-iab-2) #onetrust-button-group-parent{margin:0;padding:0;width:auto}div#onetrust-banner-sdk #onetrust-button-group,div#onetrust-banner-sdk.ot-buttons-fw:not(.ot-iab-2) #onetrust-button-group{align-items:stretch;flex-direction:column-reverse;margin:0}div#onetrust-consent-sdk #onetrust-accept-btn-handler,div#onetrust-consent-sdk #onetrust-pc-btn-handler{flex:1 0 auto}}@media only screen and (min-width:768px){div#onetrust-banner-sdk #onetrust-policy{margin:0 48px 0 0}div#onetrust-consent-sdk #onetrust-banner-sdk{padding:48px}}div#onetrust-consent-sdk #onetrust-pc-sdk h5{font-size:16px;line-height:24px}div#onetrust-consent-sdk #onetrust-pc-sdk p,div#onetrust-pc-sdk #ot-pc-desc,div#onetrust-pc-sdk .category-host-list-handler,div#onetrust-pc-sdk .ot-accordion-layout .ot-cat-header{font-size:16px;font-weight:400;line-height:24px}div#onetrust-consent-sdk a:hover,div#onetrust-pc-sdk a:hover{color:inherit!important;text-decoration-color:#eb6500!important}div#onetrust-pc-sdk{border-radius:0;bottom:0;height:auto;left:0;margin:auto;max-width:100%;overflow:hidden;right:0;top:0;width:512px;max-height:800px}div#onetrust-pc-sdk .ot-pc-header{display:none}div#onetrust-pc-sdk #ot-pc-content{overscroll-behavior:contain;padding:0 12px 0 24px;margin:16px 4px 0 0;top:0;right:16px;left:0;width:auto}div#onetrust-pc-sdk #ot-category-title,div#onetrust-pc-sdk #ot-pc-title{font-size:24px;font-weight:400;line-height:32px;margin:0 0 16px}div#onetrust-pc-sdk #ot-pc-desc{padding:0}div#onetrust-pc-sdk #ot-pc-desc a{display:inline}div#onetrust-pc-sdk #accept-recommended-btn-handler{display:none!important}div#onetrust-pc-sdk input[type=checkbox]:focus+.ot-acc-hdr{outline:2px solid #eb6500;outline-offset:-1px;transition:none}div#onetrust-pc-sdk .ot-accordion-layout.ot-cat-item{border-width:0 0 2px}div#onetrust-pc-sdk .ot-accordion-layout.ot-cat-item:first-of-type{border-width:2px 0}div#onetrust-pc-sdk .ot-accordion-layout .ot-acc-hdr{padding:8px 0;width:100%}div#onetrust-pc-sdk .ot-plus-minus{transform:translateY(2px)}div#onetrust-pc-sdk .ot-accordion-layout.ot-cat-item>button{background:0 0!important;border:0!important;height:44px!important;max-width:none!important;width:calc(100% - 48px)!important}div#onetrust-consent-sdk #onetrust-pc-sdk h5{font-weight:700}div#onetrust-pc-sdk .ot-accordion-layout .ot-hlst-cntr{padding:0}div#onetrust-pc-sdk .ot-accordion-layout.ot-cat-item .ot-acc-grpdesc{padding:0;width:100%}div#onetrust-pc-sdk .ot-acc-grpcntr .ot-subgrp-cntr{border:0;padding:0}div#onetrust-pc-sdk .ot-subgrp-cntr ul.ot-subgrps li.ot-subgrp{margin:0}div#onetrust-pc-sdk .ot-always-active-group .ot-cat-header{width:calc(100% - 160px)}#onetrust-pc-sdk .ot-accordion-layout .ot-cat-header{width:calc(100% - 88px)}div#onetrust-pc-sdk .ot-accordion-layout h4~.ot-always-active{color:inherit;font-size:12px;font-weight:400;line-height:1.5;padding-right:48px}div#onetrust-pc-sdk .ot-accordion-layout h4~.ot-always-active:before{border-radius:12px;position:absolute;right:0;top:0;content:'';background:#fff;border:2px solid #939393;box-sizing:border-box;height:20px;width:40px}div#onetrust-pc-sdk .ot-accordion-layout h4~.ot-always-active:after{border-radius:50%;position:absolute;right:5px;top:4px;content:'';background-color:#eb6500;height:12px;width:12px}div#onetrust-pc-sdk .ot-accordion-layout h4~.ot-always-active,div#onetrust-pc-sdk .ot-accordion-layout h4~.ot-tgl{right:2px}div#onetrust-pc-sdk .ot-switch{display:block;height:20px;width:40px}div#onetrust-pc-sdk .ot-tgl input+.ot-switch .ot-switch-nob,div#onetrust-pc-sdk .ot-tgl input:checked+.ot-switch .ot-switch-nob{background:#fff;border:2px solid #939393;box-sizing:border-box;height:20px;width:40px}div#onetrust-pc-sdk .ot-tgl input+.ot-switch .ot-switch-nob:before{background-color:#737373;height:8px;left:4px;top:4px;width:8px}div#onetrust-pc-sdk .ot-tgl input:checked+.ot-switch .ot-switch-nob:before{background-color:#eb6500;height:12px;left:0;top:2px;width:12px}div#onetrust-pc-sdk .ot-tgl input:focus+.ot-switch .ot-switch-nob{box-shadow:0 0;outline:2px solid #eb6500!important;outline-offset:1px;transition:none}div#onetrust-consent-sdk #onetrust-pc-sdk .ot-acc-grpcntr.ot-acc-txt{background-color:transparent;padding-left:3px}div#onetrust-pc-sdk .ot-accordion-layout .ot-hlst-cntr,div#onetrust-pc-sdk .ot-accordion-layout .ot-vlst-cntr{overflow:visible;width:100%}div#onetrust-pc-sdk .ot-pc-footer{border-top:0 solid}div#onetrust-pc-sdk .ot-btn-container{padding-top:24px;text-align:center}div#onetrust-pc-sdk .ot-pc-footer button{margin:8px 0;background-color:#fff}div#onetrust-pc-sdk .ot-pc-footer-logo{background-color:#fff}div#onetrust-pc-sdk #ot-lst-title span{font-size:24px;font-weight:400;line-height:32px}div#onetrust-pc-sdk #ot-host-lst .ot-host-desc,div#onetrust-pc-sdk #ot-host-lst .ot-host-expand,div#onetrust-pc-sdk #ot-host-lst .ot-host-name,div#onetrust-pc-sdk #ot-host-lst .ot-host-name a,div#onetrust-pc-sdk .back-btn-handler,div#onetrust-pc-sdk .ot-host-opt li>div div{font-size:16px;font-weight:400;line-height:24px}div#onetrust-pc-sdk #ot-host-lst .ot-acc-txt{width:100%}div#onetrust-pc-sdk #ot-pc-lst{top:0}div#onetrust-pc-sdk .back-btn-handler{text-decoration:none!important}div#onetrust-pc-sdk #filter-btn-handler:hover svg{filter:invert(1)}div#onetrust-pc-sdk .back-btn-handler svg{width:16px;height:16px}div#onetrust-pc-sdk .ot-host-item>button{background:0 0!important;border:0!important;height:66px!important;max-width:none!important;width:calc(100% - 5px)!important;transform:translate(2px,2px)}div#onetrust-pc-sdk .ot-host-item{border-bottom:2px solid #b9b9b9;padding:0}div#onetrust-pc-sdk .ot-host-item .ot-acc-hdr{margin:0 0 -6px;padding:8px 0}div#onetrust-pc-sdk ul li:first-child{border-top:2px solid #b9b9b9}div#onetrust-pc-sdk .ot-host-item .ot-plus-minus{margin:0 8px 0 0}div#onetrust-pc-sdk .ot-search-cntr{width:calc(100% - 48px)}div#onetrust-pc-sdk .ot-host-opt .ot-host-info{background-color:transparent}div#onetrust-pc-sdk .ot-host-opt li>div div{padding:0}div#onetrust-pc-sdk #vendor-search-handler{border-radius:0;border-color:#939393;border-style:solid;border-width:2px 0 2px 2px;font-size:20px;height:48px;margin:0}div#onetrust-pc-sdk #ot-pc-hdr{margin-left:24px}div#onetrust-pc-sdk .ot-lst-subhdr{width:calc(100% - 24px)}div#onetrust-pc-sdk .ot-lst-subhdr svg{right:0;top:8px}div#onetrust-pc-sdk .ot-fltr-cntr{box-sizing:border-box;right:0;width:48px}div#onetrust-pc-sdk #filter-btn-handler{width:48px!important;padding:8px!important}div#onetrust-consent-sdk #onetrust-pc-sdk #clear-filters-handler,div#onetrust-pc-sdk button#filter-apply-handler,div#onetrust-pc-sdk button#filter-cancel-handler{height:2em!important;padding-left:14px!important;padding-right:14px!important}div#onetrust-pc-sdk #ot-fltr-cnt{box-shadow:0 0;border:1px solid #8e8e8e;border-radius:0}div#onetrust-pc-sdk .ot-fltr-scrlcnt{max-height:calc(100% - 80px)}div#onetrust-pc-sdk #ot-fltr-modal{max-height:400px}div#onetrust-pc-sdk .ot-fltr-opt{margin-bottom:16px}div#onetrust-pc-sdk #ot-lst-cnt{margin-left:24px;width:calc(100% - 48px)}div#onetrust-pc-sdk #ot-anchor{display:none!important}
/* 2023-12-04  Fix for button order in mobile view*/
@media (max-width: 550px) {
  #onetrust-accept-btn-handler {order: 1;  }
  #onetrust-reject-all-handler { order: 2;  }
  #onetrust-pc-btn-handler { order: 3;  }
}
#onetrust-pc-sdk.otPcCenter{overflow:hidden;position:fixed;margin:0 auto;top:5%;right:0;left:0;width:40%;max-width:575px;min-width:575px;border-radius:2.5px;z-index:2147483647;background-color:#fff;-webkit-box-shadow:0px 2px 10px -3px #999;-moz-box-shadow:0px 2px 10px -3px #999;box-shadow:0px 2px 10px -3px #999}#onetrust-pc-sdk.otPcCenter[dir=rtl]{right:0;left:0}#onetrust-pc-sdk.otRelFont{font-size:1rem}#onetrust-pc-sdk .ot-optout-signal{margin-top:.625rem}#onetrust-pc-sdk #ot-addtl-venlst .ot-arw-cntr,#onetrust-pc-sdk #ot-addtl-venlst .ot-plus-minus,#onetrust-pc-sdk .ot-hide-tgl{visibility:hidden}#onetrust-pc-sdk #ot-addtl-venlst .ot-arw-cntr *,#onetrust-pc-sdk #ot-addtl-venlst .ot-plus-minus *,#onetrust-pc-sdk .ot-hide-tgl *{visibility:hidden}#onetrust-pc-sdk #ot-gn-venlst .ot-ven-item .ot-acc-hdr{min-height:40px}#onetrust-pc-sdk .ot-pc-header{height:39px;padding:10px 0 10px 30px;border-bottom:1px solid #e9e9e9}#onetrust-pc-sdk #ot-pc-title,#onetrust-pc-sdk #ot-category-title,#onetrust-pc-sdk .ot-cat-header,#onetrust-pc-sdk #ot-lst-title,#onetrust-pc-sdk .ot-ven-hdr .ot-ven-name,#onetrust-pc-sdk .ot-always-active{font-weight:bold;color:dimgray}#onetrust-pc-sdk .ot-always-active-group .ot-cat-header{width:55%;font-weight:700}#onetrust-pc-sdk .ot-cat-item p{clear:both;float:left;margin-top:10px;margin-bottom:5px;line-height:1.5;font-size:.812em;color:dimgray}#onetrust-pc-sdk .ot-close-icon{height:44px;width:44px;background-size:10px}#onetrust-pc-sdk #ot-pc-title{float:left;font-size:1em;line-height:1.5;margin-bottom:10px;margin-top:10px;width:100%}#onetrust-pc-sdk #accept-recommended-btn-handler{margin-right:10px;margin-bottom:25px;outline-offset:-1px}#onetrust-pc-sdk #ot-pc-desc{clear:both;width:100%;font-size:.812em;line-height:1.5;margin-bottom:25px}#onetrust-pc-sdk #ot-pc-desc a{margin-left:5px}#onetrust-pc-sdk #ot-pc-desc *{font-size:inherit;line-height:inherit}#onetrust-pc-sdk #ot-pc-desc ul li{padding:10px 0px}#onetrust-pc-sdk a{color:#656565;cursor:pointer}#onetrust-pc-sdk a:hover{color:#3860be}#onetrust-pc-sdk label{margin-bottom:0}#onetrust-pc-sdk #vdr-lst-dsc{font-size:.812em;line-height:1.5;padding:10px 15px 5px 15px}#onetrust-pc-sdk button{max-width:394px;padding:12px 30px;line-height:1;word-break:break-word;word-wrap:break-word;white-space:normal;font-weight:bold;height:auto}#onetrust-pc-sdk .ot-link-btn{padding:0;margin-bottom:0;border:0;font-weight:normal;line-height:normal;width:auto;height:auto}#onetrust-pc-sdk #ot-pc-content{position:absolute;overflow-y:scroll;padding-left:0px;padding-right:30px;top:60px;bottom:110px;margin:1px 3px 0 30px;width:calc(100% - 63px)}#onetrust-pc-sdk .ot-vs-list .ot-always-active,#onetrust-pc-sdk .ot-cat-grp .ot-always-active{float:right;clear:none;color:#3860be;margin:0;font-size:.813em;line-height:1.3}#onetrust-pc-sdk .ot-pc-scrollbar::-webkit-scrollbar-track{margin-right:20px}#onetrust-pc-sdk .ot-pc-scrollbar::-webkit-scrollbar{width:11px}#onetrust-pc-sdk .ot-pc-scrollbar::-webkit-scrollbar-thumb{border-radius:10px;background:#d8d8d8}#onetrust-pc-sdk input[type=checkbox]:focus+.ot-acc-hdr{outline:#000 1px solid}#onetrust-pc-sdk .ot-pc-scrollbar{scrollbar-arrow-color:#d8d8d8;scrollbar-darkshadow-color:#d8d8d8;scrollbar-face-color:#d8d8d8;scrollbar-shadow-color:#d8d8d8}#onetrust-pc-sdk .save-preference-btn-handler{margin-right:20px}#onetrust-pc-sdk .ot-pc-refuse-all-handler{margin-right:10px}#onetrust-pc-sdk #ot-pc-desc .privacy-notice-link{margin-left:0;margin-right:8px}#onetrust-pc-sdk #ot-pc-desc .ot-imprint-handler{margin-left:0;margin-right:8px}#onetrust-pc-sdk .ot-subgrp-cntr{display:inline-block;clear:both;width:100%;padding-top:15px}#onetrust-pc-sdk .ot-switch+.ot-subgrp-cntr{padding-top:10px}#onetrust-pc-sdk ul.ot-subgrps{margin:0;font-size:initial}#onetrust-pc-sdk ul.ot-subgrps li p,#onetrust-pc-sdk ul.ot-subgrps li h5{font-size:.813em;line-height:1.4;color:dimgray}#onetrust-pc-sdk ul.ot-subgrps .ot-switch{min-height:auto}#onetrust-pc-sdk ul.ot-subgrps .ot-switch-nob{top:0}#onetrust-pc-sdk ul.ot-subgrps .ot-acc-hdr{display:inline-block;width:100%}#onetrust-pc-sdk ul.ot-subgrps .ot-acc-txt{margin:0}#onetrust-pc-sdk ul.ot-subgrps li{padding:0;border:none}#onetrust-pc-sdk ul.ot-subgrps li h5{position:relative;top:5px;font-weight:bold;margin-bottom:0;float:left}#onetrust-pc-sdk li.ot-subgrp{margin-left:20px;overflow:auto}#onetrust-pc-sdk li.ot-subgrp>h5{width:calc(100% - 100px)}#onetrust-pc-sdk .ot-cat-item p>ul,#onetrust-pc-sdk li.ot-subgrp p>ul{margin:0px;list-style:disc;margin-left:15px;font-size:inherit}#onetrust-pc-sdk .ot-cat-item p>ul li,#onetrust-pc-sdk li.ot-subgrp p>ul li{font-size:inherit;padding-top:10px;padding-left:0px;padding-right:0px;border:none}#onetrust-pc-sdk .ot-cat-item p>ul li:last-child,#onetrust-pc-sdk li.ot-subgrp p>ul li:last-child{padding-bottom:10px}#onetrust-pc-sdk .ot-pc-logo{height:40px;width:120px}#onetrust-pc-sdk .ot-pc-footer{position:absolute;bottom:0px;width:100%;max-height:160px;border-top:1px solid #d8d8d8}#onetrust-pc-sdk.ot-ftr-stacked .ot-pc-refuse-all-handler{margin-bottom:0px}#onetrust-pc-sdk.ot-ftr-stacked #ot-pc-content{bottom:160px}#onetrust-pc-sdk.ot-ftr-stacked .ot-pc-footer button{width:100%;max-width:none}#onetrust-pc-sdk.ot-ftr-stacked .ot-btn-container{margin:0 30px;width:calc(100% - 60px);padding-right:0}#onetrust-pc-sdk .ot-pc-footer-logo{height:30px;width:100%;text-align:right;background:#f4f4f4}#onetrust-pc-sdk .ot-pc-footer-logo a{display:inline-block;margin-top:5px;margin-right:10px}#onetrust-pc-sdk[dir=rtl] .ot-pc-footer-logo{direction:rtl}#onetrust-pc-sdk[dir=rtl] .ot-pc-footer-logo a{margin-right:25px}#onetrust-pc-sdk .ot-tgl{float:right;position:relative;z-index:1}#onetrust-pc-sdk .ot-tgl input:checked+.ot-switch .ot-switch-nob{background-color:#468254;border:1px solid #fff}#onetrust-pc-sdk .ot-tgl input:checked+.ot-switch .ot-switch-nob:before{-webkit-transform:translateX(20px);-ms-transform:translateX(20px);transform:translateX(20px);background-color:#fff;border-color:#fff}#onetrust-pc-sdk .ot-tgl input:focus+.ot-switch{outline:#000 solid 1px}#onetrust-pc-sdk .ot-switch{position:relative;display:inline-block;width:45px;height:25px}#onetrust-pc-sdk .ot-switch-nob{position:absolute;cursor:pointer;top:0;left:0;right:0;bottom:0;background-color:#767676;border:1px solid #ddd;transition:all .2s ease-in 0s;-moz-transition:all .2s ease-in 0s;-o-transition:all .2s ease-in 0s;-webkit-transition:all .2s ease-in 0s;border-radius:20px}#onetrust-pc-sdk .ot-switch-nob:before{position:absolute;content:"";height:18px;width:18px;bottom:3px;left:3px;background-color:#fff;-webkit-transition:.4s;transition:.4s;border-radius:20px}#onetrust-pc-sdk .ot-chkbox input:checked~label::before{background-color:#3860be}#onetrust-pc-sdk .ot-chkbox input+label::after{content:none;color:#fff}#onetrust-pc-sdk .ot-chkbox input:checked+label::after{content:""}#onetrust-pc-sdk .ot-chkbox input:focus+label::before{outline-style:solid;outline-width:2px;outline-style:auto}#onetrust-pc-sdk .ot-chkbox label{position:relative;display:inline-block;padding-left:30px;cursor:pointer;font-weight:500}#onetrust-pc-sdk .ot-chkbox label::before,#onetrust-pc-sdk .ot-chkbox label::after{position:absolute;content:"";display:inline-block;border-radius:3px}#onetrust-pc-sdk .ot-chkbox label::before{height:18px;width:18px;border:1px solid #3860be;left:0px;top:auto}#onetrust-pc-sdk .ot-chkbox label::after{height:5px;width:9px;border-left:3px solid;border-bottom:3px solid;transform:rotate(-45deg);-o-transform:rotate(-45deg);-ms-transform:rotate(-45deg);-webkit-transform:rotate(-45deg);left:4px;top:5px}#onetrust-pc-sdk .ot-label-txt{display:none}#onetrust-pc-sdk .ot-chkbox input,#onetrust-pc-sdk .ot-tgl input{position:absolute;opacity:0;width:0;height:0}#onetrust-pc-sdk .ot-arw-cntr{float:right;position:relative;pointer-events:none}#onetrust-pc-sdk .ot-arw-cntr .ot-arw{width:16px;height:16px;margin-left:5px;color:dimgray;display:inline-block;vertical-align:middle;-webkit-transition:all 150ms ease-in 0s;-moz-transition:all 150ms ease-in 0s;-o-transition:all 150ms ease-in 0s;transition:all 150ms ease-in 0s}#onetrust-pc-sdk input:checked~.ot-acc-hdr .ot-arw,#onetrust-pc-sdk button[aria-expanded=true]~.ot-acc-hdr .ot-arw-cntr svg{transform:rotate(90deg);-o-transform:rotate(90deg);-ms-transform:rotate(90deg);-webkit-transform:rotate(90deg)}#onetrust-pc-sdk input[type=checkbox]:focus+.ot-acc-hdr{outline:#000 1px solid}#onetrust-pc-sdk .ot-tgl-cntr,#onetrust-pc-sdk .ot-arw-cntr{display:inline-block}#onetrust-pc-sdk .ot-tgl-cntr{width:45px;float:right;margin-top:2px}#onetrust-pc-sdk #ot-lst-cnt .ot-tgl-cntr{margin-top:10px}#onetrust-pc-sdk .ot-always-active-subgroup{width:auto;padding-left:0px !important;top:3px;position:relative}#onetrust-pc-sdk .ot-label-status{padding-left:5px;font-size:.75em;display:none}#onetrust-pc-sdk .ot-arw-cntr{margin-top:-1px}#onetrust-pc-sdk .ot-arw-cntr svg{-webkit-transition:all 300ms ease-in 0s;-moz-transition:all 300ms ease-in 0s;-o-transition:all 300ms ease-in 0s;transition:all 300ms ease-in 0s;height:10px;width:10px}#onetrust-pc-sdk input:checked~.ot-acc-hdr .ot-arw{transform:rotate(90deg);-o-transform:rotate(90deg);-ms-transform:rotate(90deg);-webkit-transform:rotate(90deg)}#onetrust-pc-sdk .ot-arw{width:10px;margin-left:15px;transition:all 300ms ease-in 0s;-webkit-transition:all 300ms ease-in 0s;-moz-transition:all 300ms ease-in 0s;-o-transition:all 300ms ease-in 0s}#onetrust-pc-sdk .ot-vlst-cntr{margin-bottom:0}#onetrust-pc-sdk .ot-hlst-cntr{margin-top:5px;display:inline-block;width:100%}#onetrust-pc-sdk .category-vendors-list-handler,#onetrust-pc-sdk .category-vendors-list-handler+a,#onetrust-pc-sdk .category-host-list-handler{clear:both;color:#3860be;margin-left:0;font-size:.813em;text-decoration:none;float:left;overflow:hidden}#onetrust-pc-sdk .category-vendors-list-handler:hover,#onetrust-pc-sdk .category-vendors-list-handler+a:hover,#onetrust-pc-sdk .category-host-list-handler:hover{text-decoration-line:underline}#onetrust-pc-sdk .category-vendors-list-handler+a{clear:none}#onetrust-pc-sdk .ot-vlst-cntr .ot-ext-lnk,#onetrust-pc-sdk .ot-ven-hdr .ot-ext-lnk{display:inline-block;height:13px;width:13px;background-repeat:no-repeat;margin-left:1px;margin-top:6px;cursor:pointer}#onetrust-pc-sdk .ot-ven-hdr .ot-ext-lnk{margin-bottom:-1px}#onetrust-pc-sdk .back-btn-handler{font-size:1em;text-decoration:none}#onetrust-pc-sdk .back-btn-handler:hover{opacity:.6}#onetrust-pc-sdk #ot-lst-title h3{display:inline-block;word-break:break-word;word-wrap:break-word;margin-bottom:0;color:#656565;font-size:1em;font-weight:bold;margin-left:15px}#onetrust-pc-sdk #ot-lst-title{margin:10px 0 10px 0px;font-size:1em;text-align:left}#onetrust-pc-sdk #ot-pc-hdr{margin:0 0 0 30px;height:auto;width:auto}#onetrust-pc-sdk #ot-pc-hdr input::placeholder{color:#d4d4d4;font-style:italic}#onetrust-pc-sdk #vendor-search-handler{height:31px;width:100%;border-radius:50px;font-size:.8em;padding-right:35px;padding-left:15px;float:left;margin-left:15px}#onetrust-pc-sdk .ot-ven-name{display:block;width:auto;padding-right:5px}#onetrust-pc-sdk #ot-lst-cnt{overflow-y:auto;margin-left:20px;margin-right:7px;width:calc(100% - 27px);max-height:calc(100% - 80px);height:100%;transform:translate3d(0, 0, 0)}#onetrust-pc-sdk #ot-pc-lst{width:100%;bottom:100px;position:absolute;top:60px}#onetrust-pc-sdk #ot-pc-lst:not(.ot-enbl-chr) .ot-tgl-cntr .ot-arw-cntr,#onetrust-pc-sdk #ot-pc-lst:not(.ot-enbl-chr) .ot-tgl-cntr .ot-arw-cntr *{visibility:hidden}#onetrust-pc-sdk #ot-pc-lst .ot-tgl-cntr{right:12px;position:absolute}#onetrust-pc-sdk #ot-pc-lst .ot-arw-cntr{float:right;position:relative}#onetrust-pc-sdk #ot-pc-lst .ot-arw{margin-left:10px}#onetrust-pc-sdk #ot-pc-lst .ot-acc-hdr{overflow:hidden;cursor:pointer}#onetrust-pc-sdk .ot-vlst-cntr{overflow:hidden}#onetrust-pc-sdk #ot-sel-blk{overflow:hidden;width:100%;position:sticky;position:-webkit-sticky;top:0;z-index:3}#onetrust-pc-sdk #ot-back-arw{height:12px;width:12px}#onetrust-pc-sdk .ot-lst-subhdr{width:100%;display:inline-block}#onetrust-pc-sdk .ot-search-cntr{float:left;width:78%;position:relative}#onetrust-pc-sdk .ot-search-cntr>svg{width:30px;height:30px;position:absolute;float:left;right:-15px}#onetrust-pc-sdk .ot-fltr-cntr{float:right;right:50px;position:relative}#onetrust-pc-sdk #filter-btn-handler{background-color:#3860be;border-radius:17px;display:inline-block;position:relative;width:32px;height:32px;-moz-transition:.1s ease;-o-transition:.1s ease;-webkit-transition:1s ease;transition:.1s ease;padding:0;margin:0}#onetrust-pc-sdk #filter-btn-handler:hover{background-color:#3860be}#onetrust-pc-sdk #filter-btn-handler svg{width:12px;height:12px;margin:3px 10px 0 10px;display:block;position:static;right:auto;top:auto}#onetrust-pc-sdk .ot-ven-link,#onetrust-pc-sdk .ot-ven-legclaim-link{color:#3860be;text-decoration:none;font-weight:100;display:inline-block;padding-top:10px;transform:translate(0, 1%);-o-transform:translate(0, 1%);-ms-transform:translate(0, 1%);-webkit-transform:translate(0, 1%);position:relative;z-index:2}#onetrust-pc-sdk .ot-ven-link *,#onetrust-pc-sdk .ot-ven-legclaim-link *{font-size:inherit}#onetrust-pc-sdk .ot-ven-link:hover,#onetrust-pc-sdk .ot-ven-legclaim-link:hover{text-decoration:underline}#onetrust-pc-sdk .ot-ven-hdr{width:calc(100% - 160px);height:auto;float:left;word-break:break-word;word-wrap:break-word;vertical-align:middle;padding-bottom:3px}#onetrust-pc-sdk .ot-ven-link,#onetrust-pc-sdk .ot-ven-legclaim-link{letter-spacing:.03em;font-size:.75em;font-weight:400}#onetrust-pc-sdk .ot-ven-dets{border-radius:2px;background-color:#f8f8f8}#onetrust-pc-sdk .ot-ven-dets li:first-child p:first-child{border-top:none}#onetrust-pc-sdk .ot-ven-dets .ot-ven-disc:not(:first-child){border-top:1px solid #ddd !important}#onetrust-pc-sdk .ot-ven-dets .ot-ven-disc:nth-child(n+3) p{display:inline-block}#onetrust-pc-sdk .ot-ven-dets .ot-ven-disc:nth-child(n+3) p:nth-of-type(odd){width:30%}#onetrust-pc-sdk .ot-ven-dets .ot-ven-disc:nth-child(n+3) p:nth-of-type(even){width:50%;word-break:break-word;word-wrap:break-word}#onetrust-pc-sdk .ot-ven-dets .ot-ven-disc p,#onetrust-pc-sdk .ot-ven-dets .ot-ven-disc h4{padding-top:5px;padding-bottom:5px;display:block}#onetrust-pc-sdk .ot-ven-dets .ot-ven-disc h4{display:inline-block}#onetrust-pc-sdk .ot-ven-dets .ot-ven-disc p:nth-last-child(-n+1){padding-bottom:10px}#onetrust-pc-sdk .ot-ven-dets .ot-ven-disc p:nth-child(-n+2):not(.disc-pur){padding-top:10px}#onetrust-pc-sdk .ot-ven-dets .ot-ven-disc .disc-pur-cont{display:inline}#onetrust-pc-sdk .ot-ven-dets .ot-ven-disc .disc-pur{position:relative;width:50% !important;word-break:break-word;word-wrap:break-word;left:calc(30% + 17px)}#onetrust-pc-sdk .ot-ven-dets .ot-ven-disc .disc-pur:nth-child(-n+1){position:static}#onetrust-pc-sdk .ot-ven-dets p,#onetrust-pc-sdk .ot-ven-dets h4,#onetrust-pc-sdk .ot-ven-dets span{font-size:.69em;text-align:left;vertical-align:middle;word-break:break-word;word-wrap:break-word;margin:0;padding-bottom:10px;padding-left:15px;color:#2e3644}#onetrust-pc-sdk .ot-ven-dets h4{padding-top:5px}#onetrust-pc-sdk .ot-ven-dets span{color:dimgray;padding:0;vertical-align:baseline}#onetrust-pc-sdk .ot-ven-dets .ot-ven-pur h4{border-top:1px solid #e9e9e9;border-bottom:1px solid #e9e9e9;padding-bottom:5px;margin-bottom:5px;font-weight:bold}#onetrust-pc-sdk #ot-host-lst .ot-sel-all{float:right;position:relative;margin-right:42px;top:10px}#onetrust-pc-sdk #ot-host-lst .ot-sel-all input[type=checkbox]{width:auto;height:auto}#onetrust-pc-sdk #ot-host-lst .ot-sel-all label{height:20px;width:20px;padding-left:0px}#onetrust-pc-sdk #ot-host-lst .ot-acc-txt{overflow:hidden;width:95%}#onetrust-pc-sdk .ot-host-hdr{position:relative;z-index:1;pointer-events:none;width:calc(100% - 125px);float:left}#onetrust-pc-sdk .ot-host-name,#onetrust-pc-sdk .ot-host-desc{display:inline-block;width:90%}#onetrust-pc-sdk .ot-host-name{pointer-events:none}#onetrust-pc-sdk .ot-host-hdr>a{text-decoration:underline;font-size:.82em;position:relative;z-index:2;float:left;margin-bottom:5px;pointer-events:initial}#onetrust-pc-sdk .ot-host-name+a{margin-top:5px}#onetrust-pc-sdk .ot-host-name,#onetrust-pc-sdk .ot-host-name a,#onetrust-pc-sdk .ot-host-desc,#onetrust-pc-sdk .ot-host-info{color:dimgray;word-break:break-word;word-wrap:break-word}#onetrust-pc-sdk .ot-host-name,#onetrust-pc-sdk .ot-host-name a{font-weight:bold;font-size:.82em;line-height:1.3}#onetrust-pc-sdk .ot-host-name a{font-size:1em}#onetrust-pc-sdk .ot-host-expand{margin-top:3px;margin-bottom:3px;clear:both;display:block;color:#3860be;font-size:.72em;font-weight:normal}#onetrust-pc-sdk .ot-host-expand *{font-size:inherit}#onetrust-pc-sdk .ot-host-desc,#onetrust-pc-sdk .ot-host-info{font-size:.688em;line-height:1.4;font-weight:normal}#onetrust-pc-sdk .ot-host-desc{margin-top:10px}#onetrust-pc-sdk .ot-host-opt{margin:0;font-size:inherit;display:inline-block;width:100%}#onetrust-pc-sdk .ot-host-opt li>div div{font-size:.8em;padding:5px 0}#onetrust-pc-sdk .ot-host-opt li>div div:nth-child(1){width:30%;float:left}#onetrust-pc-sdk .ot-host-opt li>div div:nth-child(2){width:70%;float:left;word-break:break-word;word-wrap:break-word}#onetrust-pc-sdk .ot-host-info{border:none;display:inline-block;width:calc(100% - 10px);padding:10px;margin-bottom:10px;background-color:#f8f8f8}#onetrust-pc-sdk .ot-host-info>div{overflow:auto}#onetrust-pc-sdk #no-results{text-align:center;margin-top:30px}#onetrust-pc-sdk #no-results p{font-size:1em;color:#2e3644;word-break:break-word;word-wrap:break-word}#onetrust-pc-sdk #no-results p span{font-weight:bold}#onetrust-pc-sdk #ot-fltr-modal{width:100%;height:auto;display:none;-moz-transition:.2s ease;-o-transition:.2s ease;-webkit-transition:2s ease;transition:.2s ease;overflow:hidden;opacity:1;right:0}#onetrust-pc-sdk #ot-fltr-modal .ot-label-txt{display:inline-block;font-size:.85em;color:dimgray}#onetrust-pc-sdk #ot-fltr-cnt{z-index:2147483646;background-color:#fff;position:absolute;height:90%;max-height:300px;width:325px;left:210px;margin-top:10px;margin-bottom:20px;padding-right:10px;border-radius:3px;-webkit-box-shadow:0px 0px 12px 2px #c7c5c7;-moz-box-shadow:0px 0px 12px 2px #c7c5c7;box-shadow:0px 0px 12px 2px #c7c5c7}#onetrust-pc-sdk .ot-fltr-scrlcnt{overflow-y:auto;overflow-x:hidden;clear:both;max-height:calc(100% - 60px)}#onetrust-pc-sdk #ot-anchor{border:12px solid rgba(0,0,0,0);display:none;position:absolute;z-index:2147483647;right:55px;top:75px;transform:rotate(45deg);-o-transform:rotate(45deg);-ms-transform:rotate(45deg);-webkit-transform:rotate(45deg);background-color:#fff;-webkit-box-shadow:-3px -3px 5px -2px #c7c5c7;-moz-box-shadow:-3px -3px 5px -2px #c7c5c7;box-shadow:-3px -3px 5px -2px #c7c5c7}#onetrust-pc-sdk .ot-fltr-btns{margin-left:15px}#onetrust-pc-sdk #filter-apply-handler{margin-right:15px}#onetrust-pc-sdk .ot-fltr-opt{margin-bottom:25px;margin-left:15px;width:75%;position:relative}#onetrust-pc-sdk .ot-fltr-opt p{display:inline-block;margin:0;font-size:.9em;color:#2e3644}#onetrust-pc-sdk .ot-chkbox label span{font-size:.85em;color:dimgray}#onetrust-pc-sdk .ot-chkbox input[type=checkbox]+label::after{content:none;color:#fff}#onetrust-pc-sdk .ot-chkbox input[type=checkbox]:checked+label::after{content:""}#onetrust-pc-sdk .ot-chkbox input[type=checkbox]:focus+label::before{outline-style:solid;outline-width:2px;outline-style:auto}#onetrust-pc-sdk #ot-selall-vencntr,#onetrust-pc-sdk #ot-selall-adtlvencntr,#onetrust-pc-sdk #ot-selall-hostcntr,#onetrust-pc-sdk #ot-selall-licntr,#onetrust-pc-sdk #ot-selall-gnvencntr{right:15px;position:relative;width:20px;height:20px;float:right}#onetrust-pc-sdk #ot-selall-vencntr label,#onetrust-pc-sdk #ot-selall-adtlvencntr label,#onetrust-pc-sdk #ot-selall-hostcntr label,#onetrust-pc-sdk #ot-selall-licntr label,#onetrust-pc-sdk #ot-selall-gnvencntr label{float:left;padding-left:0}#onetrust-pc-sdk #ot-ven-lst:first-child{border-top:1px solid #e2e2e2}#onetrust-pc-sdk ul{list-style:none;padding:0}#onetrust-pc-sdk ul li{position:relative;margin:0;padding:15px 15px 15px 10px;border-bottom:1px solid #e2e2e2}#onetrust-pc-sdk ul li h3{font-size:.75em;color:#656565;margin:0;display:inline-block;width:70%;height:auto;word-break:break-word;word-wrap:break-word}#onetrust-pc-sdk ul li p{margin:0;font-size:.7em}#onetrust-pc-sdk ul li input[type=checkbox]{position:absolute;cursor:pointer;width:100%;height:100%;opacity:0;margin:0;top:0;left:0}#onetrust-pc-sdk .ot-cat-item>button:focus,#onetrust-pc-sdk .ot-acc-cntr>button:focus,#onetrust-pc-sdk li>button:focus{outline:#000 solid 2px}#onetrust-pc-sdk .ot-cat-item>button,#onetrust-pc-sdk .ot-acc-cntr>button,#onetrust-pc-sdk li>button{position:absolute;cursor:pointer;width:100%;height:100%;margin:0;top:0;left:0;z-index:1;max-width:none;border:none}#onetrust-pc-sdk .ot-cat-item>button[aria-expanded=false]~.ot-acc-txt,#onetrust-pc-sdk .ot-acc-cntr>button[aria-expanded=false]~.ot-acc-txt,#onetrust-pc-sdk li>button[aria-expanded=false]~.ot-acc-txt{margin-top:0;max-height:0;opacity:0;overflow:hidden;width:100%;transition:.25s ease-out;display:none}#onetrust-pc-sdk .ot-cat-item>button[aria-expanded=true]~.ot-acc-txt,#onetrust-pc-sdk .ot-acc-cntr>button[aria-expanded=true]~.ot-acc-txt,#onetrust-pc-sdk li>button[aria-expanded=true]~.ot-acc-txt{transition:.1s ease-in;margin-top:10px;width:100%;overflow:auto;display:block}#onetrust-pc-sdk .ot-cat-item>button[aria-expanded=true]~.ot-acc-grpcntr,#onetrust-pc-sdk .ot-acc-cntr>button[aria-expanded=true]~.ot-acc-grpcntr,#onetrust-pc-sdk li>button[aria-expanded=true]~.ot-acc-grpcntr{width:auto;margin-top:0px;padding-bottom:10px}#onetrust-pc-sdk .ot-host-item>button:focus,#onetrust-pc-sdk .ot-ven-item>button:focus{outline:0;border:2px solid #000}#onetrust-pc-sdk .ot-hide-acc>button{pointer-events:none}#onetrust-pc-sdk .ot-hide-acc .ot-plus-minus>*,#onetrust-pc-sdk .ot-hide-acc .ot-arw-cntr>*{visibility:hidden}#onetrust-pc-sdk .ot-hide-acc .ot-acc-hdr{min-height:30px}#onetrust-pc-sdk.ot-addtl-vendors #ot-lst-cnt:not(.ot-host-cnt){padding-right:10px;width:calc(100% - 37px);margin-top:10px;max-height:calc(100% - 90px)}#onetrust-pc-sdk.ot-addtl-vendors #ot-lst-cnt:not(.ot-host-cnt) #ot-sel-blk{background-color:#f9f9fc;border:1px solid #e2e2e2;width:calc(100% - 2px);padding-bottom:5px;padding-top:5px}#onetrust-pc-sdk.ot-addtl-vendors #ot-lst-cnt:not(.ot-host-cnt) #ot-sel-blk.ot-vnd-list-cnt{border:unset;background-color:unset}#onetrust-pc-sdk.ot-addtl-vendors #ot-lst-cnt:not(.ot-host-cnt) #ot-sel-blk.ot-vnd-list-cnt .ot-sel-all-hdr{display:none}#onetrust-pc-sdk.ot-addtl-vendors #ot-lst-cnt:not(.ot-host-cnt) #ot-sel-blk.ot-vnd-list-cnt .ot-sel-all{padding-right:.5rem}#onetrust-pc-sdk.ot-addtl-vendors #ot-lst-cnt:not(.ot-host-cnt) #ot-sel-blk.ot-vnd-list-cnt .ot-sel-all .ot-chkbox{right:0}#onetrust-pc-sdk.ot-addtl-vendors #ot-lst-cnt:not(.ot-host-cnt) .ot-sel-all{padding-right:34px}#onetrust-pc-sdk.ot-addtl-vendors #ot-lst-cnt:not(.ot-host-cnt) .ot-sel-all-chkbox{width:auto}#onetrust-pc-sdk.ot-addtl-vendors #ot-lst-cnt:not(.ot-host-cnt) ul li{border:1px solid #e2e2e2;margin-bottom:10px}#onetrust-pc-sdk.ot-addtl-vendors #ot-lst-cnt:not(.ot-host-cnt) .ot-acc-cntr>.ot-acc-hdr{padding:10px 0 10px 15px}#onetrust-pc-sdk.ot-addtl-vendors .ot-sel-all-chkbox{float:right}#onetrust-pc-sdk.ot-addtl-vendors .ot-plus-minus~.ot-sel-all-chkbox{right:34px}#onetrust-pc-sdk.ot-addtl-vendors #ot-ven-lst:first-child{border-top:none}#onetrust-pc-sdk .ot-acc-cntr{position:relative;border-left:1px solid #e2e2e2;border-right:1px solid #e2e2e2;border-bottom:1px solid #e2e2e2}#onetrust-pc-sdk .ot-acc-cntr input{z-index:1}#onetrust-pc-sdk .ot-acc-cntr>.ot-acc-hdr{background-color:#f9f9fc;padding:5px 0 5px 15px;width:auto}#onetrust-pc-sdk .ot-acc-cntr>.ot-acc-hdr .ot-plus-minus{vertical-align:middle;top:auto}#onetrust-pc-sdk .ot-acc-cntr>.ot-acc-hdr .ot-arw-cntr{right:10px}#onetrust-pc-sdk .ot-acc-cntr>.ot-acc-hdr input{z-index:2}#onetrust-pc-sdk .ot-acc-cntr.ot-add-tech .ot-acc-hdr{padding:10px 0 10px 15px}#onetrust-pc-sdk .ot-acc-cntr>input[type=checkbox]:checked~.ot-acc-hdr{border-bottom:1px solid #e2e2e2}#onetrust-pc-sdk .ot-acc-cntr>.ot-acc-txt{padding-left:10px;padding-right:10px}#onetrust-pc-sdk .ot-acc-cntr button[aria-expanded=true]~.ot-acc-txt{width:auto}#onetrust-pc-sdk .ot-acc-cntr .ot-addtl-venbox{display:none}#onetrust-pc-sdk .ot-vlst-cntr{margin-bottom:0;width:100%}#onetrust-pc-sdk .ot-vensec-title{font-size:.813em;vertical-align:middle;display:inline-block}#onetrust-pc-sdk .category-vendors-list-handler,#onetrust-pc-sdk .category-vendors-list-handler+a{margin-left:0;margin-top:10px}#onetrust-pc-sdk #ot-selall-vencntr.line-through label::after,#onetrust-pc-sdk #ot-selall-adtlvencntr.line-through label::after,#onetrust-pc-sdk #ot-selall-licntr.line-through label::after,#onetrust-pc-sdk #ot-selall-hostcntr.line-through label::after,#onetrust-pc-sdk #ot-selall-gnvencntr.line-through label::after{height:auto;border-left:0;transform:none;-o-transform:none;-ms-transform:none;-webkit-transform:none;left:5px;top:9px}#onetrust-pc-sdk #ot-category-title{float:left;padding-bottom:10px;font-size:1em;width:100%}#onetrust-pc-sdk .ot-cat-grp{margin-top:10px}#onetrust-pc-sdk .ot-cat-item{line-height:1.1;margin-top:10px;display:inline-block;width:100%}#onetrust-pc-sdk .ot-btn-container{text-align:right}#onetrust-pc-sdk .ot-btn-container button{display:inline-block;font-size:.75em;letter-spacing:.08em;margin-top:19px}#onetrust-pc-sdk #close-pc-btn-handler.ot-close-icon{position:absolute;top:10px;right:0;z-index:1;padding:0;background-color:rgba(0,0,0,0);border:none}#onetrust-pc-sdk #close-pc-btn-handler.ot-close-icon svg{display:block;height:10px;width:10px}#onetrust-pc-sdk #clear-filters-handler{margin-top:20px;margin-bottom:10px;float:right;max-width:200px;text-decoration:none;color:#3860be;font-size:.9em;font-weight:bold;background-color:rgba(0,0,0,0);border-color:rgba(0,0,0,0);padding:1px}#onetrust-pc-sdk #clear-filters-handler:hover{color:#2285f7}#onetrust-pc-sdk #clear-filters-handler:focus{outline:#000 solid 1px}#onetrust-pc-sdk .ot-enbl-chr h4~.ot-tgl,#onetrust-pc-sdk .ot-enbl-chr h4~.ot-always-active{right:45px}#onetrust-pc-sdk .ot-enbl-chr h4~.ot-tgl+.ot-tgl{right:120px}#onetrust-pc-sdk .ot-enbl-chr .ot-pli-hdr.ot-leg-border-color span:first-child{width:90px}#onetrust-pc-sdk .ot-enbl-chr li.ot-subgrp>h5+.ot-tgl-cntr{padding-right:25px}#onetrust-pc-sdk .ot-plus-minus{width:20px;height:20px;font-size:1.5em;position:relative;display:inline-block;margin-right:5px;top:3px}#onetrust-pc-sdk .ot-plus-minus span{position:absolute;background:#27455c;border-radius:1px}#onetrust-pc-sdk .ot-plus-minus span:first-of-type{top:25%;bottom:25%;width:10%;left:45%}#onetrust-pc-sdk .ot-plus-minus span:last-of-type{left:25%;right:25%;height:10%;top:45%}#onetrust-pc-sdk button[aria-expanded=true]~.ot-acc-hdr .ot-arw,#onetrust-pc-sdk button[aria-expanded=true]~.ot-acc-hdr .ot-plus-minus span:first-of-type,#onetrust-pc-sdk button[aria-expanded=true]~.ot-acc-hdr .ot-plus-minus span:last-of-type{transform:rotate(90deg)}#onetrust-pc-sdk button[aria-expanded=true]~.ot-acc-hdr .ot-plus-minus span:last-of-type{left:50%;right:50%}#onetrust-pc-sdk #ot-selall-vencntr label,#onetrust-pc-sdk #ot-selall-adtlvencntr label,#onetrust-pc-sdk #ot-selall-hostcntr label,#onetrust-pc-sdk #ot-selall-licntr label{position:relative;display:inline-block;width:20px;height:20px}#onetrust-pc-sdk .ot-host-item .ot-plus-minus,#onetrust-pc-sdk .ot-ven-item .ot-plus-minus{float:left;margin-right:8px;top:10px}#onetrust-pc-sdk .ot-ven-item ul{list-style:none inside;font-size:100%;margin:0}#onetrust-pc-sdk .ot-ven-item ul li{margin:0 !important;padding:0;border:none !important}#onetrust-pc-sdk .ot-pli-hdr{color:#77808e;overflow:hidden;padding-top:7.5px;padding-bottom:7.5px;width:calc(100% - 2px);border-top-left-radius:3px;border-top-right-radius:3px}#onetrust-pc-sdk .ot-pli-hdr span:first-child{top:50%;transform:translateY(50%);max-width:90px}#onetrust-pc-sdk .ot-pli-hdr span:last-child{padding-right:10px;max-width:95px;text-align:center}#onetrust-pc-sdk .ot-li-title{float:right;font-size:.813em}#onetrust-pc-sdk .ot-pli-hdr.ot-leg-border-color{background-color:#f4f4f4;border:1px solid #d8d8d8}#onetrust-pc-sdk .ot-pli-hdr.ot-leg-border-color span:first-child{text-align:left;width:70px}#onetrust-pc-sdk li.ot-subgrp>h5,#onetrust-pc-sdk .ot-cat-header{width:calc(100% - 130px)}#onetrust-pc-sdk li.ot-subgrp>h5+.ot-tgl-cntr{padding-left:13px}#onetrust-pc-sdk .ot-acc-grpcntr .ot-acc-grpdesc{margin-bottom:5px}#onetrust-pc-sdk .ot-acc-grpcntr .ot-subgrp-cntr{border-top:1px solid #d8d8d8}#onetrust-pc-sdk .ot-acc-grpcntr .ot-vlst-cntr+.ot-subgrp-cntr{border-top:none}#onetrust-pc-sdk .ot-acc-hdr .ot-arw-cntr+.ot-tgl-cntr,#onetrust-pc-sdk .ot-acc-txt h4+.ot-tgl-cntr{padding-left:13px}#onetrust-pc-sdk .ot-pli-hdr~.ot-cat-item .ot-subgrp>h5,#onetrust-pc-sdk .ot-pli-hdr~.ot-cat-item .ot-cat-header{width:calc(100% - 145px)}#onetrust-pc-sdk .ot-pli-hdr~.ot-cat-item h5+.ot-tgl-cntr,#onetrust-pc-sdk .ot-pli-hdr~.ot-cat-item .ot-cat-header+.ot-tgl{padding-left:28px}#onetrust-pc-sdk .ot-sel-all-hdr,#onetrust-pc-sdk .ot-sel-all-chkbox{display:inline-block;width:100%;position:relative}#onetrust-pc-sdk .ot-sel-all-chkbox{z-index:1}#onetrust-pc-sdk .ot-sel-all{margin:0;position:relative;padding-right:23px;float:right}#onetrust-pc-sdk .ot-consent-hdr,#onetrust-pc-sdk .ot-li-hdr{float:right;font-size:.812em;line-height:normal;text-align:center;word-break:break-word;word-wrap:break-word}#onetrust-pc-sdk .ot-li-hdr{max-width:100px;padding-right:10px}#onetrust-pc-sdk .ot-consent-hdr{max-width:55px}#onetrust-pc-sdk #ot-selall-licntr{display:block;width:21px;height:auto;float:right;position:relative;right:80px}#onetrust-pc-sdk #ot-selall-licntr label{position:absolute}#onetrust-pc-sdk .ot-ven-ctgl{margin-left:66px}#onetrust-pc-sdk .ot-ven-litgl+.ot-arw-cntr{margin-left:81px}#onetrust-pc-sdk .ot-enbl-chr .ot-host-cnt .ot-tgl-cntr{width:auto}#onetrust-pc-sdk #ot-lst-cnt:not(.ot-host-cnt) .ot-tgl-cntr{width:auto;top:auto;height:20px}#onetrust-pc-sdk #ot-lst-cnt .ot-chkbox{position:relative;display:inline-block;width:20px;height:20px}#onetrust-pc-sdk #ot-lst-cnt .ot-chkbox label{position:absolute;padding:0;width:20px;height:20px}#onetrust-pc-sdk #ot-lst-cnt .ot-vnd-info-cntr{border:1px solid #d8d8d8;padding:.75rem 2rem;padding-bottom:0;width:auto;margin-top:.5rem}#onetrust-pc-sdk .ot-acc-grpdesc+.ot-leg-btn-container{padding-left:20px;padding-right:20px;width:calc(100% - 40px);margin-bottom:5px}#onetrust-pc-sdk .ot-subgrp .ot-leg-btn-container{margin-bottom:5px}#onetrust-pc-sdk #ot-ven-lst .ot-leg-btn-container{margin-top:10px}#onetrust-pc-sdk .ot-leg-btn-container{display:inline-block;width:100%;margin-bottom:10px}#onetrust-pc-sdk .ot-leg-btn-container button{height:auto;padding:6.5px 8px;margin-bottom:0;letter-spacing:0;font-size:.75em;line-height:normal}#onetrust-pc-sdk .ot-leg-btn-container svg{display:none;height:14px;width:14px;padding-right:5px;vertical-align:sub}#onetrust-pc-sdk .ot-active-leg-btn{cursor:default;pointer-events:none}#onetrust-pc-sdk .ot-active-leg-btn svg{display:inline-block}#onetrust-pc-sdk .ot-remove-objection-handler{text-decoration:underline;padding:0;font-size:.75em;font-weight:600;line-height:1;padding-left:10px}#onetrust-pc-sdk .ot-obj-leg-btn-handler span{font-weight:bold;text-align:center;font-size:inherit;line-height:1.5}#onetrust-pc-sdk.ot-close-btn-link #close-pc-btn-handler{border:none;height:auto;line-height:1.5;text-decoration:underline;font-size:.69em;background:none;right:15px;top:15px;width:auto;font-weight:normal}#onetrust-pc-sdk .ot-pgph-link{font-size:.813em !important;margin-top:5px;position:relative}#onetrust-pc-sdk .ot-pgph-link.ot-pgph-link-subgroup{margin-bottom:1rem}#onetrust-pc-sdk .ot-pgph-contr{margin:0 2.5rem}#onetrust-pc-sdk .ot-pgph-title{font-size:1.18rem;margin-bottom:2rem}#onetrust-pc-sdk .ot-pgph-desc{font-size:1rem;font-weight:400;margin-bottom:2rem;line-height:1.5rem}#onetrust-pc-sdk .ot-pgph-desc:not(:last-child):after{content:"";width:96%;display:block;margin:0 auto;padding-bottom:2rem;border-bottom:1px solid #e9e9e9}#onetrust-pc-sdk .ot-cat-header{float:left;font-weight:600;font-size:.875em;line-height:1.5;max-width:90%;vertical-align:middle}#onetrust-pc-sdk .ot-vnd-item>button:focus{outline:#000 solid 2px}#onetrust-pc-sdk .ot-vnd-item>button{position:absolute;cursor:pointer;width:100%;height:100%;margin:0;top:0;left:0;z-index:1;max-width:none;border:none}#onetrust-pc-sdk .ot-vnd-item>button[aria-expanded=false]~.ot-acc-txt{margin-top:0;max-height:0;opacity:0;overflow:hidden;width:100%;transition:.25s ease-out;display:none}#onetrust-pc-sdk .ot-vnd-item>button[aria-expanded=true]~.ot-acc-txt{transition:.1s ease-in;margin-top:10px;width:100%;overflow:auto;display:block}#onetrust-pc-sdk .ot-vnd-item>button[aria-expanded=true]~.ot-acc-grpcntr{width:auto;margin-top:0px;padding-bottom:10px}#onetrust-pc-sdk .ot-accordion-layout.ot-cat-item{position:relative;border-radius:2px;margin:0;padding:0;border:1px solid #d8d8d8;border-top:none;width:calc(100% - 2px);float:left}#onetrust-pc-sdk .ot-accordion-layout.ot-cat-item:first-of-type{margin-top:10px;border-top:1px solid #d8d8d8}#onetrust-pc-sdk .ot-accordion-layout .ot-acc-grpdesc{padding-left:20px;padding-right:20px;width:calc(100% - 40px);font-size:.812em;margin-bottom:10px;margin-top:15px}#onetrust-pc-sdk .ot-accordion-layout .ot-acc-grpdesc>ul{padding-top:10px}#onetrust-pc-sdk .ot-accordion-layout .ot-acc-grpdesc>ul li{padding-top:0;line-height:1.5;padding-bottom:10px}#onetrust-pc-sdk .ot-accordion-layout div+.ot-acc-grpdesc{margin-top:5px}#onetrust-pc-sdk .ot-accordion-layout .ot-vlst-cntr:first-child{margin-top:10px}#onetrust-pc-sdk .ot-accordion-layout .ot-vlst-cntr:last-child,#onetrust-pc-sdk .ot-accordion-layout .ot-hlst-cntr:last-child{margin-bottom:5px}#onetrust-pc-sdk .ot-accordion-layout .ot-acc-hdr{padding-top:11.5px;padding-bottom:11.5px;padding-left:20px;padding-right:20px;width:calc(100% - 40px);display:inline-block}#onetrust-pc-sdk .ot-accordion-layout .ot-acc-txt{width:100%;padding:0}#onetrust-pc-sdk .ot-accordion-layout .ot-subgrp-cntr{padding-left:20px;padding-right:15px;padding-bottom:0;width:calc(100% - 35px)}#onetrust-pc-sdk .ot-accordion-layout .ot-subgrp{padding-right:5px}#onetrust-pc-sdk .ot-accordion-layout .ot-acc-grpcntr{z-index:1;position:relative}#onetrust-pc-sdk .ot-accordion-layout .ot-cat-header+.ot-arw-cntr{position:absolute;top:50%;transform:translateY(-50%);right:20px;margin-top:-2px}#onetrust-pc-sdk .ot-accordion-layout .ot-cat-header+.ot-arw-cntr .ot-arw{width:15px;height:20px;margin-left:5px;color:dimgray}#onetrust-pc-sdk .ot-accordion-layout .ot-cat-header{float:none;color:#2e3644;margin:0;display:inline-block;height:auto;word-wrap:break-word;min-height:inherit}#onetrust-pc-sdk .ot-accordion-layout .ot-vlst-cntr,#onetrust-pc-sdk .ot-accordion-layout .ot-hlst-cntr{padding-left:20px;width:calc(100% - 20px);display:inline-block;margin-top:0;padding-bottom:2px}#onetrust-pc-sdk .ot-accordion-layout .ot-acc-hdr{position:relative;min-height:25px}#onetrust-pc-sdk .ot-accordion-layout h4~.ot-tgl,#onetrust-pc-sdk .ot-accordion-layout h4~.ot-always-active{position:absolute;top:50%;transform:translateY(-50%);right:20px}#onetrust-pc-sdk .ot-accordion-layout h4~.ot-tgl+.ot-tgl{right:95px}#onetrust-pc-sdk .ot-accordion-layout .category-vendors-list-handler,#onetrust-pc-sdk .ot-accordion-layout .category-vendors-list-handler+a{margin-top:5px}#onetrust-pc-sdk #ot-lst-cnt{margin-top:1rem;max-height:calc(100% - 96px)}#onetrust-pc-sdk #ot-lst-cnt .ot-vnd-info-cntr{border:1px solid #d8d8d8;padding:.75rem 2rem;padding-bottom:0;width:auto;margin-top:.5rem}#onetrust-pc-sdk #ot-lst-cnt .ot-vnd-info{margin-bottom:1rem;padding-left:.75rem;padding-right:.75rem;display:flex;flex-direction:column}#onetrust-pc-sdk #ot-lst-cnt .ot-vnd-info[data-vnd-info-key*=DPOEmail]{border-top:1px solid #d8d8d8;padding-top:1rem}#onetrust-pc-sdk #ot-lst-cnt .ot-vnd-info[data-vnd-info-key*=DPOLink]{border-bottom:1px solid #d8d8d8;padding-bottom:1rem}#onetrust-pc-sdk #ot-lst-cnt .ot-vnd-info .ot-vnd-lbl{font-weight:bold;font-size:.85em;margin-bottom:.5rem}#onetrust-pc-sdk #ot-lst-cnt .ot-vnd-info .ot-vnd-cnt{margin-left:.5rem;font-weight:500;font-size:.85rem}#onetrust-pc-sdk .ot-vs-list,#onetrust-pc-sdk .ot-vnd-serv{width:auto;padding:1rem 1.25rem;padding-bottom:0}#onetrust-pc-sdk .ot-vs-list .ot-vnd-serv-hdr-cntr,#onetrust-pc-sdk .ot-vnd-serv .ot-vnd-serv-hdr-cntr{padding-bottom:.75rem;border-bottom:1px solid #d8d8d8}#onetrust-pc-sdk .ot-vs-list .ot-vnd-serv-hdr-cntr .ot-vnd-serv-hdr,#onetrust-pc-sdk .ot-vnd-serv .ot-vnd-serv-hdr-cntr .ot-vnd-serv-hdr{font-weight:600;font-size:.95em;line-height:2;margin-left:.5rem}#onetrust-pc-sdk .ot-vs-list .ot-vnd-item,#onetrust-pc-sdk .ot-vnd-serv .ot-vnd-item{border:none;margin:0;padding:0}#onetrust-pc-sdk .ot-vs-list .ot-vnd-item button,#onetrust-pc-sdk .ot-vnd-serv .ot-vnd-item button{outline:none;border-bottom:1px solid #d8d8d8}#onetrust-pc-sdk .ot-vs-list .ot-vnd-item button[aria-expanded=true],#onetrust-pc-sdk .ot-vnd-serv .ot-vnd-item button[aria-expanded=true]{border-bottom:none}#onetrust-pc-sdk .ot-vs-list .ot-vnd-item:first-child,#onetrust-pc-sdk .ot-vnd-serv .ot-vnd-item:first-child{margin-top:.25rem;border-top:unset}#onetrust-pc-sdk .ot-vs-list .ot-vnd-item:last-child,#onetrust-pc-sdk .ot-vnd-serv .ot-vnd-item:last-child{margin-bottom:.5rem}#onetrust-pc-sdk .ot-vs-list .ot-vnd-item:last-child button,#onetrust-pc-sdk .ot-vnd-serv .ot-vnd-item:last-child button{border-bottom:none}#onetrust-pc-sdk .ot-vs-list .ot-vnd-item .ot-vnd-info-cntr,#onetrust-pc-sdk .ot-vnd-serv .ot-vnd-item .ot-vnd-info-cntr{border:1px solid #d8d8d8;padding:.75rem 1.75rem;padding-bottom:0;width:auto;margin-top:.5rem}#onetrust-pc-sdk .ot-vs-list .ot-vnd-item .ot-vnd-info,#onetrust-pc-sdk .ot-vnd-serv .ot-vnd-item .ot-vnd-info{margin-bottom:1rem;padding-left:.75rem;padding-right:.75rem;display:flex;flex-direction:column}#onetrust-pc-sdk .ot-vs-list .ot-vnd-item .ot-vnd-info[data-vnd-info-key*=DPOEmail],#onetrust-pc-sdk .ot-vnd-serv .ot-vnd-item .ot-vnd-info[data-vnd-info-key*=DPOEmail]{border-top:1px solid #d8d8d8;padding-top:1rem}#onetrust-pc-sdk .ot-vs-list .ot-vnd-item .ot-vnd-info[data-vnd-info-key*=DPOLink],#onetrust-pc-sdk .ot-vnd-serv .ot-vnd-item .ot-vnd-info[data-vnd-info-key*=DPOLink]{border-bottom:1px solid #d8d8d8;padding-bottom:1rem}#onetrust-pc-sdk .ot-vs-list .ot-vnd-item .ot-vnd-info .ot-vnd-lbl,#onetrust-pc-sdk .ot-vnd-serv .ot-vnd-item .ot-vnd-info .ot-vnd-lbl{font-weight:bold;font-size:.85em;margin-bottom:.5rem}#onetrust-pc-sdk .ot-vs-list .ot-vnd-item .ot-vnd-info .ot-vnd-cnt,#onetrust-pc-sdk .ot-vnd-serv .ot-vnd-item .ot-vnd-info .ot-vnd-cnt{margin-left:.5rem;font-weight:500;font-size:.85rem}#onetrust-pc-sdk .ot-vs-list.ot-vnd-subgrp-cnt,#onetrust-pc-sdk .ot-vnd-serv.ot-vnd-subgrp-cnt{padding-left:40px}#onetrust-pc-sdk .ot-vs-list.ot-vnd-subgrp-cnt .ot-vnd-serv-hdr-cntr .ot-vnd-serv-hdr,#onetrust-pc-sdk .ot-vnd-serv.ot-vnd-subgrp-cnt .ot-vnd-serv-hdr-cntr .ot-vnd-serv-hdr{font-size:.8em}#onetrust-pc-sdk .ot-vs-list.ot-vnd-subgrp-cnt .ot-cat-header,#onetrust-pc-sdk .ot-vnd-serv.ot-vnd-subgrp-cnt .ot-cat-header{font-size:.8em}#onetrust-pc-sdk .ot-subgrp-cntr .ot-vnd-serv{margin-bottom:1rem;padding:1rem .95rem}#onetrust-pc-sdk .ot-subgrp-cntr .ot-vnd-serv .ot-vnd-serv-hdr-cntr{padding-bottom:.75rem;border-bottom:1px solid #d8d8d8}#onetrust-pc-sdk .ot-subgrp-cntr .ot-vnd-serv .ot-vnd-serv-hdr-cntr .ot-vnd-serv-hdr{font-weight:700;font-size:.8em;line-height:20px;margin-left:.82rem}#onetrust-pc-sdk .ot-subgrp-cntr .ot-cat-header{font-weight:700;font-size:.8em;line-height:20px}#onetrust-pc-sdk .ot-subgrp-cntr ul.ot-subgrps .ot-vnd-serv .ot-vnd-lst-cont .ot-accordion-layout .ot-acc-hdr div.ot-chkbox{margin-left:.82rem}#onetrust-pc-sdk .ot-vs-config .ot-acc-hdr,#onetrust-pc-sdk ul.ot-subgrps .ot-acc-hdr,#onetrust-pc-sdk .ot-subgrp-cntr ul.ot-subgrps .ot-acc-hdr,#onetrust-pc-sdk .ot-vs-list .ot-vnd-item .ot-acc-hdr,#onetrust-pc-sdk .ot-vnd-serv .ot-vnd-item .ot-acc-hdr,#onetrust-pc-sdk #ot-pc-lst .ot-vs-list .ot-vnd-item .ot-acc-hdr,#onetrust-pc-sdk .ot-accordion-layout.ot-checkbox-consent .ot-acc-hdr{padding:.7rem 0;margin:0;display:flex;width:100%;align-items:center;justify-content:space-between}#onetrust-pc-sdk .ot-vs-config .ot-acc-hdr div:first-child,#onetrust-pc-sdk ul.ot-subgrps .ot-acc-hdr div:first-child,#onetrust-pc-sdk .ot-subgrp-cntr ul.ot-subgrps .ot-acc-hdr div:first-child,#onetrust-pc-sdk .ot-vs-list .ot-vnd-item .ot-acc-hdr div:first-child,#onetrust-pc-sdk .ot-vnd-serv .ot-vnd-item .ot-acc-hdr div:first-child,#onetrust-pc-sdk #ot-pc-lst .ot-vs-list .ot-vnd-item .ot-acc-hdr div:first-child,#onetrust-pc-sdk .ot-accordion-layout.ot-checkbox-consent .ot-acc-hdr div:first-child{margin-left:.5rem}#onetrust-pc-sdk .ot-vs-config .ot-acc-hdr div:last-child,#onetrust-pc-sdk ul.ot-subgrps .ot-acc-hdr div:last-child,#onetrust-pc-sdk .ot-subgrp-cntr ul.ot-subgrps .ot-acc-hdr div:last-child,#onetrust-pc-sdk .ot-vs-list .ot-vnd-item .ot-acc-hdr div:last-child,#onetrust-pc-sdk .ot-vnd-serv .ot-vnd-item .ot-acc-hdr div:last-child,#onetrust-pc-sdk #ot-pc-lst .ot-vs-list .ot-vnd-item .ot-acc-hdr div:last-child,#onetrust-pc-sdk .ot-accordion-layout.ot-checkbox-consent .ot-acc-hdr div:last-child{margin-right:.5rem;margin-left:.5rem}#onetrust-pc-sdk .ot-vs-config .ot-acc-hdr .ot-always-active,#onetrust-pc-sdk ul.ot-subgrps .ot-acc-hdr .ot-always-active,#onetrust-pc-sdk .ot-subgrp-cntr ul.ot-subgrps .ot-acc-hdr .ot-always-active,#onetrust-pc-sdk .ot-vs-list .ot-vnd-item .ot-acc-hdr .ot-always-active,#onetrust-pc-sdk .ot-vnd-serv .ot-vnd-item .ot-acc-hdr .ot-always-active,#onetrust-pc-sdk #ot-pc-lst .ot-vs-list .ot-vnd-item .ot-acc-hdr .ot-always-active,#onetrust-pc-sdk .ot-accordion-layout.ot-checkbox-consent .ot-acc-hdr .ot-always-active{position:relative;right:unset;top:unset;transform:unset}#onetrust-pc-sdk .ot-vs-config .ot-acc-hdr .ot-plus-minus,#onetrust-pc-sdk ul.ot-subgrps .ot-acc-hdr .ot-plus-minus,#onetrust-pc-sdk .ot-subgrp-cntr ul.ot-subgrps .ot-acc-hdr .ot-plus-minus,#onetrust-pc-sdk .ot-vs-list .ot-vnd-item .ot-acc-hdr .ot-plus-minus,#onetrust-pc-sdk .ot-vnd-serv .ot-vnd-item .ot-acc-hdr .ot-plus-minus,#onetrust-pc-sdk #ot-pc-lst .ot-vs-list .ot-vnd-item .ot-acc-hdr .ot-plus-minus,#onetrust-pc-sdk .ot-accordion-layout.ot-checkbox-consent .ot-acc-hdr .ot-plus-minus{top:0}#onetrust-pc-sdk .ot-vs-config .ot-acc-hdr .ot-arw-cntr,#onetrust-pc-sdk ul.ot-subgrps .ot-acc-hdr .ot-arw-cntr,#onetrust-pc-sdk .ot-subgrp-cntr ul.ot-subgrps .ot-acc-hdr .ot-arw-cntr,#onetrust-pc-sdk .ot-vs-list .ot-vnd-item .ot-acc-hdr .ot-arw-cntr,#onetrust-pc-sdk .ot-vnd-serv .ot-vnd-item .ot-acc-hdr .ot-arw-cntr,#onetrust-pc-sdk #ot-pc-lst .ot-vs-list .ot-vnd-item .ot-acc-hdr .ot-arw-cntr,#onetrust-pc-sdk .ot-accordion-layout.ot-checkbox-consent .ot-acc-hdr .ot-arw-cntr{float:none;top:unset;right:unset;transform:unset;margin-top:-2px;position:relative}#onetrust-pc-sdk .ot-vs-config .ot-acc-hdr .ot-cat-header,#onetrust-pc-sdk ul.ot-subgrps .ot-acc-hdr .ot-cat-header,#onetrust-pc-sdk .ot-subgrp-cntr ul.ot-subgrps .ot-acc-hdr .ot-cat-header,#onetrust-pc-sdk .ot-vs-list .ot-vnd-item .ot-acc-hdr .ot-cat-header,#onetrust-pc-sdk .ot-vnd-serv .ot-vnd-item .ot-acc-hdr .ot-cat-header,#onetrust-pc-sdk #ot-pc-lst .ot-vs-list .ot-vnd-item .ot-acc-hdr .ot-cat-header,#onetrust-pc-sdk .ot-accordion-layout.ot-checkbox-consent .ot-acc-hdr .ot-cat-header{flex:1;margin:0 .5rem}#onetrust-pc-sdk .ot-vs-config .ot-acc-hdr .ot-tgl,#onetrust-pc-sdk ul.ot-subgrps .ot-acc-hdr .ot-tgl,#onetrust-pc-sdk .ot-subgrp-cntr ul.ot-subgrps .ot-acc-hdr .ot-tgl,#onetrust-pc-sdk .ot-vs-list .ot-vnd-item .ot-acc-hdr .ot-tgl,#onetrust-pc-sdk .ot-vnd-serv .ot-vnd-item .ot-acc-hdr .ot-tgl,#onetrust-pc-sdk #ot-pc-lst .ot-vs-list .ot-vnd-item .ot-acc-hdr .ot-tgl,#onetrust-pc-sdk .ot-accordion-layout.ot-checkbox-consent .ot-acc-hdr .ot-tgl{position:relative;transform:none;right:0;top:0;float:none}#onetrust-pc-sdk .ot-vs-config .ot-acc-hdr .ot-chkbox,#onetrust-pc-sdk ul.ot-subgrps .ot-acc-hdr .ot-chkbox,#onetrust-pc-sdk .ot-subgrp-cntr ul.ot-subgrps .ot-acc-hdr .ot-chkbox,#onetrust-pc-sdk .ot-vs-list .ot-vnd-item .ot-acc-hdr .ot-chkbox,#onetrust-pc-sdk .ot-vnd-serv .ot-vnd-item .ot-acc-hdr .ot-chkbox,#onetrust-pc-sdk #ot-pc-lst .ot-vs-list .ot-vnd-item .ot-acc-hdr .ot-chkbox,#onetrust-pc-sdk .ot-accordion-layout.ot-checkbox-consent .ot-acc-hdr .ot-chkbox{position:relative;margin:0 .5rem}#onetrust-pc-sdk .ot-vs-config .ot-acc-hdr .ot-chkbox label,#onetrust-pc-sdk ul.ot-subgrps .ot-acc-hdr .ot-chkbox label,#onetrust-pc-sdk .ot-subgrp-cntr ul.ot-subgrps .ot-acc-hdr .ot-chkbox label,#onetrust-pc-sdk .ot-vs-list .ot-vnd-item .ot-acc-hdr .ot-chkbox label,#onetrust-pc-sdk .ot-vnd-serv .ot-vnd-item .ot-acc-hdr .ot-chkbox label,#onetrust-pc-sdk #ot-pc-lst .ot-vs-list .ot-vnd-item .ot-acc-hdr .ot-chkbox label,#onetrust-pc-sdk .ot-accordion-layout.ot-checkbox-consent .ot-acc-hdr .ot-chkbox label{padding:0}#onetrust-pc-sdk .ot-vs-config .ot-acc-hdr .ot-chkbox label::before,#onetrust-pc-sdk ul.ot-subgrps .ot-acc-hdr .ot-chkbox label::before,#onetrust-pc-sdk .ot-subgrp-cntr ul.ot-subgrps .ot-acc-hdr .ot-chkbox label::before,#onetrust-pc-sdk .ot-vs-list .ot-vnd-item .ot-acc-hdr .ot-chkbox label::before,#onetrust-pc-sdk .ot-vnd-serv .ot-vnd-item .ot-acc-hdr .ot-chkbox label::before,#onetrust-pc-sdk #ot-pc-lst .ot-vs-list .ot-vnd-item .ot-acc-hdr .ot-chkbox label::before,#onetrust-pc-sdk .ot-accordion-layout.ot-checkbox-consent .ot-acc-hdr .ot-chkbox label::before{position:relative}#onetrust-pc-sdk .ot-vs-config .ot-acc-hdr .ot-chkbox input,#onetrust-pc-sdk ul.ot-subgrps .ot-acc-hdr .ot-chkbox input,#onetrust-pc-sdk .ot-subgrp-cntr ul.ot-subgrps .ot-acc-hdr .ot-chkbox input,#onetrust-pc-sdk .ot-vs-list .ot-vnd-item .ot-acc-hdr .ot-chkbox input,#onetrust-pc-sdk .ot-vnd-serv .ot-vnd-item .ot-acc-hdr .ot-chkbox input,#onetrust-pc-sdk #ot-pc-lst .ot-vs-list .ot-vnd-item .ot-acc-hdr .ot-chkbox input,#onetrust-pc-sdk .ot-accordion-layout.ot-checkbox-consent .ot-acc-hdr .ot-chkbox input{position:absolute;cursor:pointer;width:100%;height:100%;opacity:0;margin:0;top:0;left:0;z-index:1}#onetrust-pc-sdk .ot-subgrp-cntr ul.ot-subgrps li.ot-subgrp .ot-acc-hdr h5.ot-cat-header,#onetrust-pc-sdk .ot-subgrp-cntr ul.ot-subgrps li.ot-subgrp .ot-acc-hdr h4.ot-cat-header{margin:0}#onetrust-pc-sdk .ot-vs-config .ot-subgrp-cntr ul.ot-subgrps li.ot-subgrp h5{top:0;line-height:20px}#onetrust-pc-sdk .ot-vs-list{display:flex;flex-direction:column;padding:0;margin:.5rem 4px}#onetrust-pc-sdk .ot-vs-selc-all{display:flex;padding:0;float:unset;align-items:center;justify-content:flex-start}#onetrust-pc-sdk .ot-vs-selc-all.ot-toggle-conf{justify-content:flex-end}#onetrust-pc-sdk .ot-vs-selc-all.ot-toggle-conf.ot-caret-conf .ot-sel-all-chkbox{margin-right:48px}#onetrust-pc-sdk .ot-vs-selc-all.ot-toggle-conf .ot-sel-all-chkbox{margin:0;padding:0;margin-right:14px;justify-content:flex-end}#onetrust-pc-sdk .ot-vs-selc-all.ot-toggle-conf #ot-selall-vencntr.ot-chkbox,#onetrust-pc-sdk .ot-vs-selc-all.ot-toggle-conf #ot-selall-vencntr.ot-tgl{display:inline-block;right:unset;width:auto;height:auto;float:none}#onetrust-pc-sdk .ot-vs-selc-all.ot-toggle-conf #ot-selall-vencntr label{width:45px;height:25px}#onetrust-pc-sdk .ot-vs-selc-all .ot-sel-all-chkbox{margin-right:11px;margin-left:.75rem;display:flex;align-items:center}#onetrust-pc-sdk .ot-vs-selc-all .sel-all-hdr{margin:0 1.25rem;font-size:.812em;line-height:normal;text-align:center;word-break:break-word;word-wrap:break-word}#onetrust-pc-sdk .ot-vnd-list-cnt #ot-selall-vencntr.ot-chkbox{float:unset;right:0}#onetrust-pc-sdk[dir=rtl] #ot-back-arw,#onetrust-pc-sdk[dir=rtl] input~.ot-acc-hdr .ot-arw{transform:rotate(180deg);-o-transform:rotate(180deg);-ms-transform:rotate(180deg);-webkit-transform:rotate(180deg)}#onetrust-pc-sdk[dir=rtl] input:checked~.ot-acc-hdr .ot-arw{transform:rotate(270deg);-o-transform:rotate(270deg);-ms-transform:rotate(270deg);-webkit-transform:rotate(270deg)}#onetrust-pc-sdk[dir=rtl] .ot-chkbox label::after{transform:rotate(45deg);-webkit-transform:rotate(45deg);-o-transform:rotate(45deg);-ms-transform:rotate(45deg);border-left:0;border-right:3px solid}#onetrust-pc-sdk[dir=rtl] .ot-search-cntr>svg{right:0}@media only screen and (max-width: 600px){#onetrust-pc-sdk.otPcCenter{left:0;min-width:100%;height:100%;top:0;border-radius:0}#onetrust-pc-sdk #ot-pc-content,#onetrust-pc-sdk.ot-ftr-stacked .ot-btn-container{margin:1px 3px 0 10px;padding-right:10px;width:calc(100% - 23px)}#onetrust-pc-sdk .ot-btn-container button{max-width:none;letter-spacing:.01em}#onetrust-pc-sdk #close-pc-btn-handler{top:10px;right:17px}#onetrust-pc-sdk p{font-size:.7em}#onetrust-pc-sdk #ot-pc-hdr{margin:10px 10px 0 5px;width:calc(100% - 15px)}#onetrust-pc-sdk .vendor-search-handler{font-size:1em}#onetrust-pc-sdk #ot-back-arw{margin-left:12px}#onetrust-pc-sdk #ot-lst-cnt{margin:0;padding:0 5px 0 10px;min-width:95%}#onetrust-pc-sdk .switch+p{max-width:80%}#onetrust-pc-sdk .ot-ftr-stacked button{width:100%}#onetrust-pc-sdk #ot-fltr-cnt{max-width:320px;width:90%;border-top-right-radius:0;border-bottom-right-radius:0;margin:0;margin-left:15px;left:auto;right:40px;top:85px}#onetrust-pc-sdk .ot-fltr-opt{margin-left:25px;margin-bottom:10px}#onetrust-pc-sdk .ot-pc-refuse-all-handler{margin-bottom:0}#onetrust-pc-sdk #ot-fltr-cnt{right:40px}}@media only screen and (max-width: 476px){#onetrust-pc-sdk .ot-fltr-cntr,#onetrust-pc-sdk #ot-fltr-cnt{right:10px}#onetrust-pc-sdk #ot-anchor{right:25px}#onetrust-pc-sdk button{width:100%}#onetrust-pc-sdk:not(.ot-addtl-vendors) #ot-pc-lst:not(.ot-enbl-chr) .ot-sel-all{padding-right:9px}#onetrust-pc-sdk:not(.ot-addtl-vendors) #ot-pc-lst:not(.ot-enbl-chr) .ot-tgl-cntr{right:0}}@media only screen and (max-width: 896px)and (max-height: 425px)and (orientation: landscape){#onetrust-pc-sdk.otPcCenter{left:0;top:0;min-width:100%;height:100%;border-radius:0}#onetrust-pc-sdk .ot-pc-header{height:auto;min-height:20px}#onetrust-pc-sdk .ot-pc-header .ot-pc-logo{max-height:30px}#onetrust-pc-sdk .ot-pc-footer{max-height:60px;overflow-y:auto}#onetrust-pc-sdk #ot-pc-content,#onetrust-pc-sdk #ot-pc-lst{bottom:70px}#onetrust-pc-sdk.ot-ftr-stacked #ot-pc-content{bottom:70px}#onetrust-pc-sdk #ot-anchor{left:initial;right:50px}#onetrust-pc-sdk #ot-lst-title{margin-top:12px}#onetrust-pc-sdk #ot-lst-title *{font-size:inherit}#onetrust-pc-sdk #ot-pc-hdr input{margin-right:0;padding-right:45px}#onetrust-pc-sdk .switch+p{max-width:85%}#onetrust-pc-sdk #ot-sel-blk{position:static}#onetrust-pc-sdk #ot-pc-lst{overflow:auto}#onetrust-pc-sdk #ot-lst-cnt{max-height:none;overflow:initial}#onetrust-pc-sdk #ot-lst-cnt.no-results{height:auto}#onetrust-pc-sdk input{font-size:1em !important}#onetrust-pc-sdk p{font-size:.6em}#onetrust-pc-sdk #ot-fltr-modal{width:100%;top:0}#onetrust-pc-sdk ul li p,#onetrust-pc-sdk .category-vendors-list-handler,#onetrust-pc-sdk .category-vendors-list-handler+a,#onetrust-pc-sdk .category-host-list-handler{font-size:.6em}#onetrust-pc-sdk.ot-shw-fltr #ot-anchor{display:none !important}#onetrust-pc-sdk.ot-shw-fltr #ot-pc-lst{height:100% !important;overflow:hidden;top:0px}#onetrust-pc-sdk.ot-shw-fltr #ot-fltr-cnt{margin:0;height:100%;max-height:none;padding:10px;top:0;width:calc(100% - 20px);position:absolute;right:0;left:0;max-width:none}#onetrust-pc-sdk.ot-shw-fltr .ot-fltr-scrlcnt{max-height:calc(100% - 65px)}}
            #onetrust-consent-sdk #onetrust-pc-sdk,
                #onetrust-consent-sdk #ot-search-cntr,
                #onetrust-consent-sdk #onetrust-pc-sdk .ot-switch.ot-toggle,
                #onetrust-consent-sdk #onetrust-pc-sdk ot-grp-hdr1 .checkbox,
                #onetrust-consent-sdk #onetrust-pc-sdk #ot-pc-title:after
                ,#onetrust-consent-sdk #onetrust-pc-sdk #ot-sel-blk,
                        #onetrust-consent-sdk #onetrust-pc-sdk #ot-fltr-cnt,
                        #onetrust-consent-sdk #onetrust-pc-sdk #ot-anchor {
                    background-color: #FFF;
                }
               
            #onetrust-consent-sdk #onetrust-pc-sdk h3,
                #onetrust-consent-sdk #onetrust-pc-sdk h4,
                #onetrust-consent-sdk #onetrust-pc-sdk h5,
                #onetrust-consent-sdk #onetrust-pc-sdk h6,
                #onetrust-consent-sdk #onetrust-pc-sdk p,
                #onetrust-consent-sdk #onetrust-pc-sdk #ot-ven-lst .ot-ven-opts p,
                #onetrust-consent-sdk #onetrust-pc-sdk #ot-pc-desc,
                #onetrust-consent-sdk #onetrust-pc-sdk #ot-pc-title,
                #onetrust-consent-sdk #onetrust-pc-sdk .ot-li-title,
                #onetrust-consent-sdk #onetrust-pc-sdk .ot-sel-all-hdr span,
                #onetrust-consent-sdk #onetrust-pc-sdk #ot-host-lst .ot-host-info,
                #onetrust-consent-sdk #onetrust-pc-sdk #ot-fltr-modal #modal-header,
                #onetrust-consent-sdk #onetrust-pc-sdk .ot-checkbox label span,
                #onetrust-consent-sdk #onetrust-pc-sdk #ot-pc-lst #ot-sel-blk p,
                #onetrust-consent-sdk #onetrust-pc-sdk #ot-pc-lst #ot-lst-title h3,
                #onetrust-consent-sdk #onetrust-pc-sdk #ot-pc-lst .back-btn-handler p,
                #onetrust-consent-sdk #onetrust-pc-sdk #ot-pc-lst .ot-ven-name,
                #onetrust-consent-sdk #onetrust-pc-sdk #ot-pc-lst #ot-ven-lst .consent-category,
                #onetrust-consent-sdk #onetrust-pc-sdk .ot-leg-btn-container .ot-inactive-leg-btn,
                #onetrust-consent-sdk #onetrust-pc-sdk .ot-label-status,
                #onetrust-consent-sdk #onetrust-pc-sdk .ot-chkbox label span,
                #onetrust-consent-sdk #onetrust-pc-sdk #clear-filters-handler,
                #onetrust-consent-sdk #onetrust-pc-sdk .ot-optout-signal
                {
                    color: #2E2E2E;
                }
             #onetrust-consent-sdk #onetrust-pc-sdk .privacy-notice-link,
                    #onetrust-consent-sdk #onetrust-pc-sdk .ot-pgph-link,
                    #onetrust-consent-sdk #onetrust-pc-sdk .category-vendors-list-handler,
                    #onetrust-consent-sdk #onetrust-pc-sdk .category-vendors-list-handler + a,
                    #onetrust-consent-sdk #onetrust-pc-sdk .category-host-list-handler,
                    #onetrust-consent-sdk #onetrust-pc-sdk .ot-ven-link,
                    #onetrust-consent-sdk #onetrust-pc-sdk .ot-ven-legclaim-link,
                    #onetrust-consent-sdk #onetrust-pc-sdk #ot-host-lst .ot-host-name a,
                    #onetrust-consent-sdk #onetrust-pc-sdk #ot-host-lst .ot-acc-hdr .ot-host-expand,
                    #onetrust-consent-sdk #onetrust-pc-sdk #ot-host-lst .ot-host-info a,
                    #onetrust-consent-sdk #onetrust-pc-sdk #ot-pc-content #ot-pc-desc .ot-link-btn,
                    #onetrust-consent-sdk #onetrust-pc-sdk .ot-vnd-serv .ot-vnd-item .ot-vnd-info a,
                    #onetrust-consent-sdk #onetrust-pc-sdk #ot-lst-cnt .ot-vnd-info a
                    {
                        color: #007398;
                    }
            #onetrust-consent-sdk #onetrust-pc-sdk .category-vendors-list-handler:hover { text-decoration: underline;}
            #onetrust-consent-sdk #onetrust-pc-sdk .ot-acc-grpcntr.ot-acc-txt,
            #onetrust-consent-sdk #onetrust-pc-sdk .ot-acc-txt .ot-subgrp-tgl .ot-switch.ot-toggle
             {
                background-color: #F8F8F8;
            }
             #onetrust-consent-sdk #onetrust-pc-sdk #ot-host-lst .ot-host-info,
                    #onetrust-consent-sdk #onetrust-pc-sdk .ot-acc-txt .ot-ven-dets
                            {
                                background-color: #F8F8F8;
                            }
        #onetrust-consent-sdk #onetrust-pc-sdk
            button:not(#clear-filters-handler):not(.ot-close-icon):not(#filter-btn-handler):not(.ot-remove-objection-handler):not(.ot-obj-leg-btn-handler):not([aria-expanded]):not(.ot-link-btn),
            #onetrust-consent-sdk #onetrust-pc-sdk .ot-leg-btn-container .ot-active-leg-btn {
                background-color: #007398;border-color: #007398;
                color: #FFF;
            }
            #onetrust-consent-sdk #onetrust-pc-sdk .ot-active-menu {
                border-color: #007398;
            }
            
            #onetrust-consent-sdk #onetrust-pc-sdk .ot-leg-btn-container .ot-remove-objection-handler{
                background-color: transparent;
                border: 1px solid transparent;
            }
            #onetrust-consent-sdk #onetrust-pc-sdk .ot-leg-btn-container .ot-inactive-leg-btn {
                background-color: #FFFFFF;
                color: #78808E; border-color: #78808E;
            }
            #onetrust-consent-sdk #onetrust-pc-sdk .ot-tgl input:focus + .ot-switch, .ot-switch .ot-switch-nob, .ot-switch .ot-switch-nob:before,
            #onetrust-pc-sdk .ot-checkbox input[type="checkbox"]:focus + label::before,
            #onetrust-pc-sdk .ot-chkbox input[type="checkbox"]:focus + label::before {
                outline-color: #000000;
                outline-width: 1px;
            }
            #onetrust-pc-sdk .ot-host-item > button:focus, #onetrust-pc-sdk .ot-ven-item > button:focus {
                border: 1px solid #000000;
            }
            #onetrust-consent-sdk #onetrust-pc-sdk *:focus,
            #onetrust-consent-sdk #onetrust-pc-sdk .ot-vlst-cntr > a:focus {
               outline: 1px solid #000000;
            }#onetrust-pc-sdk .ot-vlst-cntr .ot-ext-lnk,  #onetrust-pc-sdk .ot-ven-hdr .ot-ext-lnk{
                    background-image: url('https://cdn.cookielaw.org/logos/static/ot_external_link.svg');
                }
            /*! Extra code to blur out background */
.onetrust-pc-dark-filter{
background:rgba(0,0,0,.5);
z-index:2147483646;
width:100%;
height:100%;
overflow:hidden;
position:fixed;
top:0;
bottom:0;
left:0;
backdrop-filter: initial
}

/*! v6.12.0 2021-01-19 */
div#onetrust-consent-sdk #onetrust-banner-sdk{border-top:2px solid #eb6500!important;outline:1px solid transparent;box-shadow:none;padding:24px}div#onetrust-consent-sdk button{border-radius:0!important;box-shadow:none!important;box-sizing:border-box!important;font-size:20px!important;font-weight:400!important;letter-spacing:0!important;max-width:none!important;white-space:nowrap!important}div#onetrust-consent-sdk button:not(.ot-link-btn){background-color:#007398!important;border:2px solid #007398!important;color:#fff!important;height:48px!important;padding:0 1em!important;width:auto!important}div#onetrust-consent-sdk button:hover{background-color:#fff!important;border-color:#eb6500!important;color:#2e2e2e!important}div#onetrust-consent-sdk button.ot-link-btn{color:#007398!important;font-size:16px!important;text-decoration:underline}div#onetrust-consent-sdk button.ot-link-btn:hover{color:inherit!important;text-decoration-color:#eb6500!important}div#onetrust-consent-sdk a,div#onetrust-pc-sdk a{color:#007398!important;text-decoration:underline!important}div#onetrust-consent-sdk a,div#onetrust-consent-sdk button,div#onetrust-consent-sdk p:hover{opacity:1!important}div#onetrust-consent-sdk a:focus,div#onetrust-consent-sdk button:focus,div#onetrust-consent-sdk input:focus{outline:2px solid #eb6500!important;outline-offset:1px!important}div#onetrust-banner-sdk .ot-sdk-container{padding:0;width:auto}div#onetrust-banner-sdk .ot-sdk-row{align-items:flex-start;box-sizing:border-box;display:flex;flex-direction:column;justify-content:space-between;margin:auto;max-width:1152px}div#onetrust-banner-sdk .ot-sdk-row:after{display:none}div#onetrust-banner-sdk #onetrust-group-container,div#onetrust-banner-sdk.ot-bnr-flift:not(.ot-iab-2) #onetrust-group-container,div#onetrust-banner-sdk:not(.ot-iab-2) #onetrust-group-container{flex-grow:1;width:auto}div#onetrust-banner-sdk #onetrust-policy,div#onetrust-banner-sdk.ot-bnr-flift #onetrust-policy{margin:0;overflow:visible}div#onetrust-banner-sdk.ot-bnr-flift #onetrust-policy-text,div#onetrust-consent-sdk #onetrust-policy-text{font-size:16px;line-height:24px;max-width:44em;margin:0}div#onetrust-consent-sdk #onetrust-policy-text a[href]{font-weight:400;margin-left:8px}div#onetrust-banner-sdk #onetrust-button-group-parent{flex:0 0 auto;margin:32px 0 0;width:100%}div#onetrust-banner-sdk #onetrust-button-group{display:flex;flex-direction:row;flex-wrap:wrap;justify-content:flex-end;margin:-8px}div#onetrust-banner-sdk .banner-actions-container{display:flex;flex:1 0 auto}div#onetrust-banner-sdk.ot-buttons-fw:not(.ot-iab-2) #onetrust-button-group button:last-of-type,div#onetrust-consent-sdk #onetrust-accept-btn-handler,div#onetrust-consent-sdk #onetrust-pc-btn-handler{flex:1 0 auto;margin:8px;width:auto}div#onetrust-consent-sdk #onetrust-pc-btn-handler{background-color:#fff!important;color:inherit!important}div#onetrust-banner-sdk #onetrust-close-btn-container{display:none}@media only screen and (min-width:556px){div#onetrust-consent-sdk #onetrust-banner-sdk{padding:40px}div#onetrust-banner-sdk #onetrust-policy{margin:0 40px 0 0}div#onetrust-banner-sdk .ot-sdk-row{align-items:center;flex-direction:row}div#onetrust-banner-sdk #onetrust-button-group-parent,div#onetrust-banner-sdk.ot-bnr-flift:not(.ot-iab-2) #onetrust-button-group-parent,div#onetrust-banner-sdk:not(.ot-iab-2) #onetrust-button-group-parent{margin:0;padding:0;width:auto}div#onetrust-banner-sdk #onetrust-button-group,div#onetrust-banner-sdk.ot-buttons-fw:not(.ot-iab-2) #onetrust-button-group{align-items:stretch;flex-direction:column-reverse;margin:0}div#onetrust-consent-sdk #onetrust-accept-btn-handler,div#onetrust-consent-sdk #onetrust-pc-btn-handler{flex:1 0 auto}}@media only screen and (min-width:768px){div#onetrust-banner-sdk #onetrust-policy{margin:0 48px 0 0}div#onetrust-consent-sdk #onetrust-banner-sdk{padding:48px}}div#onetrust-consent-sdk #onetrust-pc-sdk h5{font-size:16px;line-height:24px}div#onetrust-consent-sdk #onetrust-pc-sdk p,div#onetrust-pc-sdk #ot-pc-desc,div#onetrust-pc-sdk .category-host-list-handler,div#onetrust-pc-sdk .ot-accordion-layout .ot-cat-header{font-size:16px;font-weight:400;line-height:24px}div#onetrust-consent-sdk a:hover,div#onetrust-pc-sdk a:hover{color:inherit!important;text-decoration-color:#eb6500!important}div#onetrust-pc-sdk{border-radius:0;bottom:0;height:auto;left:0;margin:auto;max-width:100%;overflow:hidden;right:0;top:0;width:512px;max-height:800px}div#onetrust-pc-sdk .ot-pc-header{display:none}div#onetrust-pc-sdk #ot-pc-content{overscroll-behavior:contain;padding:0 12px 0 24px;margin:16px 4px 0 0;top:0;right:16px;left:0;width:auto}div#onetrust-pc-sdk #ot-category-title,div#onetrust-pc-sdk #ot-pc-title{font-size:24px;font-weight:400;line-height:32px;margin:0 0 16px}div#onetrust-pc-sdk #ot-pc-desc{padding:0}div#onetrust-pc-sdk #ot-pc-desc a{display:inline}div#onetrust-pc-sdk #accept-recommended-btn-handler{display:none!important}div#onetrust-pc-sdk input[type=checkbox]:focus+.ot-acc-hdr{outline:2px solid #eb6500;outline-offset:-1px;transition:none}div#onetrust-pc-sdk .ot-accordion-layout.ot-cat-item{border-width:0 0 2px}div#onetrust-pc-sdk .ot-accordion-layout.ot-cat-item:first-of-type{border-width:2px 0}div#onetrust-pc-sdk .ot-accordion-layout .ot-acc-hdr{padding:8px 0;width:100%}div#onetrust-pc-sdk .ot-plus-minus{transform:translateY(2px)}div#onetrust-pc-sdk .ot-accordion-layout.ot-cat-item>button{background:0 0!important;border:0!important;height:44px!important;max-width:none!important;width:calc(100% - 48px)!important}div#onetrust-consent-sdk #onetrust-pc-sdk h5{font-weight:700}div#onetrust-pc-sdk .ot-accordion-layout .ot-hlst-cntr{padding:0}div#onetrust-pc-sdk .ot-accordion-layout.ot-cat-item .ot-acc-grpdesc{padding:0;width:100%}div#onetrust-pc-sdk .ot-acc-grpcntr .ot-subgrp-cntr{border:0;padding:0}div#onetrust-pc-sdk .ot-subgrp-cntr ul.ot-subgrps li.ot-subgrp{margin:0}div#onetrust-pc-sdk .ot-always-active-group .ot-cat-header{width:calc(100% - 160px)}#onetrust-pc-sdk .ot-accordion-layout .ot-cat-header{width:calc(100% - 88px)}div#onetrust-pc-sdk .ot-accordion-layout h4~.ot-always-active{color:inherit;font-size:12px;font-weight:400;line-height:1.5;padding-right:48px}div#onetrust-pc-sdk .ot-accordion-layout h4~.ot-always-active:before{border-radius:12px;position:absolute;right:0;top:0;content:'';background:#fff;border:2px solid #939393;box-sizing:border-box;height:20px;width:40px}div#onetrust-pc-sdk .ot-accordion-layout h4~.ot-always-active:after{border-radius:50%;position:absolute;right:5px;top:4px;content:'';background-color:#eb6500;height:12px;width:12px}div#onetrust-pc-sdk .ot-accordion-layout h4~.ot-always-active,div#onetrust-pc-sdk .ot-accordion-layout h4~.ot-tgl{right:2px}div#onetrust-pc-sdk .ot-switch{display:block;height:20px;width:40px}div#onetrust-pc-sdk .ot-tgl input+.ot-switch .ot-switch-nob,div#onetrust-pc-sdk .ot-tgl input:checked+.ot-switch .ot-switch-nob{background:#fff;border:2px solid #939393;box-sizing:border-box;height:20px;width:40px}div#onetrust-pc-sdk .ot-tgl input+.ot-switch .ot-switch-nob:before{background-color:#737373;height:8px;left:4px;top:4px;width:8px}div#onetrust-pc-sdk .ot-tgl input:checked+.ot-switch .ot-switch-nob:before{background-color:#eb6500;height:12px;left:0;top:2px;width:12px}div#onetrust-pc-sdk .ot-tgl input:focus+.ot-switch .ot-switch-nob{box-shadow:0 0;outline:2px solid #eb6500!important;outline-offset:1px;transition:none}div#onetrust-consent-sdk #onetrust-pc-sdk .ot-acc-grpcntr.ot-acc-txt{background-color:transparent;padding-left:3px}div#onetrust-pc-sdk .ot-accordion-layout .ot-hlst-cntr,div#onetrust-pc-sdk .ot-accordion-layout .ot-vlst-cntr{overflow:visible;width:100%}div#onetrust-pc-sdk .ot-pc-footer{border-top:0 solid}div#onetrust-pc-sdk .ot-btn-container{padding-top:24px;text-align:center}div#onetrust-pc-sdk .ot-pc-footer button{margin:8px 0;background-color:#fff}div#onetrust-pc-sdk .ot-pc-footer-logo{background-color:#fff}div#onetrust-pc-sdk #ot-lst-title span{font-size:24px;font-weight:400;line-height:32px}div#onetrust-pc-sdk #ot-host-lst .ot-host-desc,div#onetrust-pc-sdk #ot-host-lst .ot-host-expand,div#onetrust-pc-sdk #ot-host-lst .ot-host-name,div#onetrust-pc-sdk #ot-host-lst .ot-host-name a,div#onetrust-pc-sdk .back-btn-handler,div#onetrust-pc-sdk .ot-host-opt li>div div{font-size:16px;font-weight:400;line-height:24px}div#onetrust-pc-sdk #ot-host-lst .ot-acc-txt{width:100%}div#onetrust-pc-sdk #ot-pc-lst{top:0}div#onetrust-pc-sdk .back-btn-handler{text-decoration:none!important}div#onetrust-pc-sdk #filter-btn-handler:hover svg{filter:invert(1)}div#onetrust-pc-sdk .back-btn-handler svg{width:16px;height:16px}div#onetrust-pc-sdk .ot-host-item>button{background:0 0!important;border:0!important;height:66px!important;max-width:none!important;width:calc(100% - 5px)!important;transform:translate(2px,2px)}div#onetrust-pc-sdk .ot-host-item{border-bottom:2px solid #b9b9b9;padding:0}div#onetrust-pc-sdk .ot-host-item .ot-acc-hdr{margin:0 0 -6px;padding:8px 0}div#onetrust-pc-sdk ul li:first-child{border-top:2px solid #b9b9b9}div#onetrust-pc-sdk .ot-host-item .ot-plus-minus{margin:0 8px 0 0}div#onetrust-pc-sdk .ot-search-cntr{width:calc(100% - 48px)}div#onetrust-pc-sdk .ot-host-opt .ot-host-info{background-color:transparent}div#onetrust-pc-sdk .ot-host-opt li>div div{padding:0}div#onetrust-pc-sdk #vendor-search-handler{border-radius:0;border-color:#939393;border-style:solid;border-width:2px 0 2px 2px;font-size:20px;height:48px;margin:0}div#onetrust-pc-sdk #ot-pc-hdr{margin-left:24px}div#onetrust-pc-sdk .ot-lst-subhdr{width:calc(100% - 24px)}div#onetrust-pc-sdk .ot-lst-subhdr svg{right:0;top:8px}div#onetrust-pc-sdk .ot-fltr-cntr{box-sizing:border-box;right:0;width:48px}div#onetrust-pc-sdk #filter-btn-handler{width:48px!important;padding:8px!important}div#onetrust-consent-sdk #onetrust-pc-sdk #clear-filters-handler,div#onetrust-pc-sdk button#filter-apply-handler,div#onetrust-pc-sdk button#filter-cancel-handler{height:2em!important;padding-left:14px!important;padding-right:14px!important}div#onetrust-pc-sdk #ot-fltr-cnt{box-shadow:0 0;border:1px solid #8e8e8e;border-radius:0}div#onetrust-pc-sdk .ot-fltr-scrlcnt{max-height:calc(100% - 80px)}div#onetrust-pc-sdk #ot-fltr-modal{max-height:400px}div#onetrust-pc-sdk .ot-fltr-opt{margin-bottom:16px}div#onetrust-pc-sdk #ot-lst-cnt{margin-left:24px;width:calc(100% - 48px)}div#onetrust-pc-sdk #ot-anchor{display:none!important}
/*! Extra code to blur our background */
.onetrust-pc-dark-filter{
backdrop-filter: blur(3px)
}
.ot-sdk-cookie-policy{font-family:inherit;font-size:16px}.ot-sdk-cookie-policy.otRelFont{font-size:1rem}.ot-sdk-cookie-policy h3,.ot-sdk-cookie-policy h4,.ot-sdk-cookie-policy h6,.ot-sdk-cookie-policy p,.ot-sdk-cookie-policy li,.ot-sdk-cookie-policy a,.ot-sdk-cookie-policy th,.ot-sdk-cookie-policy #cookie-policy-description,.ot-sdk-cookie-policy .ot-sdk-cookie-policy-group,.ot-sdk-cookie-policy #cookie-policy-title{color:dimgray}.ot-sdk-cookie-policy #cookie-policy-description{margin-bottom:1em}.ot-sdk-cookie-policy h4{font-size:1.2em}.ot-sdk-cookie-policy h6{font-size:1em;margin-top:2em}.ot-sdk-cookie-policy th{min-width:75px}.ot-sdk-cookie-policy a,.ot-sdk-cookie-policy a:hover{background:#fff}.ot-sdk-cookie-policy thead{background-color:#f6f6f4;font-weight:bold}.ot-sdk-cookie-policy .ot-mobile-border{display:none}.ot-sdk-cookie-policy section{margin-bottom:2em}.ot-sdk-cookie-policy table{border-collapse:inherit}#ot-sdk-cookie-policy-v2.ot-sdk-cookie-policy{font-family:inherit;font-size:1rem}#ot-sdk-cookie-policy-v2.ot-sdk-cookie-policy h3,#ot-sdk-cookie-policy-v2.ot-sdk-cookie-policy h4,#ot-sdk-cookie-policy-v2.ot-sdk-cookie-policy h6,#ot-sdk-cookie-policy-v2.ot-sdk-cookie-policy p,#ot-sdk-cookie-policy-v2.ot-sdk-cookie-policy li,#ot-sdk-cookie-policy-v2.ot-sdk-cookie-policy a,#ot-sdk-cookie-policy-v2.ot-sdk-cookie-policy th,#ot-sdk-cookie-policy-v2.ot-sdk-cookie-policy #cookie-policy-description,#ot-sdk-cookie-policy-v2.ot-sdk-cookie-policy .ot-sdk-cookie-policy-group,#ot-sdk-cookie-policy-v2.ot-sdk-cookie-policy #cookie-policy-title{color:dimgray}#ot-sdk-cookie-policy-v2.ot-sdk-cookie-policy #cookie-policy-description{margin-bottom:1em}#ot-sdk-cookie-policy-v2.ot-sdk-cookie-policy .ot-sdk-subgroup{margin-left:1.5em}#ot-sdk-cookie-policy-v2.ot-sdk-cookie-policy #cookie-policy-description,#ot-sdk-cookie-policy-v2.ot-sdk-cookie-policy .ot-sdk-cookie-policy-group-desc,#ot-sdk-cookie-policy-v2.ot-sdk-cookie-policy .ot-table-header,#ot-sdk-cookie-policy-v2.ot-sdk-cookie-policy a,#ot-sdk-cookie-policy-v2.ot-sdk-cookie-policy span,#ot-sdk-cookie-policy-v2.ot-sdk-cookie-policy td{font-size:.9em}#ot-sdk-cookie-policy-v2.ot-sdk-cookie-policy td span,#ot-sdk-cookie-policy-v2.ot-sdk-cookie-policy td a{font-size:inherit}#ot-sdk-cookie-policy-v2.ot-sdk-cookie-policy .ot-sdk-cookie-policy-group{font-size:1em;margin-bottom:.6em}#ot-sdk-cookie-policy-v2.ot-sdk-cookie-policy .ot-sdk-cookie-policy-title{margin-bottom:1.2em}#ot-sdk-cookie-policy-v2.ot-sdk-cookie-policy>section{margin-bottom:1em}#ot-sdk-cookie-policy-v2.ot-sdk-cookie-policy th{min-width:75px}#ot-sdk-cookie-policy-v2.ot-sdk-cookie-policy a,#ot-sdk-cookie-policy-v2.ot-sdk-cookie-policy a:hover{background:#fff}#ot-sdk-cookie-policy-v2.ot-sdk-cookie-policy thead{background-color:#f6f6f4;font-weight:bold}#ot-sdk-cookie-policy-v2.ot-sdk-cookie-policy .ot-mobile-border{display:none}#ot-sdk-cookie-policy-v2.ot-sdk-cookie-policy section{margin-bottom:2em}#ot-sdk-cookie-policy-v2.ot-sdk-cookie-policy .ot-sdk-subgroup ul li{list-style:disc;margin-left:1.5em}#ot-sdk-cookie-policy-v2.ot-sdk-cookie-policy .ot-sdk-subgroup ul li h4{display:inline-block}#ot-sdk-cookie-policy-v2.ot-sdk-cookie-policy table{border-collapse:inherit;margin:auto;border:1px solid #d7d7d7;border-radius:5px;border-spacing:initial;width:100%;overflow:hidden}#ot-sdk-cookie-policy-v2.ot-sdk-cookie-policy table th,#ot-sdk-cookie-policy-v2.ot-sdk-cookie-policy table td{border-bottom:1px solid #d7d7d7;border-right:1px solid #d7d7d7}#ot-sdk-cookie-policy-v2.ot-sdk-cookie-policy table tr:last-child td{border-bottom:0px}#ot-sdk-cookie-policy-v2.ot-sdk-cookie-policy table tr th:last-child,#ot-sdk-cookie-policy-v2.ot-sdk-cookie-policy table tr td:last-child{border-right:0px}#ot-sdk-cookie-policy-v2.ot-sdk-cookie-policy table .ot-host,#ot-sdk-cookie-policy-v2.ot-sdk-cookie-policy table .ot-cookies-type{width:25%}.ot-sdk-cookie-policy[dir=rtl]{text-align:left}#ot-sdk-cookie-policy h3{font-size:1.5em}@media only screen and (max-width: 530px){.ot-sdk-cookie-policy:not(#ot-sdk-cookie-policy-v2) table,.ot-sdk-cookie-policy:not(#ot-sdk-cookie-policy-v2) thead,.ot-sdk-cookie-policy:not(#ot-sdk-cookie-policy-v2) tbody,.ot-sdk-cookie-policy:not(#ot-sdk-cookie-policy-v2) th,.ot-sdk-cookie-policy:not(#ot-sdk-cookie-policy-v2) td,.ot-sdk-cookie-policy:not(#ot-sdk-cookie-policy-v2) tr{display:block}.ot-sdk-cookie-policy:not(#ot-sdk-cookie-policy-v2) thead tr{position:absolute;top:-9999px;left:-9999px}.ot-sdk-cookie-policy:not(#ot-sdk-cookie-policy-v2) tr{margin:0 0 1em 0}.ot-sdk-cookie-policy:not(#ot-sdk-cookie-policy-v2) tr:nth-child(odd),.ot-sdk-cookie-policy:not(#ot-sdk-cookie-policy-v2) tr:nth-child(odd) a{background:#f6f6f4}.ot-sdk-cookie-policy:not(#ot-sdk-cookie-policy-v2) td{border:none;border-bottom:1px solid #eee;position:relative;padding-left:50%}.ot-sdk-cookie-policy:not(#ot-sdk-cookie-policy-v2) td:before{position:absolute;height:100%;left:6px;width:40%;padding-right:10px}.ot-sdk-cookie-policy:not(#ot-sdk-cookie-policy-v2) .ot-mobile-border{display:inline-block;background-color:#e4e4e4;position:absolute;height:100%;top:0;left:45%;width:2px}.ot-sdk-cookie-policy:not(#ot-sdk-cookie-policy-v2) td:before{content:attr(data-label);font-weight:bold}.ot-sdk-cookie-policy:not(#ot-sdk-cookie-policy-v2) li{word-break:break-word;word-wrap:break-word}#ot-sdk-cookie-policy-v2.ot-sdk-cookie-policy table{overflow:hidden}#ot-sdk-cookie-policy-v2.ot-sdk-cookie-policy table td{border:none;border-bottom:1px solid #d7d7d7}#ot-sdk-cookie-policy-v2.ot-sdk-cookie-policy table,#ot-sdk-cookie-policy-v2.ot-sdk-cookie-policy thead,#ot-sdk-cookie-policy-v2.ot-sdk-cookie-policy tbody,#ot-sdk-cookie-policy-v2.ot-sdk-cookie-policy th,#ot-sdk-cookie-policy-v2.ot-sdk-cookie-policy td,#ot-sdk-cookie-policy-v2.ot-sdk-cookie-policy tr{display:block}#ot-sdk-cookie-policy-v2.ot-sdk-cookie-policy table .ot-host,#ot-sdk-cookie-policy-v2.ot-sdk-cookie-policy table .ot-cookies-type{width:auto}#ot-sdk-cookie-policy-v2.ot-sdk-cookie-policy tr{margin:0 0 1em 0}#ot-sdk-cookie-policy-v2.ot-sdk-cookie-policy td:before{height:100%;width:40%;padding-right:10px}#ot-sdk-cookie-policy-v2.ot-sdk-cookie-policy td:before{content:attr(data-label);font-weight:bold}#ot-sdk-cookie-policy-v2.ot-sdk-cookie-policy li{word-break:break-word;word-wrap:break-word}#ot-sdk-cookie-policy-v2.ot-sdk-cookie-policy thead tr{position:absolute;top:-9999px;left:-9999px;z-index:-9999}#ot-sdk-cookie-policy-v2.ot-sdk-cookie-policy table tr:last-child td{border-bottom:1px solid #d7d7d7;border-right:0px}#ot-sdk-cookie-policy-v2.ot-sdk-cookie-policy table tr:last-child td:last-child{border-bottom:0px}}
                
                    #ot-sdk-cookie-policy-v2.ot-sdk-cookie-policy h5,
                    #ot-sdk-cookie-policy-v2.ot-sdk-cookie-policy h6,
                    #ot-sdk-cookie-policy-v2.ot-sdk-cookie-policy li,
                    #ot-sdk-cookie-policy-v2.ot-sdk-cookie-policy p,
                    #ot-sdk-cookie-policy-v2.ot-sdk-cookie-policy a,
                    #ot-sdk-cookie-policy-v2.ot-sdk-cookie-policy span,
                    #ot-sdk-cookie-policy-v2.ot-sdk-cookie-policy td,
                    #ot-sdk-cookie-policy-v2.ot-sdk-cookie-policy #cookie-policy-description {
                        color: #696969;
                    }
                    #ot-sdk-cookie-policy-v2.ot-sdk-cookie-policy th {
                        color: #696969;
                    }
                    #ot-sdk-cookie-policy-v2.ot-sdk-cookie-policy .ot-sdk-cookie-policy-group {
                        color: #696969;
                    }
                    
                    #ot-sdk-cookie-policy-v2.ot-sdk-cookie-policy #cookie-policy-title {
                            color: #696969;
                        }
                    
            
                    #ot-sdk-cookie-policy-v2.ot-sdk-cookie-policy table th {
                            background-color: #F8F8F8;
                        }
                    
            .ot-floating-button__front{background-image:url('https://cdn.cookielaw.org/logos/static/ot_persistent_cookie_icon.png')}</style><link type="text/css" rel="stylesheet" href="https://pendo-static-5661679399600128.storage.googleapis.com/guide.-323232.1721046486120.css" id="_pendo-css_"><style type="text/css" scoped="scoped" class=" pendo-style-D_T2uHq_M1r-XQq8htU6Z3GjHfE" style="white-space: pre-wrap;"></style><style type="text/css">.MathJax_SVG_Display {text-align: center; margin: 1em 0em; position: relative; display: block!important; text-indent: 0; max-width: none; max-height: none; min-width: 0; min-height: 0; width: 100%}
.MathJax_SVG .MJX-monospace {font-family: monospace}
.MathJax_SVG .MJX-sans-serif {font-family: sans-serif}
#MathJax_SVG_Tooltip {background-color: InfoBackground; color: InfoText; border: 1px solid black; box-shadow: 2px 2px 5px #AAAAAA; -webkit-box-shadow: 2px 2px 5px #AAAAAA; -moz-box-shadow: 2px 2px 5px #AAAAAA; -khtml-box-shadow: 2px 2px 5px #AAAAAA; padding: 3px 4px; z-index: 401; position: absolute; left: 0; top: 0; width: auto; height: auto; display: none}
.MathJax_SVG {display: inline; font-style: normal; font-weight: normal; line-height: normal; font-size: 100%; font-size-adjust: none; text-indent: 0; text-align: left; text-transform: none; letter-spacing: normal; word-spacing: normal; word-wrap: normal; white-space: nowrap; float: none; direction: ltr; max-width: none; max-height: none; min-width: 0; min-height: 0; border: 0; padding: 0; margin: 0}
.MathJax_SVG * {transition: none; -webkit-transition: none; -moz-transition: none; -ms-transition: none; -o-transition: none}
.MathJax_SVG > div {display: inline-block}
.mjx-svg-href {fill: blue; stroke: blue}
.MathJax_SVG_Processing {visibility: hidden; position: absolute; top: 0; left: 0; width: 0; height: 0; overflow: hidden; display: block!important}
.MathJax_SVG_Processed {display: none!important}
.MathJax_SVG_test {font-style: normal; font-weight: normal; font-size: 100%; font-size-adjust: none; text-indent: 0; text-transform: none; letter-spacing: normal; word-spacing: normal; overflow: hidden; height: 1px}
.MathJax_SVG_test.mjx-test-display {display: table!important}
.MathJax_SVG_test.mjx-test-inline {display: inline!important; margin-right: -1px}
.MathJax_SVG_test.mjx-test-default {display: block!important; clear: both}
.MathJax_SVG_ex_box {display: inline-block!important; position: absolute; overflow: hidden; min-height: 0; max-height: none; padding: 0; border: 0; margin: 0; width: 1px; height: 60ex}
.mjx-test-inline .MathJax_SVG_left_box {display: inline-block; width: 0; float: left}
.mjx-test-inline .MathJax_SVG_right_box {display: inline-block; width: 0; float: right}
.mjx-test-display .MathJax_SVG_right_box {display: table-cell!important; width: 10000em!important; min-width: 0; max-width: none; padding: 0; border: 0; margin: 0}
</style></head>
<body data-sd-ui-layer-boundary="true" class="toolbar-stuck" style=""><div style="visibility: hidden; overflow: hidden; position: absolute; top: 0px; height: 1px; width: auto; padding: 0px; border: 0px; margin: 0px; text-align: left; text-indent: 0px; text-transform: none; line-height: normal; letter-spacing: normal; word-spacing: normal;"><div id="MathJax_SVG_Hidden"></div><svg><defs id="MathJax_SVG_glyphs"><path stroke-width="1" id="MJMATHI-46" d="M48 1Q31 1 31 11Q31 13 34 25Q38 41 42 43T65 46Q92 46 125 49Q139 52 144 61Q146 66 215 342T285 622Q285 629 281 629Q273 632 228 634H197Q191 640 191 642T193 659Q197 676 203 680H742Q749 676 749 669Q749 664 736 557T722 447Q720 440 702 440H690Q683 445 683 453Q683 454 686 477T689 530Q689 560 682 579T663 610T626 626T575 633T503 634H480Q398 633 393 631Q388 629 386 623Q385 622 352 492L320 363H375Q378 363 398 363T426 364T448 367T472 374T489 386Q502 398 511 419T524 457T529 475Q532 480 548 480H560Q567 475 567 470Q567 467 536 339T502 207Q500 200 482 200H470Q463 206 463 212Q463 215 468 234T473 274Q473 303 453 310T364 317H309L277 190Q245 66 245 60Q245 46 334 46H359Q365 40 365 39T363 19Q359 6 353 0H336Q295 2 185 2Q120 2 86 2T48 1Z"></path><path stroke-width="1" id="MJMATHI-70" d="M23 287Q24 290 25 295T30 317T40 348T55 381T75 411T101 433T134 442Q209 442 230 378L240 387Q302 442 358 442Q423 442 460 395T497 281Q497 173 421 82T249 -10Q227 -10 210 -4Q199 1 187 11T168 28L161 36Q160 35 139 -51T118 -138Q118 -144 126 -145T163 -148H188Q194 -155 194 -157T191 -175Q188 -187 185 -190T172 -194Q170 -194 161 -194T127 -193T65 -192Q-5 -192 -24 -194H-32Q-39 -187 -39 -183Q-37 -156 -26 -148H-6Q28 -147 33 -136Q36 -130 94 103T155 350Q156 355 156 364Q156 405 131 405Q109 405 94 377T71 316T59 280Q57 278 43 278H29Q23 284 23 287ZM178 102Q200 26 252 26Q282 26 310 49T356 107Q374 141 392 215T411 325V331Q411 405 350 405Q339 405 328 402T306 393T286 380T269 365T254 350T243 336T235 326L232 322Q232 321 229 308T218 264T204 212Q178 106 178 102Z"></path><path stroke-width="1" id="MJMATHI-6D" d="M21 287Q22 293 24 303T36 341T56 388T88 425T132 442T175 435T205 417T221 395T229 376L231 369Q231 367 232 367L243 378Q303 442 384 442Q401 442 415 440T441 433T460 423T475 411T485 398T493 385T497 373T500 364T502 357L510 367Q573 442 659 442Q713 442 746 415T780 336Q780 285 742 178T704 50Q705 36 709 31T724 26Q752 26 776 56T815 138Q818 149 821 151T837 153Q857 153 857 145Q857 144 853 130Q845 101 831 73T785 17T716 -10Q669 -10 648 17T627 73Q627 92 663 193T700 345Q700 404 656 404H651Q565 404 506 303L499 291L466 157Q433 26 428 16Q415 -11 385 -11Q372 -11 364 -4T353 8T350 18Q350 29 384 161L420 307Q423 322 423 345Q423 404 379 404H374Q288 404 229 303L222 291L189 157Q156 26 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 112 181Q151 335 151 342Q154 357 154 369Q154 405 129 405Q107 405 92 377T69 316T57 280Q55 278 41 278H27Q21 284 21 287Z"></path><path stroke-width="1" id="MJMAIN-73" d="M295 316Q295 356 268 385T190 414Q154 414 128 401Q98 382 98 349Q97 344 98 336T114 312T157 287Q175 282 201 278T245 269T277 256Q294 248 310 236T342 195T359 133Q359 71 321 31T198 -10H190Q138 -10 94 26L86 19L77 10Q71 4 65 -1L54 -11H46H42Q39 -11 33 -5V74V132Q33 153 35 157T45 162H54Q66 162 70 158T75 146T82 119T101 77Q136 26 198 26Q295 26 295 104Q295 133 277 151Q257 175 194 187T111 210Q75 227 54 256T33 318Q33 357 50 384T93 424T143 442T187 447H198Q238 447 268 432L283 424L292 431Q302 440 314 448H322H326Q329 448 335 442V310L329 304H301Q295 310 295 316Z"></path><path stroke-width="1" id="MJMATHI-72" d="M21 287Q22 290 23 295T28 317T38 348T53 381T73 411T99 433T132 442Q161 442 183 430T214 408T225 388Q227 382 228 382T236 389Q284 441 347 441H350Q398 441 422 400Q430 381 430 363Q430 333 417 315T391 292T366 288Q346 288 334 299T322 328Q322 376 378 392Q356 405 342 405Q286 405 239 331Q229 315 224 298T190 165Q156 25 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 114 189T154 366Q154 405 128 405Q107 405 92 377T68 316T57 280Q55 278 41 278H27Q21 284 21 287Z"></path><path stroke-width="1" id="MJMATHI-65" d="M39 168Q39 225 58 272T107 350T174 402T244 433T307 442H310Q355 442 388 420T421 355Q421 265 310 237Q261 224 176 223Q139 223 138 221Q138 219 132 186T125 128Q125 81 146 54T209 26T302 45T394 111Q403 121 406 121Q410 121 419 112T429 98T420 82T390 55T344 24T281 -1T205 -11Q126 -11 83 42T39 168ZM373 353Q367 405 305 405Q272 405 244 391T199 357T170 316T154 280T149 261Q149 260 169 260Q282 260 327 284T373 353Z"></path><path stroke-width="1" id="MJMATHI-66" d="M118 -162Q120 -162 124 -164T135 -167T147 -168Q160 -168 171 -155T187 -126Q197 -99 221 27T267 267T289 382V385H242Q195 385 192 387Q188 390 188 397L195 425Q197 430 203 430T250 431Q298 431 298 432Q298 434 307 482T319 540Q356 705 465 705Q502 703 526 683T550 630Q550 594 529 578T487 561Q443 561 443 603Q443 622 454 636T478 657L487 662Q471 668 457 668Q445 668 434 658T419 630Q412 601 403 552T387 469T380 433Q380 431 435 431Q480 431 487 430T498 424Q499 420 496 407T491 391Q489 386 482 386T428 385H372L349 263Q301 15 282 -47Q255 -132 212 -173Q175 -205 139 -205Q107 -205 81 -186T55 -132Q55 -95 76 -78T118 -61Q162 -61 162 -103Q162 -122 151 -136T127 -157L118 -162Z"></path><path stroke-width="1" id="MJMATHI-69" d="M184 600Q184 624 203 642T247 661Q265 661 277 649T290 619Q290 596 270 577T226 557Q211 557 198 567T184 600ZM21 287Q21 295 30 318T54 369T98 420T158 442Q197 442 223 419T250 357Q250 340 236 301T196 196T154 83Q149 61 149 51Q149 26 166 26Q175 26 185 29T208 43T235 78T260 137Q263 149 265 151T282 153Q302 153 302 143Q302 135 293 112T268 61T223 11T161 -11Q129 -11 102 10T74 74Q74 91 79 106T122 220Q160 321 166 341T173 380Q173 404 156 404H154Q124 404 99 371T61 287Q60 286 59 284T58 281T56 279T53 278T49 278T41 278H27Q21 284 21 287Z"></path><path stroke-width="1" id="MJMATHI-6E" d="M21 287Q22 293 24 303T36 341T56 388T89 425T135 442Q171 442 195 424T225 390T231 369Q231 367 232 367L243 378Q304 442 382 442Q436 442 469 415T503 336T465 179T427 52Q427 26 444 26Q450 26 453 27Q482 32 505 65T540 145Q542 153 560 153Q580 153 580 145Q580 144 576 130Q568 101 554 73T508 17T439 -10Q392 -10 371 17T350 73Q350 92 386 193T423 345Q423 404 379 404H374Q288 404 229 303L222 291L189 157Q156 26 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 112 180T152 343Q153 348 153 366Q153 405 129 405Q91 405 66 305Q60 285 60 284Q58 278 41 278H27Q21 284 21 287Z"></path><path stroke-width="1" id="MJMAIN-3D" d="M56 347Q56 360 70 367H707Q722 359 722 347Q722 336 708 328L390 327H72Q56 332 56 347ZM56 153Q56 168 72 173H708Q722 163 722 153Q722 140 707 133H70Q56 140 56 153Z"></path><path stroke-width="1" id="MJMATHI-53" d="M308 24Q367 24 416 76T466 197Q466 260 414 284Q308 311 278 321T236 341Q176 383 176 462Q176 523 208 573T273 648Q302 673 343 688T407 704H418H425Q521 704 564 640Q565 640 577 653T603 682T623 704Q624 704 627 704T632 705Q645 705 645 698T617 577T585 459T569 456Q549 456 549 465Q549 471 550 475Q550 478 551 494T553 520Q553 554 544 579T526 616T501 641Q465 662 419 662Q362 662 313 616T263 510Q263 480 278 458T319 427Q323 425 389 408T456 390Q490 379 522 342T554 242Q554 216 546 186Q541 164 528 137T492 78T426 18T332 -20Q320 -22 298 -22Q199 -22 144 33L134 44L106 13Q83 -14 78 -18T65 -22Q52 -22 52 -14Q52 -11 110 221Q112 227 130 227H143Q149 221 149 216Q149 214 148 207T144 186T142 153Q144 114 160 87T203 47T255 29T308 24Z"></path><path stroke-width="1" id="MJMATHI-67" d="M311 43Q296 30 267 15T206 0Q143 0 105 45T66 160Q66 265 143 353T314 442Q361 442 401 394L404 398Q406 401 409 404T418 412T431 419T447 422Q461 422 470 413T480 394Q480 379 423 152T363 -80Q345 -134 286 -169T151 -205Q10 -205 10 -137Q10 -111 28 -91T74 -71Q89 -71 102 -80T116 -111Q116 -121 114 -130T107 -144T99 -154T92 -162L90 -164H91Q101 -167 151 -167Q189 -167 211 -155Q234 -144 254 -122T282 -75Q288 -56 298 -13Q311 35 311 43ZM384 328L380 339Q377 350 375 354T369 368T359 382T346 393T328 402T306 405Q262 405 221 352Q191 313 171 233T151 117Q151 38 213 38Q269 38 323 108L331 118L384 328Z"></path><path stroke-width="1" id="MJMATHI-6F" d="M201 -11Q126 -11 80 38T34 156Q34 221 64 279T146 380Q222 441 301 441Q333 441 341 440Q354 437 367 433T402 417T438 387T464 338T476 268Q476 161 390 75T201 -11ZM121 120Q121 70 147 48T206 26Q250 26 289 58T351 142Q360 163 374 216T388 308Q388 352 370 375Q346 405 306 405Q243 405 195 347Q158 303 140 230T121 120Z"></path><path stroke-width="1" id="MJMATHI-64" d="M366 683Q367 683 438 688T511 694Q523 694 523 686Q523 679 450 384T375 83T374 68Q374 26 402 26Q411 27 422 35Q443 55 463 131Q469 151 473 152Q475 153 483 153H487H491Q506 153 506 145Q506 140 503 129Q490 79 473 48T445 8T417 -8Q409 -10 393 -10Q359 -10 336 5T306 36L300 51Q299 52 296 50Q294 48 292 46Q233 -10 172 -10Q117 -10 75 30T33 157Q33 205 53 255T101 341Q148 398 195 420T280 442Q336 442 364 400Q369 394 369 396Q370 400 396 505T424 616Q424 629 417 632T378 637H357Q351 643 351 645T353 664Q358 683 366 683ZM352 326Q329 405 277 405Q242 405 210 374T160 293Q131 214 119 129Q119 126 119 118T118 106Q118 61 136 44T179 26Q233 26 290 98L298 109L352 326Z"></path><path stroke-width="1" id="MJMAIN-28" d="M94 250Q94 319 104 381T127 488T164 576T202 643T244 695T277 729T302 750H315H319Q333 750 333 741Q333 738 316 720T275 667T226 581T184 443T167 250T184 58T225 -81T274 -167T316 -220T333 -241Q333 -250 318 -250H315H302L274 -226Q180 -141 137 -14T94 250Z"></path><path stroke-width="1" id="MJMAIN-57" d="M792 683Q810 680 914 680Q991 680 1003 683H1009V637H996Q931 633 915 598Q912 591 863 438T766 135T716 -17Q711 -22 694 -22Q676 -22 673 -15Q671 -13 593 231L514 477L435 234Q416 174 391 92T358 -6T341 -22H331Q314 -21 310 -15Q309 -14 208 302T104 622Q98 632 87 633Q73 637 35 637H18V683H27Q69 681 154 681Q164 681 181 681T216 681T249 682T276 683H287H298V637H285Q213 637 213 620Q213 616 289 381L364 144L427 339Q490 535 492 546Q487 560 482 578T475 602T468 618T461 628T449 633T433 636T408 637H380V683H388Q397 680 508 680Q629 680 650 683H660V637H647Q576 637 576 619L727 146Q869 580 869 600Q869 605 863 612T839 627T794 637H783V683H792Z"></path><path stroke-width="1" id="MJMAIN-2B" d="M56 237T56 250T70 270H369V420L370 570Q380 583 389 583Q402 583 409 568V270H707Q722 262 722 250T707 230H409V-68Q401 -82 391 -82H389H387Q375 -82 369 -68V230H70Q56 237 56 250Z"></path><path stroke-width="1" id="MJMAIN-62" d="M307 -11Q234 -11 168 55L158 37Q156 34 153 28T147 17T143 10L138 1L118 0H98V298Q98 599 97 603Q94 622 83 628T38 637H20V660Q20 683 22 683L32 684Q42 685 61 686T98 688Q115 689 135 690T165 693T176 694H179V543Q179 391 180 391L183 394Q186 397 192 401T207 411T228 421T254 431T286 439T323 442Q401 442 461 379T522 216Q522 115 458 52T307 -11ZM182 98Q182 97 187 90T196 79T206 67T218 55T233 44T250 35T271 29T295 26Q330 26 363 46T412 113Q424 148 424 212Q424 287 412 323Q385 405 300 405Q270 405 239 390T188 347L182 339V98Z"></path><path stroke-width="1" id="MJMAIN-29" d="M60 749L64 750Q69 750 74 750H86L114 726Q208 641 251 514T294 250Q294 182 284 119T261 12T224 -76T186 -143T145 -194T113 -227T90 -246Q87 -249 86 -250H74Q66 -250 63 -250T58 -247T55 -238Q56 -237 66 -225Q221 -64 221 250T66 725Q56 737 55 738Q55 746 60 749Z"></path><path stroke-width="1" id="MJMATHI-4C" d="M228 637Q194 637 192 641Q191 643 191 649Q191 673 202 682Q204 683 217 683Q271 680 344 680Q485 680 506 683H518Q524 677 524 674T522 656Q517 641 513 637H475Q406 636 394 628Q387 624 380 600T313 336Q297 271 279 198T252 88L243 52Q243 48 252 48T311 46H328Q360 46 379 47T428 54T478 72T522 106T564 161Q580 191 594 228T611 270Q616 273 628 273H641Q647 264 647 262T627 203T583 83T557 9Q555 4 553 3T537 0T494 -1Q483 -1 418 -1T294 0H116Q32 0 32 10Q32 17 34 24Q39 43 44 45Q48 46 59 46H65Q92 46 125 49Q139 52 144 61Q147 65 216 339T285 628Q285 635 228 637Z"></path><path stroke-width="1" id="MJMATHI-42" d="M231 637Q204 637 199 638T194 649Q194 676 205 682Q206 683 335 683Q594 683 608 681Q671 671 713 636T756 544Q756 480 698 429T565 360L555 357Q619 348 660 311T702 219Q702 146 630 78T453 1Q446 0 242 0Q42 0 39 2Q35 5 35 10Q35 17 37 24Q42 43 47 45Q51 46 62 46H68Q95 46 128 49Q142 52 147 61Q150 65 219 339T288 628Q288 635 231 637ZM649 544Q649 574 634 600T585 634Q578 636 493 637Q473 637 451 637T416 636H403Q388 635 384 626Q382 622 352 506Q352 503 351 500L320 374H401Q482 374 494 376Q554 386 601 434T649 544ZM595 229Q595 273 572 302T512 336Q506 337 429 337Q311 337 310 336Q310 334 293 263T258 122L240 52Q240 48 252 48T333 46Q422 46 429 47Q491 54 543 105T595 229Z"></path><path stroke-width="1" id="MJMATHI-50" d="M287 628Q287 635 230 637Q206 637 199 638T192 648Q192 649 194 659Q200 679 203 681T397 683Q587 682 600 680Q664 669 707 631T751 530Q751 453 685 389Q616 321 507 303Q500 302 402 301H307L277 182Q247 66 247 59Q247 55 248 54T255 50T272 48T305 46H336Q342 37 342 35Q342 19 335 5Q330 0 319 0Q316 0 282 1T182 2Q120 2 87 2T51 1Q33 1 33 11Q33 13 36 25Q40 41 44 43T67 46Q94 46 127 49Q141 52 146 61Q149 65 218 339T287 628ZM645 554Q645 567 643 575T634 597T609 619T560 635Q553 636 480 637Q463 637 445 637T416 636T404 636Q391 635 386 627Q384 621 367 550T332 412T314 344Q314 342 395 342H407H430Q542 342 590 392Q617 419 631 471T645 554Z"></path><path stroke-width="1" id="MJMATHI-78" d="M52 289Q59 331 106 386T222 442Q257 442 286 424T329 379Q371 442 430 442Q467 442 494 420T522 361Q522 332 508 314T481 292T458 288Q439 288 427 299T415 328Q415 374 465 391Q454 404 425 404Q412 404 406 402Q368 386 350 336Q290 115 290 78Q290 50 306 38T341 26Q378 26 414 59T463 140Q466 150 469 151T485 153H489Q504 153 504 145Q504 144 502 134Q486 77 440 33T333 -11Q263 -11 227 52Q186 -10 133 -10H127Q78 -10 57 16T35 71Q35 103 54 123T99 143Q142 143 142 101Q142 81 130 66T107 46T94 41L91 40Q91 39 97 36T113 29T132 26Q168 26 194 71Q203 87 217 139T245 247T261 313Q266 340 266 352Q266 380 251 392T217 404Q177 404 142 372T93 290Q91 281 88 280T72 278H58Q52 284 52 289Z"></path><path stroke-width="1" id="MJMATHI-63" d="M34 159Q34 268 120 355T306 442Q362 442 394 418T427 355Q427 326 408 306T360 285Q341 285 330 295T319 325T330 359T352 380T366 386H367Q367 388 361 392T340 400T306 404Q276 404 249 390Q228 381 206 359Q162 315 142 235T121 119Q121 73 147 50Q169 26 205 26H209Q321 26 394 111Q403 121 406 121Q410 121 419 112T429 98T420 83T391 55T346 25T282 0T202 -11Q127 -11 81 37T34 159Z"></path><path stroke-width="1" id="MJMAIN-2C" d="M78 35T78 60T94 103T137 121Q165 121 187 96T210 8Q210 -27 201 -60T180 -117T154 -158T130 -185T117 -194Q113 -194 104 -185T95 -172Q95 -168 106 -156T131 -126T157 -76T173 -3V9L172 8Q170 7 167 6T161 3T152 1T140 0Q113 0 96 17Z"></path><path stroke-width="1" id="MJMATHI-79" d="M21 287Q21 301 36 335T84 406T158 442Q199 442 224 419T250 355Q248 336 247 334Q247 331 231 288T198 191T182 105Q182 62 196 45T238 27Q261 27 281 38T312 61T339 94Q339 95 344 114T358 173T377 247Q415 397 419 404Q432 431 462 431Q475 431 483 424T494 412T496 403Q496 390 447 193T391 -23Q363 -106 294 -155T156 -205Q111 -205 77 -183T43 -117Q43 -95 50 -80T69 -58T89 -48T106 -45Q150 -45 150 -87Q150 -107 138 -122T115 -142T102 -147L99 -148Q101 -153 118 -160T152 -167H160Q177 -167 186 -165Q219 -156 247 -127T290 -65T313 -9T321 21L315 17Q309 13 296 6T270 -6Q250 -11 231 -11Q185 -11 150 11T104 82Q103 89 103 113Q103 170 138 262T173 379Q173 380 173 381Q173 390 173 393T169 400T158 404H154Q131 404 112 385T82 344T65 302T57 280Q55 278 41 278H27Q21 284 21 287Z"></path><path stroke-width="1" id="MJSZ1-2211" d="M61 748Q64 750 489 750H913L954 640Q965 609 976 579T993 533T999 516H979L959 517Q936 579 886 621T777 682Q724 700 655 705T436 710H319Q183 710 183 709Q186 706 348 484T511 259Q517 250 513 244L490 216Q466 188 420 134T330 27L149 -187Q149 -188 362 -188Q388 -188 436 -188T506 -189Q679 -189 778 -162T936 -43Q946 -27 959 6H999L913 -249L489 -250Q65 -250 62 -248Q56 -246 56 -239Q56 -234 118 -161Q186 -81 245 -11L428 206Q428 207 242 462L57 717L56 728Q56 744 61 748Z"></path><path stroke-width="1" id="MJMAIN-37" d="M55 458Q56 460 72 567L88 674Q88 676 108 676H128V672Q128 662 143 655T195 646T364 644H485V605L417 512Q408 500 387 472T360 435T339 403T319 367T305 330T292 284T284 230T278 162T275 80Q275 66 275 52T274 28V19Q270 2 255 -10T221 -22Q210 -22 200 -19T179 0T168 40Q168 198 265 368Q285 400 349 489L395 552H302Q128 552 119 546Q113 543 108 522T98 479L95 458V455H55V458Z"></path><path stroke-width="1" id="MJMAIN-30" d="M96 585Q152 666 249 666Q297 666 345 640T423 548Q460 465 460 320Q460 165 417 83Q397 41 362 16T301 -15T250 -22Q224 -22 198 -16T137 16T82 83Q39 165 39 320Q39 494 96 585ZM321 597Q291 629 250 629Q208 629 178 597Q153 571 145 525T137 333Q137 175 145 125T181 46Q209 16 250 16Q290 16 318 46Q347 76 354 130T362 333Q362 478 354 524T321 597Z"></path><path stroke-width="1" id="MJMAIN-2212" d="M84 237T84 250T98 270H679Q694 262 694 250T679 230H98Q84 237 84 250Z"></path><path stroke-width="1" id="MJMAIN-32" d="M109 429Q82 429 66 447T50 491Q50 562 103 614T235 666Q326 666 387 610T449 465Q449 422 429 383T381 315T301 241Q265 210 201 149L142 93L218 92Q375 92 385 97Q392 99 409 186V189H449V186Q448 183 436 95T421 3V0H50V19V31Q50 38 56 46T86 81Q115 113 136 137Q145 147 170 174T204 211T233 244T261 278T284 308T305 340T320 369T333 401T340 431T343 464Q343 527 309 573T212 619Q179 619 154 602T119 569T109 550Q109 549 114 549Q132 549 151 535T170 489Q170 464 154 447T109 429Z"></path><path stroke-width="1" id="MJMAIN-7B" d="M434 -231Q434 -244 428 -250H410Q281 -250 230 -184Q225 -177 222 -172T217 -161T213 -148T211 -133T210 -111T209 -84T209 -47T209 0Q209 21 209 53Q208 142 204 153Q203 154 203 155Q189 191 153 211T82 231Q71 231 68 234T65 250T68 266T82 269Q116 269 152 289T203 345Q208 356 208 377T209 529V579Q209 634 215 656T244 698Q270 724 324 740Q361 748 377 749Q379 749 390 749T408 750H428Q434 744 434 732Q434 719 431 716Q429 713 415 713Q362 710 332 689T296 647Q291 634 291 499V417Q291 370 288 353T271 314Q240 271 184 255L170 250L184 245Q202 239 220 230T262 196T290 137Q291 131 291 1Q291 -134 296 -147Q306 -174 339 -192T415 -213Q429 -213 431 -216Q434 -219 434 -231Z"></path><path stroke-width="1" id="MJMAIN-31" d="M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z"></path><path stroke-width="1" id="MJMAIN-2265" d="M83 616Q83 624 89 630T99 636Q107 636 253 568T543 431T687 361Q694 356 694 346T687 331Q685 329 395 192L107 56H101Q83 58 83 76Q83 77 83 79Q82 86 98 95Q117 105 248 167Q326 204 378 228L626 346L360 472Q291 505 200 548Q112 589 98 597T83 616ZM84 -118Q84 -108 99 -98H678Q694 -104 694 -118Q694 -130 679 -138H98Q84 -131 84 -118Z"></path><path stroke-width="1" id="MJMAIN-2264" d="M674 636Q682 636 688 630T694 615T687 601Q686 600 417 472L151 346L399 228Q687 92 691 87Q694 81 694 76Q694 58 676 56H670L382 192Q92 329 90 331Q83 336 83 348Q84 359 96 365Q104 369 382 500T665 634Q669 636 674 636ZM84 -118Q84 -108 99 -98H678Q694 -104 694 -118Q694 -130 679 -138H98Q84 -131 84 -118Z"></path><path stroke-width="1" id="MJSZ3-7B" d="M618 -943L612 -949H582L568 -943Q472 -903 411 -841T332 -703Q327 -682 327 -653T325 -350Q324 -28 323 -18Q317 24 301 61T264 124T221 171T179 205T147 225T132 234Q130 238 130 250Q130 255 130 258T131 264T132 267T134 269T139 272T144 275Q207 308 256 367Q310 436 323 519Q324 529 325 851Q326 1124 326 1154T332 1205Q369 1358 566 1443L582 1450H612L618 1444V1429Q618 1413 616 1411L608 1406Q599 1402 585 1393T552 1372T515 1343T479 1305T449 1257T429 1200Q425 1180 425 1152T423 851Q422 579 422 549T416 498Q407 459 388 424T346 364T297 318T250 284T214 264T197 254L188 251L205 242Q290 200 345 138T416 3Q421 -18 421 -48T423 -349Q423 -397 423 -472Q424 -677 428 -694Q429 -697 429 -699Q434 -722 443 -743T465 -782T491 -816T519 -845T548 -868T574 -886T595 -899T610 -908L616 -910Q618 -912 618 -928V-943Z"></path><path stroke-width="1" id="MJMATHI-52" d="M230 637Q203 637 198 638T193 649Q193 676 204 682Q206 683 378 683Q550 682 564 680Q620 672 658 652T712 606T733 563T739 529Q739 484 710 445T643 385T576 351T538 338L545 333Q612 295 612 223Q612 212 607 162T602 80V71Q602 53 603 43T614 25T640 16Q668 16 686 38T712 85Q717 99 720 102T735 105Q755 105 755 93Q755 75 731 36Q693 -21 641 -21H632Q571 -21 531 4T487 82Q487 109 502 166T517 239Q517 290 474 313Q459 320 449 321T378 323H309L277 193Q244 61 244 59Q244 55 245 54T252 50T269 48T302 46H333Q339 38 339 37T336 19Q332 6 326 0H311Q275 2 180 2Q146 2 117 2T71 2T50 1Q33 1 33 10Q33 12 36 24Q41 43 46 45Q50 46 61 46H67Q94 46 127 49Q141 52 146 61Q149 65 218 339T287 628Q287 635 230 637ZM630 554Q630 586 609 608T523 636Q521 636 500 636T462 637H440Q393 637 386 627Q385 624 352 494T319 361Q319 360 388 360Q466 361 492 367Q556 377 592 426Q608 449 619 486T630 554Z"></path><path stroke-width="1" id="MJMAIN-23" d="M56 347Q56 360 70 367H313L355 524Q394 676 401 686Q406 694 416 694Q434 694 436 676Q436 672 396 522Q355 374 355 369L354 367H543L585 524Q626 679 630 685Q636 694 646 694Q653 694 659 689T665 678Q665 668 626 522Q585 374 585 369L584 367H762Q777 359 777 347Q777 334 767 331T722 327H667H572L552 251L531 174Q531 173 647 173H720Q756 173 766 170T777 153T762 133H519L477 -24Q436 -179 432 -185Q426 -194 416 -194Q409 -194 403 -189T397 -177Q397 -167 436 -21Q477 125 477 131L478 133H289L247 -24Q206 -179 202 -185Q196 -194 186 -194Q179 -194 173 -189T167 -177Q167 -167 206 -21Q247 125 247 131L248 133H70Q56 140 56 153Q56 168 72 173H260L280 249L301 326Q301 327 186 327H72Q56 332 56 347ZM531 326Q531 327 437 327H342L322 251L301 174Q301 173 395 173H490L510 249L531 326Z"></path><path stroke-width="1" id="MJMATHI-75" d="M21 287Q21 295 30 318T55 370T99 420T158 442Q204 442 227 417T250 358Q250 340 216 246T182 105Q182 62 196 45T238 27T291 44T328 78L339 95Q341 99 377 247Q407 367 413 387T427 416Q444 431 463 431Q480 431 488 421T496 402L420 84Q419 79 419 68Q419 43 426 35T447 26Q469 29 482 57T512 145Q514 153 532 153Q551 153 551 144Q550 139 549 130T540 98T523 55T498 17T462 -8Q454 -10 438 -10Q372 -10 347 46Q345 45 336 36T318 21T296 6T267 -6T233 -11Q189 -11 155 7Q103 38 103 113Q103 170 138 262T173 379Q173 380 173 381Q173 390 173 393T169 400T158 404H154Q131 404 112 385T82 344T65 302T57 280Q55 278 41 278H27Q21 284 21 287Z"></path><path stroke-width="1" id="MJMATHI-73" d="M131 289Q131 321 147 354T203 415T300 442Q362 442 390 415T419 355Q419 323 402 308T364 292Q351 292 340 300T328 326Q328 342 337 354T354 372T367 378Q368 378 368 379Q368 382 361 388T336 399T297 405Q249 405 227 379T204 326Q204 301 223 291T278 274T330 259Q396 230 396 163Q396 135 385 107T352 51T289 7T195 -10Q118 -10 86 19T53 87Q53 126 74 143T118 160Q133 160 146 151T160 120Q160 94 142 76T111 58Q109 57 108 57T107 55Q108 52 115 47T146 34T201 27Q237 27 263 38T301 66T318 97T323 122Q323 150 302 164T254 181T195 196T148 231Q131 256 131 289Z"></path><path stroke-width="1" id="MJMATHI-55" d="M107 637Q73 637 71 641Q70 643 70 649Q70 673 81 682Q83 683 98 683Q139 681 234 681Q268 681 297 681T342 682T362 682Q378 682 378 672Q378 670 376 658Q371 641 366 638H364Q362 638 359 638T352 638T343 637T334 637Q295 636 284 634T266 623Q265 621 238 518T184 302T154 169Q152 155 152 140Q152 86 183 55T269 24Q336 24 403 69T501 205L552 406Q599 598 599 606Q599 633 535 637Q511 637 511 648Q511 650 513 660Q517 676 519 679T529 683Q532 683 561 682T645 680Q696 680 723 681T752 682Q767 682 767 672Q767 650 759 642Q756 637 737 637Q666 633 648 597Q646 592 598 404Q557 235 548 205Q515 105 433 42T263 -22Q171 -22 116 34T60 167V183Q60 201 115 421Q164 622 164 628Q164 635 107 637Z"></path><path stroke-width="1" id="MJAMS-2A7D" d="M674 636Q682 636 688 630T694 615T687 601Q686 600 417 472L151 346L399 228Q687 92 691 87Q694 81 694 76Q694 58 676 56H670L382 192Q92 329 90 331Q83 336 83 348Q84 359 96 365Q104 369 382 500T665 634Q669 636 674 636ZM94 170Q102 172 104 172Q110 171 254 103T535 -30T678 -98Q694 -106 694 -118Q694 -136 676 -138H670L382 -2Q92 135 90 137Q83 142 83 154Q84 164 94 170Z"></path><path stroke-width="1" id="MJMATHI-74" d="M26 385Q19 392 19 395Q19 399 22 411T27 425Q29 430 36 430T87 431H140L159 511Q162 522 166 540T173 566T179 586T187 603T197 615T211 624T229 626Q247 625 254 615T261 596Q261 589 252 549T232 470L222 433Q222 431 272 431H323Q330 424 330 420Q330 398 317 385H210L174 240Q135 80 135 68Q135 26 162 26Q197 26 230 60T283 144Q285 150 288 151T303 153H307Q322 153 322 145Q322 142 319 133Q314 117 301 95T267 48T216 6T155 -11Q125 -11 98 4T59 56Q57 64 57 83V101L92 241Q127 382 128 383Q128 385 77 385H26Z"></path><path stroke-width="1" id="MJMATHI-68" d="M137 683Q138 683 209 688T282 694Q294 694 294 685Q294 674 258 534Q220 386 220 383Q220 381 227 388Q288 442 357 442Q411 442 444 415T478 336Q478 285 440 178T402 50Q403 36 407 31T422 26Q450 26 474 56T513 138Q516 149 519 151T535 153Q555 153 555 145Q555 144 551 130Q535 71 500 33Q466 -10 419 -10H414Q367 -10 346 17T325 74Q325 90 361 192T398 345Q398 404 354 404H349Q266 404 205 306L198 293L164 158Q132 28 127 16Q114 -11 83 -11Q69 -11 59 -2T48 16Q48 30 121 320L195 616Q195 629 188 632T149 637H128Q122 643 122 645T124 664Q129 683 137 683Z"></path><path stroke-width="1" id="MJMATHI-77" d="M580 385Q580 406 599 424T641 443Q659 443 674 425T690 368Q690 339 671 253Q656 197 644 161T609 80T554 12T482 -11Q438 -11 404 5T355 48Q354 47 352 44Q311 -11 252 -11Q226 -11 202 -5T155 14T118 53T104 116Q104 170 138 262T173 379Q173 380 173 381Q173 390 173 393T169 400T158 404H154Q131 404 112 385T82 344T65 302T57 280Q55 278 41 278H27Q21 284 21 287Q21 293 29 315T52 366T96 418T161 441Q204 441 227 416T250 358Q250 340 217 250T184 111Q184 65 205 46T258 26Q301 26 334 87L339 96V119Q339 122 339 128T340 136T341 143T342 152T345 165T348 182T354 206T362 238T373 281Q402 395 406 404Q419 431 449 431Q468 431 475 421T483 402Q483 389 454 274T422 142Q420 131 420 107V100Q420 85 423 71T442 42T487 26Q558 26 600 148Q609 171 620 213T632 273Q632 306 619 325T593 357T580 385Z"></path><path stroke-width="1" id="MJSZ4-23A7" d="M712 899L718 893V876V865Q718 854 704 846Q627 793 577 710T510 525Q510 524 509 521Q505 493 504 349Q504 345 504 334Q504 277 504 240Q504 -2 503 -4Q502 -8 494 -9T444 -10Q392 -10 390 -9Q387 -8 386 -5Q384 5 384 230Q384 262 384 312T383 382Q383 481 392 535T434 656Q510 806 664 892L677 899H712Z"></path><path stroke-width="1" id="MJSZ4-23A9" d="M718 -893L712 -899H677L666 -893Q542 -825 468 -714T385 -476Q384 -466 384 -282Q384 3 385 5L389 9Q392 10 444 10Q486 10 494 9T503 4Q504 2 504 -239V-310V-366Q504 -470 508 -513T530 -609Q546 -657 569 -698T617 -767T661 -812T699 -843T717 -856T718 -876V-893Z"></path><path stroke-width="1" id="MJSZ4-23A8" d="M389 1159Q391 1160 455 1160Q496 1160 498 1159Q501 1158 502 1155Q504 1145 504 924Q504 691 503 682Q494 549 425 439T243 259L229 250L243 241Q349 175 421 66T503 -182Q504 -191 504 -424Q504 -600 504 -629T499 -659H498Q496 -660 444 -660T390 -659Q387 -658 386 -655Q384 -645 384 -425V-282Q384 -176 377 -116T342 10Q325 54 301 92T255 155T214 196T183 222T171 232Q170 233 170 250T171 268Q171 269 191 284T240 331T300 407T354 524T383 679Q384 691 384 925Q384 1152 385 1155L389 1159Z"></path><path stroke-width="1" id="MJSZ4-23AA" d="M384 150V266Q384 304 389 309Q391 310 455 310Q496 310 498 309Q502 308 503 298Q504 283 504 150Q504 32 504 12T499 -9H498Q496 -10 444 -10T390 -9Q386 -8 385 2Q384 17 384 150Z"></path><path stroke-width="1" id="MJMAIN-D7" d="M630 29Q630 9 609 9Q604 9 587 25T493 118L389 222L284 117Q178 13 175 11Q171 9 168 9Q160 9 154 15T147 29Q147 36 161 51T255 146L359 250L255 354Q174 435 161 449T147 471Q147 480 153 485T168 490Q173 490 175 489Q178 487 284 383L389 278L493 382Q570 459 587 475T609 491Q630 491 630 471Q630 464 620 453T522 355L418 250L522 145Q606 61 618 48T630 29Z"></path></defs></svg></div><div id="MathJax_Message" style="display: none;"></div>
<script type="text/javascript">
        window.__PRELOADED_STATE__ = {"abstracts":{"content":[{"$$":[{"$":{"id":"st005"},"#name":"section-title","_":"Abstract"},{"$$":[{"$":{"view":"all","id":"sp0005"},"#name":"simple-para","_":"Facial expression recognition is a hot research topic and can be applied in many computer vision fields, such as human–computer interaction, affective computing and so on. In this paper, we propose a novel end-to-end network with attention mechanism for automatic facial expression recognition. The new network architecture consists of four parts, i.e., the feature extraction module, the attention module, the reconstruction module and the classification module. The LBP features extract image texture information and then catch the small movements of the faces, which can improve the network performance. Attention mechanism can make the neural network pay more attention to useful features. We combine LBP features and attention mechanism to enhance the attention model to obtain better results. In addition, we collected and labelled a new facial expression dataset of seven expressions from 35 subjects aged from 20 to 25. For each subject, we captured both RGB images and depth images with a Microsoft Kinect sensor. For each image type, there are 245 image sequences, each of which contains 110 images, resulting in 26,950 images in total. We apply the newly proposed method to our own dataset and four representative expression datasets, i.e., JAFFE, CK+, FER2013 and Oulu-CASIA. The experimental results demonstrate the feasibility and effectiveness of the proposed method."}],"$":{"view":"all","id":"as005"},"#name":"abstract-sec"}],"$":{"view":"all","id":"ab005","lang":"en","class":"author"},"#name":"abstract"}],"floats":[],"footnotes":[],"attachments":[]},"accessbarConfig":{"fallback":false,"id":"accessbar","version":"0.0.1","analytics":{"location":"accessbar","eventName":"ctaImpression"},"label":{},"ariaLabel":{"accessbar":"Download options and search","componentsList":"PDF Options"},"banner":{"id":"Banner"},"banners":[{"id":"Banner"},{"id":"BannerSsrn"}],"components":[{"target":"_blank","analytics":[{"ids":["accessbar:fta:single-article"],"eventName":"ctaClick"}],"label":"View&nbsp;**PDF**","ariaLabel":"View PDF. Opens in a new window.","id":"ViewPDF"},{"analytics":[{"ids":["accessbar:fta:full-issue"],"eventName":"ctaClick"}],"label":"Download full issue","id":"DownloadFullIssue"}],"search":{"inputPlaceHolder":"Search ScienceDirect","ariaLabel":{"input":"Search ScienceDirect","submit":"Submit search"},"formAction":"/search#submit","analytics":[{"ids":["accessbar:search"],"eventName":"searchStart"}],"id":"QuickSearch"}},"adobeTarget":{"sd:genai-question-and-answer":{}},"article":{"analyticsMetadata":{"accountId":"50401","accountName":"IT University of Copenhagen","loginStatus":"logged in","userId":"71970787","isLoggedIn":true},"cid":"271597","content-family":"serial","copyright-line":"© 2020 Elsevier B.V. All rights reserved.","cover-date-years":["2020"],"cover-date-start":"2020-10-21","cover-date-text":"21 October 2020","document-subtype":"fla","document-type":"article","entitledToken":"40F7D33E8F3B45107579DDF65AA168AA9C18868A11A6E1716F82C2958D2846C726409ECDA4925166","genAiToken":"eyJ0eXAiOiJKV1QiLCJhbGciOiJIUzI1NiJ9.eyJhdWQiOiJnZW5BaUFwcHMiLCJzdWIiOiI1MDQwMSIsInBpaSI6IlMwOTI1MjMxMjIwMzA5ODM4IiwiaXNzIjoiYXJwIiwic2Vzc2lvbklkIjoiZDNlOTE2NTMxZGUwYzg0OTE2MGI3M2Y0NzkyNTBiODU5NGNhZ3hycWIiLCJleHAiOjE3Mjg5OTI1MjgsImlhdCI6MTcyODk5MDcyOCwidmVyc2lvbiI6MSwianRpIjoiM2U5MzM0MGQtYzM5MS00MDIzLThhNjUtMTRjOTlkNGFmMGU5In0.w3vWVh8EJR1q38kBN1_cFPKwML8Ax-7NfTcY87vfM08","eid":"1-s2.0-S0925231220309838","doi":"10.1016/j.neucom.2020.06.014","first-fp":"340","hub-eid":"1-s2.0-S0925231220X00336","issuePii":"S0925231220X00336","item-weight":"FULL-TEXT","language":"en","last-lp":"350","last-author":{"#name":"last-author","$":{"xmlns:ce":true,"xmlns:dm":true,"xmlns:sb":true},"$$":[{"#name":"author","$":{"biographyid":"bg025","id":"au025","author-id":"S0925231220309838-7480a9ce833ed48716b63edbda059763"},"$$":[{"#name":"given-name","_":"Zhaojie"},{"#name":"surname","_":"Ju"},{"#name":"contributor-role","$":{"role":"http://dictionary.casrai.org/Contributor_Roles/Conceptualization"},"_":"Conceptualization"},{"#name":"contributor-role","$":{"role":"http://dictionary.casrai.org/Contributor_Roles/Methodology"},"_":"Methodology"},{"#name":"contributor-role","$":{"role":"http://dictionary.casrai.org/Contributor_Roles/Writing_%E2%80%93_original_draft"},"_":"Writing - original draft"},{"#name":"cross-ref","$":{"id":"c0150","refid":"af010"},"$$":[{"#name":"sup","$":{"loc":"post"},"_":"b"}]},{"#name":"cross-ref","$":{"id":"c0155","refid":"cor1"},"$$":[{"#name":"sup","$":{"loc":"post"},"_":"⁎"}]},{"#name":"encoded-e-address","__encoded":"JTdCJTIyJTIzbmFtZSUyMiUzQSUyMmUtYWRkcmVzcyUyMiUyQyUyMiUyNCUyMiUzQSU3QiUyMnhtbG5zJTNBeGxpbmslMjIlM0F0cnVlJTJDJTIyaWQlMjIlM0ElMjJlbTAwNSUyMiUyQyUyMnR5cGUlMjIlM0ElMjJlbWFpbCUyMiUyQyUyMmhyZWYlMjIlM0ElMjJtYWlsdG8lM0F6aGFvamllLmp1JTQwcG9ydC5hYy51ayUyMiU3RCUyQyUyMl8lMjIlM0ElMjJ6aGFvamllLmp1JTQwcG9ydC5hYy51ayUyMiU3RA=="}]}]},"normalized-first-auth-initial":"J","normalized-first-auth-surname":"LI","open-research":{"#name":"open-research","$":{"xmlns:xocs":true},"$$":[{"#name":"or-agreements","$$":[{"#name":"or-agreement","$$":[{"#name":"or-agreement-name","_":"HEFCE"},{"#name":"or-agreement-terms","_":"none"}]}]}]},"pages":[{"last-page":"350","first-page":"340"}],"pii":"S0925231220309838","self-archiving":{"#name":"self-archiving","$":{"xmlns:xocs":true},"$$":[{"#name":"sa-start-date","_":"2021-07-03T00:00:00.000Z"},{"#name":"sa-user-license","_":"http://creativecommons.org/licenses/by-nc-nd/4.0/"}]},"srctitle":"Neurocomputing","suppl":"C","timestamp":"2020-09-11T22:33:17.352222Z","title":{"content":[{"#name":"title","$":{"id":"tm005"},"_":"Attention mechanism-based CNN for facial expression recognition"}],"floats":[],"footnotes":[],"attachments":[]},"vol-first":"411","vol-iss-suppl-text":"Volume 411","userSettings":{"forceAbstract":false,"creditCardPurchaseAllowed":true,"blockFullTextForAnonymousAccess":false,"disableWholeIssueDownload":false,"preventTransactionalAccess":false,"preventDocumentDelivery":true},"contentType":"JL","crossmark":true,"document-references":44,"freeHtmlGiven":false,"userProfile":{"departmentName":"Library","webUserId":"71970787","accountName":"IT University of Copenhagen","shibProfile":{"canRegister":false},"departmentId":"71310","hasMultipleOrganizations":false,"accountNumber":"C000050401","userName":"Gergo Gyori","supportUserData":"xyhJEXWoHAMsz8VQOu3h2LHHIekBL3hT38urfpOCxeAty3TF61ibE7vsQPaZh4C6srqm9MNOxus2v65ykDkikA4MoWWax9xsxmy7qS6Jhq1MDk8fC~ZGE1crT~IU0fB88KgH29YS658ka3vhWTqW3QsF38M7JrWC3EPvnlMgTGg39gl1xRqh4DNloSU9hGNUBWmK_Teu~5LuRZ6Al86jUzFxO7CiLa3WIvaVAP5f3g900Gfh5TZfq33GuKqA9hfimBRbW0fFzY3a21RwOu4PLrz0ZSWIczBuiylb5NC3rWc*","accessType":"SHIBREG","accountId":"50401","userType":"NORMAL","privilegeType":"BASIC","email":"gegy@itu.dk"},"access":{"openAccess":false,"openArchive":false},"aipType":"none","articleEntitlement":{"authenticationMethod":"SHIBBOLETH","entitled":true,"isCasaUser":false,"usageInfo":"(71970787,U|71310,D|50401,A|26,S|34,P|2,PL)(SDFE,CON|d3e916531de0c849160b73f479250b8594cagxrqb,SSO|REG_SHIBBOLETH,ACCESS_TYPE)","entitledByAccount":false},"crawlerInformation":{"canCrawlPDFContent":false,"isCrawler":false},"dates":{"Available online":"12 June 2020","Received":"5 January 2020","Revised":["23 April 2020"],"Accepted":"2 June 2020","Publication date":"21 October 2020","Version of Record":"3 July 2020"},"downloadFullIssue":true,"entitlementReason":"package","hasBody":true,"has-large-authors":false,"hasScholarlyAbstract":true,"headerConfig":{"helpUrl":"https://service.elsevier.com/ci/pta/login/redirect/home/supporthub/sciencedirect/p_li/xyhJEXWoHAMsz8VQOu3h2LHHIekBL3hT38urfpOCxeAty3TF61ibE7vsQPaZh4C6srqm9MNOxus2v65ykDkikA4MoWWax9xsxmy7qS6Jhq1MDk8fC~ZGE1crT~IU0fB88KgH29YS658ka3vhWTqW3QsF38M7JrWC3EPvnlMgTGg39gl1xRqh4DNloSU9hGNUBWmK_Teu~5LuRZ6Al86jUzFxO7CiLa3WIvaVAP5f3g900Gfh5TZfq33GuKqA9hfimBRbW0fFzY3a21RwOu4PLrz0ZSWIczBuiylb5NC3rWc*","contactUrl":"https://service.elsevier.com/ci/pta/login/redirect/contact/supporthub/sciencedirect/p_li/xyhJEXWoHAMsz8VQOu3h2LHHIekBL3hT38urfpOCxeAty3TF61ibE7vsQPaZh4C6srqm9MNOxus2v65ykDkikA4MoWWax9xsxmy7qS6Jhq1MDk8fC~ZGE1crT~IU0fB88KgH29YS658ka3vhWTqW3QsF38M7JrWC3EPvnlMgTGg39gl1xRqh4DNloSU9hGNUBWmK_Teu~5LuRZ6Al86jUzFxO7CiLa3WIvaVAP5f3g900Gfh5TZfq33GuKqA9hfimBRbW0fFzY3a21RwOu4PLrz0ZSWIczBuiylb5NC3rWc*","userName":"Gergo Gyori","userEmail":"gegy@itu.dk","orgName":"IT University of Copenhagen","webUserId":"71970787","libraryBanner":null,"shib_regUrl":"","tick_regUrl":"","recentInstitutions":[],"canActivatePersonalization":false,"hasInstitutionalAssociation":true,"hasMultiOrg":false,"userType":"SHIBREG","userAnonymity":"INDIVIDUAL","allowCart":true,"environment":"prod","cdnAssetsHost":"https://sdfestaticassets-eu-west-1.sciencedirectassets.com","supportUserData":"xyhJEXWoHAMsz8VQOu3h2LHHIekBL3hT38urfpOCxeAty3TF61ibE7vsQPaZh4C6srqm9MNOxus2v65ykDkikA4MoWWax9xsxmy7qS6Jhq1MDk8fC~ZGE1crT~IU0fB88KgH29YS658ka3vhWTqW3QsF38M7JrWC3EPvnlMgTGg39gl1xRqh4DNloSU9hGNUBWmK_Teu~5LuRZ6Al86jUzFxO7CiLa3WIvaVAP5f3g900Gfh5TZfq33GuKqA9hfimBRbW0fFzY3a21RwOu4PLrz0ZSWIczBuiylb5NC3rWc*","institutionName":"your institution"},"isCorpReq":false,"isPdfFullText":false,"issn":"09252312","issn-primary-formatted":"0925-2312","issRange":"","isThirdParty":false,"pageCount":11,"pdfDownload":{"isPdfFullText":false,"urlMetadata":{"queryParams":{"md5":"6060445b3bd2193d0e2fd0cc1bd93d5e","pid":"1-s2.0-S0925231220309838-main.pdf"},"pii":"S0925231220309838","pdfExtension":"/pdfft","path":"science/article/pii"}},"publication-content":{"noElsevierLogo":false,"imprintPublisher":{"displayName":"Elsevier","id":"47"},"isSpecialIssue":false,"isSampleIssue":false,"transactionsBlocked":false,"publicationOpenAccess":{"oaStatus":"","oaArticleCount":532,"openArchiveStatus":false,"openArchiveArticleCount":18,"openAccessStartDate":"","oaAllowsAuthorPaid":true},"issue-cover":{"attachment":[{"attachment-eid":"1-s2.0-S0925231220X00336-cov200h.gif","file-basename":"cov200h","extension":"gif","filename":"cov200h.gif","ucs-locator":["https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0925231220X00336/cover/DOWNSAMPLED200/image/gif/ee998c3fef616ee2a37da33c85557e18/cov200h.gif"],"attachment-type":"IMAGE-COVER-H200","filesize":"5256","pixel-height":"200","pixel-width":"149"},{"attachment-eid":"1-s2.0-S0925231220X00336-cov150h.gif","file-basename":"cov150h","extension":"gif","filename":"cov150h.gif","ucs-locator":["https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0925231220X00336/cover/DOWNSAMPLED/image/gif/8ea0464aee0ee7c33b1fc54ca412a4e5/cov150h.gif"],"attachment-type":"IMAGE-COVER-H150","filesize":"3684","pixel-height":"150","pixel-width":"112"}]},"smallCoverUrl":"https://ars.els-cdn.com/content/image/S09252312.gif","title":"neurocomputing","contentTypeCode":"JL","images":{"coverImage":"https://ars.els-cdn.com/content/image/1-s2.0-S0925231220X00336-cov150h.gif","logo":"https://sdfestaticassets-eu-west-1.sciencedirectassets.com/prod/fe5f1a9a67d6a2bd1341815211e4a5a7e50a5117/image/elsevier-non-solus.png","logoAltText":"Elsevier"},"publicationCoverImageUrl":"https://ars.els-cdn.com/content/image/1-s2.0-S0925231220X00336-cov150h.gif"},"volRange":"411","features":["aamAttachments","keywords","references","biography","preview"],"titleString":"Attention mechanism-based CNN for facial expression recognition","ssrn":{},"renderingMode":"Article","isAbstract":false,"isContentVisible":false,"ajaxLinks":{"questionsAndAnswers":true,"referenceLinks":true,"references":true,"referredToBy":true,"recommendations-entitled":true,"toc":true,"body":true,"recommendations":true,"citingArticles":true,"authorMetadata":true},"pdfEmbed":false,"displayViewFullText":false},"authors":{"content":[{"#name":"author-group","$":{"id":"ag005"},"$$":[{"#name":"author","$":{"biographyid":"bg005","id":"au005","author-id":"S0925231220309838-b8e0db7615e597047ea479976eff249f"},"$$":[{"#name":"given-name","_":"Jing"},{"#name":"surname","_":"Li"},{"#name":"contributor-role","$":{"role":"http://dictionary.casrai.org/Contributor_Roles/Conceptualization"},"_":"Conceptualization"},{"#name":"contributor-role","$":{"role":"http://dictionary.casrai.org/Contributor_Roles/Methodology"},"_":"Methodology"},{"#name":"contributor-role","$":{"role":"http://dictionary.casrai.org/Contributor_Roles/Writing_%E2%80%93_original_draft"},"_":"Writing - original draft"},{"#name":"cross-ref","$":{"id":"c0130","refid":"af005"},"$$":[{"#name":"sup","$":{"loc":"post"},"_":"a"}]}]},{"#name":"author","$":{"biographyid":"bg010","id":"au010","author-id":"S0925231220309838-7f7d38721b6c4d53bf61b170dafc06ea"},"$$":[{"#name":"given-name","_":"Kan"},{"#name":"surname","_":"Jin"},{"#name":"cross-ref","$":{"id":"c0135","refid":"af005"},"$$":[{"#name":"sup","$":{"loc":"post"},"_":"a"}]}]},{"#name":"author","$":{"biographyid":"bg015","id":"au015","author-id":"S0925231220309838-df5250f072e86ff1ef645a7edf552847"},"$$":[{"#name":"given-name","_":"Dalin"},{"#name":"surname","_":"Zhou"},{"#name":"cross-ref","$":{"id":"c0140","refid":"af010"},"$$":[{"#name":"sup","$":{"loc":"post"},"_":"b"}]}]},{"#name":"author","$":{"biographyid":"bg020","id":"au020","author-id":"S0925231220309838-dafff61daf979cc880c54bf7660332dc"},"$$":[{"#name":"given-name","_":"Naoyuki"},{"#name":"surname","_":"Kubota"},{"#name":"contributor-role","$":{"role":"http://dictionary.casrai.org/Contributor_Roles/Writing_%E2%80%93_review_%26_editing"},"_":"Writing - review & editing"},{"#name":"cross-ref","$":{"id":"c0145","refid":"af015"},"$$":[{"#name":"sup","$":{"loc":"post"},"_":"c"}]}]},{"#name":"author","$":{"biographyid":"bg025","id":"au025","author-id":"S0925231220309838-7480a9ce833ed48716b63edbda059763"},"$$":[{"#name":"given-name","_":"Zhaojie"},{"#name":"surname","_":"Ju"},{"#name":"contributor-role","$":{"role":"http://dictionary.casrai.org/Contributor_Roles/Conceptualization"},"_":"Conceptualization"},{"#name":"contributor-role","$":{"role":"http://dictionary.casrai.org/Contributor_Roles/Methodology"},"_":"Methodology"},{"#name":"contributor-role","$":{"role":"http://dictionary.casrai.org/Contributor_Roles/Writing_%E2%80%93_original_draft"},"_":"Writing - original draft"},{"#name":"cross-ref","$":{"id":"c0150","refid":"af010"},"$$":[{"#name":"sup","$":{"loc":"post"},"_":"b"}]},{"#name":"cross-ref","$":{"id":"c0155","refid":"cor1"},"$$":[{"#name":"sup","$":{"loc":"post"},"_":"⁎"}]},{"#name":"encoded-e-address","__encoded":"JTdCJTIyJTIzbmFtZSUyMiUzQSUyMmUtYWRkcmVzcyUyMiUyQyUyMiUyNCUyMiUzQSU3QiUyMnhtbG5zJTNBeGxpbmslMjIlM0F0cnVlJTJDJTIyaWQlMjIlM0ElMjJlbTAwNSUyMiUyQyUyMnR5cGUlMjIlM0ElMjJlbWFpbCUyMiUyQyUyMmhyZWYlMjIlM0ElMjJtYWlsdG8lM0F6aGFvamllLmp1JTQwcG9ydC5hYy51ayUyMiU3RCUyQyUyMl8lMjIlM0ElMjJ6aGFvamllLmp1JTQwcG9ydC5hYy51ayUyMiU3RA=="}]},{"#name":"affiliation","$":{"id":"af005","affiliation-id":"S0925231220309838-db6ea6446ed7323c47485d455d20f819"},"$$":[{"#name":"label","_":"a"},{"#name":"textfn","_":"School of Information Engineering, Nanchang University, Nanchang 330031, China"},{"#name":"affiliation","$":{"xmlns:sa":true},"$$":[{"#name":"organization","_":"School of Information Engineering"},{"#name":"organization","_":"Nanchang University"},{"#name":"city","_":"Nanchang"},{"#name":"postal-code","_":"330031"},{"#name":"country","_":"China"}]},{"#name":"source-text","$":{"id":"stx005"},"_":"School of Information Engineering, Nanchang University, Nanchang 330031, China"}]},{"#name":"affiliation","$":{"id":"af010","affiliation-id":"S0925231220309838-2fd2feae665eb651d7910c1efd60aa49"},"$$":[{"#name":"label","_":"b"},{"#name":"textfn","_":"School of Computing, University of Portsmouth, Portsmouth PO1 3HE, UK"},{"#name":"affiliation","$":{"xmlns:sa":true},"$$":[{"#name":"organization","_":"School of Computing"},{"#name":"organization","_":"University of Portsmouth"},{"#name":"city","_":"Portsmouth"},{"#name":"postal-code","_":"PO1 3HE"},{"#name":"country","_":"UK"}]},{"#name":"source-text","$":{"id":"stx010"},"_":"School of Computing, University of Portsmouth, Portsmouth PO1 3HE, UK"}]},{"#name":"affiliation","$":{"id":"af015","affiliation-id":"S0925231220309838-36a7e8ec3743be600c29dd36f00bbcc0"},"$$":[{"#name":"label","_":"c"},{"#name":"textfn","_":"Graduate School of Systems Design, Tokyo Metropolitan University, China"},{"#name":"affiliation","$":{"xmlns:sa":true},"$$":[{"#name":"organization","_":"Graduate School of Systems Design"},{"#name":"organization","_":"Tokyo Metropolitan University"},{"#name":"country","_":"China"}]},{"#name":"source-text","$":{"id":"stx015"},"_":"Graduate School of Systems Design, Tokyo Metropolitan University, China"}]},{"#name":"correspondence","$":{"id":"cor1"},"$$":[{"#name":"label","_":"⁎"},{"#name":"text","_":"Corresponding author."}]}]}],"floats":[],"footnotes":[],"affiliations":{"af005":{"#name":"affiliation","$":{"id":"af005","affiliation-id":"S0925231220309838-db6ea6446ed7323c47485d455d20f819"},"$$":[{"#name":"label","_":"a"},{"#name":"textfn","_":"School of Information Engineering, Nanchang University, Nanchang 330031, China"},{"#name":"affiliation","$":{"xmlns:sa":true},"$$":[{"#name":"organization","_":"School of Information Engineering"},{"#name":"organization","_":"Nanchang University"},{"#name":"city","_":"Nanchang"},{"#name":"postal-code","_":"330031"},{"#name":"country","_":"China"}]},{"#name":"source-text","$":{"id":"stx005"},"_":"School of Information Engineering, Nanchang University, Nanchang 330031, China"}]},"af010":{"#name":"affiliation","$":{"id":"af010","affiliation-id":"S0925231220309838-2fd2feae665eb651d7910c1efd60aa49"},"$$":[{"#name":"label","_":"b"},{"#name":"textfn","_":"School of Computing, University of Portsmouth, Portsmouth PO1 3HE, UK"},{"#name":"affiliation","$":{"xmlns:sa":true},"$$":[{"#name":"organization","_":"School of Computing"},{"#name":"organization","_":"University of Portsmouth"},{"#name":"city","_":"Portsmouth"},{"#name":"postal-code","_":"PO1 3HE"},{"#name":"country","_":"UK"}]},{"#name":"source-text","$":{"id":"stx010"},"_":"School of Computing, University of Portsmouth, Portsmouth PO1 3HE, UK"}]},"af015":{"#name":"affiliation","$":{"id":"af015","affiliation-id":"S0925231220309838-36a7e8ec3743be600c29dd36f00bbcc0"},"$$":[{"#name":"label","_":"c"},{"#name":"textfn","_":"Graduate School of Systems Design, Tokyo Metropolitan University, China"},{"#name":"affiliation","$":{"xmlns:sa":true},"$$":[{"#name":"organization","_":"Graduate School of Systems Design"},{"#name":"organization","_":"Tokyo Metropolitan University"},{"#name":"country","_":"China"}]},{"#name":"source-text","$":{"id":"stx015"},"_":"Graduate School of Systems Design, Tokyo Metropolitan University, China"}]}},"correspondences":{"cor1":{"#name":"correspondence","$":{"id":"cor1"},"$$":[{"#name":"label","_":"⁎"},{"#name":"text","_":"Corresponding author."}]}},"attachments":[],"scopusAuthorIds":{},"articles":{}},"authorMetadata":[],"banner":{"expanded":false},"biographies":{"content":[{"#name":"biography","$":{"xmlns:ce":true,"xmlns:aep":true,"xmlns:mml":true,"xmlns:xs":true,"xmlns:xlink":true,"xmlns:xocs":true,"xmlns:tb":true,"xmlns:xsi":true,"xmlns:cals":true,"xmlns:sb":true,"xmlns:sa":true,"xmlns:ja":true,"xmlns":true,"id":"bg005","view":"all"},"$$":[{"#name":"link","$":{"id":"lk00045","locator":"fx1","href":"pii:S0925231220309838/fx1","role":"http://data.elsevier.com/vocabulary/ElsevierContentTypes/23.4","type":"simple"}},{"#name":"simple-para","$":{"id":"sp0010","view":"all"},"_":"Jing Li received the B.E. degree in Electronic Information Engineering from Nanchang University, China, in 2005, and obtained her PhD degree in Electronic and Electrical Engineering from the University of Sheffield, UK, in 2011. From 2011 to 2012, she was a Research Associate with the Department of Computer Science at the University of Sheffield. Currently, she is an Associate Professor with the School of Information Engineering at Nanchang University. Her research interests include visual tracking, behavior recognition, and crowd scene analysis. She has authored or coauthored in various journals, such as IEEE Transactions on Industrial Informatics, IEEE Transactions on Image Processing, Information Sciences (Elsevier), etc."}]},{"#name":"biography","$":{"xmlns:ce":true,"xmlns:aep":true,"xmlns:mml":true,"xmlns:xs":true,"xmlns:xlink":true,"xmlns:xocs":true,"xmlns:tb":true,"xmlns:xsi":true,"xmlns:cals":true,"xmlns:sb":true,"xmlns:sa":true,"xmlns:ja":true,"xmlns":true,"id":"bg010","view":"all"},"$$":[{"#name":"link","$":{"id":"lk00050","locator":"fx2","href":"pii:S0925231220309838/fx2","role":"http://data.elsevier.com/vocabulary/ElsevierContentTypes/23.4","type":"simple"}},{"#name":"simple-para","$":{"id":"sp0015","view":"all"},"_":"Kan Jin received the B.E. degree in Mechatronic Engineering from Hubei Polytechnic University, China, in 2017. He is currently pursuing the M.S. degree in the School of Information Engineering at Nanchang University, China. His research interests include facial expression recognition and crowd counting."}]},{"#name":"biography","$":{"xmlns:ce":true,"xmlns:aep":true,"xmlns:mml":true,"xmlns:xs":true,"xmlns:xlink":true,"xmlns:xocs":true,"xmlns:tb":true,"xmlns:xsi":true,"xmlns:cals":true,"xmlns:sb":true,"xmlns:sa":true,"xmlns:ja":true,"xmlns":true,"id":"bg015","view":"all"},"$$":[{"#name":"link","$":{"id":"lk00055","locator":"fx3","href":"pii:S0925231220309838/fx3","role":"http://data.elsevier.com/vocabulary/ElsevierContentTypes/23.4","type":"simple"}},{"#name":"simple-para","$":{"id":"sp0020","view":"all"},"_":"Dalin Zhou received the B.S. degree in automation from the University of Science and Technology of China, Hefei, China, in 2012, the Ph.D. degree in computing from the University of Portsmouth, UK, in 2018 and is currently a Lecturer in Computer Science with the School of Computing, the University of Portsmouth, UK. His current research interests include signal processing, machine learning, computational intelligence, biomedical robotics and multimodal sensor fusion. His current research contributes to the monitoring and rehabilitation of limb motor function improving the daily life activity and working capability for both the disadvantaged group of limb-impaired patients and the aging community."}]},{"#name":"biography","$":{"xmlns:ce":true,"xmlns:aep":true,"xmlns:mml":true,"xmlns:xs":true,"xmlns:xlink":true,"xmlns:xocs":true,"xmlns:tb":true,"xmlns:xsi":true,"xmlns:cals":true,"xmlns:sb":true,"xmlns:sa":true,"xmlns:ja":true,"xmlns":true,"id":"bg020","view":"all"},"$$":[{"#name":"link","$":{"id":"lk00060","locator":"fx4","href":"pii:S0925231220309838/fx4","role":"http://data.elsevier.com/vocabulary/ElsevierContentTypes/23.4","type":"simple"}},{"#name":"simple-para","$":{"id":"sp0025","view":"all"},"$$":[{"#name":"__text__","_":"Naoyuki Kubota,"},{"#name":"hsp","$":{"sp":"0.25"}},{"#name":"__text__","_":"Faculty of Systems Design, Tokyo Metropolitan University, Tokyo, Japan Naoyuki Kubota received the B.Sc. degree from Osaka Kyoiku University, Kashiwara, Japan, in 1992, the M.Eng. degree from Hokkaido University, Hokkaido, Japan, in 1994, and the D.E. degree from Nagoya University, Nagoya, Japan, in 1997. He joined the Osaka Institute of Technology, Osaka, Japan, in 1997. He joined the Department of Human and Artificial Intelligence Systems, University of Fukui, Fukui, Japan, as an Associate Professor in 2000. He joined the Department of Mechanical Engineering, Tokyo Metropolitan University, Tokyo, Japan, in 2004. He was an Associate Professor from 2005 to 2012, and has been a Professor since 2012 at the Department of System Design, Tokyo Metropolitan University."}]}]},{"#name":"biography","$":{"xmlns:ce":true,"xmlns:aep":true,"xmlns:mml":true,"xmlns:xs":true,"xmlns:xlink":true,"xmlns:xocs":true,"xmlns:tb":true,"xmlns:xsi":true,"xmlns:cals":true,"xmlns:sb":true,"xmlns:sa":true,"xmlns:ja":true,"xmlns":true,"id":"bg025","view":"all"},"$$":[{"#name":"link","$":{"id":"lk00065","locator":"fx5","href":"pii:S0925231220309838/fx5","role":"http://data.elsevier.com/vocabulary/ElsevierContentTypes/23.4","type":"simple"}},{"#name":"simple-para","$":{"id":"sp0030","view":"all"},"_":"Zhaojie Ju received the B.S. in automatic control and the M.S. in intelligent robotics both from Huazhong University of Science and Technology, China, and the Ph.D. degree in intelligent robotics at the University of Portsmouth, UK. He held a research appointment at the University College London, London, U.K., before he started his independent academic position at the University of Portsmouth, U.K., in 2012. His research interests include machine intelligence, pattern recognition, and their applications on human motion analysis, multi-fingered robotic hand control, human–robot interaction and collaboration, and robot skill learning. He has authored or co-authored over 180 publications in journals, book chapters, and conference proceedings and received four best paper awards and one Best AE Award in ICRA2018."}]}],"floats":[],"footnotes":[],"attachments":[{"attachment-eid":"1-s2.0-S0925231220309838-fx1.jpg","ucs-locator":"https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0925231220309838/fx1/DOWNSAMPLED/image/jpeg/d2d59e80bf74e9671f42699fd98145c3/fx1.jpg","file-basename":"fx1","filename":"fx1.jpg","extension":"jpg","filesize":"5641","pixel-height":"155","pixel-width":"111","attachment-type":"IMAGE-DOWNSAMPLED"},{"attachment-eid":"1-s2.0-S0925231220309838-fx2.jpg","ucs-locator":"https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0925231220309838/fx2/DOWNSAMPLED/image/jpeg/937e99f0333c57cea6ae9883dac4a803/fx2.jpg","file-basename":"fx2","filename":"fx2.jpg","extension":"jpg","filesize":"5735","pixel-height":"155","pixel-width":"111","attachment-type":"IMAGE-DOWNSAMPLED"},{"attachment-eid":"1-s2.0-S0925231220309838-fx3.jpg","ucs-locator":"https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0925231220309838/fx3/DOWNSAMPLED/image/jpeg/8f854280a9dd43e042cadb9d582d43af/fx3.jpg","file-basename":"fx3","filename":"fx3.jpg","extension":"jpg","filesize":"7192","pixel-height":"155","pixel-width":"111","attachment-type":"IMAGE-DOWNSAMPLED"},{"attachment-eid":"1-s2.0-S0925231220309838-fx4.jpg","ucs-locator":"https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0925231220309838/fx4/DOWNSAMPLED/image/jpeg/80dc799dc726c313460c56c1acdd9b24/fx4.jpg","file-basename":"fx4","filename":"fx4.jpg","extension":"jpg","filesize":"4756","pixel-height":"155","pixel-width":"111","attachment-type":"IMAGE-DOWNSAMPLED"},{"attachment-eid":"1-s2.0-S0925231220309838-fx5.jpg","ucs-locator":"https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0925231220309838/fx5/DOWNSAMPLED/image/jpeg/2ed7f3840a33bbd8a4600759dd274d38/fx5.jpg","file-basename":"fx5","filename":"fx5.jpg","extension":"jpg","filesize":"6361","pixel-height":"155","pixel-width":"111","attachment-type":"IMAGE-DOWNSAMPLED"},{"attachment-eid":"1-s2.0-S0925231220309838-fx1.sml","ucs-locator":"https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0925231220309838/fx1/THUMBNAIL/image/gif/8bbb982b06f312f13bb9c3fd5d3f11f9/fx1.sml","file-basename":"fx1","filename":"fx1.sml","extension":"sml","filesize":"16195","pixel-height":"164","pixel-width":"117","attachment-type":"IMAGE-THUMBNAIL"},{"attachment-eid":"1-s2.0-S0925231220309838-fx2.sml","ucs-locator":"https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0925231220309838/fx2/THUMBNAIL/image/gif/263ab112104b61e363351937daf6d187/fx2.sml","file-basename":"fx2","filename":"fx2.sml","extension":"sml","filesize":"13494","pixel-height":"164","pixel-width":"117","attachment-type":"IMAGE-THUMBNAIL"},{"attachment-eid":"1-s2.0-S0925231220309838-fx3.sml","ucs-locator":"https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0925231220309838/fx3/THUMBNAIL/image/gif/eb01a3de56d5e84f6e7abaa288fae1a5/fx3.sml","file-basename":"fx3","filename":"fx3.sml","extension":"sml","filesize":"16385","pixel-height":"164","pixel-width":"117","attachment-type":"IMAGE-THUMBNAIL"},{"attachment-eid":"1-s2.0-S0925231220309838-fx4.sml","ucs-locator":"https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0925231220309838/fx4/THUMBNAIL/image/gif/44745c38531ee1e6a1b3e0ac7abbec8e/fx4.sml","file-basename":"fx4","filename":"fx4.sml","extension":"sml","filesize":"11422","pixel-height":"164","pixel-width":"117","attachment-type":"IMAGE-THUMBNAIL"},{"attachment-eid":"1-s2.0-S0925231220309838-fx5.sml","ucs-locator":"https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0925231220309838/fx5/THUMBNAIL/image/gif/f385afb145741e271872a424e0ad1331/fx5.sml","file-basename":"fx5","filename":"fx5.sml","extension":"sml","filesize":"15239","pixel-height":"164","pixel-width":"117","attachment-type":"IMAGE-THUMBNAIL"},{"attachment-eid":"1-s2.0-S0925231220309838-fx1_lrg.jpg","ucs-locator":"https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0925231220309838/fx1/HIGHRES/image/jpeg/ed169733e266c387298186dada47bbae/fx1_lrg.jpg","file-basename":"fx1","filename":"fx1_lrg.jpg","extension":"jpg","filesize":"14883","pixel-height":"413","pixel-width":"295","attachment-type":"IMAGE-HIGH-RES"},{"attachment-eid":"1-s2.0-S0925231220309838-fx2_lrg.jpg","ucs-locator":"https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0925231220309838/fx2/HIGHRES/image/jpeg/f2f45dbdd96160f109305e8e5e5f1d7b/fx2_lrg.jpg","file-basename":"fx2","filename":"fx2_lrg.jpg","extension":"jpg","filesize":"15373","pixel-height":"413","pixel-width":"295","attachment-type":"IMAGE-HIGH-RES"},{"attachment-eid":"1-s2.0-S0925231220309838-fx3_lrg.jpg","ucs-locator":"https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0925231220309838/fx3/HIGHRES/image/jpeg/7864a7482642cdb1445820cbd8e3a0bb/fx3_lrg.jpg","file-basename":"fx3","filename":"fx3_lrg.jpg","extension":"jpg","filesize":"22752","pixel-height":"413","pixel-width":"295","attachment-type":"IMAGE-HIGH-RES"},{"attachment-eid":"1-s2.0-S0925231220309838-fx4_lrg.jpg","ucs-locator":"https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0925231220309838/fx4/HIGHRES/image/jpeg/c5d2430616e7dd996dd4984ba34eb3b9/fx4_lrg.jpg","file-basename":"fx4","filename":"fx4_lrg.jpg","extension":"jpg","filesize":"13545","pixel-height":"413","pixel-width":"295","attachment-type":"IMAGE-HIGH-RES"},{"attachment-eid":"1-s2.0-S0925231220309838-fx5_lrg.jpg","ucs-locator":"https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0925231220309838/fx5/HIGHRES/image/jpeg/9e49feb3d4b3d576910851109f62f819/fx5_lrg.jpg","file-basename":"fx5","filename":"fx5_lrg.jpg","extension":"jpg","filesize":"18630","pixel-height":"413","pixel-width":"295","attachment-type":"IMAGE-HIGH-RES"}]},"body":{},"chapters":{"toc":[],"isLoading":false},"changeViewLinks":{"showFullTextLink":false,"showAbstractLink":true},"citingArticles":{},"combinedContentItems":{"content":[{"#name":"keywords","$$":[{"#name":"keywords","$":{"xmlns:ce":true,"xmlns:aep":true,"xmlns:xoe":true,"xmlns:mml":true,"xmlns:xs":true,"xmlns:xlink":true,"xmlns:xocs":true,"xmlns:tb":true,"xmlns:xsi":true,"xmlns:cals":true,"xmlns:sb":true,"xmlns:sa":true,"xmlns:ja":true,"xmlns":true,"class":"keyword","id":"kg005","view":"all"},"$$":[{"#name":"section-title","$":{"id":"st010"},"_":"Keywords"},{"#name":"keyword","$":{"id":"k0005"},"$$":[{"#name":"text","_":"Facial Expression Recognition"}]},{"#name":"keyword","$":{"id":"k0010"},"$$":[{"#name":"text","_":"Convolutional Neural Network"}]},{"#name":"keyword","$":{"id":"k0015"},"$$":[{"#name":"text","_":"Attention Mechanism"}]},{"#name":"keyword","$":{"id":"k0020"},"$$":[{"#name":"text","_":"Local Binary Patten"}]},{"#name":"keyword","$":{"id":"k0025"},"$$":[{"#name":"text","_":"Image Classification"}]}]}]},{"#name":"miscellaneous","$":{"xmlns:ce":true,"xmlns:aep":true,"xmlns:xoe":true,"xmlns:mml":true,"xmlns:xs":true,"xmlns:xlink":true,"xmlns:xocs":true,"xmlns:tb":true,"xmlns:xsi":true,"xmlns:cals":true,"xmlns:sb":true,"xmlns:sa":true,"xmlns:ja":true,"xmlns":true,"id":"ms005"},"_":"Communicated by Y. Liu"}],"floats":[],"footnotes":[],"attachments":[]},"crossMark":{"isOpen":false},"domainConfig":{"cdnAssetsHost":"https://sdfestaticassets-eu-west-1.sciencedirectassets.com","assetRoute":"https://sdfestaticassets-eu-west-1.sciencedirectassets.com/prod/fe5f1a9a67d6a2bd1341815211e4a5a7e50a5117"},"downloadIssue":{"openOnPageLoad":false,"isOpen":false,"downloadCapOpen":false,"articles":[],"selected":[]},"enrichedContent":{"tableOfContents":false,"researchData":{"hasResearchData":false,"dataProfile":{},"openData":{},"mendeleyData":{},"databaseLinking":{}},"geospatialData":{"attachments":[]},"interactiveCaseInsights":{},"virtualMicroscope":{}},"entitledRecommendations":{"openOnPageLoad":false,"isOpen":false,"articles":[],"selected":[],"currentPage":1,"totalPages":1},"exam":{},"helpText":{"keyDates":{"html":"<div class=\"key-dates-help\"><h3 class=\"u-margin-s-bottom u-h4\">Publication milestones</h3><p class=\"u-margin-m-bottom\">The dates displayed for an article provide information on when various publication milestones were reached at the journal that has published the article. Where applicable, activities on preceding journals at which the article was previously under consideration are not shown (for instance submission, revisions, rejection).</p><p class=\"u-margin-xs-bottom\">The publication milestones include:</p><ul class=\"key-dates-help-list u-margin-m-bottom u-padding-s-left\"><li><span class=\"u-text-italic\">Received</span>: The date the article was originally submitted to the journal.</li><li><span class=\"u-text-italic\">Revised</span>: The date the most recent revision of the article was submitted to the journal. Dates corresponding to intermediate revisions are not shown.</li><li><span class=\"u-text-italic\">Accepted</span>: The date the article was accepted for publication in the journal.</li><li><span class=\"u-text-italic\">Available online</span>: The date a version of the article was made available online in the journal.</li><li><span class=\"u-text-italic\">Version of Record</span>: The date the finalized version of the article was made available in the journal.</li></ul><p>More information on publishing policies can be found on the <a class=\"anchor anchor-secondary u-display-inline anchor-underline\" href=\"https://www.elsevier.com/about/policies-and-standards/publishing-ethics\" target=\"_blank\"><span class=\"anchor-text-container\"><span class=\"anchor-text\">Publishing Ethics Policies</span></span></a> page. View our <a class=\"anchor anchor-secondary u-display-inline anchor-underline\" href=\"https://www.elsevier.com/researcher/author/submit-your-paper\" target=\"_blank\"><span class=\"anchor-text-container\"><span class=\"anchor-text\">Publishing with Elsevier: step-by-step</span></span></a> page to learn more about the publishing process. For any questions on your own submission or other questions related to publishing an article, <a class=\"anchor anchor-secondary u-display-inline anchor-underline\" href=\"https://service.elsevier.com/app/phone/supporthub/publishing\" target=\"_blank\"><span class=\"anchor-text-container\"><span class=\"anchor-text\">contact our Researcher support team.</span></span></a></p></div>","title":"What do these dates mean?"}},"glossary":{},"issueNavigation":{"previous":{},"next":{}},"linkingHubLinks":{},"metrics":{"isOpen":true},"preview":{},"rawtext":"","recommendations":{},"references":{},"referenceLinks":{"internal":[],"internalLoaded":false,"external":[]},"refersTo":{},"referredToBy":{},"relatedContent":{"isModal":false,"isOpenSpecialIssueArticles":false,"isOpenVirtualSpecialIssueLink":false,"isOpenRecommendations":true,"isOpenSubstances":true,"citingArticles":[false,false,false,false,false,false],"recommendations":[false,false,false,false,false,false]},"seamlessAccess":{},"specialIssueArticles":{},"substances":{},"supplementaryFilesData":[],"tableOfContents":{"showEntitledTocLinks":true},"tail":{},"transientError":{"isOpen":false},"sidePanel":{"openState":1},"viewConfig":{"articleFeature":{"rightsAndContentLink":true,"sdAnswersButton":false},"pathPrefix":""},"virtualSpecialIssue":{"showVirtualSpecialIssueLink":false},"userCookiePreferences":{"STRICTLY_NECESSARY":true,"PERFORMANCE":true,"FUNCTIONAL":true,"TARGETING":true}};
      </script>
<noscript>
      JavaScript is disabled on your browser.
      Please enable JavaScript to use all the features on this page.
      <img src=https://smetrics.elsevier.com/b/ss/elsevier-sd-prod/1/G.4--NS/1728990728923?pageName=sd%3Aproduct%3Ajournal%3Aarticle&c16=els%3Arp%3Ast&c2=sd&v185=img&v33=ae%3AREG_SHIBBOLETH&c1=ae%3A50401&c12=ae%3A71970787 />
    </noscript>
<a class="anchor sr-only sr-only-focusable u-display-inline anchor-primary" href="#screen-reader-main-content"><span class="anchor-text-container"><span class="anchor-text">Skip to main content</span></span></a><a class="anchor sr-only sr-only-focusable u-display-inline anchor-primary" href="#screen-reader-main-title"><span class="anchor-text-container"><span class="anchor-text">Skip to article</span></span></a>
<div id="root"><div class="App" id="app" data-aa-name="root"><div class="page"><div class="sd-flex-container"><div class="sd-flex-content"><header id="gh-cnt"><div id="gh-main-cnt" class="u-flex-center-ver u-position-relative u-padding-s-hor u-padding-l-hor-from-xl"><a id="gh-branding" class="u-flex-center-ver" href="/" aria-label="ScienceDirect home page" data-aa-region="header" data-aa-name="ScienceDirect"><img class="gh-logo" src="https://sdfestaticassets-eu-west-1.sciencedirectassets.com/shared-assets/24/images/elsevier-non-solus-new-grey.svg" alt="Elsevier logo" height="48" width="54"><svg xmlns="http://www.w3.org/2000/svg" version="1.1" height="15" viewBox="0 0 190 23" role="img" class="gh-wordmark u-margin-s-left" aria-labelledby="gh-wm-science-direct" focusable="false" aria-hidden="true" alt="ScienceDirect Wordmark"><title id="gh-wm-science-direct">ScienceDirect</title><g><path fill="#EB6500" d="M3.81 6.9c0-1.48 0.86-3.04 3.7-3.04 1.42 0 3.1 0.43 4.65 1.32l0.13-2.64c-1.42-0.63-2.97-0.96-4.78-0.96 -4.62 0-6.6 2.44-6.6 5.45 0 5.61 8.78 6.14 8.78 9.93 0 1.48-1.15 3.04-3.86 3.04 -1.72 0-3.4-0.56-4.72-1.39l-0.36 2.64c1.55 0.76 3.57 1.06 5.15 1.06 4.26 0 6.7-2.48 6.7-5.51C12.59 11.49 3.81 10.76 3.81 6.9M20.27 9.01c0.23-0.13 0.69-0.26 1.72-0.26 1.72 0 2.41 0.3 2.41 1.58h2.38c0-0.36 0-0.79-0.03-1.09 -0.23-1.98-2.15-2.67-4.88-2.67 -3 0-6.7 2.31-6.7 7.76 0 5.22 2.77 7.99 6.63 7.99 1.68 0 3.47-0.36 4.95-1.39l-0.2-2.31c-0.99 0.82-2.84 1.52-4.06 1.52 -2.14 0-4.55-1.71-4.55-5.91C17.93 10.2 20.01 9.18 20.27 9.01"></path><rect x="29.42" y="6.97" fill="#EB6500" width="2.54" height="14.95"></rect><path fill="#EB6500" d="M30.67 0.7c-0.92 0-1.65 0.92-1.65 1.81 0 0.93 0.76 1.85 1.65 1.85 0.89 0 1.68-0.96 1.68-1.88C32.35 1.55 31.56 0.7 30.67 0.7M48.06 14.13c0-5.18-1.42-7.56-6.01-7.56 -3.86 0-6.67 2.77-6.67 7.92 0 4.92 2.97 7.82 6.73 7.82 2.81 0 4.36-0.63 5.68-1.42l-0.2-2.31c-0.89 0.79-2.94 1.55-4.69 1.55 -3.14 0-4.88-1.95-4.88-5.51v-0.49H48.06M39.91 9.18c0.17-0.17 1.29-0.46 1.98-0.46 2.48 0 3.76 0.53 3.86 3.43h-7.46C38.56 10.27 39.71 9.37 39.91 9.18zM58.82 6.57c-2.24 0-3.63 1.12-4.85 2.61l-0.4-2.21h-2.34l0.13 1.19c0.1 0.76 0.13 1.78 0.13 2.97v10.79h2.54V11.88c0.69-0.96 2.15-2.48 2.48-2.64 0.23-0.13 1.29-0.4 2.08-0.4 2.28 0 2.48 1.15 2.54 3.43 0.03 1.19 0.03 3.17 0.03 3.17 0.03 3-0.1 6.47-0.1 6.47h2.54c0 0 0.07-4.49 0.07-6.96 0-1.48 0.03-2.97-0.1-4.46C63.31 7.43 61.49 6.57 58.82 6.57M72.12 9.01c0.23-0.13 0.69-0.26 1.72-0.26 1.72 0 2.41 0.3 2.41 1.58h2.38c0-0.36 0-0.79-0.03-1.09 -0.23-1.98-2.15-2.67-4.88-2.67 -3 0-6.7 2.31-6.7 7.76 0 5.22 2.77 7.99 6.63 7.99 1.68 0 3.47-0.36 4.95-1.39l-0.2-2.31c-0.99 0.82-2.84 1.52-4.06 1.52 -2.15 0-4.55-1.71-4.55-5.91C69.77 10.2 71.85 9.18 72.12 9.01M92.74 14.13c0-5.18-1.42-7.56-6.01-7.56 -3.86 0-6.67 2.77-6.67 7.92 0 4.92 2.97 7.82 6.73 7.82 2.81 0 4.36-0.63 5.68-1.42l-0.2-2.31c-0.89 0.79-2.94 1.55-4.69 1.55 -3.14 0-4.88-1.95-4.88-5.51v-0.49H92.74M84.59 9.18c0.17-0.17 1.29-0.46 1.98-0.46 2.48 0 3.76 0.53 3.86 3.43h-7.46C83.24 10.27 84.39 9.37 84.59 9.18zM103.9 1.98h-7.13v19.93h6.83c7.26 0 9.77-5.68 9.77-10.03C113.37 7.33 110.93 1.98 103.9 1.98M103.14 19.8h-3.76V4.1h4.09c5.38 0 6.96 4.39 6.96 7.79C110.43 16.87 108.19 19.8 103.14 19.8zM118.38 0.7c-0.92 0-1.65 0.92-1.65 1.81 0 0.93 0.76 1.85 1.65 1.85 0.89 0 1.69-0.96 1.69-1.88C120.07 1.55 119.28 0.7 118.38 0.7"></path><rect x="117.13" y="6.97" fill="#EB6500" width="2.54" height="14.95"></rect><path fill="#EB6500" d="M130.2 6.6c-1.62 0-2.87 1.45-3.4 2.74l-0.43-2.37h-2.34l0.13 1.19c0.1 0.76 0.13 1.75 0.13 2.9v10.86h2.54v-9.51c0.53-1.29 1.72-3.7 3.17-3.7 0.96 0 1.06 0.99 1.06 1.22l2.08-0.6V9.18c0-0.03-0.03-0.17-0.06-0.4C132.8 7.36 131.91 6.6 130.2 6.6M145.87 14.13c0-5.18-1.42-7.56-6.01-7.56 -3.86 0-6.67 2.77-6.67 7.92 0 4.92 2.97 7.82 6.73 7.82 2.81 0 4.36-0.63 5.68-1.42l-0.2-2.31c-0.89 0.79-2.94 1.55-4.69 1.55 -3.14 0-4.89-1.95-4.89-5.51v-0.49H145.87M137.72 9.18c0.17-0.17 1.29-0.46 1.98-0.46 2.48 0 3.76 0.53 3.86 3.43h-7.46C136.37 10.27 137.52 9.37 137.72 9.18zM153.23 9.01c0.23-0.13 0.69-0.26 1.72-0.26 1.72 0 2.41 0.3 2.41 1.58h2.38c0-0.36 0-0.79-0.03-1.09 -0.23-1.98-2.14-2.67-4.88-2.67 -3 0-6.7 2.31-6.7 7.76 0 5.22 2.77 7.99 6.63 7.99 1.69 0 3.47-0.36 4.95-1.39l-0.2-2.31c-0.99 0.82-2.84 1.52-4.06 1.52 -2.15 0-4.55-1.71-4.55-5.91C150.89 10.2 152.97 9.18 153.23 9.01M170 19.44c-0.92 0.36-1.72 0.69-2.51 0.69 -1.16 0-1.58-0.66-1.58-2.34V8.95h3.93V6.97h-3.93V2.97h-2.48v3.99h-2.71v1.98h2.71v9.67c0 2.64 1.39 3.73 3.33 3.73 1.15 0 2.54-0.39 3.43-0.79L170 19.44M173.68 5.96c-1.09 0-2-0.87-2-1.97 0-1.1 0.91-1.97 2-1.97s1.98 0.88 1.98 1.98C175.66 5.09 174.77 5.96 173.68 5.96zM173.67 2.46c-0.85 0-1.54 0.67-1.54 1.52 0 0.85 0.69 1.54 1.54 1.54 0.85 0 1.54-0.69 1.54-1.54C175.21 3.13 174.52 2.46 173.67 2.46zM174.17 5.05c-0.09-0.09-0.17-0.19-0.25-0.3l-0.41-0.56h-0.16v0.87h-0.39V2.92c0.22-0.01 0.47-0.03 0.66-0.03 0.41 0 0.82 0.16 0.82 0.64 0 0.29-0.21 0.55-0.49 0.63 0.23 0.32 0.45 0.62 0.73 0.91H174.17zM173.56 3.22l-0.22 0.01v0.63h0.22c0.26 0 0.43-0.05 0.43-0.34C174 3.28 173.83 3.21 173.56 3.22z"></path></g></svg></a><div class="gh-nav-cnt u-hide-from-print"><div class="gh-nav-links-container gh-nav-links-container-h u-hide-from-print gh-nav-content-container"><nav aria-label="links" class="gh-nav gh-nav-links gh-nav-h"><ul class="gh-nav-list u-list-reset"><li class="gh-nav-item gh-move-to-spine"><a class="anchor gh-nav-action text-s anchor-secondary anchor-medium" href="/browse/journals-and-books" id="gh-journals-books-link" data-aa-region="header" data-aa-name="Journals &amp; Books"><span class="anchor-text-container"><span class="anchor-text">Journals &amp; Books</span></span></a></li></ul></nav><nav aria-label="utilities" class="gh-nav gh-nav-utilities gh-nav-h"><ul class="gh-nav-list u-list-reset"><li class="gh-nav-help text-s u-flex-center-ver u-gap-6 gh-nav-action"><div class="gh-move-to-spine gh-help-button gh-help-icon gh-nav-item"><div class="popover" id="gh-help-icon-popover"><div id="popover-trigger-gh-help-icon-popover"><input type="hidden"><button class="button-link button-link-secondary gh-icon-btn button-link-medium button-link-icon-left" title="Help" aria-expanded="false" type="button"><svg focusable="false" viewBox="0 0 114 128" height="20" width="20" class="icon icon-help gh-icon"><path d="M57 8C35.69 7.69 15.11 21.17 6.68 40.71c-8.81 19.38-4.91 43.67 9.63 59.25 13.81 15.59 36.85 21.93 56.71 15.68 21.49-6.26 37.84-26.81 38.88-49.21 1.59-21.15-10.47-42.41-29.29-52.1C74.76 10.17 65.88 7.99 57 8zm0 10c20.38-.37 39.57 14.94 43.85 34.85 4.59 18.53-4.25 39.23-20.76 48.79-17.05 10.59-40.96 7.62-54.9-6.83-14.45-13.94-17.42-37.85-6.83-54.9C26.28 26.5 41.39 17.83 57 18zm-.14 14C45.31 32.26 40 40.43 40 50v2h10v-2c0-4.22 2.22-9.66 8-9.24 5.5.4 6.32 5.14 5.78 8.14C62.68 55.06 52 58.4 52 69.4V76h10v-5.56c0-8.16 11.22-11.52 12-21.7.74-9.86-5.56-16.52-16-16.74-.39-.01-.76-.01-1.14 0zM52 82v10h10V82H52z"></path></svg><span class="button-link-text-container"><span class="button-link-text">Help</span></span></button></div></div></div></li><li class="gh-nav-search text-s u-flex-center-ver u-gap-6 gh-nav-action"><div class="gh-search-toggle gh-nav-item search-button-link"><a class="anchor button-link-secondary anchor-secondary u-margin-l-left gh-nav-action gh-icon-btn anchor-medium anchor-icon-left anchor-with-icon" href="/search" id="gh-search-link" title="Search" data-aa-button="search-in-header-opened-from-article" role="button"><svg focusable="false" viewBox="0 0 100 128" height="20" class="icon icon-search gh-icon"><path d="M19.22 76.91c-5.84-5.84-9.05-13.6-9.05-21.85s3.21-16.01 9.05-21.85c5.84-5.83 13.59-9.05 21.85-9.05 8.25 0 16.01 3.22 21.84 9.05 5.84 5.84 9.05 13.6 9.05 21.85s-3.21 16.01-9.05 21.85c-5.83 5.83-13.59 9.05-21.84 9.05-8.26 0-16.01-3.22-21.85-9.05zm80.33 29.6L73.23 80.19c5.61-7.15 8.68-15.9 8.68-25.13 0-10.91-4.25-21.17-11.96-28.88-7.72-7.71-17.97-11.96-28.88-11.96S19.9 18.47 12.19 26.18C4.47 33.89.22 44.15.22 55.06s4.25 21.17 11.97 28.88C19.9 91.65 30.16 95.9 41.07 95.9c9.23 0 17.98-3.07 25.13-8.68l26.32 26.32 7.03-7.03"></path></svg><span class="anchor-text-container"><span class="anchor-text">Search</span></span></a></div></li></ul></nav></div></div><div class="gh-profile-container u-hide-from-print"><div id="gh-profile-cnt" class="u-flex-center-ver gh-move-to-spine"><div class="popover" id="gh-profile-dropdown"><div id="popover-trigger-gh-profile-dropdown"><input type="hidden"><button class="button-link gh-icon-btn gh-user-icon u-margin-l-left gh-truncate text-s button-link-secondary button-link-medium button-link-icon-left" title="Gergo Gyori" aria-expanded="false" type="button"><svg focusable="false" viewBox="0 0 106 128" height="20" class="icon icon-person"><path d="M11.07 120l.84-9.29C13.88 91.92 35.25 87.78 53 87.78c17.74 0 39.11 4.13 41.08 22.84l.84 9.38h10.04l-.93-10.34C101.88 89.23 83.89 78 53 78S4.11 89.22 1.95 109.73L1.04 120h10.03M53 17.71c-9.72 0-18.24 8.69-18.24 18.59 0 13.67 7.84 23.98 18.24 23.98S71.24 49.97 71.24 36.3c0-9.9-8.52-18.59-18.24-18.59zM53 70c-15.96 0-28-14.48-28-33.67C25 20.97 37.82 8 53 8s28 12.97 28 28.33C81 55.52 68.96 70 53 70"></path></svg><span class="button-link-text-container"><span class="button-link-text">Gergo Gyori</span></span></button></div></div></div></div><div class="gh-move-to-spine u-hide-from-print gh-institution-item"><div class="popover text-s" id="institution-popover"><div id="popover-trigger-institution-popover"><input type="hidden"><button class="button-link gh-icon-btn gh-has-institution gh-truncate text-s button-link-secondary u-margin-l-left button-link-medium button-link-icon-left" id="gh-inst-icon-btn" aria-expanded="false" aria-label="Institutional Access" title="IT University of Copenhagen" type="button"><svg focusable="false" viewBox="0 0 106 128" height="20" class="icon icon-institution gh-inst-icon"><path d="M84 98h10v10H12V98h10V52h14v46h10V52h14v46h10V52h14v46zM12 36.86l41-20.84 41 20.84V42H12v-5.14zM104 52V30.74L53 4.8 2 30.74V52h10v36H2v30h102V88H94V52h10z"></path></svg><span class="button-link-text-container"><span class="button-link-text">IT University of Copenhagen</span></span></button></div></div></div><div id="gh-mobile-menu" class="mobile-menu u-hide-from-print"><div class="gh-hamburger u-fill-grey7"><button class="button-link u-flex-center-ver button-link-primary button-link-icon-left" aria-label="Toggle mobile menu" aria-expanded="false" type="button"><svg class="gh-hamburger-svg-el gh-hamburger-closed" role="img" aria-hidden="true" height="20" width="20"><path d="M0 14h40v2H0zm0-7h40v2H0zm0-7h40v2H0z"></path></svg></button></div><div id="gh-overlay" class="mobile-menu-overlay u-overlay u-display-none" role="button" tabindex="-1"></div><div id="gh-drawer" aria-label="Mobile menu" class="" role="navigation"></div></div></div></header><div class="Article" id="mathjax-container" role="main"><div class="accessbar-sticky"><div id="screen-reader-main-content"></div><div role="region" aria-label="Download options and search"><div class="accessbar"><div class="accessbar-label"></div><ul aria-label="PDF Options"><li class="ViewPDF"><a class="link-button accessbar-utility-component accessbar-utility-link link-button-primary link-button-icon-left" target="_blank" aria-label="View PDF. Opens in a new window." href="/science/article/pii/S0925231220309838/pdfft?md5=6060445b3bd2193d0e2fd0cc1bd93d5e&amp;pid=1-s2.0-S0925231220309838-main.pdf" rel="nofollow"><svg focusable="false" viewBox="0 0 35 32" height="20" class="icon icon-pdf-multicolor"><path d="M7 .362h17.875l6.763 6.1V31.64H6.948V16z" stroke="#000" stroke-width=".703" fill="#fff"></path><path d="M.167 2.592H22.39V9.72H.166z" fill="#da0000"></path><path fill="#fff9f9" d="M5.97 3.638h1.62c1.053 0 1.483.677 1.488 1.564.008.96-.6 1.564-1.492 1.564h-.644v1.66h-.977V3.64m.977.897v1.34h.542c.27 0 .596-.068.596-.673-.002-.6-.32-.667-.596-.667h-.542m3.8.036v2.92h.35c.933 0 1.223-.448 1.228-1.462.008-1.06-.316-1.45-1.23-1.45h-.347m-.977-.94h1.03c1.68 0 2.523.586 2.534 2.39.01 1.688-.607 2.4-2.534 2.4h-1.03V3.64m4.305 0h2.63v.934h-1.657v.894H16.6V6.4h-1.56v2.026h-.97V3.638"></path><path d="M19.462 13.46c.348 4.274-6.59 16.72-8.508 15.792-1.82-.85 1.53-3.317 2.92-4.366-2.864.894-5.394 3.252-3.837 3.93 2.113.895 7.048-9.25 9.41-15.394zM14.32 24.874c4.767-1.526 14.735-2.974 15.152-1.407.824-3.157-13.72-.37-15.153 1.407zm5.28-5.043c2.31 3.237 9.816 7.498 9.788 3.82-.306 2.046-6.66-1.097-8.925-4.164-4.087-5.534-2.39-8.772-1.682-8.732.917.047 1.074 1.307.67 2.442-.173-1.406-.58-2.44-1.224-2.415-1.835.067-1.905 4.46 1.37 9.065z" fill="#f91d0a"></path></svg><span class="link-button-text-container"><span class="link-button-text"><span>View&nbsp;<strong>PDF</strong></span></span></span></a></li><li class="DownloadFullIssue"><button class="button-link accessbar-utility-component button-link-primary" aria-label="Download full issue" type="button"><span class="button-link-text-container"><span class="button-link-text"><span>Download full issue</span></span></span></button></li></ul><form class="QuickSearch" action="/search#submit" method="get" aria-label="form"><div class="search-input"><div class="search-input-container search-input-container-no-label"><label class="search-input-label u-hide-visually" for="article-quick-search">Search ScienceDirect</label><input type="search" id="article-quick-search" name="qs" class="search-input-field" aria-describedby="article-quick-search-description-message" aria-invalid="false" aria-label="Search ScienceDirect" placeholder="Search ScienceDirect" value=""></div><div class="search-input-message-container"><div class="search-input-validation-error" aria-live="polite"></div><div id="article-quick-search-description-message"></div></div></div><button type="submit" class="button u-margin-xs-left button-primary small button-icon-only" aria-disabled="false" aria-label="Submit search"><svg focusable="false" viewBox="0 0 100 128" height="20" class="icon icon-search"><path d="M19.22 76.91c-5.84-5.84-9.05-13.6-9.05-21.85s3.21-16.01 9.05-21.85c5.84-5.83 13.59-9.05 21.85-9.05 8.25 0 16.01 3.22 21.84 9.05 5.84 5.84 9.05 13.6 9.05 21.85s-3.21 16.01-9.05 21.85c-5.83 5.83-13.59 9.05-21.84 9.05-8.26 0-16.01-3.22-21.85-9.05zm80.33 29.6L73.23 80.19c5.61-7.15 8.68-15.9 8.68-25.13 0-10.91-4.25-21.17-11.96-28.88-7.72-7.71-17.97-11.96-28.88-11.96S19.9 18.47 12.19 26.18C4.47 33.89.22 44.15.22 55.06s4.25 21.17 11.97 28.88C19.9 91.65 30.16 95.9 41.07 95.9c9.23 0 17.98-3.07 25.13-8.68l26.32 26.32 7.03-7.03"></path></svg></button><input type="hidden" name="origin" value="article"><input type="hidden" name="zone" value="qSearch"></form></div></div></div><div class="article-wrapper grid row"><div role="navigation" class="u-display-block-from-lg col-lg-6 u-padding-s-top sticky-table-of-contents" aria-label="Table of contents"><div class="TableOfContents" lang="en"><div class="Outline" id="toc-outline"><h2 class="u-h4">Outline</h2><ol class="u-padding-xs-bottom"><li class="toc-list-entry-outline-padding"><a class="anchor u-truncate-anchor-text anchor-primary" href="#ab005" data-aa-button="sd:product:journal:article:type=anchor:name=outlinelink" title="Abstract"><span class="anchor-text-container"><span class="anchor-text">Abstract</span></span></a></li><li class="ai-components-toc-entry toc-list-entry-outline-padding" id="ai-components-toc-entry"><span class="ai-badges"><strong class="badge-info badge-md u-font-sans u-bg-info-blue text-2xs u-margin-xs-right">Beta</strong><strong class="badge-info badge-md u-font-sans u-bg-ai-dark-purple text-2xs">Powered by GenAI</strong></span><a class="anchor u-truncate-anchor-text anchor-primary" href="#ai-components-toc-id" title="Questions answered in this article"><span class="anchor-text-container"><span class="anchor-text">Questions answered in this article</span></span></a></li><li class="toc-list-entry-outline-padding"><a class="anchor u-truncate-anchor-text anchor-primary" href="#kg005" data-aa-button="sd:product:journal:article:type=anchor:name=outlinelink" title="Keywords"><span class="anchor-text-container"><span class="anchor-text">Keywords</span></span></a></li><li class="toc-list-entry-outline-padding"><a class="anchor u-truncate-anchor-text anchor-primary" href="#s0005" data-aa-button="sd:product:journal:article:type=anchor:name=outlinelink" title="1. Introduction"><span class="anchor-text-container"><span class="anchor-text">1. Introduction</span></span></a></li><li class="toc-list-entry-outline-padding"><a class="anchor u-truncate-anchor-text anchor-primary" href="#s0010" data-aa-button="sd:product:journal:article:type=anchor:name=outlinelink" title="2. Related works"><span class="anchor-text-container"><span class="anchor-text">2. Related works</span></span></a></li><li class="toc-list-entry-outline-padding"><a class="anchor u-truncate-anchor-text anchor-primary" href="#s0015" data-aa-button="sd:product:journal:article:type=anchor:name=outlinelink" title="3. The proposed method"><span class="anchor-text-container"><span class="anchor-text">3. The proposed method</span></span></a></li><li class="toc-list-entry-outline-padding"><a class="anchor u-truncate-anchor-text anchor-primary" href="#s0040" data-aa-button="sd:product:journal:article:type=anchor:name=outlinelink" title="4. Experimental results"><span class="anchor-text-container"><span class="anchor-text">4. Experimental results</span></span></a></li><li class="toc-list-entry-outline-padding"><a class="anchor u-truncate-anchor-text anchor-primary" href="#s0080" data-aa-button="sd:product:journal:article:type=anchor:name=outlinelink" title="5. Conclusions and future work"><span class="anchor-text-container"><span class="anchor-text">5. Conclusions and future work</span></span></a></li><li class="toc-list-entry-outline-padding"><a class="anchor u-truncate-anchor-text anchor-primary" href="#s0090" data-aa-button="sd:product:journal:article:type=anchor:name=outlinelink" title="CRediT authorship contribution statement"><span class="anchor-text-container"><span class="anchor-text">CRediT authorship contribution statement</span></span></a></li><li class="toc-list-entry-outline-padding"><a class="anchor u-truncate-anchor-text anchor-primary" href="#coi005" data-aa-button="sd:product:journal:article:type=anchor:name=outlinelink" title="Declaration of Competing Interest"><span class="anchor-text-container"><span class="anchor-text">Declaration of Competing Interest</span></span></a></li><li class="toc-list-entry-outline-padding"><a class="anchor u-truncate-anchor-text anchor-primary" href="#ak005" data-aa-button="sd:product:journal:article:type=anchor:name=outlinelink" title="Acknowledgements"><span class="anchor-text-container"><span class="anchor-text">Acknowledgements</span></span></a></li><li class="toc-list-entry-outline-padding"><a class="anchor u-truncate-anchor-text anchor-primary" href="#bi005" data-aa-button="sd:product:journal:article:type=anchor:name=outlinelink" title="References"><span class="anchor-text-container"><span class="anchor-text">References</span></span></a></li><li class="toc-list-entry-outline-padding"><a class="anchor u-truncate-anchor-text anchor-primary" href="#bg005" data-aa-button="sd:product:journal:article:type=anchor:name=outlinelink" title="Vitae"><span class="anchor-text-container"><span class="anchor-text">Vitae</span></span></a></li></ol><button class="button-link u-margin-xs-top u-margin-s-bottom button-link-primary button-link-icon-right" aria-expanded="false" data-aa-button="sd:product:journal:article:type=menu:name=show-full-outline" type="button"><span class="button-link-text-container"><span class="button-link-text">Show full outline</span></span><svg focusable="false" viewBox="0 0 92 128" height="20" class="icon icon-navigate-down"><path d="M1 51l7-7 38 38 38-38 7 7-45 45z"></path></svg></button><div class="PageDivider"></div></div><div class="CitedBy" id="toc-cited-by"><h2 class="u-h4"><a class="anchor anchor-primary" href="#section-cited-by"><span class="anchor-text-container"><span class="anchor-text">Cited by (242)</span></span></a></h2><div class="PageDivider"></div></div><div class="Figures" id="toc-figures"><h2 class="u-h4">Figures (8)</h2><ol class="u-margin-s-bottom"><li><a class="anchor u-display-block anchor-primary anchor-icon-only anchor-with-icon" href="#f0005" data-aa-button="sd:product:journal:article:type=anchor:name=figure"><img alt="Fig. 1. The main steps of facial expression recognition" class="u-display-block" height="58px" src="https://ars.els-cdn.com/content/image/1-s2.0-S0925231220309838-gr1.sml" width="219px"></a></li><li><a class="anchor u-display-block anchor-primary anchor-icon-only anchor-with-icon" href="#f0010" data-aa-button="sd:product:journal:article:type=anchor:name=figure"><img alt="Fig. 2. Sample images in the NCUFE dataset" class="u-display-block" height="58px" src="https://ars.els-cdn.com/content/image/1-s2.0-S0925231220309838-gr2.sml" width="219px"></a></li><li><a class="anchor u-display-block anchor-primary anchor-icon-only anchor-with-icon" href="#f0015" data-aa-button="sd:product:journal:article:type=anchor:name=figure"><img alt="Fig. 3. Examples of the datasets used in our experiments, from top to bottom is from…" class="u-display-block" height="164px" src="https://ars.els-cdn.com/content/image/1-s2.0-S0925231220309838-gr3.sml" width="199px"></a></li><li><a class="anchor u-display-block anchor-primary anchor-icon-only anchor-with-icon" href="#f0020" data-aa-button="sd:product:journal:article:type=anchor:name=figure"><img alt="Fig. 4. The architecture of our network" class="u-display-block" height="136px" src="https://ars.els-cdn.com/content/image/1-s2.0-S0925231220309838-gr4.sml" width="219px"></a></li><li><a class="anchor u-display-block anchor-primary anchor-icon-only anchor-with-icon" href="#f0025" data-aa-button="sd:product:journal:article:type=anchor:name=figure"><img alt="Fig. 5. The architecture of dimensionality reduction-based CNN and feature…" class="u-display-block" height="120px" src="https://ars.els-cdn.com/content/image/1-s2.0-S0925231220309838-gr5.sml" width="219px"></a></li><li><a class="anchor u-display-block anchor-primary anchor-icon-only anchor-with-icon" href="#f0030" data-aa-button="sd:product:journal:article:type=anchor:name=figure"><img alt="Fig. 6. Results of attention heatmap" class="u-display-block" height="164px" src="https://ars.els-cdn.com/content/image/1-s2.0-S0925231220309838-gr6.sml" width="153px"></a></li></ol><button class="button-link u-margin-xs-top u-margin-s-bottom button-link-primary button-link-icon-right" data-aa-button="sd:product:journal:article:type=menu:name=show-figures" type="button"><span class="button-link-text-container"><span class="button-link-text">Show 2 more figures</span></span><svg focusable="false" viewBox="0 0 92 128" height="20" class="icon icon-navigate-down"><path d="M1 51l7-7 38 38 38-38 7 7-45 45z"></path></svg></button><div class="PageDivider"></div></div><div class="Tables" id="toc-tables"><h2 class="u-h4">Tables (8)</h2><ol class="u-padding-s-bottom"><li class="toc-list-entry-outline-padding"><a class="anchor u-truncate-anchor-text anchor-primary anchor-icon-left anchor-with-icon" href="#t0005" data-aa-button="sd:product:journal:article:type=anchor:name=table" title="Comparison of different LBPs on FER2013 dataset."><svg focusable="false" viewBox="0 0 98 128" height="20" class="icon icon-table"><path d="M54 68h32v32H54V68zm-42 0h32v32H12V68zm0-42h32v32H12V26zm42 0h32v32H54V26zM2 110h94V16H2v94z"></path></svg><span class="anchor-text-container"><span class="anchor-text">Table 1</span></span></a></li><li class="toc-list-entry-outline-padding"><a class="anchor u-truncate-anchor-text anchor-primary anchor-icon-left anchor-with-icon" href="#t0010" data-aa-button="sd:product:journal:article:type=anchor:name=table" title="Comparison of different architectures on the FER2013 dataset."><svg focusable="false" viewBox="0 0 98 128" height="20" class="icon icon-table"><path d="M54 68h32v32H54V68zm-42 0h32v32H12V68zm0-42h32v32H12V26zm42 0h32v32H54V26zM2 110h94V16H2v94z"></path></svg><span class="anchor-text-container"><span class="anchor-text">Table 2</span></span></a></li><li class="toc-list-entry-outline-padding"><a class="anchor u-truncate-anchor-text anchor-primary anchor-icon-left anchor-with-icon" href="#t0015" data-aa-button="sd:product:journal:article:type=anchor:name=table" title="Comparison of different dilation rates of the reconstruction module on the FER2013 dataset."><svg focusable="false" viewBox="0 0 98 128" height="20" class="icon icon-table"><path d="M54 68h32v32H54V68zm-42 0h32v32H12V68zm0-42h32v32H12V26zm42 0h32v32H54V26zM2 110h94V16H2v94z"></path></svg><span class="anchor-text-container"><span class="anchor-text">Table 3</span></span></a></li><li class="toc-list-entry-outline-padding"><a class="anchor u-truncate-anchor-text anchor-primary anchor-icon-left anchor-with-icon" href="#t0020" data-aa-button="sd:product:journal:article:type=anchor:name=table" title="Comparison of different methods on the FER2013 dataset."><svg focusable="false" viewBox="0 0 98 128" height="20" class="icon icon-table"><path d="M54 68h32v32H54V68zm-42 0h32v32H12V68zm0-42h32v32H12V26zm42 0h32v32H54V26zM2 110h94V16H2v94z"></path></svg><span class="anchor-text-container"><span class="anchor-text">Table 4</span></span></a></li><li class="toc-list-entry-outline-padding"><a class="anchor u-truncate-anchor-text anchor-primary anchor-icon-left anchor-with-icon" href="#t0025" data-aa-button="sd:product:journal:article:type=anchor:name=table" title="Comparison of different methods on the CK+ dataset."><svg focusable="false" viewBox="0 0 98 128" height="20" class="icon icon-table"><path d="M54 68h32v32H54V68zm-42 0h32v32H12V68zm0-42h32v32H12V26zm42 0h32v32H54V26zM2 110h94V16H2v94z"></path></svg><span class="anchor-text-container"><span class="anchor-text">Table 5</span></span></a></li><li class="toc-list-entry-outline-padding"><a class="anchor u-truncate-anchor-text anchor-primary anchor-icon-left anchor-with-icon" href="#t0030" data-aa-button="sd:product:journal:article:type=anchor:name=table" title="Comparison of different methods on the Oulu-CASIA dataset."><svg focusable="false" viewBox="0 0 98 128" height="20" class="icon icon-table"><path d="M54 68h32v32H54V68zm-42 0h32v32H12V68zm0-42h32v32H12V26zm42 0h32v32H54V26zM2 110h94V16H2v94z"></path></svg><span class="anchor-text-container"><span class="anchor-text">Table 6</span></span></a></li></ol><button class="button-link u-margin-xs-top u-margin-s-bottom button-link-primary button-link-icon-right" data-aa-button="sd:product:journal:article:type=menu:name=show-tables" type="button"><span class="button-link-text-container"><span class="button-link-text">Show all tables</span></span><svg focusable="false" viewBox="0 0 92 128" height="20" class="icon icon-navigate-down"><path d="M1 51l7-7 38 38 38-38 7 7-45 45z"></path></svg></button><div class="PageDivider"></div></div></div></div><article class="col-lg-12 col-md-16 pad-left pad-right u-padding-s-top" lang="en"><div class="Publication" id="publication"><div class="publication-brand u-display-block-from-sm"><a class="anchor anchor-primary" href="/journal/neurocomputing" title="Go to Neurocomputing on ScienceDirect"><span class="anchor-text-container"><span class="anchor-text"><img class="publication-brand-image" src="https://sdfestaticassets-eu-west-1.sciencedirectassets.com/prod/fe5f1a9a67d6a2bd1341815211e4a5a7e50a5117/image/elsevier-non-solus.png" alt="Elsevier"></span></span></a></div><div class="publication-volume u-text-center"><h2 class="publication-title u-h3" id="publication-title"><a class="anchor anchor-secondary publication-title-link" href="/journal/neurocomputing" title="Go to Neurocomputing on ScienceDirect"><span class="anchor-text-container"><span class="anchor-text">Neurocomputing</span></span></a></h2><div class="text-xs"><a class="anchor anchor-primary" href="/journal/neurocomputing/vol/411/suppl/C" title="Go to table of contents for this volume/issue"><span class="anchor-text-container"><span class="anchor-text">Volume 411</span></span></a>, <!-- -->21 October 2020<!-- -->, Pages 340-350</div></div><div class="publication-cover u-display-block-from-sm"><a class="anchor anchor-primary" href="/journal/neurocomputing/vol/411/suppl/C"><span class="anchor-text-container"><span class="anchor-text"><img class="publication-cover-image" src="https://ars.els-cdn.com/content/image/1-s2.0-S0925231220X00336-cov150h.gif" alt="Neurocomputing"></span></span></a></div></div><h1 id="screen-reader-main-title" class="Head u-font-serif u-h2 u-margin-s-ver"><span class="title-text">Attention mechanism-based CNN for facial expression recognition</span></h1><div class="Banner" id="banner"><div class="wrapper truncated"><div class="AuthorGroups"><div class="author-group" id="author-group"><span class="sr-only">Author links open overlay panel</span><button class="button-link button-link-secondary button-link-underline" data-sd-ui-side-panel-opener="true" data-xocs-content-type="author" data-xocs-content-id="au005" type="button"><span class="button-link-text-container"><span class="button-link-text"><span class="react-xocs-alternative-link"><span class="given-name">Jing</span> <span class="text surname">Li</span> </span><span class="author-ref" id="baf005"><sup>a</sup></span></span></span></button>, <button class="button-link button-link-secondary button-link-underline" data-sd-ui-side-panel-opener="true" data-xocs-content-type="author" data-xocs-content-id="au010" type="button"><span class="button-link-text-container"><span class="button-link-text"><span class="react-xocs-alternative-link"><span class="given-name">Kan</span> <span class="text surname">Jin</span> </span><span class="author-ref" id="baf005"><sup>a</sup></span></span></span></button>, <button class="button-link button-link-secondary button-link-underline" data-sd-ui-side-panel-opener="true" data-xocs-content-type="author" data-xocs-content-id="au015" type="button"><span class="button-link-text-container"><span class="button-link-text"><span class="react-xocs-alternative-link"><span class="given-name">Dalin</span> <span class="text surname">Zhou</span> </span><span class="author-ref" id="baf010"><sup>b</sup></span></span></span></button>, <button class="button-link button-link-secondary button-link-underline" data-sd-ui-side-panel-opener="true" data-xocs-content-type="author" data-xocs-content-id="au020" type="button"><span class="button-link-text-container"><span class="button-link-text"><span class="react-xocs-alternative-link"><span class="given-name">Naoyuki</span> <span class="text surname">Kubota</span> </span><span class="author-ref" id="baf015"><sup>c</sup></span></span></span></button>, <button class="button-link button-link-secondary button-link-underline" data-sd-ui-side-panel-opener="true" data-xocs-content-type="author" data-xocs-content-id="au025" type="button"><span class="button-link-text-container"><span class="button-link-text"><span class="react-xocs-alternative-link"><span class="given-name">Zhaojie</span> <span class="text surname">Ju</span> </span><span class="author-ref" id="baf010"><sup>b</sup></span><svg focusable="false" viewBox="0 0 106 128" height="20" title="Correspondence author icon" class="icon icon-person react-xocs-author-icon u-fill-grey8"><path d="M11.07 120l.84-9.29C13.88 91.92 35.25 87.78 53 87.78c17.74 0 39.11 4.13 41.08 22.84l.84 9.38h10.04l-.93-10.34C101.88 89.23 83.89 78 53 78S4.11 89.22 1.95 109.73L1.04 120h10.03M53 17.71c-9.72 0-18.24 8.69-18.24 18.59 0 13.67 7.84 23.98 18.24 23.98S71.24 49.97 71.24 36.3c0-9.9-8.52-18.59-18.24-18.59zM53 70c-15.96 0-28-14.48-28-33.67C25 20.97 37.82 8 53 8s28 12.97 28 28.33C81 55.52 68.96 70 53 70"></path></svg><svg focusable="false" viewBox="0 0 102 128" height="20" title="Author email or social media contact details icon" class="icon icon-envelope react-xocs-author-icon u-fill-grey8"><path d="M55.8 57.2c-1.78 1.31-5.14 1.31-6.9 0L17.58 34h69.54L55.8 57.19zM0 32.42l42.94 32.62c2.64 1.95 6.02 2.93 9.4 2.93s6.78-.98 9.42-2.93L102 34.34V24H0zM92 88.9L73.94 66.16l-8.04 5.95L83.28 94H18.74l18.38-23.12-8.04-5.96L10 88.94V51.36L0 42.9V104h102V44.82l-10 8.46V88.9"></path></svg></span></span></button></div></div></div><button class="button-link u-margin-s-ver button-link-primary button-link-icon-right" id="show-more-btn" type="button" data-aa-button="icon-expand"><span class="button-link-text-container"><span class="button-link-text">Show more</span></span><svg focusable="false" viewBox="0 0 92 128" height="20" class="icon icon-navigate-down"><path d="M1 51l7-7 38 38 38-38 7 7-45 45z"></path></svg></button><div class="banner-options u-padding-xs-bottom"><div class="toc-button-wrap u-display-inline-block u-display-none-from-lg u-margin-s-right"><button class="button-link button-link-secondary button-link-icon-left button-link-has-colored-icon" type="button"><svg focusable="false" viewBox="0 0 128 128" height="20" class="icon icon-list"><path d="M23 26a9 9 0 0 0-9 9 9 9 0 0 0 9 9 9 9 0 0 0 9-9 9 9 0 0 0-9-9zm23 4v10h68V30zM23 56a9 9 0 0 0-9 9 9 9 0 0 0 9 9 9 9 0 0 0 9-9 9 9 0 0 0-9-9zm23 4v10h68V60zM23 86a9 9 0 0 0-9 9 9 9 0 0 0 9 9 9 9 0 0 0 9-9 9 9 0 0 0-9-9zm23 4v10h68V90z"></path></svg><span class="button-link-text-container"><span class="button-link-text">Outline</span></span></button></div><button class="button-link AddToMendeley button-link-secondary u-margin-s-right u-display-inline-flex-from-md button-link-icon-left button-link-has-colored-icon" type="button"><svg focusable="false" viewBox="0 0 86 128" height="20" class="icon icon-plus"><path d="M48 58V20H38v38H0v10h38v38h10V68h38V58z"></path></svg><span class="button-link-text-container"><span class="button-link-text">Add to Mendeley</span></span></button><div class="Social u-display-inline-block" id="social"><div class="popover social-popover" id="social-popover"><div id="popover-trigger-social-popover"><button class="button-link button-link-secondary u-margin-s-right button-link-icon-left button-link-has-colored-icon" aria-expanded="false" aria-haspopup="true" type="button"><svg focusable="false" viewBox="0 0 114 128" height="20" class="icon icon-share"><path d="M90 112c-6.62 0-12-5.38-12-12s5.38-12 12-12 12 5.38 12 12-5.38 12-12 12zM24 76c-6.62 0-12-5.38-12-12s5.38-12 12-12 12 5.38 12 12-5.38 12-12 12zm66-60c6.62 0 12 5.38 12 12s-5.38 12-12 12-12-5.38-12-12 5.38-12 12-12zm0 62c-6.56 0-12.44 2.9-16.48 7.48L45.1 70.2c.58-1.98.9-4.04.9-6.2s-.32-4.22-.9-6.2l28.42-15.28C77.56 47.1 83.44 50 90 50c12.14 0 22-9.86 22-22S102.14 6 90 6s-22 9.86-22 22c0 1.98.28 3.9.78 5.72L40.14 49.1C36.12 44.76 30.38 42 24 42 11.86 42 2 51.86 2 64s9.86 22 22 22c6.38 0 12.12-2.76 16.14-7.12l28.64 15.38c-.5 1.84-.78 3.76-.78 5.74 0 12.14 9.86 22 22 22s22-9.86 22-22-9.86-22-22-22z"></path></svg><span class="button-link-text-container"><span class="button-link-text">Share</span></span></button></div></div></div><div class="ExportCitation u-display-inline-block" id="export-citation"><div class="popover export-citation-popover" id="export-citation-popover"><div id="popover-trigger-export-citation-popover"><button class="button-link button-link-secondary button-link-icon-left button-link-has-colored-icon" aria-expanded="false" aria-haspopup="true" type="button"><svg focusable="false" viewBox="0 0 104 128" height="20" class="icon icon-cited-by-66"><path d="M2 58.78V106h44V64H12v-5.22C12 40.28 29.08 32 46 32V22C20.1 22 2 37.12 2 58.78zM102 32V22c-25.9 0-44 15.12-44 36.78V106h44V64H68v-5.22C68 40.28 85.08 32 102 32z"></path></svg><span class="button-link-text-container"><span class="button-link-text">Cite</span></span></button></div></div></div></div></div><div class="ArticleIdentifierLinks u-margin-xs-bottom text-xs" id="article-identifier-links"><a class="anchor doi anchor-primary" href="https://doi.org/10.1016/j.neucom.2020.06.014" target="_blank" rel="noreferrer noopener" aria-label="Persistent link using digital object identifier" title="Persistent link using digital object identifier"><span class="anchor-text-container"><span class="anchor-text">https://doi.org/10.1016/j.neucom.2020.06.014</span><svg focusable="false" viewBox="0 0 8 8" height="20" aria-label="Opens in new window" class="icon icon-arrow-up-right-tiny arrow-external-link"><path d="M1.12949 2.1072V1H7V6.85795H5.89111V2.90281L0.784057 8L0 7.21635L5.11902 2.1072H1.12949Z"></path></svg></span></a><a class="anchor rights-and-content anchor-primary" href="https://s100.copyright.com/AppDispatchServlet?publisherName=ELS&amp;contentID=S0925231220309838&amp;orderBeanReset=true" target="_blank" rel="noreferrer noopener"><span class="anchor-text-container"><span class="anchor-text">Get rights and content</span><svg focusable="false" viewBox="0 0 8 8" height="20" aria-label="Opens in new window" class="icon icon-arrow-up-right-tiny arrow-external-link"><path d="M1.12949 2.1072V1H7V6.85795H5.89111V2.90281L0.784057 8L0 7.21635L5.11902 2.1072H1.12949Z"></path></svg></span></a></div><section class="ReferencedArticles"></section><section class="ReferencedArticles"></section><div class="PageDivider"></div><div class="Abstracts u-font-serif" id="abstracts"><div class="abstract author" id="ab005" lang="en"><h2 class="section-title u-h4 u-margin-l-top u-margin-xs-bottom">Abstract</h2><div id="as005"><div class="u-margin-s-bottom" id="sp0005"><span><span><a href="/topics/biochemistry-genetics-and-molecular-biology/facial-recognition" title="Learn more about Facial expression recognition from ScienceDirect's AI-generated Topic Pages" class="topic-link">Facial expression recognition</a> is a hot </span><a href="/topics/computer-science/research-topic" title="Learn more about research topic from ScienceDirect's AI-generated Topic Pages" class="topic-link">research topic</a><span><span> and can be applied in many <a href="/topics/engineering/computervision" title="Learn more about computer vision from ScienceDirect's AI-generated Topic Pages" class="topic-link">computer vision</a><span> fields, such as human–computer interaction, <a href="/topics/computer-science/affective-computing" title="Learn more about affective computing from ScienceDirect's AI-generated Topic Pages" class="topic-link">affective computing</a> and so on. In this paper, we propose a novel end-to-end network with </span></span><a href="/topics/computer-science/attention-machine-learning" title="Learn more about attention mechanism from ScienceDirect's AI-generated Topic Pages" class="topic-link">attention mechanism</a><span> for automatic facial expression recognition. The new <a href="/topics/computer-science/network-architecture" title="Learn more about network architecture from ScienceDirect's AI-generated Topic Pages" class="topic-link">network architecture</a> consists of four parts, i.e., the feature extraction module, the attention module, the reconstruction module and the classification module. The </span></span></span><a href="/topics/engineering/local-binary-pattern" title="Learn more about LBP from ScienceDirect's AI-generated Topic Pages" class="topic-link">LBP</a><span><span> features extract image <a href="/topics/computer-science/texture-information" title="Learn more about texture information from ScienceDirect's AI-generated Topic Pages" class="topic-link">texture information</a> and then catch the small movements of the faces, which can improve the network performance. Attention mechanism can make the </span><a href="/topics/computer-science/neural-network" title="Learn more about neural network from ScienceDirect's AI-generated Topic Pages" class="topic-link">neural network</a><span><span> pay more attention to useful features. We combine LBP features and attention mechanism to enhance the attention model to obtain better results. In addition, we collected and labelled a new facial expression dataset of seven expressions from 35 subjects aged from 20 to 25. For each subject, we captured both <a href="/topics/engineering/rgb-image" title="Learn more about RGB images from ScienceDirect's AI-generated Topic Pages" class="topic-link">RGB images</a> and depth images with a </span><a href="/topics/computer-science/microsoft-kinect-sensor" title="Learn more about Microsoft Kinect sensor from ScienceDirect's AI-generated Topic Pages" class="topic-link">Microsoft Kinect sensor</a>. For each image type, there are 245 image sequences, each of which contains 110 images, resulting in 26,950 images in total. We apply the newly proposed method to our own dataset and four representative expression datasets, i.e., JAFFE, CK+, FER2013 and Oulu-CASIA. The experimental results demonstrate the feasibility and effectiveness of the proposed method.</span></span></div></div></div></div><div id="reading-assistant-main-body-section"><section class="questions-and-answers" aria-labelledby="ai-components-toc-id"><div class="questions-and-answers-header"><div class="questions-and-answers-title"><h2 id="ai-components-toc-id">Questions answered in this article</h2><span class="ai-badges"><strong class="badge-info badge-md u-font-sans u-bg-info-blue text-2xs u-margin-xs-right">Beta</strong><strong class="badge-info badge-md u-font-sans u-bg-ai-dark-purple text-2xs">Powered by GenAI</strong></span></div><i class="u-clr-grey7"><span>This is generative AI content and the quality may vary. </span><button class="button-link button-link-secondary u-text-italic u-clr-grey7 button-link-underline" type="button"><span class="button-link-text-container"><span class="button-link-text">Learn more</span></span></button><span>.</span></i></div><ol class="accordion-container u-font-sans " role="tablist"><li class="accordion-panel"><button id="0-accordion-tab-0" type="button" class="u-display-flex icon-left accordion-panel-title u-padding-xs-ver u-text-left" tabindex="0" role="tab" aria-expanded="false" aria-selected="true" aria-controls="0-accordion-panel-0"><svg focusable="false" viewBox="0 0 92 128" height="20" class="icon icon-navigate-down accordion-icon"><path d="M1 51l7-7 38 38 38-38 7 7-45 45z"></path></svg><div><span class="accordion-title"><span class="accordion-text">What happens to the recognition rates when LBP or attention is not used?</span></span></div></button></li><li class="accordion-panel"><button id="0-accordion-tab-1" type="button" class="u-display-flex icon-left accordion-panel-title u-padding-xs-ver u-text-left" tabindex="0" role="tab" aria-expanded="false" aria-selected="true" aria-controls="0-accordion-panel-1"><svg focusable="false" viewBox="0 0 92 128" height="20" class="icon icon-navigate-down accordion-icon"><path d="M1 51l7-7 38 38 38-38 7 7-45 45z"></path></svg><div><span class="accordion-title"><span class="accordion-text">What deep network architectures were most works inspired by for facial expression recognition?</span></span></div></button></li><li class="accordion-panel"><button id="0-accordion-tab-2" type="button" class="u-display-flex icon-left accordion-panel-title u-padding-xs-ver u-text-left" tabindex="0" role="tab" aria-expanded="false" aria-selected="true" aria-controls="0-accordion-panel-2"><svg focusable="false" viewBox="0 0 92 128" height="20" class="icon icon-navigate-down accordion-icon"><path d="M1 51l7-7 38 38 38-38 7 7-45 45z"></path></svg><div><span class="accordion-title"><span class="accordion-text">How are LBP features and convolution features combined in the attention module?</span></span></div></button></li><li class="accordion-panel"><button id="0-accordion-tab-3" type="button" class="u-display-flex icon-left accordion-panel-title u-padding-xs-ver u-text-left" tabindex="0" role="tab" aria-expanded="false" aria-selected="true" aria-controls="0-accordion-panel-3"><svg focusable="false" viewBox="0 0 92 128" height="20" class="icon icon-navigate-down accordion-icon"><path d="M1 51l7-7 38 38 38-38 7 7-45 45z"></path></svg><div><span class="accordion-title"><span class="accordion-text">Why is data augmentation important for facial expression recognition?</span></span></div></button></li><li class="accordion-panel"><button id="0-accordion-tab-4" type="button" class="u-display-flex icon-left accordion-panel-title u-padding-xs-ver u-text-left" tabindex="0" role="tab" aria-expanded="false" aria-selected="true" aria-controls="0-accordion-panel-4"><svg focusable="false" viewBox="0 0 92 128" height="20" class="icon icon-navigate-down accordion-icon"><path d="M1 51l7-7 38 38 38-38 7 7-45 45z"></path></svg><div><span class="accordion-title"><span class="accordion-text">What are the advantages of using LBP features in facial expression recognition?</span></span></div></button></li></ol></section></div><ul id="issue-navigation" class="issue-navigation u-margin-s-bottom u-bg-grey1"><li class="previous move-left u-padding-s-ver u-padding-s-left"><a class="button-alternative button-alternative-tertiary u-display-flex button-alternative-icon-left" href="/science/article/pii/S0925231220310444"><svg focusable="false" viewBox="0 0 54 128" height="20" class="icon icon-navigate-left"><path d="M1 61l45-45 7 7-38 38 38 38-7 7z"></path></svg><span class="button-alternative-text-container"><span class="button-alternative-text">Previous <span class="extra-detail-1">article</span><span class="extra-detail-2"> in issue</span></span></span></a></li><li class="next move-right u-padding-s-ver u-padding-s-right"><a class="button-alternative button-alternative-tertiary u-display-flex button-alternative-icon-right" href="/science/article/pii/S0925231220308687"><span class="button-alternative-text-container"><span class="button-alternative-text">Next <span class="extra-detail-1">article</span><span class="extra-detail-2"> in issue</span></span></span><svg focusable="false" viewBox="0 0 54 128" height="20" class="icon icon-navigate-right"><path d="M1 99l38-38L1 23l7-7 45 45-45 45z"></path></svg></a></li></ul><div class="Keywords u-font-serif"><div id="kg005" class="keywords-section"><h2 class="section-title u-h4 u-margin-l-top u-margin-xs-bottom">Keywords</h2><div id="k0005" class="keyword"><span>Facial Expression Recognition</span></div><div id="k0010" class="keyword"><span>Convolutional Neural Network</span></div><div id="k0015" class="keyword"><span>Attention Mechanism</span></div><div id="k0020" class="keyword"><span>Local Binary Patten</span></div><div id="k0025" class="keyword"><span>Image Classification</span></div></div></div><div class="Body u-font-serif" id="body"><div><section id="s0005"><h2 id="st015" class="u-h4 u-margin-l-top u-margin-xs-bottom">1. Introduction</h2><div class="u-margin-s-bottom" id="p0005"><span>Facial expression is one of the most direct signals to express inner feelings in people's daily communication. The physical or mental state of a person at one time can be obtained by analyzing facial expressions. Therefore, facial expression recognition is of great significance in autopilot, human–computer interaction, medical treatment and other fields related to facial expression, and has gradually become a more and more important research direction. In <a href="/topics/computer-science/machine-learning" title="Learn more about machine learning from ScienceDirect's AI-generated Topic Pages" class="topic-link">machine learning</a>, a variety of facial expression </span><a href="/topics/computer-science/recognition-algorithm" title="Learn more about recognition algorithms from ScienceDirect's AI-generated Topic Pages" class="topic-link">recognition algorithms</a><span> have been proposed. Due to the complexity, diversity, occlusion, lighting and other challenges in facial expression recognition, the <a href="/topics/computer-science/recognition-accuracy" title="Learn more about recognition accuracy from ScienceDirect's AI-generated Topic Pages" class="topic-link">recognition accuracy</a> in practical applications is still unsatisfactory.</span></div><div class="u-margin-s-bottom"><div id="p0010">In this paper, our goal is to design a recognition model that can automatically and accurately recognize different expressions in various types of images. Generally, the process of facial expression recognition consists of the following steps: i) pre-processing of the facial expression data; ii) feature extraction of facial expressions; and iii) classification of facial expressions. The process is depicted in <a class="anchor anchor-primary" href="#f0005" name="bf0005" data-sd-ui-side-panel-opener="true" data-xocs-content-type="reference" data-xocs-content-id="f0005"><span class="anchor-text-container"><span class="anchor-text">Fig. 1</span></span></a><span><span>. We usually consider two kinds of features, namely, <a href="/topics/computer-science/facial-feature" title="Learn more about facial features from ScienceDirect's AI-generated Topic Pages" class="topic-link">facial features</a> and </span><a href="/topics/computer-science/face-model" title="Learn more about face model from ScienceDirect's AI-generated Topic Pages" class="topic-link">face model</a> features. The facial features are specific points on the face, like eyes, mouth, and eyebrows; the face model features are the features used to model the face. Therefore, there are several ways for facial representation, like using the whole face to get the holistic representation, using specific points for local representation, and combining different points to get a hybrid approach. The final step is to define some set of categories to which the expression belongs.</span></div><figure class="figure text-xs" id="f0005"><span><img src="https://ars.els-cdn.com/content/image/1-s2.0-S0925231220309838-gr1.jpg" height="190" alt="" aria-describedby="cn0005"><ol class="u-margin-s-bottom"><li><a class="anchor download-link u-font-sans anchor-primary" href="https://ars.els-cdn.com/content/image/1-s2.0-S0925231220309838-gr1_lrg.jpg" target="_blank" download="" title="Download high-res image (108KB)"><span class="anchor-text-container"><span class="anchor-text">Download: <span class="download-link-title">Download high-res image (108KB)</span></span></span></a></li><li><a class="anchor download-link u-font-sans anchor-primary" href="https://ars.els-cdn.com/content/image/1-s2.0-S0925231220309838-gr1.jpg" target="_blank" download="" title="Download full-size image"><span class="anchor-text-container"><span class="anchor-text">Download: <span class="download-link-title">Download full-size image</span></span></span></a></li></ol></span><span class="captions text-s"><span id="cn0005"><p id="sp0035"><span class="label">Fig. 1</span>. The main steps of <a href="/topics/biochemistry-genetics-and-molecular-biology/facial-recognition" title="Learn more about facial expression recognition from ScienceDirect's AI-generated Topic Pages" class="topic-link">facial expression recognition</a>.</p></span></span></figure></div><div class="u-margin-s-bottom" id="p0015"><span><span><span>When dealing with expression recognition as a classification problem, traditional methods often use hand-crafted features such as <a href="/topics/engineering/local-binary-pattern" title="Learn more about Local Binary Patterns from ScienceDirect's AI-generated Topic Pages" class="topic-link">Local Binary Patterns</a><span> (LBP) and traditional <a href="/topics/engineering/machine-learning-algorithm" title="Learn more about machine learning algorithms from ScienceDirect's AI-generated Topic Pages" class="topic-link">machine learning algorithms</a> such as </span></span><a href="/topics/chemical-engineering/support-vector-machine" title="Learn more about Support Vector Machine from ScienceDirect's AI-generated Topic Pages" class="topic-link">Support Vector Machine</a> (SVM) to classify. These methods may work well on datasets collected under laboratory conditions, but with the introduction of more challenging expression datasets in uncontrollable environments (e.g., FER2013), they cannot effectively achieve this task. Fortunately, </span><a href="/topics/computer-science/deep-learning" title="Learn more about deep learning from ScienceDirect's AI-generated Topic Pages" class="topic-link">deep learning</a> has made a breakthrough in convenience and effectiveness since it has been used to deal with the </span><a href="/topics/computer-science/image-classification" title="Learn more about image classification from ScienceDirect's AI-generated Topic Pages" class="topic-link">image classification</a> problem.</div><div class="u-margin-s-bottom" id="p0020"><span><span>The <a href="/topics/computer-science/attention-machine-learning" title="Learn more about attention mechanism from ScienceDirect's AI-generated Topic Pages" class="topic-link">attention mechanism</a> has been widely used in various </span><a href="/topics/computer-science/computer-vision-task" title="Learn more about computer vision tasks from ScienceDirect's AI-generated Topic Pages" class="topic-link">computer vision tasks</a><span> such as <a href="/topics/computer-science/saliency-detection" title="Learn more about saliency detection from ScienceDirect's AI-generated Topic Pages" class="topic-link">saliency detection</a> </span></span><a class="anchor anchor-primary" href="#b0095" name="bb0095" data-sd-ui-side-panel-opener="true" data-xocs-content-type="reference" data-xocs-content-id="b0095"><span class="anchor-text-container"><span class="anchor-text">[15]</span></span></a>, crowd counting <a class="anchor anchor-primary" href="#b0100" name="bb0100" data-sd-ui-side-panel-opener="true" data-xocs-content-type="reference" data-xocs-content-id="b0100"><span class="anchor-text-container"><span class="anchor-text">[16]</span></span></a> and facial expression recognition <a class="anchor anchor-primary" href="#b0210" name="bb0210" data-sd-ui-side-panel-opener="true" data-xocs-content-type="reference" data-xocs-content-id="b0210"><span class="anchor-text-container"><span class="anchor-text">[38]</span></span></a>. The operation can select the most useful features for classification by learning an intermediate attention map and then applying element-wise product on attention maps and source feature maps to weight the importance of different features. For the task of facial expression recognition, the features that are useful for recognition are mainly in some key parts such as eyes, nose and mouth. The attention mechanism increases the weights of these key features and helps improve the expression recognition results.</div><div class="u-margin-s-bottom" id="p0025"><span>In this paper, we design a novel <a href="/topics/engineering/convolutional-neural-network" title="Learn more about Convolutional Neural Network from ScienceDirect's AI-generated Topic Pages" class="topic-link">Convolutional Neural Network</a> with an attention model for recognizing facial expressions. In </span><a class="anchor anchor-primary" href="#b0235" name="bb0235" data-sd-ui-side-panel-opener="true" data-xocs-content-type="reference" data-xocs-content-id="b0235"><span class="anchor-text-container"><span class="anchor-text">[43]</span></span></a><span>, it showed that using LBP features is better than using HOG and <a href="/topics/computer-science/gabor-feature" title="Learn more about Gabor features from ScienceDirect's AI-generated Topic Pages" class="topic-link">Gabor features</a><span><span> because LBP can achieve rotation invariance and grey-scale invariance and thus is suitable for extracting <a href="/topics/computer-science/texture-feature" title="Learn more about texture features from ScienceDirect's AI-generated Topic Pages" class="topic-link">texture features</a><span> at different scales and can solve the imbalance of displacement, <a href="/topics/computer-science/rotation-angle" title="Learn more about rotation angles from ScienceDirect's AI-generated Topic Pages" class="topic-link">rotation angles</a> and </span></span><a href="/topics/engineering/illumination-condition" title="Learn more about illumination conditions from ScienceDirect's AI-generated Topic Pages" class="topic-link">illumination conditions</a><span> in <a href="/topics/computer-science/facial-image" title="Learn more about facial images from ScienceDirect's AI-generated Topic Pages" class="topic-link">facial images</a>. In addition, LBP features can reflect fine facial changes in skin textures like wrinkles and furrows, which shows the changes of expressions. In </span></span></span><a class="anchor anchor-primary" href="#b0210" name="bb0210" data-sd-ui-side-panel-opener="true" data-xocs-content-type="reference" data-xocs-content-id="b0210"><span class="anchor-text-container"><span class="anchor-text">[38]</span></span></a>, an end-to-end network with an attention model was presented for facial expression recognition. The attention module makes the network focus more on useful features which are vital for expression recognition by increasing the weights of these features. This makes the network recognize expressions more efficiently. Inspired by <a class="anchor anchor-primary" href="#b0210" name="bb0210" data-sd-ui-side-panel-opener="true" data-xocs-content-type="reference" data-xocs-content-id="b0210"><span class="anchor-text-container"><span class="anchor-text">[38]</span></span></a>, <a class="anchor anchor-primary" href="#b0235" name="bb0235" data-sd-ui-side-panel-opener="true" data-xocs-content-type="reference" data-xocs-content-id="b0235"><span class="anchor-text-container"><span class="anchor-text">[43]</span></span></a><span>, we combine LBP features with an attention model for facial expression recognition. Embedding the attention model into the network allows the network to pay different attention and weight to different parts of the input data. This can make the <a href="/topics/computer-science/neural-network" title="Learn more about neural network from ScienceDirect's AI-generated Topic Pages" class="topic-link">neural network</a> pay more attention to useful features, which is vital to expression recognition. Furthermore, we combine LBP features with convolution features to improve our recognition results. The proposed method has been tested on five facial expression datasets, which are CK+ </span><a class="anchor anchor-primary" href="#b0075" name="bb0075" data-sd-ui-side-panel-opener="true" data-xocs-content-type="reference" data-xocs-content-id="b0075"><span class="anchor-text-container"><span class="anchor-text">[11]</span></span></a>, JAFFE <a class="anchor anchor-primary" href="#b0085" name="bb0085" data-sd-ui-side-panel-opener="true" data-xocs-content-type="reference" data-xocs-content-id="b0085"><span class="anchor-text-container"><span class="anchor-text">[13]</span></span></a>, FER2013 <a class="anchor anchor-primary" href="#b0215" name="bb0215" data-sd-ui-side-panel-opener="true" data-xocs-content-type="reference" data-xocs-content-id="b0215"><span class="anchor-text-container"><span class="anchor-text">[39]</span></span></a>, Oulu-CASIA <a class="anchor anchor-primary" href="#b0145" name="bb0145" data-sd-ui-side-panel-opener="true" data-xocs-content-type="reference" data-xocs-content-id="b0145"><span class="anchor-text-container"><span class="anchor-text">[25]</span></span></a>, and our self-collected Nanchang University Facial Expression (NCUFE).</div><div class="u-margin-s-bottom"><div id="p0030"><span>To verify the effectiveness of our algorithm, we collected a new facial expression dataset called NCUFE. The dataset consists of seven expressions (i.e., anger, disgust, fear, happiness, sadness, surprise and neutral). We collected these facial expression images from 35 graduate students (6 females and 29 males) by a <a href="/topics/computer-science/microsoft-kinect-sensor" title="Learn more about Microsoft Kinect sensor from ScienceDirect's AI-generated Topic Pages" class="topic-link">Microsoft Kinect sensor</a><span> for acquiring both <a href="/topics/engineering/rgb-image" title="Learn more about RGB images from ScienceDirect's AI-generated Topic Pages" class="topic-link">RGB images</a> and depth images. The sample images are shown in </span></span><a class="anchor anchor-primary" href="#f0010" name="bf0010" data-sd-ui-side-panel-opener="true" data-xocs-content-type="reference" data-xocs-content-id="f0010"><span class="anchor-text-container"><span class="anchor-text">Fig. 2</span></span></a>. For each student, the size of these two types of images is 1280*1024 and 512*424, respectively. For each image type, there are 245 image sequences, each of which contains 110 images, resulting in 26,950 images in total. During the process of image capture, the students sat on a chair in front of the Kinect and faced the camera. The distance between the face and the Kinect was about 100&nbsp;cm. We asked each student to look the expression examples printed on some pieces of paper and then make seven expressions.</div><figure class="figure text-xs" id="f0010"><span><img src="https://ars.els-cdn.com/content/image/1-s2.0-S0925231220309838-gr2.jpg" height="154" alt="" aria-describedby="cn0010"><ol class="u-margin-s-bottom"><li><a class="anchor download-link u-font-sans anchor-primary" href="https://ars.els-cdn.com/content/image/1-s2.0-S0925231220309838-gr2_lrg.jpg" target="_blank" download="" title="Download high-res image (59KB)"><span class="anchor-text-container"><span class="anchor-text">Download: <span class="download-link-title">Download high-res image (59KB)</span></span></span></a></li><li><a class="anchor download-link u-font-sans anchor-primary" href="https://ars.els-cdn.com/content/image/1-s2.0-S0925231220309838-gr2.jpg" target="_blank" download="" title="Download full-size image"><span class="anchor-text-container"><span class="anchor-text">Download: <span class="download-link-title">Download full-size image</span></span></span></a></li></ol></span><span class="captions text-s"><span id="cn0010"><p id="sp0040"><span class="label">Fig. 2</span>. Sample images in the NCUFE dataset. The left one is an <a href="/topics/computer-science/rgb-image" title="Learn more about RGB image from ScienceDirect's AI-generated Topic Pages" class="topic-link">RGB image</a>, and the right one is its corresponding depth image.</p></span></span></figure></div><div class="u-margin-s-bottom" id="p0035">The main contributions of this paper are as follows:<ul class="list"><li class="react-xocs-list-item"><span class="list-label">1)</span><span><div class="u-margin-s-bottom" id="p0040">We introduce a novel facial expression recognition method with attention mechanism. Not only raw images, but also LBP features are added to the attention layers of the network. LBP features contain <a href="/topics/computer-science/texture-information" title="Learn more about texture information from ScienceDirect's AI-generated Topic Pages" class="topic-link">texture information</a> and can reflect fine facial changes in skin textures, which can help distinguish expressions with subtle difference.</div></span></li><li class="react-xocs-list-item"><span class="list-label">2)</span><span><div class="u-margin-s-bottom" id="p0045">We collected and labelled a new dataset named Nanchang University Facial Expression (NCUFE) for facial expression recognition. The dataset includes 490 image sequence collected from 35 subjects labeled with seven facial expressions (i.e., anger, disgust, fear, happiness, sadness, surprise and neutral). For each subject, we captured both <a href="/topics/computer-science/rgb-image" title="Learn more about RGB images from ScienceDirect's AI-generated Topic Pages" class="topic-link">RGB images</a> and depth images.</div></span></li><li class="react-xocs-list-item"><span class="list-label">3)</span><span><div class="u-margin-s-bottom"><div id="p0050">We implement substantial experiments on five different datasets, as shown in <a class="anchor anchor-primary" href="#f0015" name="bf0015" data-sd-ui-side-panel-opener="true" data-xocs-content-type="reference" data-xocs-content-id="f0015"><span class="anchor-text-container"><span class="anchor-text">Fig. 3</span></span></a>. There are not only datasets collected under laboratory conditions, such as CK+, JAFFE, Oulu-CASIA and NCUFE, but also those collected in real world like FER2013. We also compare the model performance with some state-of-the-art expression recognition algorithms, and the results show that our model is superior.</div><figure class="figure text-xs" id="f0015"><span><img src="https://ars.els-cdn.com/content/image/1-s2.0-S0925231220309838-gr3.jpg" height="586" alt="" aria-describedby="cn0015"><ol class="u-margin-s-bottom"><li><a class="anchor download-link u-font-sans anchor-primary" href="https://ars.els-cdn.com/content/image/1-s2.0-S0925231220309838-gr3_lrg.jpg" target="_blank" download="" title="Download high-res image (331KB)"><span class="anchor-text-container"><span class="anchor-text">Download: <span class="download-link-title">Download high-res image (331KB)</span></span></span></a></li><li><a class="anchor download-link u-font-sans anchor-primary" href="https://ars.els-cdn.com/content/image/1-s2.0-S0925231220309838-gr3.jpg" target="_blank" download="" title="Download full-size image"><span class="anchor-text-container"><span class="anchor-text">Download: <span class="download-link-title">Download full-size image</span></span></span></a></li></ol></span><span class="captions text-s"><span id="cn0015"><p id="sp0045"><span class="label">Fig. 3</span>. Examples of the datasets used in our experiments, from top to bottom is from CK+ <a class="anchor anchor-primary" href="#b0075" name="bb0075" data-sd-ui-side-panel-opener="true" data-xocs-content-type="reference" data-xocs-content-id="b0075"><span class="anchor-text-container"><span class="anchor-text">[11]</span></span></a>, JAFFE <a class="anchor anchor-primary" href="#b0085" name="bb0085" data-sd-ui-side-panel-opener="true" data-xocs-content-type="reference" data-xocs-content-id="b0085"><span class="anchor-text-container"><span class="anchor-text">[13]</span></span></a>, Oulu-CASIA <a class="anchor anchor-primary" href="#b0145" name="bb0145" data-sd-ui-side-panel-opener="true" data-xocs-content-type="reference" data-xocs-content-id="b0145"><span class="anchor-text-container"><span class="anchor-text">[25]</span></span></a>, FER2013 <a class="anchor anchor-primary" href="#b0215" name="bb0215" data-sd-ui-side-panel-opener="true" data-xocs-content-type="reference" data-xocs-content-id="b0215"><span class="anchor-text-container"><span class="anchor-text">[39]</span></span></a>, and our dataset NCUFE.</p></span></span></figure></div></span></li></ul></div><div class="u-margin-s-bottom" id="p0055">The remainder of this paper is as follows. In <a class="anchor anchor-primary" href="#s0010" name="bs0010" data-sd-ui-side-panel-opener="true" data-xocs-content-type="reference" data-xocs-content-id="s0010"><span class="anchor-text-container"><span class="anchor-text">Section 2</span></span></a>, we introduce the related works in expression recognition and the existing algorithms. In <a class="anchor anchor-primary" href="#s0015" name="bs0015" data-sd-ui-side-panel-opener="true" data-xocs-content-type="reference" data-xocs-content-id="s0015"><span class="anchor-text-container"><span class="anchor-text">Section 3</span></span></a>, we describe the proposed method in detail. We describe our experimental process and results on different datasets and compare them with the results of the state-of-the-art algorithms in <a class="anchor anchor-primary" href="#s0040" name="bs0040" data-sd-ui-side-panel-opener="true" data-xocs-content-type="reference" data-xocs-content-id="s0040"><span class="anchor-text-container"><span class="anchor-text">Section 4</span></span></a>. We give a conclusion of the whole paper in <a class="anchor anchor-primary" href="#s0080" name="bs0080" data-sd-ui-side-panel-opener="true" data-xocs-content-type="reference" data-xocs-content-id="s0080"><span class="anchor-text-container"><span class="anchor-text">Section 5</span></span></a>.</div></section><section id="s0010"><h2 id="st020" class="u-h4 u-margin-l-top u-margin-xs-bottom">2. Related works</h2><div class="u-margin-s-bottom" id="p0060"><span><span>Traditional <a href="/topics/computer-science/facial-feature" title="Learn more about facial feature from ScienceDirect's AI-generated Topic Pages" class="topic-link">facial feature</a> extraction algorithms can be separated into two categories: 1) geometric-based methods, such as </span><a href="/topics/computer-science/active-appearance-model" title="Learn more about Active Appearance Models from ScienceDirect's AI-generated Topic Pages" class="topic-link">Active Appearance Models</a> (AAM) </span><a class="anchor anchor-primary" href="#b0105" name="bb0105" data-sd-ui-side-panel-opener="true" data-xocs-content-type="reference" data-xocs-content-id="b0105"><span class="anchor-text-container"><span class="anchor-text">[17]</span></span></a>; and 2) appearance-based methods, such as LBP <a class="anchor anchor-primary" href="#b0060" name="bb0060" data-sd-ui-side-panel-opener="true" data-xocs-content-type="reference" data-xocs-content-id="b0060"><span class="anchor-text-container"><span class="anchor-text">[9]</span></span></a><span> and Gabor <a href="/topics/computer-science/wavelet-representation" title="Learn more about Wavelet Representation from ScienceDirect's AI-generated Topic Pages" class="topic-link">Wavelet Representation</a> </span><a class="anchor anchor-primary" href="#b0125" name="bb0125" data-sd-ui-side-panel-opener="true" data-xocs-content-type="reference" data-xocs-content-id="b0125"><span class="anchor-text-container"><span class="anchor-text">[21]</span></span></a><span>. After feature description, the features are fed into a classifier, such as <a href="/topics/chemical-engineering/support-vector-machine" title="Learn more about SVM from ScienceDirect's AI-generated Topic Pages" class="topic-link">SVM</a> </span><a class="anchor anchor-primary" href="#b0130" name="bb0130" data-sd-ui-side-panel-opener="true" data-xocs-content-type="reference" data-xocs-content-id="b0130"><span class="anchor-text-container"><span class="anchor-text">[22]</span></span></a> and K-nearest Neighbors (KNN) <a class="anchor anchor-primary" href="#b0140" name="bb0140" data-sd-ui-side-panel-opener="true" data-xocs-content-type="reference" data-xocs-content-id="b0140"><span class="anchor-text-container"><span class="anchor-text">[24]</span></span></a>, for recognizing different facial expressions. Therefore, the performance of the classifier depends to a large extent on the quality of the extracted features. In <a class="anchor anchor-primary" href="#b0235" name="bb0235" data-sd-ui-side-panel-opener="true" data-xocs-content-type="reference" data-xocs-content-id="b0235"><span class="anchor-text-container"><span class="anchor-text">[43]</span></span></a><span>, various feature extraction techniques combined with different <a href="/topics/biochemistry-genetics-and-molecular-biology/classification-algorithm" title="Learn more about classification algorithms from ScienceDirect's AI-generated Topic Pages" class="topic-link">classification algorithms</a><span> were presented to find the best combination that can be used for emotion intensity recognition. The results with LBP features are better than those using HOG and <a href="/topics/computer-science/gabor-feature" title="Learn more about Gabor features from ScienceDirect's AI-generated Topic Pages" class="topic-link">Gabor features</a>.</span></span></div><div class="u-margin-s-bottom" id="p0065">The CK+ dataset <a class="anchor anchor-primary" href="#b0075" name="bb0075" data-sd-ui-side-panel-opener="true" data-xocs-content-type="reference" data-xocs-content-id="b0075"><span class="anchor-text-container"><span class="anchor-text">[11]</span></span></a><span><span> contains emotion annotations as well as action unit annotations. In the classification stage, the dataset was evaluated by AAM and <a href="/topics/computer-science/support-vector-machine" title="Learn more about SVM from ScienceDirect's AI-generated Topic Pages" class="topic-link">SVM</a><span>. AAM tracks the face and extracts facial features, and then <a href="/topics/engineering/support-vector-machine" title="Learn more about SVM from ScienceDirect's AI-generated Topic Pages" class="topic-link">SVM</a> classifies the facial expressions. For each expression, the architecture achieves more than 65% accuracy, and the best </span></span><a href="/topics/computer-science/recognition-accuracy" title="Learn more about recognition accuracy from ScienceDirect's AI-generated Topic Pages" class="topic-link">recognition accuracy</a> is 100% for the happy emotion.</span></div><div class="u-margin-s-bottom" id="p0070"><span>In recent years, <a href="/topics/chemical-engineering/deep-neural-network" title="Learn more about deep neural network from ScienceDirect's AI-generated Topic Pages" class="topic-link">deep neural network</a><span> has become popular in recognizing facial expressions and other <a href="/topics/computer-science/computer-vision-task" title="Learn more about computer vision tasks from ScienceDirect's AI-generated Topic Pages" class="topic-link">computer vision tasks</a>. In </span></span><a class="anchor anchor-primary" href="#b0200" name="bb0200" data-sd-ui-side-panel-opener="true" data-xocs-content-type="reference" data-xocs-content-id="b0200"><span class="anchor-text-container"><span class="anchor-text">[36]</span></span></a><span><span>, LeNet-5, which is the earliest convolutional neural network, is presented to recognize handwriting. There are only seven layers in the network, including three <a href="/topics/engineering/convolutional-layer" title="Learn more about convolutional layers from ScienceDirect's AI-generated Topic Pages" class="topic-link">convolutional layers</a>, two sub-sampling layers and two fully connected layers. Then, many variants of networks based on this basic design are prevalent in </span><a href="/topics/computer-science/deep-learning" title="Learn more about deep learning from ScienceDirect's AI-generated Topic Pages" class="topic-link">deep learning</a> tasks. VGG Net </span><a class="anchor anchor-primary" href="#b0180" name="bb0180" data-sd-ui-side-panel-opener="true" data-xocs-content-type="reference" data-xocs-content-id="b0180"><span class="anchor-text-container"><span class="anchor-text">[32]</span></span></a><span><span> used very small <a href="/topics/computer-science/convolution-filter" title="Learn more about convolution filters from ScienceDirect's AI-generated Topic Pages" class="topic-link">convolution filters</a> (3*3) to increase the architecture depth, where the small-size filter can make the decision function more discriminative and decrease the number of parameters. The network often stacked several </span><a href="/topics/computer-science/convolutional-layer" title="Learn more about convolutional layers from ScienceDirect's AI-generated Topic Pages" class="topic-link">convolutional layers</a> and then followed one pooling layers. When there are 16 or 19&nbsp;wt layers in the network, the architecture can achieve significant improvement on the prior-art configurations. GoogLeNet </span><a class="anchor anchor-primary" href="#b0025" name="bb0025" data-sd-ui-side-panel-opener="true" data-xocs-content-type="reference" data-xocs-content-id="b0025"><span class="anchor-text-container"><span class="anchor-text">[3]</span></span></a><span> is a 22-layer deep network. Not only the width, but also the depth of the network is increased compared with previous networks. The main structure of the network is “Inception” layers, which contain several parallel convolution branches. “Inception” layers have difference sizes of convolution filters, and the input images can convolve at different scales of feature maps. In <a href="/topics/computer-science/residual-neural-network" title="Learn more about ResNet from ScienceDirect's AI-generated Topic Pages" class="topic-link">ResNet</a> </span><a class="anchor anchor-primary" href="#b0030" name="bb0030" data-sd-ui-side-panel-opener="true" data-xocs-content-type="reference" data-xocs-content-id="b0030"><span class="anchor-text-container"><span class="anchor-text">[4]</span></span></a>, skip connections are added between the input layer and output layer in the network. This structure not only increases the training speed and improves the training effect of the model, but also avoids gradient disappearance and network degradation.</div><div class="u-margin-s-bottom" id="p0075"><span><span>For the facial expression recognition task, most works were inspired by the above-mentioned deep <a href="/topics/computer-science/network-architecture" title="Learn more about network architectures from ScienceDirect's AI-generated Topic Pages" class="topic-link">network architectures</a>. When classifying static images, a facial expression </span><a href="/topics/computer-science/recognition-network" title="Learn more about recognition network from ScienceDirect's AI-generated Topic Pages" class="topic-link">recognition network</a> </span><a class="anchor anchor-primary" href="#b0020" name="bb0020" data-sd-ui-side-panel-opener="true" data-xocs-content-type="reference" data-xocs-content-id="b0020"><span class="anchor-text-container"><span class="anchor-text">[2]</span></span></a> inspired by GoogLeNet was proposed. The network includes two convolutional layers, each of which is followed by a max-pooling layer, and then four inception layers are followed. Sun et al. <a class="anchor anchor-primary" href="#b0080" name="bb0080" data-sd-ui-side-panel-opener="true" data-xocs-content-type="reference" data-xocs-content-id="b0080"><span class="anchor-text-container"><span class="anchor-text">[12]</span></span></a> proposed a facial expression recognition network with visual attention.&nbsp;In this network, the deep convolution features are extracted from the face, and thus the regions of interest are detected and used to classify expressions. In <a class="anchor anchor-primary" href="#b0035" name="bb0035" data-sd-ui-side-panel-opener="true" data-xocs-content-type="reference" data-xocs-content-id="b0035"><span class="anchor-text-container"><span class="anchor-text">[5]</span></span></a>, binarized Auto-encoders and Stacked Binarized Auto-encoders were used to learn a type of domain knowledge from unlabeled facial expression datasets. Fernandez et al. <a class="anchor anchor-primary" href="#b0210" name="bb0210" data-sd-ui-side-panel-opener="true" data-xocs-content-type="reference" data-xocs-content-id="b0210"><span class="anchor-text-container"><span class="anchor-text">[38]</span></span></a> proposed an end-to-end network with an attention model for facial expression recognition. The results showed that the attention module improves the classification performance. In <a class="anchor anchor-primary" href="#b0015" name="bb0015" data-sd-ui-side-panel-opener="true" data-xocs-content-type="reference" data-xocs-content-id="b0015"><span class="anchor-text-container"><span class="anchor-text">[1]</span></span></a>, a GAN-based face frontalization method was presented.&nbsp;The input face images are frontalized by the generator and the identity and expression characteristics are preserved at the same time.&nbsp;<span>Then, the <a href="/topics/earth-and-planetary-sciences/discriminator" title="Learn more about discriminator from ScienceDirect's AI-generated Topic Pages" class="topic-link">discriminator</a> makes a distinction between the real images and the generated face images.</span></div><div class="u-margin-s-bottom" id="p0080">While classifying video images, in <a class="anchor anchor-primary" href="#b0045" name="bb0045" data-sd-ui-side-panel-opener="true" data-xocs-content-type="reference" data-xocs-content-id="b0045"><span class="anchor-text-container"><span class="anchor-text">[7]</span></span></a><span>, a DNN-based architecture combined with <a href="/topics/computer-science/conditional-random-field" title="Learn more about conditional Random Field from ScienceDirect's AI-generated Topic Pages" class="topic-link">conditional Random Field</a> was proposed to solve the expression recognition problem. Here, the Inception-ResNet networks </span><a class="anchor anchor-primary" href="#b0040" name="bb0040" data-sd-ui-side-panel-opener="true" data-xocs-content-type="reference" data-xocs-content-id="b0040"><span class="anchor-text-container"><span class="anchor-text">[6]</span></span></a><span> is used in the networks for facial expression recognition, the experimental results show <a href="/topics/computer-science/good-performance" title="Learn more about good performance from ScienceDirect's AI-generated Topic Pages" class="topic-link">good performance</a> on CK+, MMI and FER2013. In </span><a class="anchor anchor-primary" href="#b0185" name="bb0185" data-sd-ui-side-panel-opener="true" data-xocs-content-type="reference" data-xocs-content-id="b0185"><span class="anchor-text-container"><span class="anchor-text">[33]</span></span></a><span>, VGG-based convolutional neural network was first used to learn facial features, which are then linked to a <a href="/topics/engineering/long-short-term-memory" title="Learn more about Long Short Term Memory from ScienceDirect's AI-generated Topic Pages" class="topic-link">Long Short Term Memory</a> (LSTM) to exploit the temporal relation between video frames. An accuracy of 97.2% was obtained on CK+. A network termed Spatio-Temporal Convolutional features with Nested LSTM (STC-NLSTM) </span><a class="anchor anchor-primary" href="#b0050" name="bb0050" data-sd-ui-side-panel-opener="true" data-xocs-content-type="reference" data-xocs-content-id="b0050"><span class="anchor-text-container"><span class="anchor-text">[8]</span></span></a><span> was proposed to learn muti-level facial expression features and temporal dynamics of facial expressions in a <a href="/topics/engineering/joints-structural-components" title="Learn more about joint from ScienceDirect's AI-generated Topic Pages" class="topic-link">joint</a> way.</span></div><div class="u-margin-s-bottom" id="p0085"><span><span>In this paper, a novel convolutional neural network with attention mechanism is presented to classify different facial expressions. We combine LBP features and convolution features in an attention module. With the help of LBP features which provide <a href="/topics/computer-science/texture-information" title="Learn more about texture information from ScienceDirect's AI-generated Topic Pages" class="topic-link">texture information</a> and can reflect fine changes on the face, the ability of the attention module can be improved so as to improve the recognition accuracy of the network. In addition, in order to avoid overfitting, </span><a href="/topics/computer-science/data-augmentation" title="Learn more about data augmentation from ScienceDirect's AI-generated Topic Pages" class="topic-link">data augmentation</a> is applied in the datasets used in our experiments. We also use the </span><a href="/topics/computer-science/batch-normalization" title="Learn more about batch normalization from ScienceDirect's AI-generated Topic Pages" class="topic-link">batch normalization</a> after each layer to speed up the convergence of the network.</div></section><section id="s0015"><h2 id="st025" class="u-h4 u-margin-l-top u-margin-xs-bottom">3. The proposed method</h2><section id="s0020"><h3 id="st030" class="u-h4 u-margin-m-top u-margin-xs-bottom">3.1. Network architecture</h3><div class="u-margin-s-bottom" id="p0090"><span>In this section, we introduce our newly proposed convolutional neural network with attention mechanism for automatically recognizing facial expressions. The new network consists of four parts, i.e., the feature extraction module, the attention module, the reconstruction module and the classification module. The architecture starts from the feature extraction module composed of two separate CNN processing streams: one is for raw images and the other is for LBP feature maps. Our model uses pure <a href="/topics/engineering/convolutional-layer" title="Learn more about convolutional layers from ScienceDirect's AI-generated Topic Pages" class="topic-link">convolutional layers</a><span><span> as the backbone to extract features. To prevent the network from being too complex, small-size <a href="/topics/computer-science/convolution-filter" title="Learn more about convolution filters from ScienceDirect's AI-generated Topic Pages" class="topic-link">convolution filters</a> (3&nbsp;×&nbsp;3) are used in all layers. Because VGG-16 Net has strong ability </span><a href="/topics/biochemistry-genetics-and-molecular-biology/transfer-of-learning" title="Learn more about of transfer learning from ScienceDirect's AI-generated Topic Pages" class="topic-link">of transfer learning</a> and a flexible architecture, it can easily concatenate the backend to extract deeper features for classification. To this end, the first 13 layers of VGG-16 are used as the front-end of our model to extract initial features of the raw images. For LBP </span></span><a href="/topics/computer-science/image-feature" title="Learn more about feature images from ScienceDirect's AI-generated Topic Pages" class="topic-link">feature images</a>, we also use the first 13 layers from VGG-16 to extract deeper features and then reduce the dimensionality to the same as that of the raw images.</div><div class="u-margin-s-bottom"><div id="p0095">As shown in <a class="anchor anchor-primary" href="#f0025" name="bf0025" data-sd-ui-side-panel-opener="true" data-xocs-content-type="reference" data-xocs-content-id="f0025"><span class="anchor-text-container"><span class="anchor-text">Fig. 5</span></span></a><span>, our dimensionality reduction-based CNN and feature extraction-based CNN have the same architecture. In order to reduce the <a href="/topics/computer-science/computational-complexity" title="Learn more about computational complexity from ScienceDirect's AI-generated Topic Pages" class="topic-link">computational complexity</a>, we add three 1&nbsp;×&nbsp;1&nbsp;×&nbsp;64 convolutions into the original VGG-16 net to reduce the channels. Unlike the traditional two-stream CNN networks such as Light-CNN </span><a class="anchor anchor-primary" href="#b0170" name="bb0170" data-sd-ui-side-panel-opener="true" data-xocs-content-type="reference" data-xocs-content-id="b0170"><span class="anchor-text-container"><span class="anchor-text">[30]</span></span></a>, <a class="anchor anchor-primary" href="#b0240" name="bb0240" data-sd-ui-side-panel-opener="true" data-xocs-content-type="reference" data-xocs-content-id="b0240"><span class="anchor-text-container"><span class="anchor-text">[44]</span></span></a> which extract two different features and then simply fuse them to classify, our feature extraction module is to obtain initial features for future processing in the following modules. Afterwards, we fuse the features F1 extracted from the raw images with the features F2 extracted from the LBP feature images, and then add the fused features F3 to an attention module.</div><figure class="figure text-xs" id="f0020"><span><img src="https://ars.els-cdn.com/content/image/1-s2.0-S0925231220309838-gr4.jpg" height="442" alt="" aria-describedby="cn0020"><ol class="u-margin-s-bottom"><li><a class="anchor download-link u-font-sans anchor-primary" href="https://ars.els-cdn.com/content/image/1-s2.0-S0925231220309838-gr4_lrg.jpg" target="_blank" download="" title="Download high-res image (215KB)"><span class="anchor-text-container"><span class="anchor-text">Download: <span class="download-link-title">Download high-res image (215KB)</span></span></span></a></li><li><a class="anchor download-link u-font-sans anchor-primary" href="https://ars.els-cdn.com/content/image/1-s2.0-S0925231220309838-gr4.jpg" target="_blank" download="" title="Download full-size image"><span class="anchor-text-container"><span class="anchor-text">Download: <span class="download-link-title">Download full-size image</span></span></span></a></li></ol></span><span class="captions text-s"><span id="cn0020"><p id="sp0050"><span class="label">Fig. 4</span>. The architecture of our network.</p></span></span></figure><figure class="figure text-xs" id="f0025"><span><img src="https://ars.els-cdn.com/content/image/1-s2.0-S0925231220309838-gr5.jpg" height="296" alt="" aria-describedby="cn0025"><ol class="u-margin-s-bottom"><li><a class="anchor download-link u-font-sans anchor-primary" href="https://ars.els-cdn.com/content/image/1-s2.0-S0925231220309838-gr5_lrg.jpg" target="_blank" download="" title="Download high-res image (168KB)"><span class="anchor-text-container"><span class="anchor-text">Download: <span class="download-link-title">Download high-res image (168KB)</span></span></span></a></li><li><a class="anchor download-link u-font-sans anchor-primary" href="https://ars.els-cdn.com/content/image/1-s2.0-S0925231220309838-gr5.jpg" target="_blank" download="" title="Download full-size image"><span class="anchor-text-container"><span class="anchor-text">Download: <span class="download-link-title">Download full-size image</span></span></span></a></li></ol></span><span class="captions text-s"><span id="cn0025"><p id="sp0055"><span class="label">Fig. 5</span>. The architecture of dimensionality reduction-based <a href="/topics/computer-science/convolutional-neural-network" title="Learn more about CNN from ScienceDirect's AI-generated Topic Pages" class="topic-link">CNN</a> and feature extraction-based CNN.</p></span></span></figure></div><div class="u-margin-s-bottom" id="p0100">The attention module works by increasing the weights of useful features and makes the network focus more on these features that are vital for expression recognition. In this way, the network can recognize different expressions more efficiently.</div><div class="u-margin-s-bottom" id="p0105"><span>Followed the attention module, we use a dense connection <a href="/topics/computer-science/convolution-layer" title="Learn more about convolution layers from ScienceDirect's AI-generated Topic Pages" class="topic-link">convolution layers</a><span> as the reconstruction module to adjust the attention map in order to create an enhanced feature map for the classification module. Many works like <a href="/topics/computer-science/densenet" title="Learn more about DenseNet from ScienceDirect's AI-generated Topic Pages" class="topic-link">DenseNet</a> </span></span><a class="anchor anchor-primary" href="#b0090" name="bb0090" data-sd-ui-side-panel-opener="true" data-xocs-content-type="reference" data-xocs-content-id="b0090"><span class="anchor-text-container"><span class="anchor-text">[14]</span></span></a><span> and <a href="/topics/computer-science/residual-neural-network" title="Learn more about ResNet from ScienceDirect's AI-generated Topic Pages" class="topic-link">ResNet</a> </span><a class="anchor anchor-primary" href="#b0030" name="bb0030" data-sd-ui-side-panel-opener="true" data-xocs-content-type="reference" data-xocs-content-id="b0030"><span class="anchor-text-container"><span class="anchor-text">[4]</span></span></a> have shown that convolution networks with skip connections between different layers can be substantially deeper, more accurate, and more efficient to train. Motivated by DenseNet <a class="anchor anchor-primary" href="#b0090" name="bb0090" data-sd-ui-side-panel-opener="true" data-xocs-content-type="reference" data-xocs-content-id="b0090"><span class="anchor-text-container"><span class="anchor-text">[14]</span></span></a> and ResNet <a class="anchor anchor-primary" href="#b0030" name="bb0030" data-sd-ui-side-panel-opener="true" data-xocs-content-type="reference" data-xocs-content-id="b0030"><span class="anchor-text-container"><span class="anchor-text">[4]</span></span></a><span>, in this work, we use dense atrous convolution for reconstruction. Atrous kernel can be dilated in varied rates by inserting zeros into appropriate positions in the kernel mask. A large dilation rate means a large receptive field, vice versa. Our dense atrous convolution module consists of four 3&nbsp;×&nbsp;3 atrous convolution, the dilation rates from lower layers to higher layers are 2, 3, 4 and 5, respectively. Compared to the traditional convolution operator, atrous convolution is able to achieve a larger <a href="/topics/engineering/receptive-field-size" title="Learn more about receptive field size from ScienceDirect's AI-generated Topic Pages" class="topic-link">receptive field size</a><span><span> without increasing the number of <a href="/topics/computer-science/kernel-parameter" title="Learn more about kernel parameters from ScienceDirect's AI-generated Topic Pages" class="topic-link">kernel parameters</a>. Feature maps from the attention module contain important information for expression recognition. Atrous convolution can&nbsp;increase the receptive field while keeping the resolution of feature maps unchanged. We can further extract features with atrous convolution without information loss and have larger a receptive field. For each layer, the feature-maps of all preceding layers and features F1 are concatenated as inputs, and its own feature-maps are used as inputs into all subsequent layers. The fused feature maps F3 are made element-wise sum operation with the output of the attention module. This architecture not only can extract deeper features but also can help alleviate the problem of vanishing-gradient and reuse useful features. At last, fully connected layers with softmax are used for classification. We use the </span><a href="/topics/computer-science/batch-normalization" title="Learn more about batch normalization from ScienceDirect's AI-generated Topic Pages" class="topic-link">batch normalization</a> after each layer to speed up the convergence of the network and avoid overfitting. The detail of each module in the schema can be seen in </span></span><a class="anchor anchor-primary" href="#f0020" name="bf0020" data-sd-ui-side-panel-opener="true" data-xocs-content-type="reference" data-xocs-content-id="f0020"><span class="anchor-text-container"><span class="anchor-text">Fig. 4</span></span></a>.</div></section><section id="s0025"><h3 id="st035" class="u-h4 u-margin-m-top u-margin-xs-bottom">3.2. Attention mechanism</h3><div class="u-margin-s-bottom" id="p0110"><span>For a <a href="/topics/computer-science/classification-task" title="Learn more about classification task from ScienceDirect's AI-generated Topic Pages" class="topic-link">classification task</a>, we extract image features and classify the images into different categories by the differences among these features. However, only useful features are helpful for classification and different features contribute different significance. The attention mechanism has been proved to be useful in pixel-wise computer vision tasks and is used to measure how much attention to pay to the features in different regions. In this paper, our attention module contains two branches, one is the trunk branch to obtain feature </span><span class="math"><span class="MathJax_Preview" style=""></span><span class="MathJax_SVG" id="MathJax-Element-1-Frame" tabindex="0" data-mathml="<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mrow is=&quot;true&quot;><msub is=&quot;true&quot;><mi is=&quot;true&quot;>F</mi><mi is=&quot;true&quot;>p</mi></msub></mrow></math>" role="presentation" style="font-size: 90%; display: inline-block; position: relative;"><svg xmlns:xlink="http://www.w3.org/1999/xlink" width="2.554ex" height="2.548ex" viewBox="0 -747.2 1099.5 1096.9" role="img" focusable="false" style="vertical-align: -0.812ex;" aria-hidden="true"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><g is="true"><g is="true"><g is="true"><use xlink:href="#MJMATHI-46"></use></g><g is="true" transform="translate(643,-150)"><use transform="scale(0.707)" xlink:href="#MJMATHI-70"></use></g></g></g></g></svg><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow is="true"><msub is="true"><mi is="true">F</mi><mi is="true">p</mi></msub></mrow></math></span></span><script type="math/mml" id="MathJax-Element-1"><math><mrow is="true"><msub is="true"><mi is="true">F</mi><mi is="true">p</mi></msub></mrow></math></script></span>, and the other is the mask branch which integrates LBP features to obtain attention maps <span class="math"><span class="MathJax_Preview" style=""></span><span class="MathJax_SVG" id="MathJax-Element-2-Frame" tabindex="0" data-mathml="<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mrow is=&quot;true&quot;><msub is=&quot;true&quot;><mi is=&quot;true&quot;>F</mi><mi is=&quot;true&quot;>m</mi></msub></mrow></math>" role="presentation" style="font-size: 90%; display: inline-block; position: relative;"><svg xmlns:xlink="http://www.w3.org/1999/xlink" width="3.17ex" height="2.317ex" viewBox="0 -747.2 1364.7 997.6" role="img" focusable="false" style="vertical-align: -0.582ex;" aria-hidden="true"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><g is="true"><g is="true"><g is="true"><use xlink:href="#MJMATHI-46"></use></g><g is="true" transform="translate(643,-150)"><use transform="scale(0.707)" xlink:href="#MJMATHI-6D"></use></g></g></g></g></svg><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow is="true"><msub is="true"><mi is="true">F</mi><mi is="true">m</mi></msub></mrow></math></span></span><script type="math/mml" id="MathJax-Element-2"><math><mrow is="true"><msub is="true"><mi is="true">F</mi><mi is="true">m</mi></msub></mrow></math></script></span>. Then, the element-wise product is applied on attention map<span class="math"><span class="MathJax_Preview" style=""></span><span class="MathJax_SVG" id="MathJax-Element-3-Frame" tabindex="0" data-mathml="<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mrow is=&quot;true&quot;><mi mathvariant=&quot;normal&quot; is=&quot;true&quot;>s</mi><msub is=&quot;true&quot;><mi is=&quot;true&quot;>F</mi><mi is=&quot;true&quot;>m</mi></msub></mrow></math>" role="presentation" style="font-size: 90%; display: inline-block; position: relative;"><svg xmlns:xlink="http://www.w3.org/1999/xlink" width="4.086ex" height="2.317ex" viewBox="0 -747.2 1759.2 997.6" role="img" focusable="false" style="vertical-align: -0.582ex;" aria-hidden="true"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><g is="true"><g is="true"><use xlink:href="#MJMAIN-73"></use></g><g is="true" transform="translate(394,0)"><g is="true"><use xlink:href="#MJMATHI-46"></use></g><g is="true" transform="translate(643,-150)"><use transform="scale(0.707)" xlink:href="#MJMATHI-6D"></use></g></g></g></g></svg><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow is="true"><mi mathvariant="normal" is="true">s</mi><msub is="true"><mi is="true">F</mi><mi is="true">m</mi></msub></mrow></math></span></span><script type="math/mml" id="MathJax-Element-3"><math><mrow is="true"><mi mathvariant="normal" is="true">s</mi><msub is="true"><mi is="true">F</mi><mi is="true">m</mi></msub></mrow></math></script></span> and the feature maps <span class="math"><span class="MathJax_Preview" style=""></span><span class="MathJax_SVG" id="MathJax-Element-4-Frame" tabindex="0" data-mathml="<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mrow is=&quot;true&quot;><msub is=&quot;true&quot;><mi is=&quot;true&quot;>F</mi><mi is=&quot;true&quot;>p</mi></msub></mrow></math>" role="presentation" style="font-size: 90%; display: inline-block; position: relative;"><svg xmlns:xlink="http://www.w3.org/1999/xlink" width="2.554ex" height="2.548ex" viewBox="0 -747.2 1099.5 1096.9" role="img" focusable="false" style="vertical-align: -0.812ex;" aria-hidden="true"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><g is="true"><g is="true"><g is="true"><use xlink:href="#MJMATHI-46"></use></g><g is="true" transform="translate(643,-150)"><use transform="scale(0.707)" xlink:href="#MJMATHI-70"></use></g></g></g></g></svg><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow is="true"><msub is="true"><mi is="true">F</mi><mi is="true">p</mi></msub></mrow></math></span></span><script type="math/mml" id="MathJax-Element-4"><math><mrow is="true"><msub is="true"><mi is="true">F</mi><mi is="true">p</mi></msub></mrow></math></script></span> to generate refined feature maps <span class="math"><span class="MathJax_Preview" style=""></span><span class="MathJax_SVG" id="MathJax-Element-5-Frame" tabindex="0" data-mathml="<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mrow is=&quot;true&quot;><msub is=&quot;true&quot;><mi is=&quot;true&quot;>F</mi><mi is=&quot;true&quot;>m</mi></msub></mrow></math>" role="presentation" style="font-size: 90%; display: inline-block; position: relative;"><svg xmlns:xlink="http://www.w3.org/1999/xlink" width="3.17ex" height="2.317ex" viewBox="0 -747.2 1364.7 997.6" role="img" focusable="false" style="vertical-align: -0.582ex;" aria-hidden="true"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><g is="true"><g is="true"><g is="true"><use xlink:href="#MJMATHI-46"></use></g><g is="true" transform="translate(643,-150)"><use transform="scale(0.707)" xlink:href="#MJMATHI-6D"></use></g></g></g></g></svg><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow is="true"><msub is="true"><mi is="true">F</mi><mi is="true">m</mi></msub></mrow></math></span></span><script type="math/mml" id="MathJax-Element-5"><math><mrow is="true"><msub is="true"><mi is="true">F</mi><mi is="true">m</mi></msub></mrow></math></script></span> as:<span class="display"><span id="e0005" class="formula"><span class="label">(1)</span><span class="math"><span class="MathJax_Preview" style=""></span><span class="MathJax_SVG" id="MathJax-Element-6-Frame" tabindex="0" data-mathml="<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mrow is=&quot;true&quot;><mtable is=&quot;true&quot;><mtr is=&quot;true&quot;><mtd is=&quot;true&quot;><mrow is=&quot;true&quot;><msub is=&quot;true&quot;><mi is=&quot;true&quot;>F</mi><mrow is=&quot;true&quot;><mi mathvariant=&quot;italic&quot; is=&quot;true&quot;>refine</mi></mrow></msub><mo is=&quot;true&quot;>=</mo><msub is=&quot;true&quot;><mi is=&quot;true&quot;>F</mi><mi is=&quot;true&quot;>p</mi></msub><msub is=&quot;true&quot;><mi is=&quot;true&quot;>F</mi><mi is=&quot;true&quot;>m</mi></msub></mrow></mtd></mtr></mtable></mrow></math>" role="presentation" style="font-size: 90%; display: inline-block; position: relative;"><svg xmlns:xlink="http://www.w3.org/1999/xlink" width="15.922ex" height="3.009ex" viewBox="0 -896.2 6855.4 1295.7" role="img" focusable="false" style="vertical-align: -0.928ex;" aria-hidden="true"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><g is="true"><g is="true" transform="translate(167,0)"><g transform="translate(-16,0)"><g is="true"><g is="true"><g is="true"><g is="true"><use xlink:href="#MJMATHI-46"></use></g><g is="true" transform="translate(643,-155)"><g is="true"><use transform="scale(0.707)" xlink:href="#MJMATHI-72"></use><use transform="scale(0.707)" xlink:href="#MJMATHI-65" x="451" y="0"></use><use transform="scale(0.707)" xlink:href="#MJMATHI-66" x="918" y="0"></use><use transform="scale(0.707)" xlink:href="#MJMATHI-69" x="1408" y="0"></use><use transform="scale(0.707)" xlink:href="#MJMATHI-6E" x="1754" y="0"></use><use transform="scale(0.707)" xlink:href="#MJMATHI-65" x="2354" y="0"></use></g></g></g><g is="true" transform="translate(3016,0)"><use xlink:href="#MJMAIN-3D"></use></g><g is="true" transform="translate(4072,0)"><g is="true"><use xlink:href="#MJMATHI-46"></use></g><g is="true" transform="translate(643,-150)"><use transform="scale(0.707)" xlink:href="#MJMATHI-70"></use></g></g><g is="true" transform="translate(5171,0)"><g is="true"><use xlink:href="#MJMATHI-46"></use></g><g is="true" transform="translate(643,-150)"><use transform="scale(0.707)" xlink:href="#MJMATHI-6D"></use></g></g></g></g></g></g></g></g></svg><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow is="true"><mtable is="true"><mtr is="true"><mtd is="true"><mrow is="true"><msub is="true"><mi is="true">F</mi><mrow is="true"><mi mathvariant="italic" is="true">refine</mi></mrow></msub><mo is="true">=</mo><msub is="true"><mi is="true">F</mi><mi is="true">p</mi></msub><msub is="true"><mi is="true">F</mi><mi is="true">m</mi></msub></mrow></mtd></mtr></mtable></mrow></math></span></span><script type="math/mml" id="MathJax-Element-6"><math><mrow is="true"><mtable is="true"><mtr is="true"><mtd is="true"><mrow is="true"><msub is="true"><mi is="true">F</mi><mrow is="true"><mi mathvariant="italic" is="true">refine</mi></mrow></msub><mo is="true">=</mo><msub is="true"><mi is="true">F</mi><mi is="true">p</mi></msub><msub is="true"><mi is="true">F</mi><mi is="true">m</mi></msub></mrow></mtd></mtr></mtable></mrow></math></script></span></span></span></div><div class="u-margin-s-bottom"><div id="p0115">Suppose the input of the last layer in the mask branch as <span class="math"><span class="MathJax_Preview" style=""></span><span class="MathJax_SVG" id="MathJax-Element-7-Frame" tabindex="0" data-mathml="<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mrow is=&quot;true&quot;><msub is=&quot;true&quot;><mi is=&quot;true&quot;>f</mi><mi is=&quot;true&quot;>m</mi></msub></mrow></math>" role="presentation" style="font-size: 90%; display: inline-block; position: relative;"><svg xmlns:xlink="http://www.w3.org/1999/xlink" width="2.814ex" height="2.548ex" viewBox="0 -796.9 1211.7 1096.9" role="img" focusable="false" style="vertical-align: -0.697ex;" aria-hidden="true"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><g is="true"><g is="true"><g is="true"><use xlink:href="#MJMATHI-66"></use></g><g is="true" transform="translate(490,-150)"><use transform="scale(0.707)" xlink:href="#MJMATHI-6D"></use></g></g></g></g></svg><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow is="true"><msub is="true"><mi is="true">f</mi><mi is="true">m</mi></msub></mrow></math></span></span><script type="math/mml" id="MathJax-Element-7"><math><mrow is="true"><msub is="true"><mi is="true">f</mi><mi is="true">m</mi></msub></mrow></math></script></span>, the attention maps <span class="math"><span class="MathJax_Preview" style=""></span><span class="MathJax_SVG" id="MathJax-Element-8-Frame" tabindex="0" data-mathml="<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mrow is=&quot;true&quot;><msub is=&quot;true&quot;><mi is=&quot;true&quot;>F</mi><mi is=&quot;true&quot;>m</mi></msub></mrow></math>" role="presentation" style="font-size: 90%; display: inline-block; position: relative;"><svg xmlns:xlink="http://www.w3.org/1999/xlink" width="3.17ex" height="2.317ex" viewBox="0 -747.2 1364.7 997.6" role="img" focusable="false" style="vertical-align: -0.582ex;" aria-hidden="true"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><g is="true"><g is="true"><g is="true"><use xlink:href="#MJMATHI-46"></use></g><g is="true" transform="translate(643,-150)"><use transform="scale(0.707)" xlink:href="#MJMATHI-6D"></use></g></g></g></g></svg><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow is="true"><msub is="true"><mi is="true">F</mi><mi is="true">m</mi></msub></mrow></math></span></span><script type="math/mml" id="MathJax-Element-8"><math><mrow is="true"><msub is="true"><mi is="true">F</mi><mi is="true">m</mi></msub></mrow></math></script></span> are generated as:<span class="display"><span id="e0010" class="formula"><span class="label">(2)</span><span class="math"><span class="MathJax_Preview" style=""></span><span class="MathJax_SVG" id="MathJax-Element-9-Frame" tabindex="0" data-mathml="<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mrow is=&quot;true&quot;><mtable is=&quot;true&quot;><mtr is=&quot;true&quot;><mtd is=&quot;true&quot;><mrow is=&quot;true&quot;><msub is=&quot;true&quot;><mi is=&quot;true&quot;>F</mi><mi is=&quot;true&quot;>m</mi></msub><mo is=&quot;true&quot;>=</mo><mi is=&quot;true&quot;>S</mi><mi is=&quot;true&quot;>i</mi><mi is=&quot;true&quot;>g</mi><mi is=&quot;true&quot;>m</mi><mi is=&quot;true&quot;>o</mi><mi is=&quot;true&quot;>i</mi><mi is=&quot;true&quot;>d</mi><mrow is=&quot;true&quot;><mfenced close=&quot;)&quot; open=&quot;(&quot; is=&quot;true&quot;><mrow is=&quot;true&quot;><mi mathvariant=&quot;normal&quot; is=&quot;true&quot;>W</mi><mi mathvariant=&quot;normal&quot; is=&quot;true&quot;>&amp;#xA9;</mi><msub is=&quot;true&quot;><mi is=&quot;true&quot;>f</mi><mi is=&quot;true&quot;>m</mi></msub><mo is=&quot;true&quot;>+</mo><mi mathvariant=&quot;normal&quot; is=&quot;true&quot;>b</mi></mrow></mfenced></mrow></mrow></mtd></mtr></mtable></mrow></math>" role="presentation" style="font-size: 90%; display: inline-block; position: relative;"><svg xmlns:xlink="http://www.w3.org/1999/xlink" width="28.168ex" height="2.779ex" viewBox="0 -846.5 12128 1196.3" role="img" focusable="false" style="vertical-align: -0.812ex;" aria-hidden="true"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><g is="true"><g is="true" transform="translate(167,0)"><g transform="translate(-16,0)"><g is="true" transform="translate(0,-25)"><g is="true"><g is="true"><g is="true"><use xlink:href="#MJMATHI-46"></use></g><g is="true" transform="translate(643,-150)"><use transform="scale(0.707)" xlink:href="#MJMATHI-6D"></use></g></g><g is="true" transform="translate(1642,0)"><use xlink:href="#MJMAIN-3D"></use></g><g is="true" transform="translate(2698,0)"><use xlink:href="#MJMATHI-53"></use></g><g is="true" transform="translate(3344,0)"><use xlink:href="#MJMATHI-69"></use></g><g is="true" transform="translate(3689,0)"><use xlink:href="#MJMATHI-67"></use></g><g is="true" transform="translate(4170,0)"><use xlink:href="#MJMATHI-6D"></use></g><g is="true" transform="translate(5048,0)"><use xlink:href="#MJMATHI-6F"></use></g><g is="true" transform="translate(5534,0)"><use xlink:href="#MJMATHI-69"></use></g><g is="true" transform="translate(5879,0)"><use xlink:href="#MJMATHI-64"></use></g><g is="true" transform="translate(6403,0)"><g is="true"><use xlink:href="#MJMAIN-28" x="0" y="0"></use><g is="true" transform="translate(389,0)"><g is="true"><use xlink:href="#MJMAIN-57"></use></g><g is="true" transform="translate(1028,0)"><text font-family="STIXGeneral,'Arial Unicode MS',serif" stroke="none" transform="scale(55.199) matrix(1 0 0 -1 0 0)">©</text></g><g is="true" transform="translate(1635,0)"><g is="true"><use xlink:href="#MJMATHI-66"></use></g><g is="true" transform="translate(490,-150)"><use transform="scale(0.707)" xlink:href="#MJMATHI-6D"></use></g></g><g is="true" transform="translate(3069,0)"><use xlink:href="#MJMAIN-2B"></use></g><g is="true" transform="translate(4070,0)"><use xlink:href="#MJMAIN-62"></use></g></g><use xlink:href="#MJMAIN-29" x="5016" y="0"></use></g></g></g></g></g></g></g></g></svg><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow is="true"><mtable is="true"><mtr is="true"><mtd is="true"><mrow is="true"><msub is="true"><mi is="true">F</mi><mi is="true">m</mi></msub><mo is="true">=</mo><mi is="true">S</mi><mi is="true">i</mi><mi is="true">g</mi><mi is="true">m</mi><mi is="true">o</mi><mi is="true">i</mi><mi is="true">d</mi><mrow is="true"><mfenced close=")" open="(" is="true"><mrow is="true"><mi mathvariant="normal" is="true">W</mi><mi mathvariant="normal" is="true">©</mi><msub is="true"><mi is="true">f</mi><mi is="true">m</mi></msub><mo is="true">+</mo><mi mathvariant="normal" is="true">b</mi></mrow></mfenced></mrow></mrow></mtd></mtr></mtable></mrow></math></span></span><script type="math/mml" id="MathJax-Element-9"><math><mrow is="true"><mtable is="true"><mtr is="true"><mtd is="true"><mrow is="true"><msub is="true"><mi is="true">F</mi><mi is="true">m</mi></msub><mo is="true">=</mo><mi is="true">S</mi><mi is="true">i</mi><mi is="true">g</mi><mi is="true">m</mi><mi is="true">o</mi><mi is="true">i</mi><mi is="true">d</mi><mrow is="true"><mfenced close=")" open="(" is="true"><mrow is="true"><mi mathvariant="normal" is="true">W</mi><mi mathvariant="normal" is="true">©</mi><msub is="true"><mi is="true">f</mi><mi is="true">m</mi></msub><mo is="true">+</mo><mi mathvariant="normal" is="true">b</mi></mrow></mfenced></mrow></mrow></mtd></mtr></mtable></mrow></math></script></span></span></span>where w and b are the weights and bias of the convolution layer, respectively; <span class="math"><span class="MathJax_Preview" style=""></span><span class="MathJax_SVG" id="MathJax-Element-10-Frame" tabindex="0" data-mathml="<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mrow is=&quot;true&quot;><mi mathvariant=&quot;normal&quot; is=&quot;true&quot;>&amp;#xA9;</mi></mrow></math>" role="presentation" style="font-size: 90%; display: inline-block; position: relative;"><svg xmlns:xlink="http://www.w3.org/1999/xlink" width="1.41ex" height="2.432ex" viewBox="0 -796.9 607.2 1047.3" role="img" focusable="false" style="vertical-align: -0.582ex;" aria-hidden="true"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><g is="true"><g is="true"><text font-family="STIXGeneral,'Arial Unicode MS',serif" stroke="none" transform="scale(55.199) matrix(1 0 0 -1 0 0)">©</text></g></g></g></svg><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow is="true"><mi mathvariant="normal" is="true">©</mi></mrow></math></span></span><script type="math/mml" id="MathJax-Element-10"><math><mrow is="true"><mi mathvariant="normal" is="true">©</mi></mrow></math></script></span><span><span> denotes the <a href="/topics/computer-science/convolution-operation" title="Learn more about convolution operation from ScienceDirect's AI-generated Topic Pages" class="topic-link">convolution operation</a> and Sigmoid denotes the </span><a href="/topics/computer-science/sigmoid-function" title="Learn more about sigmoid function from ScienceDirect's AI-generated Topic Pages" class="topic-link">sigmoid function</a><span>. The Sigmoid <a href="/topics/computer-science/activation-function" title="Learn more about activation function from ScienceDirect's AI-generated Topic Pages" class="topic-link">activation function</a> gives out (0, 1) probability scores to make network discriminate the importance of different features. </span></span><a class="anchor anchor-primary" href="#f0030" name="bf0030" data-sd-ui-side-panel-opener="true" data-xocs-content-type="reference" data-xocs-content-id="f0030"><span class="anchor-text-container"><span class="anchor-text">Fig. 6</span></span></a> provides two example images in FER2013 and their corresponding attention heatmaps generated by our method. As we can see, the heatmaps show the attention areas clearly. For the upper side ‘angry’ face, the attention of our network is mainly on the eyes; for the lower side ‘happy’ face, the attention of our network is mainly on the mouth. This indicates that the eyes area contains the most useful features for recognizing the angry expression; while the mouth area is the most suitable for recognizing the happy expression.</div><figure class="figure text-xs" id="f0030"><span><img src="https://ars.els-cdn.com/content/image/1-s2.0-S0925231220309838-gr6.jpg" height="404" alt="" aria-describedby="cn0030"><ol class="u-margin-s-bottom"><li><a class="anchor download-link u-font-sans anchor-primary" href="https://ars.els-cdn.com/content/image/1-s2.0-S0925231220309838-gr6_lrg.jpg" target="_blank" download="" title="Download high-res image (90KB)"><span class="anchor-text-container"><span class="anchor-text">Download: <span class="download-link-title">Download high-res image (90KB)</span></span></span></a></li><li><a class="anchor download-link u-font-sans anchor-primary" href="https://ars.els-cdn.com/content/image/1-s2.0-S0925231220309838-gr6.jpg" target="_blank" download="" title="Download full-size image"><span class="anchor-text-container"><span class="anchor-text">Download: <span class="download-link-title">Download full-size image</span></span></span></a></li></ol></span><span class="captions text-s"><span id="cn0030"><p id="sp0060"><span class="label">Fig. 6</span>. Results of attention heatmap.</p></span></span></figure></div></section><section id="s0030"><h3 id="st040" class="u-h4 u-margin-m-top u-margin-xs-bottom">3.3. Local binary patterns</h3><div class="u-margin-s-bottom"><div id="p0120"><span><span>Local binary patterns (LBPs) reflect the basic information that is helpful to recognize facial expressions. More specifically, subtle changes can be reflected by the features extracted with LBPs. In addition, LBPs can achieve rotation invariance and grey-scale invariance and thus are suitable for extracting <a href="/topics/computer-science/texture-feature" title="Learn more about texture features from ScienceDirect's AI-generated Topic Pages" class="topic-link">texture features</a><span> at different scales and can solve the displacement imbalance, <a href="/topics/computer-science/rotation-angle" title="Learn more about rotation angles from ScienceDirect's AI-generated Topic Pages" class="topic-link">rotation angles</a> and </span></span><a href="/topics/engineering/illumination-condition" title="Learn more about illumination conditions from ScienceDirect's AI-generated Topic Pages" class="topic-link">illumination conditions</a><span> in <a href="/topics/computer-science/facial-image" title="Learn more about facial images from ScienceDirect's AI-generated Topic Pages" class="topic-link">facial images</a>. In </span></span><a class="anchor anchor-primary" href="#f0035" name="bf0035" data-sd-ui-side-panel-opener="true" data-xocs-content-type="reference" data-xocs-content-id="f0035"><span class="anchor-text-container"><span class="anchor-text">Fig. 7</span></span></a>, we provide some examples of LBP images extracted from five datasets used in this paper.</div><figure class="figure text-xs" id="f0035"><span><img src="https://ars.els-cdn.com/content/image/1-s2.0-S0925231220309838-gr7.jpg" height="619" alt="" aria-describedby="cn0035"><ol class="u-margin-s-bottom"><li><a class="anchor download-link u-font-sans anchor-primary" href="https://ars.els-cdn.com/content/image/1-s2.0-S0925231220309838-gr7_lrg.jpg" target="_blank" download="" title="Download high-res image (517KB)"><span class="anchor-text-container"><span class="anchor-text">Download: <span class="download-link-title">Download high-res image (517KB)</span></span></span></a></li><li><a class="anchor download-link u-font-sans anchor-primary" href="https://ars.els-cdn.com/content/image/1-s2.0-S0925231220309838-gr7.jpg" target="_blank" download="" title="Download full-size image"><span class="anchor-text-container"><span class="anchor-text">Download: <span class="download-link-title">Download full-size image</span></span></span></a></li></ol></span><span class="captions text-s"><span id="cn0035"><p id="sp0065"><span class="label">Fig. 7</span>. Examples of <a href="/topics/engineering/local-binary-pattern" title="Learn more about LBP from ScienceDirect's AI-generated Topic Pages" class="topic-link">LBP</a> images extracted from CK+, JAFFE, NCUFE, Oulu-CASIA and FER2013. From top to bottom is the original image, circle LBP image, original LBP image, and uniform LBP image.</p></span></span></figure></div><div class="u-margin-s-bottom" id="p0125">In <a class="anchor anchor-primary" href="#b0060" name="bb0060" data-sd-ui-side-panel-opener="true" data-xocs-content-type="reference" data-xocs-content-id="b0060"><span class="anchor-text-container"><span class="anchor-text">[9]</span></span></a><span>, the original LBP defined in a 3&nbsp;×&nbsp;3 window was first introduced. The center pixel of the window is taken as the threshold and then is compared with the gray values of the adjacent 8 pixels. If the value of the surrounding pixel is greater than the value of the center pixel, the position of the pixel is marked as 1; otherwise, it is 0. In this way, the comparison of the 8 points in the 3&nbsp;×&nbsp;3 neighborhood can generate 8-bit binary numbers, which are usually converted to <a href="/topics/engineering/decimal-number" title="Learn more about decimal numbers from ScienceDirect's AI-generated Topic Pages" class="topic-link">decimal numbers</a> which is namely LBP code and have a total of 256 kinds. Through the above steps, the LBP value of the pixel in the center of the window is obtained, and the texture information of the region is reflected by the value. It can be defined as follows:</span><span class="display"><span id="e0015" class="formula"><span class="label">(1)</span><span class="math"><span class="MathJax_Preview" style=""></span><span class="MathJax_SVG" id="MathJax-Element-11-Frame" tabindex="0" data-mathml="<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mrow is=&quot;true&quot;><mtable is=&quot;true&quot;><mtr is=&quot;true&quot;><mtd is=&quot;true&quot;><mrow is=&quot;true&quot;><mi is=&quot;true&quot;>L</mi><mi is=&quot;true&quot;>B</mi><mi is=&quot;true&quot;>P</mi><mrow is=&quot;true&quot;><mfenced close=&quot;)&quot; open=&quot;(&quot; is=&quot;true&quot;><mrow is=&quot;true&quot;><msub is=&quot;true&quot;><mi is=&quot;true&quot;>x</mi><mi is=&quot;true&quot;>c</mi></msub><mo is=&quot;true&quot;>,</mo><msub is=&quot;true&quot;><mi is=&quot;true&quot;>y</mi><mi is=&quot;true&quot;>c</mi></msub></mrow></mfenced></mrow><mo is=&quot;true&quot;>=</mo><msubsup is=&quot;true&quot;><mo is=&quot;true&quot;>&amp;#x2211;</mo><mrow is=&quot;true&quot;><mi is=&quot;true&quot;>p</mi><mo is=&quot;true&quot;>=</mo><mn is=&quot;true&quot;>0</mn></mrow><mn is=&quot;true&quot;>7</mn></msubsup><mi is=&quot;true&quot;>S</mi><mrow is=&quot;true&quot;><mfenced close=&quot;)&quot; open=&quot;(&quot; is=&quot;true&quot;><mrow is=&quot;true&quot;><msub is=&quot;true&quot;><mi is=&quot;true&quot;>i</mi><mi is=&quot;true&quot;>p</mi></msub><mo is=&quot;true&quot;>-</mo><msub is=&quot;true&quot;><mi is=&quot;true&quot;>i</mi><mi is=&quot;true&quot;>c</mi></msub></mrow></mfenced></mrow><msup is=&quot;true&quot;><mrow is=&quot;true&quot;><mn is=&quot;true&quot;>2</mn></mrow><mi is=&quot;true&quot;>p</mi></msup></mrow></mtd></mtr></mtable></mrow></math>" role="presentation" style="font-size: 90%; display: inline-block; position: relative;"><svg xmlns:xlink="http://www.w3.org/1999/xlink" width="33.466ex" height="3.471ex" viewBox="0 -995.6 14409 1494.4" role="img" focusable="false" style="vertical-align: -1.158ex;" aria-hidden="true"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><g is="true"><g is="true" transform="translate(167,0)"><g transform="translate(-16,0)"><g is="true" transform="translate(0,-17)"><g is="true"><g is="true"><use xlink:href="#MJMATHI-4C"></use></g><g is="true" transform="translate(681,0)"><use xlink:href="#MJMATHI-42"></use></g><g is="true" transform="translate(1441,0)"><use xlink:href="#MJMATHI-50"></use></g><g is="true" transform="translate(2192,0)"><g is="true"><use xlink:href="#MJMAIN-28" x="0" y="0"></use><g is="true" transform="translate(389,0)"><g is="true"><g is="true"><use xlink:href="#MJMATHI-78"></use></g><g is="true" transform="translate(572,-150)"><use transform="scale(0.707)" xlink:href="#MJMATHI-63"></use></g></g><g is="true" transform="translate(979,0)"><use xlink:href="#MJMAIN-2C"></use></g><g is="true" transform="translate(1424,0)"><g is="true"><use xlink:href="#MJMATHI-79"></use></g><g is="true" transform="translate(490,-150)"><use transform="scale(0.707)" xlink:href="#MJMATHI-63"></use></g></g></g><use xlink:href="#MJMAIN-29" x="2710" y="0"></use></g></g><g is="true" transform="translate(5292,0)"><use xlink:href="#MJMAIN-3D"></use></g><g is="true" transform="translate(6349,0)"><g is="true"><use xlink:href="#MJSZ1-2211"></use></g><g is="true" transform="translate(1056,477)"><use transform="scale(0.707)" xlink:href="#MJMAIN-37"></use></g><g is="true" transform="translate(1056,-287)"><g is="true"><use transform="scale(0.707)" xlink:href="#MJMATHI-70"></use></g><g is="true" transform="translate(356,0)"><use transform="scale(0.707)" xlink:href="#MJMAIN-3D"></use></g><g is="true" transform="translate(906,0)"><use transform="scale(0.707)" xlink:href="#MJMAIN-30"></use></g></g></g><g is="true" transform="translate(8932,0)"><use xlink:href="#MJMATHI-53"></use></g><g is="true" transform="translate(9578,0)"><g is="true"><use xlink:href="#MJMAIN-28"></use><g is="true" transform="translate(389,0)"><g is="true"><g is="true"><use xlink:href="#MJMATHI-69"></use></g><g is="true" transform="translate(345,-150)"><use transform="scale(0.707)" xlink:href="#MJMATHI-70"></use></g></g><g is="true" transform="translate(1023,0)"><use xlink:href="#MJMAIN-2212"></use></g><g is="true" transform="translate(2024,0)"><g is="true"><use xlink:href="#MJMATHI-69"></use></g><g is="true" transform="translate(345,-150)"><use transform="scale(0.707)" xlink:href="#MJMATHI-63"></use></g></g></g><use xlink:href="#MJMAIN-29" x="3166" y="0"></use></g></g><g is="true" transform="translate(13133,0)"><g is="true"><g is="true"><use xlink:href="#MJMAIN-32"></use></g></g><g is="true" transform="translate(500,393)"><use transform="scale(0.707)" xlink:href="#MJMATHI-70"></use></g></g></g></g></g></g></g></g></svg><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow is="true"><mtable is="true"><mtr is="true"><mtd is="true"><mrow is="true"><mi is="true">L</mi><mi is="true">B</mi><mi is="true">P</mi><mrow is="true"><mfenced close=")" open="(" is="true"><mrow is="true"><msub is="true"><mi is="true">x</mi><mi is="true">c</mi></msub><mo is="true">,</mo><msub is="true"><mi is="true">y</mi><mi is="true">c</mi></msub></mrow></mfenced></mrow><mo is="true">=</mo><msubsup is="true"><mo is="true">∑</mo><mrow is="true"><mi is="true">p</mi><mo is="true">=</mo><mn is="true">0</mn></mrow><mn is="true">7</mn></msubsup><mi is="true">S</mi><mrow is="true"><mfenced close=")" open="(" is="true"><mrow is="true"><msub is="true"><mi is="true">i</mi><mi is="true">p</mi></msub><mo is="true">-</mo><msub is="true"><mi is="true">i</mi><mi is="true">c</mi></msub></mrow></mfenced></mrow><msup is="true"><mrow is="true"><mn is="true">2</mn></mrow><mi is="true">p</mi></msup></mrow></mtd></mtr></mtable></mrow></math></span></span><script type="math/mml" id="MathJax-Element-11"><math><mrow is="true"><mtable is="true"><mtr is="true"><mtd is="true"><mrow is="true"><mi is="true">L</mi><mi is="true">B</mi><mi is="true">P</mi><mrow is="true"><mfenced close=")" open="(" is="true"><mrow is="true"><msub is="true"><mi is="true">x</mi><mi is="true">c</mi></msub><mo is="true">,</mo><msub is="true"><mi is="true">y</mi><mi is="true">c</mi></msub></mrow></mfenced></mrow><mo is="true">=</mo><msubsup is="true"><mo is="true">∑</mo><mrow is="true"><mi is="true">p</mi><mo is="true">=</mo><mn is="true">0</mn></mrow><mn is="true">7</mn></msubsup><mi is="true">S</mi><mrow is="true"><mfenced close=")" open="(" is="true"><mrow is="true"><msub is="true"><mi is="true">i</mi><mi is="true">p</mi></msub><mo is="true">-</mo><msub is="true"><mi is="true">i</mi><mi is="true">c</mi></msub></mrow></mfenced></mrow><msup is="true"><mrow is="true"><mn is="true">2</mn></mrow><mi is="true">p</mi></msup></mrow></mtd></mtr></mtable></mrow></math></script></span></span></span>where p is the number of pixels, (<span class="math"><span class="MathJax_Preview" style=""></span><span class="MathJax_SVG" id="MathJax-Element-12-Frame" tabindex="0" data-mathml="<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mrow is=&quot;true&quot;><msub is=&quot;true&quot;><mi is=&quot;true&quot;>x</mi><mi is=&quot;true&quot;>c</mi></msub></mrow></math>" role="presentation" style="font-size: 90%; display: inline-block; position: relative;"><svg xmlns:xlink="http://www.w3.org/1999/xlink" width="2.274ex" height="1.74ex" viewBox="0 -498.8 979 749.2" role="img" focusable="false" style="vertical-align: -0.582ex;" aria-hidden="true"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><g is="true"><g is="true"><g is="true"><use xlink:href="#MJMATHI-78"></use></g><g is="true" transform="translate(572,-150)"><use transform="scale(0.707)" xlink:href="#MJMATHI-63"></use></g></g></g></g></svg><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow is="true"><msub is="true"><mi is="true">x</mi><mi is="true">c</mi></msub></mrow></math></span></span><script type="math/mml" id="MathJax-Element-12"><math><mrow is="true"><msub is="true"><mi is="true">x</mi><mi is="true">c</mi></msub></mrow></math></script></span>,<span class="math"><span class="MathJax_Preview" style=""></span><span class="MathJax_SVG" id="MathJax-Element-13-Frame" tabindex="0" data-mathml="<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mrow is=&quot;true&quot;><msub is=&quot;true&quot;><mi is=&quot;true&quot;>y</mi><mi is=&quot;true&quot;>c</mi></msub></mrow></math>" role="presentation" style="font-size: 90%; display: inline-block; position: relative;"><svg xmlns:xlink="http://www.w3.org/1999/xlink" width="2.083ex" height="1.855ex" viewBox="0 -498.8 897 798.9" role="img" focusable="false" style="vertical-align: -0.697ex;" aria-hidden="true"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><g is="true"><g is="true"><g is="true"><use xlink:href="#MJMATHI-79"></use></g><g is="true" transform="translate(490,-150)"><use transform="scale(0.707)" xlink:href="#MJMATHI-63"></use></g></g></g></g></svg><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow is="true"><msub is="true"><mi is="true">y</mi><mi is="true">c</mi></msub></mrow></math></span></span><script type="math/mml" id="MathJax-Element-13"><math><mrow is="true"><msub is="true"><mi is="true">y</mi><mi is="true">c</mi></msub></mrow></math></script></span>) is the coordinate of the center pixel, <span class="math"><span class="MathJax_Preview" style=""></span><span class="MathJax_SVG" id="MathJax-Element-14-Frame" tabindex="0" data-mathml="<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mrow is=&quot;true&quot;><msub is=&quot;true&quot;><mi is=&quot;true&quot;>i</mi><mi is=&quot;true&quot;>c</mi></msub></mrow></math>" role="presentation" style="font-size: 90%; display: inline-block; position: relative;"><svg xmlns:xlink="http://www.w3.org/1999/xlink" width="1.747ex" height="2.317ex" viewBox="0 -747.2 752 997.6" role="img" focusable="false" style="vertical-align: -0.582ex;" aria-hidden="true"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><g is="true"><g is="true"><g is="true"><use xlink:href="#MJMATHI-69"></use></g><g is="true" transform="translate(345,-150)"><use transform="scale(0.707)" xlink:href="#MJMATHI-63"></use></g></g></g></g></svg><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow is="true"><msub is="true"><mi is="true">i</mi><mi is="true">c</mi></msub></mrow></math></span></span><script type="math/mml" id="MathJax-Element-14"><math><mrow is="true"><msub is="true"><mi is="true">i</mi><mi is="true">c</mi></msub></mrow></math></script></span> is the pixel value of the center pixel and <span class="math"><span class="MathJax_Preview" style=""></span><span class="MathJax_SVG" id="MathJax-Element-15-Frame" tabindex="0" data-mathml="<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mrow is=&quot;true&quot;><msub is=&quot;true&quot;><mi is=&quot;true&quot;>i</mi><mi is=&quot;true&quot;>p</mi></msub></mrow></math>" role="presentation" style="font-size: 90%; display: inline-block; position: relative;"><svg xmlns:xlink="http://www.w3.org/1999/xlink" width="1.862ex" height="2.548ex" viewBox="0 -747.2 801.5 1096.9" role="img" focusable="false" style="vertical-align: -0.812ex;" aria-hidden="true"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><g is="true"><g is="true"><g is="true"><use xlink:href="#MJMATHI-69"></use></g><g is="true" transform="translate(345,-150)"><use transform="scale(0.707)" xlink:href="#MJMATHI-70"></use></g></g></g></g></svg><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow is="true"><msub is="true"><mi is="true">i</mi><mi is="true">p</mi></msub></mrow></math></span></span><script type="math/mml" id="MathJax-Element-15"><math><mrow is="true"><msub is="true"><mi is="true">i</mi><mi is="true">p</mi></msub></mrow></math></script></span> is the pixel value of the neighborhood pixel, <span class="math"><span class="MathJax_Preview" style=""></span><span class="MathJax_SVG" id="MathJax-Element-16-Frame" tabindex="0" data-mathml="<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mrow is=&quot;true&quot;><mi mathvariant=&quot;normal&quot; is=&quot;true&quot;>s</mi></mrow></math>" role="presentation" style="font-size: 90%; display: inline-block; position: relative;"><svg xmlns:xlink="http://www.w3.org/1999/xlink" width="0.916ex" height="1.509ex" viewBox="0 -548.5 394.5 649.8" role="img" focusable="false" style="vertical-align: -0.235ex;" aria-hidden="true"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><g is="true"><g is="true"><use xlink:href="#MJMAIN-73"></use></g></g></g></svg><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow is="true"><mi mathvariant="normal" is="true">s</mi></mrow></math></span></span><script type="math/mml" id="MathJax-Element-16"><math><mrow is="true"><mi mathvariant="normal" is="true">s</mi></mrow></math></script></span> is the sign function and can be defined as follows:<span class="display"><span id="e0020" class="formula"><span class="label">(2)</span><span class="math"><span class="MathJax_Preview" style=""></span><span class="MathJax_SVG" id="MathJax-Element-17-Frame" tabindex="0" data-mathml="<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mrow is=&quot;true&quot;><mi is=&quot;true&quot;>S</mi><mrow is=&quot;true&quot;><mfenced close=&quot;)&quot; open=&quot;(&quot; is=&quot;true&quot;><mrow is=&quot;true&quot;><mi is=&quot;true&quot;>x</mi></mrow></mfenced></mrow><mo linebreak=&quot;goodbreak&quot; is=&quot;true&quot;>=</mo><mrow is=&quot;true&quot;><mfenced close=&quot;&quot; open=&quot;{&quot; is=&quot;true&quot;><mrow is=&quot;true&quot;><mrow is=&quot;true&quot;><mtable is=&quot;true&quot;><mtr is=&quot;true&quot;><mtd columnalign=&quot;left&quot; is=&quot;true&quot;><mn is=&quot;true&quot;>1</mn></mtd><mtd columnalign=&quot;left&quot; is=&quot;true&quot;><mrow is=&quot;true&quot;><mi mathvariant=&quot;italic&quot; is=&quot;true&quot;>if x</mi><mo is=&quot;true&quot;>&amp;#x2265;</mo><mn is=&quot;true&quot;>0</mn></mrow></mtd></mtr><mtr is=&quot;true&quot;><mtd columnalign=&quot;left&quot; is=&quot;true&quot;><mrow is=&quot;true&quot;><mn is=&quot;true&quot;>0</mn></mrow></mtd><mtd columnalign=&quot;left&quot; is=&quot;true&quot;><mrow is=&quot;true&quot;><mi mathvariant=&quot;italic&quot; is=&quot;true&quot;>if x</mi><mo is=&quot;true&quot;>&amp;#x2264;</mo><mn is=&quot;true&quot;>0</mn></mrow></mtd></mtr></mtable></mrow></mrow></mfenced></mrow></mrow></math>" role="presentation" style="font-size: 90%; display: inline-block; position: relative;"><svg xmlns:xlink="http://www.w3.org/1999/xlink" width="20.064ex" height="6.009ex" viewBox="0 -1542.1 8638.5 2587.3" role="img" focusable="false" style="vertical-align: -2.428ex;" aria-hidden="true"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><g is="true"><g is="true"><use xlink:href="#MJMATHI-53"></use></g><g is="true" transform="translate(645,0)"><g is="true"><use xlink:href="#MJMAIN-28" x="0" y="0"></use><g is="true" transform="translate(389,0)"><g is="true"><use xlink:href="#MJMATHI-78"></use></g></g><use xlink:href="#MJMAIN-29" x="962" y="0"></use></g></g><g is="true" transform="translate(1997,0)"><use xlink:href="#MJMAIN-3D"></use></g><g is="true" transform="translate(2775,0)"><g is="true"><use xlink:href="#MJSZ3-7B"></use><g is="true" transform="translate(750,0)"><g is="true"><g is="true" transform="translate(167,0)"><g transform="translate(-16,0)"><g is="true" transform="translate(0,671)"><g is="true"><use xlink:href="#MJMAIN-31"></use></g></g><g is="true" transform="translate(0,-766)"><g is="true"><g is="true"><use xlink:href="#MJMAIN-30"></use></g></g></g></g><g transform="translate(1285,0)"><g is="true" transform="translate(0,671)"><g is="true"><g is="true"><use xlink:href="#MJMATHI-69"></use><use xlink:href="#MJMATHI-66" x="345" y="0"></use><use xlink:href="#MJMATHI-78" x="1086" y="0"></use></g><g is="true" transform="translate(1936,0)"><use xlink:href="#MJMAIN-2265"></use></g><g is="true" transform="translate(2992,0)"><use xlink:href="#MJMAIN-30"></use></g></g></g><g is="true" transform="translate(0,-766)"><g is="true"><g is="true"><use xlink:href="#MJMATHI-69"></use><use xlink:href="#MJMATHI-66" x="345" y="0"></use><use xlink:href="#MJMATHI-78" x="1086" y="0"></use></g><g is="true" transform="translate(1936,0)"><use xlink:href="#MJMAIN-2264"></use></g><g is="true" transform="translate(2992,0)"><use xlink:href="#MJMAIN-30"></use></g></g></g></g></g></g></g></g></g></g></g></svg><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow is="true"><mi is="true">S</mi><mrow is="true"><mfenced close=")" open="(" is="true"><mrow is="true"><mi is="true">x</mi></mrow></mfenced></mrow><mo linebreak="goodbreak" is="true">=</mo><mrow is="true"><mfenced close="" open="{" is="true"><mrow is="true"><mrow is="true"><mtable is="true"><mtr is="true"><mtd columnalign="left" is="true"><mn is="true">1</mn></mtd><mtd columnalign="left" is="true"><mrow is="true"><mi mathvariant="italic" is="true">if x</mi><mo is="true">≥</mo><mn is="true">0</mn></mrow></mtd></mtr><mtr is="true"><mtd columnalign="left" is="true"><mrow is="true"><mn is="true">0</mn></mrow></mtd><mtd columnalign="left" is="true"><mrow is="true"><mi mathvariant="italic" is="true">if x</mi><mo is="true">≤</mo><mn is="true">0</mn></mrow></mtd></mtr></mtable></mrow></mrow></mfenced></mrow></mrow></math></span></span><script type="math/mml" id="MathJax-Element-17"><math><mrow is="true"><mi is="true">S</mi><mrow is="true"><mfenced close=")" open="(" is="true"><mrow is="true"><mi is="true">x</mi></mrow></mfenced></mrow><mo linebreak="goodbreak" is="true">=</mo><mrow is="true"><mfenced close="" open="{" is="true"><mrow is="true"><mrow is="true"><mtable is="true"><mtr is="true"><mtd columnalign="left" is="true"><mn is="true">1</mn></mtd><mtd columnalign="left" is="true"><mrow is="true"><mi mathvariant="italic" is="true">if x</mi><mo is="true">≥</mo><mn is="true">0</mn></mrow></mtd></mtr><mtr is="true"><mtd columnalign="left" is="true"><mrow is="true"><mn is="true">0</mn></mrow></mtd><mtd columnalign="left" is="true"><mrow is="true"><mi mathvariant="italic" is="true">if x</mi><mo is="true">≤</mo><mn is="true">0</mn></mrow></mtd></mtr></mtable></mrow></mrow></mfenced></mrow></mrow></math></script></span></span></span></div><div class="u-margin-s-bottom" id="p0130">The biggest drawback of the original LBP is that only a small region is covered by it within a fixed radius, and this is not suitable when the sizes and frequency of textures are different. Circle LBP was proposed to make it suitable for different size and frequency textures features and meet the needs of gray scale and rotation invariance. It is not only 3&nbsp;×&nbsp;3 neighborhood but can be any neighborhood, and the circular neighborhood is also replaced with a square neighborhood. Circle LBP allows arbitrary multiple pixel points in the circular neighborhood with radius R. The LBP operator with P sampling points in the circular region with radius R is obtained. It can be defined as follows:<span class="display"><span id="e0025" class="formula"><span class="label">(3)</span><span class="math"><span class="MathJax_Preview" style=""></span><span class="MathJax_SVG" id="MathJax-Element-18-Frame" tabindex="0" data-mathml="<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mrow is=&quot;true&quot;><mtable is=&quot;true&quot;><mtr is=&quot;true&quot;><mtd is=&quot;true&quot;><mrow is=&quot;true&quot;><msub is=&quot;true&quot;><mrow is=&quot;true&quot;><mi mathvariant=&quot;italic&quot; is=&quot;true&quot;>LBP</mi></mrow><mrow is=&quot;true&quot;><mi is=&quot;true&quot;>P</mi><mo is=&quot;true&quot;>,</mo><mi is=&quot;true&quot;>R</mi></mrow></msub><mrow is=&quot;true&quot;><mfenced close=&quot;)&quot; open=&quot;(&quot; is=&quot;true&quot;><mrow is=&quot;true&quot;><msub is=&quot;true&quot;><mi is=&quot;true&quot;>x</mi><mi is=&quot;true&quot;>c</mi></msub><mo is=&quot;true&quot;>,</mo><msub is=&quot;true&quot;><mi is=&quot;true&quot;>y</mi><mi is=&quot;true&quot;>c</mi></msub></mrow></mfenced></mrow><mo is=&quot;true&quot;>=</mo><msubsup is=&quot;true&quot;><mo is=&quot;true&quot;>&amp;#x2211;</mo><mrow is=&quot;true&quot;><mi is=&quot;true&quot;>P</mi><mo is=&quot;true&quot;>=</mo><mn is=&quot;true&quot;>0</mn></mrow><mrow is=&quot;true&quot;><mi is=&quot;true&quot;>P</mi><mo is=&quot;true&quot;>-</mo><mn is=&quot;true&quot;>1</mn></mrow></msubsup><mi is=&quot;true&quot;>S</mi><mrow is=&quot;true&quot;><mfenced close=&quot;)&quot; open=&quot;(&quot; is=&quot;true&quot;><mrow is=&quot;true&quot;><msub is=&quot;true&quot;><mi is=&quot;true&quot;>i</mi><mi is=&quot;true&quot;>p</mi></msub><mo is=&quot;true&quot;>-</mo><msub is=&quot;true&quot;><mi is=&quot;true&quot;>i</mi><mi is=&quot;true&quot;>c</mi></msub></mrow></mfenced></mrow><msup is=&quot;true&quot;><mrow is=&quot;true&quot;><mn is=&quot;true&quot;>2</mn></mrow><mi is=&quot;true&quot;>p</mi></msup><mo is=&quot;true&quot;>#</mo></mrow></mtd></mtr></mtable></mrow></math>" role="presentation" style="font-size: 90%; display: inline-block; position: relative;"><svg xmlns:xlink="http://www.w3.org/1999/xlink" width="38.727ex" height="3.24ex" viewBox="0 -945.9 16674.3 1395" role="img" focusable="false" style="vertical-align: -1.043ex;" aria-hidden="true"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><g is="true"><g is="true" transform="translate(167,0)"><g transform="translate(-16,0)"><g is="true" transform="translate(0,-80)"><g is="true"><g is="true"><g is="true"><g is="true"><use xlink:href="#MJMATHI-4C"></use><use xlink:href="#MJMATHI-42" x="681" y="0"></use><use xlink:href="#MJMATHI-50" x="1441" y="0"></use></g></g><g is="true" transform="translate(2083,-150)"><g is="true"><use transform="scale(0.707)" xlink:href="#MJMATHI-50"></use></g><g is="true" transform="translate(531,0)"><use transform="scale(0.707)" xlink:href="#MJMAIN-2C"></use></g><g is="true" transform="translate(728,0)"><use transform="scale(0.707)" xlink:href="#MJMATHI-52"></use></g></g></g><g is="true" transform="translate(3448,0)"><g is="true"><use xlink:href="#MJMAIN-28" x="0" y="0"></use><g is="true" transform="translate(389,0)"><g is="true"><g is="true"><use xlink:href="#MJMATHI-78"></use></g><g is="true" transform="translate(572,-150)"><use transform="scale(0.707)" xlink:href="#MJMATHI-63"></use></g></g><g is="true" transform="translate(979,0)"><use xlink:href="#MJMAIN-2C"></use></g><g is="true" transform="translate(1424,0)"><g is="true"><use xlink:href="#MJMATHI-79"></use></g><g is="true" transform="translate(490,-150)"><use transform="scale(0.707)" xlink:href="#MJMATHI-63"></use></g></g></g><use xlink:href="#MJMAIN-29" x="2710" y="0"></use></g></g><g is="true" transform="translate(6549,0)"><use xlink:href="#MJMAIN-3D"></use></g><g is="true" transform="translate(7605,0)"><g is="true"><use xlink:href="#MJSZ1-2211"></use></g><g is="true" transform="translate(1056,477)"><g is="true"><use transform="scale(0.707)" xlink:href="#MJMATHI-50"></use></g><g is="true" transform="translate(531,0)"><use transform="scale(0.707)" xlink:href="#MJMAIN-2212"></use></g><g is="true" transform="translate(1081,0)"><use transform="scale(0.707)" xlink:href="#MJMAIN-31"></use></g></g><g is="true" transform="translate(1056,-287)"><g is="true"><use transform="scale(0.707)" xlink:href="#MJMATHI-50"></use></g><g is="true" transform="translate(531,0)"><use transform="scale(0.707)" xlink:href="#MJMAIN-3D"></use></g><g is="true" transform="translate(1081,0)"><use transform="scale(0.707)" xlink:href="#MJMAIN-30"></use></g></g></g><g is="true" transform="translate(10364,0)"><use xlink:href="#MJMATHI-53"></use></g><g is="true" transform="translate(11009,0)"><g is="true"><use xlink:href="#MJMAIN-28"></use><g is="true" transform="translate(389,0)"><g is="true"><g is="true"><use xlink:href="#MJMATHI-69"></use></g><g is="true" transform="translate(345,-150)"><use transform="scale(0.707)" xlink:href="#MJMATHI-70"></use></g></g><g is="true" transform="translate(1023,0)"><use xlink:href="#MJMAIN-2212"></use></g><g is="true" transform="translate(2024,0)"><g is="true"><use xlink:href="#MJMATHI-69"></use></g><g is="true" transform="translate(345,-150)"><use transform="scale(0.707)" xlink:href="#MJMATHI-63"></use></g></g></g><use xlink:href="#MJMAIN-29" x="3166" y="0"></use></g></g><g is="true" transform="translate(14565,0)"><g is="true"><g is="true"><use xlink:href="#MJMAIN-32"></use></g></g><g is="true" transform="translate(500,393)"><use transform="scale(0.707)" xlink:href="#MJMATHI-70"></use></g></g><g is="true" transform="translate(15521,0)"><use xlink:href="#MJMAIN-23"></use></g></g></g></g></g></g></g></svg><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow is="true"><mtable is="true"><mtr is="true"><mtd is="true"><mrow is="true"><msub is="true"><mrow is="true"><mi mathvariant="italic" is="true">LBP</mi></mrow><mrow is="true"><mi is="true">P</mi><mo is="true">,</mo><mi is="true">R</mi></mrow></msub><mrow is="true"><mfenced close=")" open="(" is="true"><mrow is="true"><msub is="true"><mi is="true">x</mi><mi is="true">c</mi></msub><mo is="true">,</mo><msub is="true"><mi is="true">y</mi><mi is="true">c</mi></msub></mrow></mfenced></mrow><mo is="true">=</mo><msubsup is="true"><mo is="true">∑</mo><mrow is="true"><mi is="true">P</mi><mo is="true">=</mo><mn is="true">0</mn></mrow><mrow is="true"><mi is="true">P</mi><mo is="true">-</mo><mn is="true">1</mn></mrow></msubsup><mi is="true">S</mi><mrow is="true"><mfenced close=")" open="(" is="true"><mrow is="true"><msub is="true"><mi is="true">i</mi><mi is="true">p</mi></msub><mo is="true">-</mo><msub is="true"><mi is="true">i</mi><mi is="true">c</mi></msub></mrow></mfenced></mrow><msup is="true"><mrow is="true"><mn is="true">2</mn></mrow><mi is="true">p</mi></msup><mo is="true">#</mo></mrow></mtd></mtr></mtable></mrow></math></span></span><script type="math/mml" id="MathJax-Element-18"><math><mrow is="true"><mtable is="true"><mtr is="true"><mtd is="true"><mrow is="true"><msub is="true"><mrow is="true"><mi mathvariant="italic" is="true">LBP</mi></mrow><mrow is="true"><mi is="true">P</mi><mo is="true">,</mo><mi is="true">R</mi></mrow></msub><mrow is="true"><mfenced close=")" open="(" is="true"><mrow is="true"><msub is="true"><mi is="true">x</mi><mi is="true">c</mi></msub><mo is="true">,</mo><msub is="true"><mi is="true">y</mi><mi is="true">c</mi></msub></mrow></mfenced></mrow><mo is="true">=</mo><msubsup is="true"><mo is="true">∑</mo><mrow is="true"><mi is="true">P</mi><mo is="true">=</mo><mn is="true">0</mn></mrow><mrow is="true"><mi is="true">P</mi><mo is="true">-</mo><mn is="true">1</mn></mrow></msubsup><mi is="true">S</mi><mrow is="true"><mfenced close=")" open="(" is="true"><mrow is="true"><msub is="true"><mi is="true">i</mi><mi is="true">p</mi></msub><mo is="true">-</mo><msub is="true"><mi is="true">i</mi><mi is="true">c</mi></msub></mrow></mfenced></mrow><msup is="true"><mrow is="true"><mn is="true">2</mn></mrow><mi is="true">p</mi></msup><mo is="true">#</mo></mrow></mtd></mtr></mtable></mrow></math></script></span></span></span>where p is the number of sampling points, R is the radius of the circle neighborhood, (<span class="math"><span class="MathJax_Preview" style=""></span><span class="MathJax_SVG" id="MathJax-Element-19-Frame" tabindex="0" data-mathml="<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mrow is=&quot;true&quot;><msub is=&quot;true&quot;><mi is=&quot;true&quot;>x</mi><mi is=&quot;true&quot;>c</mi></msub></mrow></math>" role="presentation" style="font-size: 90%; display: inline-block; position: relative;"><svg xmlns:xlink="http://www.w3.org/1999/xlink" width="2.274ex" height="1.74ex" viewBox="0 -498.8 979 749.2" role="img" focusable="false" style="vertical-align: -0.582ex;" aria-hidden="true"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><g is="true"><g is="true"><g is="true"><use xlink:href="#MJMATHI-78"></use></g><g is="true" transform="translate(572,-150)"><use transform="scale(0.707)" xlink:href="#MJMATHI-63"></use></g></g></g></g></svg><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow is="true"><msub is="true"><mi is="true">x</mi><mi is="true">c</mi></msub></mrow></math></span></span><script type="math/mml" id="MathJax-Element-19"><math><mrow is="true"><msub is="true"><mi is="true">x</mi><mi is="true">c</mi></msub></mrow></math></script></span>,<span class="math"><span class="MathJax_Preview" style=""></span><span class="MathJax_SVG" id="MathJax-Element-20-Frame" tabindex="0" data-mathml="<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mrow is=&quot;true&quot;><msub is=&quot;true&quot;><mi is=&quot;true&quot;>y</mi><mi is=&quot;true&quot;>c</mi></msub></mrow></math>" role="presentation" style="font-size: 90%; display: inline-block; position: relative;"><svg xmlns:xlink="http://www.w3.org/1999/xlink" width="2.083ex" height="1.855ex" viewBox="0 -498.8 897 798.9" role="img" focusable="false" style="vertical-align: -0.697ex;" aria-hidden="true"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><g is="true"><g is="true"><g is="true"><use xlink:href="#MJMATHI-79"></use></g><g is="true" transform="translate(490,-150)"><use transform="scale(0.707)" xlink:href="#MJMATHI-63"></use></g></g></g></g></svg><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow is="true"><msub is="true"><mi is="true">y</mi><mi is="true">c</mi></msub></mrow></math></span></span><script type="math/mml" id="MathJax-Element-20"><math><mrow is="true"><msub is="true"><mi is="true">y</mi><mi is="true">c</mi></msub></mrow></math></script></span>) is the coordinate of center pixel, <span class="math"><span class="MathJax_Preview" style=""></span><span class="MathJax_SVG" id="MathJax-Element-21-Frame" tabindex="0" data-mathml="<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mrow is=&quot;true&quot;><msub is=&quot;true&quot;><mi is=&quot;true&quot;>i</mi><mi is=&quot;true&quot;>c</mi></msub></mrow></math>" role="presentation" style="font-size: 90%; display: inline-block; position: relative;"><svg xmlns:xlink="http://www.w3.org/1999/xlink" width="1.747ex" height="2.317ex" viewBox="0 -747.2 752 997.6" role="img" focusable="false" style="vertical-align: -0.582ex;" aria-hidden="true"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><g is="true"><g is="true"><g is="true"><use xlink:href="#MJMATHI-69"></use></g><g is="true" transform="translate(345,-150)"><use transform="scale(0.707)" xlink:href="#MJMATHI-63"></use></g></g></g></g></svg><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow is="true"><msub is="true"><mi is="true">i</mi><mi is="true">c</mi></msub></mrow></math></span></span><script type="math/mml" id="MathJax-Element-21"><math><mrow is="true"><msub is="true"><mi is="true">i</mi><mi is="true">c</mi></msub></mrow></math></script></span> is the pixel value of the center pixel and <span class="math"><span class="MathJax_Preview" style=""></span><span class="MathJax_SVG" id="MathJax-Element-22-Frame" tabindex="0" data-mathml="<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mrow is=&quot;true&quot;><msub is=&quot;true&quot;><mi is=&quot;true&quot;>i</mi><mi is=&quot;true&quot;>p</mi></msub></mrow></math>" role="presentation" style="font-size: 90%; display: inline-block; position: relative;"><svg xmlns:xlink="http://www.w3.org/1999/xlink" width="1.862ex" height="2.548ex" viewBox="0 -747.2 801.5 1096.9" role="img" focusable="false" style="vertical-align: -0.812ex;" aria-hidden="true"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><g is="true"><g is="true"><g is="true"><use xlink:href="#MJMATHI-69"></use></g><g is="true" transform="translate(345,-150)"><use transform="scale(0.707)" xlink:href="#MJMATHI-70"></use></g></g></g></g></svg><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow is="true"><msub is="true"><mi is="true">i</mi><mi is="true">p</mi></msub></mrow></math></span></span><script type="math/mml" id="MathJax-Element-22"><math><mrow is="true"><msub is="true"><mi is="true">i</mi><mi is="true">p</mi></msub></mrow></math></script></span> is the pixel value of P sampling points, and <span class="math"><span class="MathJax_Preview" style=""></span><span class="MathJax_SVG" id="MathJax-Element-23-Frame" tabindex="0" data-mathml="<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mrow is=&quot;true&quot;><mi mathvariant=&quot;normal&quot; is=&quot;true&quot;>s</mi></mrow></math>" role="presentation" style="font-size: 90%; display: inline-block; position: relative;"><svg xmlns:xlink="http://www.w3.org/1999/xlink" width="0.916ex" height="1.509ex" viewBox="0 -548.5 394.5 649.8" role="img" focusable="false" style="vertical-align: -0.235ex;" aria-hidden="true"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><g is="true"><g is="true"><use xlink:href="#MJMAIN-73"></use></g></g></g></svg><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow is="true"><mi mathvariant="normal" is="true">s</mi></mrow></math></span></span><script type="math/mml" id="MathJax-Element-23"><math><mrow is="true"><mi mathvariant="normal" is="true">s</mi></mrow></math></script></span> is the sign function which is same as in Eq. (2).</div><div class="u-margin-s-bottom" id="p0135">Further extension of LBP such as uniform patterns <a class="anchor anchor-primary" href="#b0070" name="bb0070" data-sd-ui-side-panel-opener="true" data-xocs-content-type="reference" data-xocs-content-id="b0070"><span class="anchor-text-container"><span class="anchor-text">[10]</span></span></a><span> was used to solve the problems of too many binary eigenvalue encoding modes and improve statistical performance. When the bitwise pattern is <a href="/topics/engineering/circularity" title="Learn more about circularity from ScienceDirect's AI-generated Topic Pages" class="topic-link">circularity</a>, uniform LBP includes at most two bitwise transitions from 0 to 1 or 1 to 0. It can be defined as follows:</span><span class="display"><span id="e0030" class="formula"><span class="label">(4)</span><span class="math"><span class="MathJax_Preview" style=""></span><span class="MathJax_SVG" id="MathJax-Element-24-Frame" tabindex="0" data-mathml="<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mrow is=&quot;true&quot;><msubsup is=&quot;true&quot;><mrow is=&quot;true&quot;><mi mathvariant=&quot;italic&quot; is=&quot;true&quot;>LBP</mi></mrow><mrow is=&quot;true&quot;><mi is=&quot;true&quot;>P</mi><mo is=&quot;true&quot;>,</mo><mi is=&quot;true&quot;>R</mi></mrow><mrow is=&quot;true&quot;><mi is=&quot;true&quot;>r</mi><mi is=&quot;true&quot;>i</mi><mi is=&quot;true&quot;>u</mi><mi is=&quot;true&quot;>s</mi><mn is=&quot;true&quot;>2</mn></mrow></msubsup><mo linebreak=&quot;goodbreak&quot; is=&quot;true&quot;>=</mo><mrow is=&quot;true&quot;><mfenced close=&quot;&quot; open=&quot;{&quot; is=&quot;true&quot;><mrow is=&quot;true&quot;><mrow is=&quot;true&quot;><mtable is=&quot;true&quot;><mtr is=&quot;true&quot;><mtd is=&quot;true&quot;><mrow is=&quot;true&quot;><munderover is=&quot;true&quot;><mo movablelimits=&quot;false&quot; is=&quot;true&quot;>&amp;#x2211;</mo><mrow is=&quot;true&quot;><mi is=&quot;true&quot;>P</mi><mo is=&quot;true&quot;>=</mo><mn is=&quot;true&quot;>0</mn></mrow><mrow is=&quot;true&quot;><mi is=&quot;true&quot;>P</mi><mo is=&quot;true&quot;>-</mo><mn is=&quot;true&quot;>1</mn></mrow></munderover><mrow is=&quot;true&quot;><mi is=&quot;true&quot;>s</mi><mo stretchy=&quot;false&quot; is=&quot;true&quot;>(</mo><msub is=&quot;true&quot;><mi is=&quot;true&quot;>i</mi><mi is=&quot;true&quot;>p</mi></msub><mo is=&quot;true&quot;>-</mo><msub is=&quot;true&quot;><mi is=&quot;true&quot;>i</mi><mi is=&quot;true&quot;>c</mi></msub><mo stretchy=&quot;false&quot; is=&quot;true&quot;>)</mo></mrow></mrow></mtd><mtd is=&quot;true&quot;><mrow is=&quot;true&quot;><mi mathvariant=&quot;italic&quot; is=&quot;true&quot;>if</mi></mrow></mtd><mtd is=&quot;true&quot;><mrow is=&quot;true&quot;><mi is=&quot;true&quot;>U</mi><mo stretchy=&quot;false&quot; is=&quot;true&quot;>(</mo><msub is=&quot;true&quot;><mrow is=&quot;true&quot;><mi mathvariant=&quot;italic&quot; is=&quot;true&quot;>LBP</mi></mrow><mrow is=&quot;true&quot;><mi is=&quot;true&quot;>P</mi><mo is=&quot;true&quot;>,</mo><mi is=&quot;true&quot;>R</mi></mrow></msub><mo stretchy=&quot;false&quot; is=&quot;true&quot;>)</mo><mo is=&quot;true&quot;>&amp;#x2A7D;</mo><mn is=&quot;true&quot;>2</mn></mrow></mtd></mtr><mtr is=&quot;true&quot;><mtd is=&quot;true&quot;><mrow is=&quot;true&quot;><mrow is=&quot;true&quot;><mi is=&quot;true&quot;>P</mi><mo is=&quot;true&quot;>+</mo><mn is=&quot;true&quot;>1</mn></mrow></mrow></mtd><mtd is=&quot;true&quot;><mspace width=&quot;0.166667em&quot; is=&quot;true&quot; /></mtd><mtd is=&quot;true&quot;><mrow is=&quot;true&quot;><mi mathvariant=&quot;italic&quot; is=&quot;true&quot;>otherwise</mi></mrow></mtd></mtr></mtable></mrow></mrow></mfenced></mrow></mrow></math>" role="presentation" style="font-size: 90%; display: inline-block; position: relative;"><svg xmlns:xlink="http://www.w3.org/1999/xlink" width="48.765ex" height="9.702ex" viewBox="0 -2336.9 20995.8 4177.1" role="img" focusable="false" style="vertical-align: -4.274ex;" aria-hidden="true"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><g is="true"><g is="true"><g is="true"><g is="true"><use xlink:href="#MJMATHI-4C"></use><use xlink:href="#MJMATHI-42" x="681" y="0"></use><use xlink:href="#MJMATHI-50" x="1441" y="0"></use></g></g><g is="true" transform="translate(2083,410)"><g is="true"><use transform="scale(0.707)" xlink:href="#MJMATHI-72"></use></g><g is="true" transform="translate(319,0)"><use transform="scale(0.707)" xlink:href="#MJMATHI-69"></use></g><g is="true" transform="translate(563,0)"><use transform="scale(0.707)" xlink:href="#MJMATHI-75"></use></g><g is="true" transform="translate(968,0)"><use transform="scale(0.707)" xlink:href="#MJMATHI-73"></use></g><g is="true" transform="translate(1300,0)"><use transform="scale(0.707)" xlink:href="#MJMAIN-32"></use></g></g><g is="true" transform="translate(2083,-262)"><g is="true"><use transform="scale(0.707)" xlink:href="#MJMATHI-50"></use></g><g is="true" transform="translate(531,0)"><use transform="scale(0.707)" xlink:href="#MJMAIN-2C"></use></g><g is="true" transform="translate(728,0)"><use transform="scale(0.707)" xlink:href="#MJMATHI-52"></use></g></g></g><g is="true" transform="translate(4115,0)"><use xlink:href="#MJMAIN-3D"></use></g><g is="true" transform="translate(4894,0)"><g is="true"><g transform="translate(0,2241)"><use xlink:href="#MJSZ4-23A7" x="0" y="-900"></use><g transform="translate(0,-1121.199566223729) scale(1,0.836654553774049)"><use xlink:href="#MJSZ4-23AA"></use></g><use xlink:href="#MJSZ4-23A8" x="0" y="-2242"></use><g transform="translate(0,-3112.602332538973) scale(1,0.836654553774049)"><use xlink:href="#MJSZ4-23AA"></use></g><use xlink:href="#MJSZ4-23A9" x="0" y="-3083"></use></g><g is="true" transform="translate(889,0)"><g is="true"><g is="true" transform="translate(167,0)"><g transform="translate(-16,0)"><g is="true" transform="translate(0,706)"><g is="true"><g is="true"><g is="true" transform="translate(189,0)"><use xlink:href="#MJSZ1-2211"></use></g><g is="true" transform="translate(0,-902)"><g is="true"><use transform="scale(0.707)" xlink:href="#MJMATHI-50"></use></g><g is="true" transform="translate(531,0)"><use transform="scale(0.707)" xlink:href="#MJMAIN-3D"></use></g><g is="true" transform="translate(1081,0)"><use transform="scale(0.707)" xlink:href="#MJMAIN-30"></use></g></g><g is="true" transform="translate(0,951)"><g is="true"><use transform="scale(0.707)" xlink:href="#MJMATHI-50"></use></g><g is="true" transform="translate(531,0)"><use transform="scale(0.707)" xlink:href="#MJMAIN-2212"></use></g><g is="true" transform="translate(1081,0)"><use transform="scale(0.707)" xlink:href="#MJMAIN-31"></use></g></g></g><g is="true" transform="translate(1602,0)"><g is="true"><use xlink:href="#MJMATHI-73"></use></g><g is="true" transform="translate(469,0)"><use xlink:href="#MJMAIN-28"></use></g><g is="true" transform="translate(859,0)"><g is="true"><use xlink:href="#MJMATHI-69"></use></g><g is="true" transform="translate(345,-150)"><use transform="scale(0.707)" xlink:href="#MJMATHI-70"></use></g></g><g is="true" transform="translate(1882,0)"><use xlink:href="#MJMAIN-2212"></use></g><g is="true" transform="translate(2883,0)"><g is="true"><use xlink:href="#MJMATHI-69"></use></g><g is="true" transform="translate(345,-150)"><use transform="scale(0.707)" xlink:href="#MJMATHI-63"></use></g></g><g is="true" transform="translate(3635,0)"><use xlink:href="#MJMAIN-29"></use></g></g></g></g><g is="true" transform="translate(1576,-1542)"><g is="true"><g is="true"><g is="true"><use xlink:href="#MJMATHI-50"></use></g><g is="true" transform="translate(973,0)"><use xlink:href="#MJMAIN-2B"></use></g><g is="true" transform="translate(1974,0)"><use xlink:href="#MJMAIN-31"></use></g></g></g></g></g><g transform="translate(6412,0)"><g is="true" transform="translate(0,706)"><g is="true"><g is="true"><use xlink:href="#MJMATHI-69"></use><use xlink:href="#MJMATHI-66" x="345" y="0"></use></g></g></g><g is="true" transform="translate(334,-1542)"><g is="true"></g></g></g><g transform="translate(8048,0)"><g is="true" transform="translate(0,706)"><g is="true"><g is="true"><use xlink:href="#MJMATHI-55"></use></g><g is="true" transform="translate(767,0)"><use xlink:href="#MJMAIN-28"></use></g><g is="true" transform="translate(1157,0)"><g is="true"><g is="true"><use xlink:href="#MJMATHI-4C"></use><use xlink:href="#MJMATHI-42" x="681" y="0"></use><use xlink:href="#MJMATHI-50" x="1441" y="0"></use></g></g><g is="true" transform="translate(2083,-150)"><g is="true"><use transform="scale(0.707)" xlink:href="#MJMATHI-50"></use></g><g is="true" transform="translate(531,0)"><use transform="scale(0.707)" xlink:href="#MJMAIN-2C"></use></g><g is="true" transform="translate(728,0)"><use transform="scale(0.707)" xlink:href="#MJMATHI-52"></use></g></g></g><g is="true" transform="translate(4605,0)"><use xlink:href="#MJMAIN-29"></use></g><g is="true" transform="translate(5273,0)"><use xlink:href="#MJAMS-2A7D"></use></g><g is="true" transform="translate(6329,0)"><use xlink:href="#MJMAIN-32"></use></g></g></g><g is="true" transform="translate(1245,-1542)"><g is="true"><g is="true"><use xlink:href="#MJMATHI-6F"></use><use xlink:href="#MJMATHI-74" x="485" y="0"></use><use xlink:href="#MJMATHI-68" x="847" y="0"></use><use xlink:href="#MJMATHI-65" x="1423" y="0"></use><use xlink:href="#MJMATHI-72" x="1890" y="0"></use><use xlink:href="#MJMATHI-77" x="2341" y="0"></use><use xlink:href="#MJMATHI-69" x="3058" y="0"></use><use xlink:href="#MJMATHI-73" x="3403" y="0"></use><use xlink:href="#MJMATHI-65" x="3873" y="0"></use></g></g></g></g></g></g></g></g></g></g></g></svg><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow is="true"><msubsup is="true"><mrow is="true"><mi mathvariant="italic" is="true">LBP</mi></mrow><mrow is="true"><mi is="true">P</mi><mo is="true">,</mo><mi is="true">R</mi></mrow><mrow is="true"><mi is="true">r</mi><mi is="true">i</mi><mi is="true">u</mi><mi is="true">s</mi><mn is="true">2</mn></mrow></msubsup><mo linebreak="goodbreak" is="true">=</mo><mrow is="true"><mfenced close="" open="{" is="true"><mrow is="true"><mrow is="true"><mtable is="true"><mtr is="true"><mtd is="true"><mrow is="true"><munderover is="true"><mo movablelimits="false" is="true">∑</mo><mrow is="true"><mi is="true">P</mi><mo is="true">=</mo><mn is="true">0</mn></mrow><mrow is="true"><mi is="true">P</mi><mo is="true">-</mo><mn is="true">1</mn></mrow></munderover><mrow is="true"><mi is="true">s</mi><mo stretchy="false" is="true">(</mo><msub is="true"><mi is="true">i</mi><mi is="true">p</mi></msub><mo is="true">-</mo><msub is="true"><mi is="true">i</mi><mi is="true">c</mi></msub><mo stretchy="false" is="true">)</mo></mrow></mrow></mtd><mtd is="true"><mrow is="true"><mi mathvariant="italic" is="true">if</mi></mrow></mtd><mtd is="true"><mrow is="true"><mi is="true">U</mi><mo stretchy="false" is="true">(</mo><msub is="true"><mrow is="true"><mi mathvariant="italic" is="true">LBP</mi></mrow><mrow is="true"><mi is="true">P</mi><mo is="true">,</mo><mi is="true">R</mi></mrow></msub><mo stretchy="false" is="true">)</mo><mo is="true">⩽</mo><mn is="true">2</mn></mrow></mtd></mtr><mtr is="true"><mtd is="true"><mrow is="true"><mrow is="true"><mi is="true">P</mi><mo is="true">+</mo><mn is="true">1</mn></mrow></mrow></mtd><mtd is="true"><mspace width="0.166667em" is="true"></mspace></mtd><mtd is="true"><mrow is="true"><mi mathvariant="italic" is="true">otherwise</mi></mrow></mtd></mtr></mtable></mrow></mrow></mfenced></mrow></mrow></math></span></span><script type="math/mml" id="MathJax-Element-24"><math><mrow is="true"><msubsup is="true"><mrow is="true"><mi mathvariant="italic" is="true">LBP</mi></mrow><mrow is="true"><mi is="true">P</mi><mo is="true">,</mo><mi is="true">R</mi></mrow><mrow is="true"><mi is="true">r</mi><mi is="true">i</mi><mi is="true">u</mi><mi is="true">s</mi><mn is="true">2</mn></mrow></msubsup><mo linebreak="goodbreak" is="true">=</mo><mrow is="true"><mfenced close="" open="{" is="true"><mrow is="true"><mrow is="true"><mtable is="true"><mtr is="true"><mtd is="true"><mrow is="true"><munderover is="true"><mo movablelimits="false" is="true">∑</mo><mrow is="true"><mi is="true">P</mi><mo is="true">=</mo><mn is="true">0</mn></mrow><mrow is="true"><mi is="true">P</mi><mo is="true">-</mo><mn is="true">1</mn></mrow></munderover><mrow is="true"><mi is="true">s</mi><mo stretchy="false" is="true">(</mo><msub is="true"><mi is="true">i</mi><mi is="true">p</mi></msub><mo is="true">-</mo><msub is="true"><mi is="true">i</mi><mi is="true">c</mi></msub><mo stretchy="false" is="true">)</mo></mrow></mrow></mtd><mtd is="true"><mrow is="true"><mi mathvariant="italic" is="true">if</mi></mrow></mtd><mtd is="true"><mrow is="true"><mi is="true">U</mi><mo stretchy="false" is="true">(</mo><msub is="true"><mrow is="true"><mi mathvariant="italic" is="true">LBP</mi></mrow><mrow is="true"><mi is="true">P</mi><mo is="true">,</mo><mi is="true">R</mi></mrow></msub><mo stretchy="false" is="true">)</mo><mo is="true">⩽</mo><mn is="true">2</mn></mrow></mtd></mtr><mtr is="true"><mtd is="true"><mrow is="true"><mrow is="true"><mi is="true">P</mi><mo is="true">+</mo><mn is="true">1</mn></mrow></mrow></mtd><mtd is="true"><mspace width="0.166667em" is="true"></mspace></mtd><mtd is="true"><mrow is="true"><mi mathvariant="italic" is="true">otherwise</mi></mrow></mtd></mtr></mtable></mrow></mrow></mfenced></mrow></mrow></math></script></span></span></span>where U is the uniformity measure and the ‘rius2’ represents rotation-invariant uniform pattern.</div></section><section id="s0035"><h3 id="st045" class="u-h4 u-margin-m-top u-margin-xs-bottom">3.4. Data augmentation</h3><div class="u-margin-s-bottom" id="p0140">In order to ensure that the network can achieve a good <a href="/topics/computer-science/generalization-ability" title="Learn more about generalization ability from ScienceDirect's AI-generated Topic Pages" class="topic-link">generalization ability</a><span>, enough <a href="/topics/computer-science/training-data" title="Learn more about training data from ScienceDirect's AI-generated Topic Pages" class="topic-link">training data</a> are required. However, most publicly-available datasets such as JAFFE do not have enough number of images for training. The amount of data is small, which can also lead to the overfitting problem. Therefore, data augmentation is important for facial expression recognition.</span></div><div class="u-margin-s-bottom"><div id="p0145">Label-preserving transformation is one of the most common methods to enlarge the number of images in datasets. In this paper, four methods are used to enlarge the image number of the original data and the example images after augmentation are shown in <a class="anchor anchor-primary" href="#f0040" name="bf0040" data-sd-ui-side-panel-opener="true" data-xocs-content-type="reference" data-xocs-content-id="f0040"><span class="anchor-text-container"><span class="anchor-text">Fig. 8</span></span></a>. We take random rotation, flipping, shifting and scaling on the images. The rotation range is 0–20° and the shifting ranges of width and height are set to 0–15%. Both the shear range and the zoom range are 0–0.15. Before data augmentation, the number of images in FER2013, CK+, JAFFE, Oulu-CASIA and NCUFE are 35,795, 981, 213, 1440 and 735, respectively. After data augmentation, the number of images in FER2013, CK+, Oulu-CASIA and NCUFE are increased to 45,017, 12,000, 11,843, 13,800 and 13,827, respectively.</div><figure class="figure text-xs" id="f0040"><span><img src="https://ars.els-cdn.com/content/image/1-s2.0-S0925231220309838-gr8.jpg" height="143" alt="" aria-describedby="cn0040"><ol class="u-margin-s-bottom"><li><a class="anchor download-link u-font-sans anchor-primary" href="https://ars.els-cdn.com/content/image/1-s2.0-S0925231220309838-gr8_lrg.jpg" target="_blank" download="" title="Download high-res image (65KB)"><span class="anchor-text-container"><span class="anchor-text">Download: <span class="download-link-title">Download high-res image (65KB)</span></span></span></a></li><li><a class="anchor download-link u-font-sans anchor-primary" href="https://ars.els-cdn.com/content/image/1-s2.0-S0925231220309838-gr8.jpg" target="_blank" download="" title="Download full-size image"><span class="anchor-text-container"><span class="anchor-text">Download: <span class="download-link-title">Download full-size image</span></span></span></a></li></ol></span><span class="captions text-s"><span id="cn0040"><p id="sp0070"><span class="label">Fig. 8</span>. Examples for <a href="/topics/computer-science/data-augmentation" title="Learn more about data augmentation from ScienceDirect's AI-generated Topic Pages" class="topic-link">data augmentation</a> in the NCUFE dataset, (a) is the image from the original dataset, (b), (c), (d) and (e) are the images after augmentation.</p></span></span></figure></div></section></section><section id="s0040"><h2 id="st050" class="u-h4 u-margin-l-top u-margin-xs-bottom">4. Experimental results</h2><div class="u-margin-s-bottom"><div id="p0150"><span>In this work, we design a novel <a href="/topics/computer-science/deep-convolutional-neural-networks" title="Learn more about deep Convolutional Neural Network from ScienceDirect's AI-generated Topic Pages" class="topic-link">deep Convolutional Neural Network</a> with an attention model to automatically recognizing facial expressions. Except for the famous facial expression datasets such as CK+ </span><a class="anchor anchor-primary" href="#b0075" name="bb0075" data-sd-ui-side-panel-opener="true" data-xocs-content-type="reference" data-xocs-content-id="b0075"><span class="anchor-text-container"><span class="anchor-text">[11]</span></span></a>, JAFFE <a class="anchor anchor-primary" href="#b0085" name="bb0085" data-sd-ui-side-panel-opener="true" data-xocs-content-type="reference" data-xocs-content-id="b0085"><span class="anchor-text-container"><span class="anchor-text">[13]</span></span></a>, Oulu-CASIA <a class="anchor anchor-primary" href="#b0145" name="bb0145" data-sd-ui-side-panel-opener="true" data-xocs-content-type="reference" data-xocs-content-id="b0145"><span class="anchor-text-container"><span class="anchor-text">[25]</span></span></a> and FER2013 <a class="anchor anchor-primary" href="#b0215" name="bb0215" data-sd-ui-side-panel-opener="true" data-xocs-content-type="reference" data-xocs-content-id="b0215"><span class="anchor-text-container"><span class="anchor-text">[39]</span></span></a><span><span>, we also evaluate our proposed method on our self-collected dataset NCUFE. Because CK+, JAFFE, Oulu-CASIA and NCUFE do not provide specified training and testing sets, we employ 5-fold cross-validation protocol in these four datasets. The proposed facial expression recognition framework is implemented with <a href="/topics/computer-science/keras" title="Learn more about Keras from ScienceDirect's AI-generated Topic Pages" class="topic-link">Keras</a>. The framework is trained with an initialized </span><a href="/topics/computer-science/learning-rate" title="Learn more about learning rate from ScienceDirect's AI-generated Topic Pages" class="topic-link">learning rate</a> 0.000001, and the batch size is 40. The size of input data is 256,256</span><span class="math"><span class="MathJax_Preview" style=""></span><span class="MathJax_SVG" id="MathJax-Element-25-Frame" tabindex="0" data-mathml="<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mrow is=&quot;true&quot;><mo is=&quot;true&quot;>&amp;#xD7;</mo></mrow></math>" role="presentation" style="font-size: 90%; display: inline-block; position: relative;"><svg xmlns:xlink="http://www.w3.org/1999/xlink" width="1.808ex" height="1.394ex" viewBox="0 -548.5 778.5 600.2" role="img" focusable="false" style="vertical-align: 0.019ex; margin-bottom: -0.139ex;" aria-hidden="true"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><g is="true"><g is="true"><use xlink:href="#MJMAIN-D7"></use></g></g></g></svg><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow is="true"><mo is="true">×</mo></mrow></math></span></span><script type="math/mml" id="MathJax-Element-25"><math><mrow is="true"><mo is="true">×</mo></mrow></math></script></span><span> because using large images as input to the network can make the network as deep as possible and help extract more useful features. We add batch normalization after each convolutional layer. Our network is trained on one TITAN RTX <a href="/topics/engineering/graphics-processing-unit" title="Learn more about GPU from ScienceDirect's AI-generated Topic Pages" class="topic-link">GPU</a>. In this section, we first conduct an ablation study on FER2013 </span><a class="anchor anchor-primary" href="#b0215" name="bb0215" data-sd-ui-side-panel-opener="true" data-xocs-content-type="reference" data-xocs-content-id="b0215"><span class="anchor-text-container"><span class="anchor-text">[39]</span></span></a> to analyze the configuration of our framework (as shown in <a class="anchor anchor-primary" href="#t0005" name="bt0005" data-sd-ui-side-panel-opener="true" data-xocs-content-type="reference" data-xocs-content-id="t0005"><span class="anchor-text-container"><span class="anchor-text">Table 1</span></span></a>). Then, we evaluate our proposed method in all these five datasets and compare the result to some state-of-the-art methods.</div><div class="tables colsep-0 frame-topbot rowsep-0" id="t0005"><span class="captions text-s"><span id="cn0045"><p id="sp0075"><span class="label">Table 1</span>. Comparison of different LBPs on FER2013 dataset.</p></span></span><div class="groups"><table><thead><tr class="rowsep-1 valign-top"><th scope="col" class="align-left">LBP</th><th scope="col" class="align-left">Recognition Rates (%)</th></tr></thead><tbody><tr class="valign-top"><td class="align-left">Original LBP</td><td class="align-left">72.56</td></tr><tr class="valign-top"><td class="align-left">Uniform LBP</td><td class="align-left">70.32</td></tr><tr class="valign-top"><td class="align-left"><strong>Circle LBP</strong></td><td class="align-left"><strong>75.82</strong></td></tr><tr class="valign-top"><td class="align-left">Without LBP</td><td class="align-left">67.73</td></tr></tbody></table></div></div></div><section id="s0045"><h3 id="st055" class="u-h4 u-margin-m-top u-margin-xs-bottom">4.1. Ablations on FER2013</h3><div class="u-margin-s-bottom" id="p0155">We perform an ablation study to analyze the effects of three kinds of LBPs (original LBP, circle LBP and uniform LBP) in our method on the FER2013 dataset <a class="anchor anchor-primary" href="#b0215" name="bb0215" data-sd-ui-side-panel-opener="true" data-xocs-content-type="reference" data-xocs-content-id="b0215"><span class="anchor-text-container"><span class="anchor-text">[39]</span></span></a>, which is a large-scale and unconstrained dataset collected from Internet. It is challenging to classify these images because of varied perspectives of face, wrong labels and some other noises. The recognition results are shown in <a class="anchor anchor-primary" href="#t0005" name="bt0005" data-sd-ui-side-panel-opener="true" data-xocs-content-type="reference" data-xocs-content-id="t0005"><span class="anchor-text-container"><span class="anchor-text">Table 1</span></span></a>, where circle LBP achieves the best accuracy. Therefore, we use circle LBP in our model for the following experiments.</div><div class="u-margin-s-bottom"><div id="p0160">Our model includes four parts, which are the feature extraction module, the attention module, the reconstruction module and the classification module. In order to figure out how each module affects the performance of our network we perform an ablation study on the networks. Because the classification module is necessary to classify in our networks, we retain the classification module and remove the feature extraction module, the attention module, and the reconstruction module separately and then conduct different experiments. The results are given in <a class="anchor anchor-primary" href="#t0010" name="bt0010" data-sd-ui-side-panel-opener="true" data-xocs-content-type="reference" data-xocs-content-id="t0010"><span class="anchor-text-container"><span class="anchor-text">Table 2</span></span></a>. As we can see, when one of these modules is removed, the recognition rate has a certain degree of decline compared with the complete network which achieves the recognition rate of 75.82%. Especially, when there is no feature extraction module, the recognition rate drops to 57.86%. In the feature extraction module, initial features are extracted from raw images and then sent to later modules for future processing. Generally, the obtained initial features are too coarse, but we need more refined features to send to the later attention module in order to make it work directly. Therefore, the feature extraction module is necessary in the network for extracting refined features. The attention module can make our network focus more on useful features and improve the recognition rate. When the attention module is removed, the recognition rate reduces to 73.96%, which proves the effectiveness of the attention module. The reconstruction module can improve the recognition rate by adjusting the attention map to create an enhanced feature map. When there is no reconstruction module in the network, the recognition rate drops to 74.25%. Based on the experimental results, we conclude that each module has a certain degree of improvement on the final results.</div><div class="tables colsep-0 frame-topbot rowsep-0" id="t0010"><span class="captions text-s"><span id="cn0050"><p id="sp0080"><span class="label">Table 2</span>. Comparison of different architectures on the FER2013 dataset.</p></span></span><div class="groups"><table><thead><tr class="rowsep-1 valign-top"><th scope="col" class="align-left">Architecture</th><th scope="col" class="align-left">Recognition Rates (%)</th></tr></thead><tbody><tr class="valign-top"><td class="align-left">Without the feature extraction module</td><td class="align-left">57.86</td></tr><tr class="valign-top"><td class="align-left">Without the attention module</td><td class="align-left">73.96</td></tr><tr class="valign-top"><td class="align-left">Without the reconstruction module</td><td class="align-left">74.25</td></tr><tr class="valign-top"><td class="align-left">Complete network</td><td class="align-left">75.82</td></tr></tbody></table></div></div></div><div class="u-margin-s-bottom"><div id="p0165">When designing the reconstruction module, we try several atrous kernels of different dilation rates. We perform experiments on five kinds of configurations and use A, B, C, D and E to refer to them separately. There are four atrous convolutions in the reconstruction module. In A, B, C and D, we use invariable dilation rates, the dilation rates are 1, 2, 3, and 4 separately. We use four atrous convolutions with four different dilation rates in E, which are 2, 3, 4 and 5 separately. The results are provided in <a class="anchor anchor-primary" href="#t0015" name="bt0015" data-sd-ui-side-panel-opener="true" data-xocs-content-type="reference" data-xocs-content-id="t0015"><span class="anchor-text-container"><span class="anchor-text">Table 3</span></span></a>. We can see that the reconstruction module E achieves the highest recognition rates. Therefore, we use variable dilation rates which are 2, 3, 4, 5 in the proposed method in this paper.</div><div class="tables colsep-0 frame-topbot rowsep-0" id="t0015"><span class="captions text-s"><span id="cn0055"><p id="sp0085"><span class="label">Table 3</span>. Comparison of different dilation rates of the reconstruction module on the FER2013 dataset.</p></span></span><div class="groups"><table><thead><tr class="rowsep-1 valign-top"><th scope="col" class="align-left">Dilation Rate</th><th scope="col" class="align-left">Recognition Rates (%)</th></tr></thead><tbody><tr class="valign-top"><td class="align-left">A (1)</td><td class="align-left">74.83</td></tr><tr class="valign-top"><td class="align-left">B (2)</td><td class="align-left">73.91</td></tr><tr class="valign-top"><td class="align-left">C (3)</td><td class="align-left">75.52</td></tr><tr class="valign-top"><td class="align-left">D (4)</td><td class="align-left">74.31</td></tr><tr class="valign-top"><td class="align-left">E (2, 3, 4, 5)</td><td class="align-left">75.82</td></tr></tbody></table></div></div></div></section><section id="s0050"><h3 id="st060" class="u-h4 u-margin-m-top u-margin-xs-bottom">4.2. Evaluation and comparison</h3><section id="s0055"><h4 id="st065" class="u-margin-m-top u-margin-xs-bottom">4.2.1. FER2013 dataset</h4><div class="u-margin-s-bottom"><div id="p0170">FER2013 <a class="anchor anchor-primary" href="#b0215" name="bb0215" data-sd-ui-side-panel-opener="true" data-xocs-content-type="reference" data-xocs-content-id="b0215"><span class="anchor-text-container"><span class="anchor-text">[39]</span></span></a> is a dataset collected in real world, which includes 28,709 training images and 3589 test images. Unlike CK+, Oulu-CASIA and JAFFE, FER2013 contains pictures of different postures, unbalanced illumination, and occlusion. We evaluate and compare our method with other five recent works <a class="anchor anchor-primary" href="#b0110" name="bb0110" data-sd-ui-side-panel-opener="true" data-xocs-content-type="reference" data-xocs-content-id="b0110"><span class="anchor-text-container"><span class="anchor-text">[18]</span></span></a>, <a class="anchor anchor-primary" href="#b0170" name="bb0170" data-sd-ui-side-panel-opener="true" data-xocs-content-type="reference" data-xocs-content-id="b0170"><span class="anchor-text-container"><span class="anchor-text">[30]</span></span></a>, <a class="anchor anchor-primary" href="#b0220" name="bb0220" data-sd-ui-side-panel-opener="true" data-xocs-content-type="reference" data-xocs-content-id="b0220"><span class="anchor-text-container"><span class="anchor-text">[40]</span></span></a>, <a class="anchor anchor-primary" href="#b0230" name="bb0230" data-sd-ui-side-panel-opener="true" data-xocs-content-type="reference" data-xocs-content-id="b0230"><span class="anchor-text-container"><span class="anchor-text">[42]</span></span></a>, <a class="anchor anchor-primary" href="#b0240" name="bb0240" data-sd-ui-side-panel-opener="true" data-xocs-content-type="reference" data-xocs-content-id="b0240"><span class="anchor-text-container"><span class="anchor-text">[44]</span></span></a>. The recognition results are given in <a class="anchor anchor-primary" href="#t0020" name="bt0020" data-sd-ui-side-panel-opener="true" data-xocs-content-type="reference" data-xocs-content-id="t0020"><span class="anchor-text-container"><span class="anchor-text">Table 4</span></span></a>, which show that our method is superior to all of the five advanced algorithms. The recognition rates are reduced in this dataset when there is no LBP or attention module. The result is reduced to 67.73% without LBP and 73.96 without attention module.</div><div class="tables colsep-0 frame-topbot rowsep-0" id="t0020"><span class="captions text-s"><span id="cn0060"><p id="sp0090"><span class="label">Table 4</span>. Comparison of different methods on the FER2013 dataset.</p></span></span><div class="groups"><table><thead><tr class="rowsep-1 valign-top"><th scope="col" class="align-left">Method</th><th scope="col" class="align-left">Recognition Rates (%)</th></tr></thead><tbody><tr class="valign-top"><td class="align-left">Wang <a class="anchor anchor-primary" href="#b0110" name="bb0110" data-sd-ui-side-panel-opener="true" data-xocs-content-type="reference" data-xocs-content-id="b0110"><span class="anchor-text-container"><span class="anchor-text">[18]</span></span></a></td><td class="align-left">71.1</td></tr><tr class="valign-top"><td class="align-left">Pramerdorfer et al. <a class="anchor anchor-primary" href="#b0230" name="bb0230" data-sd-ui-side-panel-opener="true" data-xocs-content-type="reference" data-xocs-content-id="b0230"><span class="anchor-text-container"><span class="anchor-text">[42]</span></span></a></td><td class="align-left">75.2</td></tr><tr class="valign-top"><td class="align-left">Kim et al. <a class="anchor anchor-primary" href="#b0225" name="bb0225" data-sd-ui-side-panel-opener="true" data-xocs-content-type="reference" data-xocs-content-id="b0225"><span class="anchor-text-container"><span class="anchor-text">[41]</span></span></a></td><td class="align-left">73.73</td></tr><tr class="valign-top"><td class="align-left">Guo et al. <a class="anchor anchor-primary" href="#b0220" name="bb0220" data-sd-ui-side-panel-opener="true" data-xocs-content-type="reference" data-xocs-content-id="b0220"><span class="anchor-text-container"><span class="anchor-text">[40]</span></span></a></td><td class="align-left">71.33</td></tr><tr class="valign-top"><td class="align-left">Shao et al. <a class="anchor anchor-primary" href="#b0170" name="bb0170" data-sd-ui-side-panel-opener="true" data-xocs-content-type="reference" data-xocs-content-id="b0170"><span class="anchor-text-container"><span class="anchor-text">[30]</span></span></a></td><td class="align-left">71.14</td></tr><tr class="valign-top"><td class="align-left"><strong>Ours</strong></td><td class="align-left"><strong>75.82</strong></td></tr><tr class="valign-top"><td class="align-left">Ours (without LBP)</td><td class="align-left">67.73</td></tr><tr class="valign-top"><td class="align-left">Ours (without attention module)</td><td class="align-left">73.96</td></tr></tbody></table></div></div></div></section><section id="s0060"><h4 id="st070" class="u-margin-m-top u-margin-xs-bottom">4.2.2. CK+ dataset</h4><div class="u-margin-s-bottom"><div id="p0175">The CK+ dataset <a class="anchor anchor-primary" href="#b0075" name="bb0075" data-sd-ui-side-panel-opener="true" data-xocs-content-type="reference" data-xocs-content-id="b0075"><span class="anchor-text-container"><span class="anchor-text">[11]</span></span></a> includes 593 image sequences collected from 123 subjects, and 327 of these sequences are labeled with six facial expressions (i.e., anger, disgust, fear, happiness, sadness, and surprise). Each image sequence gradually reaches a peak expression from neutral face. In this paper, for each kind of these six expressions, we select the last three frames with peak information as our new dataset. The comparison results of our method and some representative methods <a class="anchor anchor-primary" href="#b0120" name="bb0120" data-sd-ui-side-panel-opener="true" data-xocs-content-type="reference" data-xocs-content-id="b0120"><span class="anchor-text-container"><span class="anchor-text">[20]</span></span></a>, <a class="anchor anchor-primary" href="#b0170" name="bb0170" data-sd-ui-side-panel-opener="true" data-xocs-content-type="reference" data-xocs-content-id="b0170"><span class="anchor-text-container"><span class="anchor-text">[30]</span></span></a>, <a class="anchor anchor-primary" href="#b0185" name="bb0185" data-sd-ui-side-panel-opener="true" data-xocs-content-type="reference" data-xocs-content-id="b0185"><span class="anchor-text-container"><span class="anchor-text">[33]</span></span></a>, <a class="anchor anchor-primary" href="#b0195" name="bb0195" data-sd-ui-side-panel-opener="true" data-xocs-content-type="reference" data-xocs-content-id="b0195"><span class="anchor-text-container"><span class="anchor-text">[35]</span></span></a>, <a class="anchor anchor-primary" href="#b0205" name="bb0205" data-sd-ui-side-panel-opener="true" data-xocs-content-type="reference" data-xocs-content-id="b0205"><span class="anchor-text-container"><span class="anchor-text">[37]</span></span></a> on this dataset are listed in <a class="anchor anchor-primary" href="#t0025" name="bt0025" data-sd-ui-side-panel-opener="true" data-xocs-content-type="reference" data-xocs-content-id="t0025"><span class="anchor-text-container"><span class="anchor-text">Table 5</span></span></a>, which indicate that our method performs better than most of the methods except Zhang et al. <a class="anchor anchor-primary" href="#b0205" name="bb0205" data-sd-ui-side-panel-opener="true" data-xocs-content-type="reference" data-xocs-content-id="b0205"><span class="anchor-text-container"><span class="anchor-text">[37]</span></span></a>. However, the multitask network in <a class="anchor anchor-primary" href="#b0205" name="bb0205" data-sd-ui-side-panel-opener="true" data-xocs-content-type="reference" data-xocs-content-id="b0205"><span class="anchor-text-container"><span class="anchor-text">[37]</span></span></a><span> learns from some <a href="/topics/chemical-engineering/auxiliaries" title="Learn more about auxiliary from ScienceDirect's AI-generated Topic Pages" class="topic-link">auxiliary</a> attributes like gender, age and head pose, except for facial expression images. Our method can achieve competitive result by only using the facial expression data. When removing the LBP or the attention module, the recognition results are reduced from 98.68% to 97.53% and 97.10%, respectively. This shows that LBP and the attention module can improve the recognition accuracy.</span></div><div class="tables colsep-0 frame-topbot rowsep-0" id="t0025"><span class="captions text-s"><span id="cn0065"><p id="sp0095"><span class="label">Table 5</span>. Comparison of different methods on the CK+ dataset.</p></span></span><div class="groups"><table><thead><tr class="rowsep-1 valign-top"><th scope="col" class="align-left">Method</th><th scope="col" class="align-left">Recognition Rates (%)</th></tr></thead><tbody><tr class="valign-top"><td class="align-left">VGG Net&nbsp;+&nbsp;LSTM <a class="anchor anchor-primary" href="#b0185" name="bb0185" data-sd-ui-side-panel-opener="true" data-xocs-content-type="reference" data-xocs-content-id="b0185"><span class="anchor-text-container"><span class="anchor-text">[33]</span></span></a></td><td class="align-left">97.2</td></tr><tr class="valign-top"><td class="align-left">Yang et al. <a class="anchor anchor-primary" href="#b0195" name="bb0195" data-sd-ui-side-panel-opener="true" data-xocs-content-type="reference" data-xocs-content-id="b0195"><span class="anchor-text-container"><span class="anchor-text">[35]</span></span></a></td><td class="align-left">97.3</td></tr><tr class="valign-top"><td class="align-left"><strong>Zhang et al.</strong> <a class="anchor anchor-primary" href="#b0205" name="bb0205" data-sd-ui-side-panel-opener="true" data-xocs-content-type="reference" data-xocs-content-id="b0205"><span class="anchor-text-container"><span class="anchor-text">[37]</span></span></a></td><td class="align-left"><strong>98.9</strong></td></tr><tr class="valign-top"><td class="align-left">Turan <a class="anchor anchor-primary" href="#b0120" name="bb0120" data-sd-ui-side-panel-opener="true" data-xocs-content-type="reference" data-xocs-content-id="b0120"><span class="anchor-text-container"><span class="anchor-text">[20]</span></span></a></td><td class="align-left">96.10</td></tr><tr class="valign-top"><td class="align-left">Shao et al. <a class="anchor anchor-primary" href="#b0170" name="bb0170" data-sd-ui-side-panel-opener="true" data-xocs-content-type="reference" data-xocs-content-id="b0170"><span class="anchor-text-container"><span class="anchor-text">[30]</span></span></a></td><td class="align-left">95.29</td></tr><tr class="valign-top"><td class="align-left">Ours</td><td class="align-left">98.68</td></tr><tr class="valign-top"><td class="align-left">Ours (Without LBP)</td><td class="align-left">97.53</td></tr><tr class="valign-top"><td class="align-left">Ours (Without the attention module)</td><td class="align-left">97.10</td></tr></tbody></table></div></div></div></section><section id="s0065"><h4 id="st075" class="u-margin-m-top u-margin-xs-bottom">4.2.3. Oulu-CASIA dataset</h4><div class="u-margin-s-bottom"><div id="p0180">The Oulu-CASIA dataset <a class="anchor anchor-primary" href="#b0145" name="bb0145" data-sd-ui-side-panel-opener="true" data-xocs-content-type="reference" data-xocs-content-id="b0145"><span class="anchor-text-container"><span class="anchor-text">[25]</span></span></a> contains 2880 image sequences which are collected from 80 subjects and each sequence is labeled with six facial expression labels (i.e., anger, disgust, fear, happiness, sadness, and surprise). Each image sequence gradually reaches a peak expression from neutral face. The last three frames from each expression sequence are selected to be new data used in our experiment. We compare our approach with previous state-of-the-art methods and give the results in <a class="anchor anchor-primary" href="#t0030" name="bt0030" data-sd-ui-side-panel-opener="true" data-xocs-content-type="reference" data-xocs-content-id="t0030"><span class="anchor-text-container"><span class="anchor-text">Table 6</span></span></a>. As we can see, our method is superior to all the other methods and achieves the state-of-the-art performance which is 94.63%. This also demonstrates that LBP and the attention module can improve the accuracy in different degrees. When there is no LBP or attention module, the results are reduced to 93.52% and 91.17 respectively.</div><div class="tables colsep-0 frame-topbot rowsep-0" id="t0030"><span class="captions text-s"><span id="cn0070"><p id="sp0100"><span class="label">Table 6</span>. Comparison of different methods on the Oulu-CASIA dataset.</p></span></span><div class="groups"><table><thead><tr class="rowsep-1 valign-top"><th scope="col" class="align-left">Method</th><th scope="col" class="align-left">Recognition Rates (%)</th></tr></thead><tbody><tr class="valign-top"><td class="align-left">Zhong et al. <a class="anchor anchor-primary" href="#b0160" name="bb0160" data-sd-ui-side-panel-opener="true" data-xocs-content-type="reference" data-xocs-content-id="b0160"><span class="anchor-text-container"><span class="anchor-text">[28]</span></span></a></td><td class="align-left">93.06</td></tr><tr class="valign-top"><td class="align-left">Yang et al. <a class="anchor anchor-primary" href="#b0150" name="bb0150" data-sd-ui-side-panel-opener="true" data-xocs-content-type="reference" data-xocs-content-id="b0150"><span class="anchor-text-container"><span class="anchor-text">[26]</span></span></a></td><td class="align-left">88.00</td></tr><tr class="valign-top"><td class="align-left">Zhang et al. <a class="anchor anchor-primary" href="#b0135" name="bb0135" data-sd-ui-side-panel-opener="true" data-xocs-content-type="reference" data-xocs-content-id="b0135"><span class="anchor-text-container"><span class="anchor-text">[23]</span></span></a></td><td class="align-left">86.95</td></tr><tr class="valign-top"><td class="align-left">Kuo et al. <a class="anchor anchor-primary" href="#b0115" name="bb0115" data-sd-ui-side-panel-opener="true" data-xocs-content-type="reference" data-xocs-content-id="b0115"><span class="anchor-text-container"><span class="anchor-text">[19]</span></span></a></td><td class="align-left">88.75</td></tr><tr class="valign-top"><td class="align-left"><strong>Ours</strong></td><td class="align-left"><strong>94.63</strong></td></tr><tr class="valign-top"><td class="align-left">Ours (Without LBP)</td><td class="align-left">93.52</td></tr><tr class="valign-top"><td class="align-left">Ours (without the attention module)</td><td class="align-left">91.17</td></tr></tbody></table></div></div></div></section><section id="s0070"><h4 id="st080" class="u-margin-m-top u-margin-xs-bottom">4.2.4. JAFFE dataset</h4><div class="u-margin-s-bottom"><div id="p0185">The JAFFE dataset was collected from 10 Japanese females in a laboratory condition and includes 213 images of posed expressions. For each subject, there are three or four images belonging to one of the six expressions which are anger, disgust, fear, happiness, sadness, and surprise, and one image belongs to neutral face. We compare our method with five existing methods <a class="anchor anchor-primary" href="#b0110" name="bb0110" data-sd-ui-side-panel-opener="true" data-xocs-content-type="reference" data-xocs-content-id="b0110"><span class="anchor-text-container"><span class="anchor-text">[18]</span></span></a>, <a class="anchor anchor-primary" href="#b0120" name="bb0120" data-sd-ui-side-panel-opener="true" data-xocs-content-type="reference" data-xocs-content-id="b0120"><span class="anchor-text-container"><span class="anchor-text">[20]</span></span></a>, <a class="anchor anchor-primary" href="#b0155" name="bb0155" data-sd-ui-side-panel-opener="true" data-xocs-content-type="reference" data-xocs-content-id="b0155"><span class="anchor-text-container"><span class="anchor-text">[27]</span></span></a>, <a class="anchor anchor-primary" href="#b0175" name="bb0175" data-sd-ui-side-panel-opener="true" data-xocs-content-type="reference" data-xocs-content-id="b0175"><span class="anchor-text-container"><span class="anchor-text">[31]</span></span></a> and the comparison results are provided in <a class="anchor anchor-primary" href="#t0035" name="bt0035" data-sd-ui-side-panel-opener="true" data-xocs-content-type="reference" data-xocs-content-id="t0035"><span class="anchor-text-container"><span class="anchor-text">Table 7</span></span></a>, which shows that the result of our method achieves 98.52% and outperforms the others on the JAFFE dataset. When LBP or attention is not used, the recognition rates are reduced to 96.53% and 95.12%, respectively.</div><div class="tables colsep-0 frame-topbot rowsep-0" id="t0035"><span class="captions text-s"><span id="cn0075"><p id="sp0105"><span class="label">Table 7</span>. Comparison of different methods on the JAFFE dataset.</p></span></span><div class="groups"><table><thead><tr class="rowsep-1 valign-top"><th scope="col" class="align-left">Method</th><th scope="col" class="align-left">Recognition Rates (%)</th></tr></thead><tbody><tr class="valign-top"><td class="align-left">Hamester et al. <a class="anchor anchor-primary" href="#b0175" name="bb0175" data-sd-ui-side-panel-opener="true" data-xocs-content-type="reference" data-xocs-content-id="b0175"><span class="anchor-text-container"><span class="anchor-text">[31]</span></span></a></td><td class="align-left">95.8</td></tr><tr class="valign-top"><td class="align-left">Liu et al. <a class="anchor anchor-primary" href="#b0155" name="bb0155" data-sd-ui-side-panel-opener="true" data-xocs-content-type="reference" data-xocs-content-id="b0155"><span class="anchor-text-container"><span class="anchor-text">[27]</span></span></a></td><td class="align-left">91.8</td></tr><tr class="valign-top"><td class="align-left">Turan <a class="anchor anchor-primary" href="#b0120" name="bb0120" data-sd-ui-side-panel-opener="true" data-xocs-content-type="reference" data-xocs-content-id="b0120"><span class="anchor-text-container"><span class="anchor-text">[20]</span></span></a></td><td class="align-left">91.8</td></tr><tr class="valign-top"><td class="align-left">Wang <a class="anchor anchor-primary" href="#b0110" name="bb0110" data-sd-ui-side-panel-opener="true" data-xocs-content-type="reference" data-xocs-content-id="b0110"><span class="anchor-text-container"><span class="anchor-text">[18]</span></span></a></td><td class="align-left">95.7</td></tr><tr class="valign-top"><td class="align-left"><strong>Ours</strong></td><td class="align-left"><strong>98.52</strong></td></tr><tr class="valign-top"><td class="align-left">Ours (Without LBP)</td><td class="align-left">96.53</td></tr><tr class="valign-top"><td class="align-left">Ours (Without the attention module)</td><td class="align-left">95.12</td></tr></tbody></table></div></div></div></section><section id="s0075"><h4 id="st085" class="u-margin-m-top u-margin-xs-bottom">4.2.5. NCUFE dataset</h4><div class="u-margin-s-bottom"><div id="p0190"><span><span>We collected a new facial expression dataset called Nanchang University Facial Expression (NCUFE) from 35 graduate students (6 females and 29 males) by the <a href="/topics/computer-science/microsoft-kinect-sensor" title="Learn more about Microsoft Kinect sensor from ScienceDirect's AI-generated Topic Pages" class="topic-link">Microsoft Kinect sensor</a>. For each student, we captured both RGB images and depth images, and the sizes of these two kinds of images are 1280*1024 and 512*424, respectively. The NCUFE dataset was annotated with seven expressions (i.e., anger, disgust, fear, happiness, sadness, surprise, and neural). For each image type, there are 245 image sequences, each of which contains 110 images, resulting in 26,950 images in total. Because none of the other four datasets has depth images, we only use RGB images as our datasets in this work. To better distinguish different kinds of expressions, for every expression sequence, we select three images that are close to the peak expression as our new dataset. We evaluate our method on this dataset and achieve 94.33% accuracy. When we remove LBP or the attention module, the recognition rates are reduced to 93.91% and 92.07%, respectively. In addition, when we replace LBP with depth images, the recognition result is lower than that using only raw images or LBP images. It indicates that depth images are not helpful in our networks. The reason is that in our network we fuse these two kinds of features by element-wise sum, as a kind of auxiliary feature, depth features have a negative effect on the raw </span><a href="/topics/computer-science/image-feature" title="Learn more about image features from ScienceDirect's AI-generated Topic Pages" class="topic-link">image features</a> when fusing these two kinds of features. In our future work, we will apply depth images to other methods, for example, we can concatenate the feature vectors of these two kinds of features. We also compare our method with some other works. From </span><a class="anchor anchor-primary" href="#t0040" name="bt0040" data-sd-ui-side-panel-opener="true" data-xocs-content-type="reference" data-xocs-content-id="t0040"><span class="anchor-text-container"><span class="anchor-text">Table 8</span></span></a>, we can find that our method outperforms the others on our dataset. The recognition results of <a class="anchor anchor-primary" href="#b0165" name="bb0165" data-sd-ui-side-panel-opener="true" data-xocs-content-type="reference" data-xocs-content-id="b0165"><span class="anchor-text-container"><span class="anchor-text">[29]</span></span></a>, <a class="anchor anchor-primary" href="#b0170" name="bb0170" data-sd-ui-side-panel-opener="true" data-xocs-content-type="reference" data-xocs-content-id="b0170"><span class="anchor-text-container"><span class="anchor-text">[30]</span></span></a>, <a class="anchor anchor-primary" href="#b0190" name="bb0190" data-sd-ui-side-panel-opener="true" data-xocs-content-type="reference" data-xocs-content-id="b0190"><span class="anchor-text-container"><span class="anchor-text">[34]</span></span></a> on NCUFE are 91.58%, 81.3% and 82.5%, respectively.</div><div class="tables colsep-0 frame-topbot rowsep-0" id="t0040"><span class="captions text-s"><span id="cn0080"><p id="sp0110"><span class="label">Table 8</span>. Comparison of different methods on NCUFE dataset.</p></span></span><div class="groups"><table><thead><tr class="rowsep-1 valign-top"><th scope="col" class="align-left">Method</th><th scope="col" class="align-left">Recognition Rates (%)</th></tr></thead><tbody><tr class="valign-top"><td class="align-left">Li et al. <a class="anchor anchor-primary" href="#b0190" name="bb0190" data-sd-ui-side-panel-opener="true" data-xocs-content-type="reference" data-xocs-content-id="b0190"><span class="anchor-text-container"><span class="anchor-text">[34]</span></span></a></td><td class="align-left">91.58</td></tr><tr class="valign-top"><td class="align-left">Arriaga et al. <a class="anchor anchor-primary" href="#b0165" name="bb0165" data-sd-ui-side-panel-opener="true" data-xocs-content-type="reference" data-xocs-content-id="b0165"><span class="anchor-text-container"><span class="anchor-text">[29]</span></span></a></td><td class="align-left">81.3</td></tr><tr class="valign-top"><td class="align-left">Light-CNN. <a class="anchor anchor-primary" href="#b0170" name="bb0170" data-sd-ui-side-panel-opener="true" data-xocs-content-type="reference" data-xocs-content-id="b0170"><span class="anchor-text-container"><span class="anchor-text">[30]</span></span></a></td><td class="align-left">82.5</td></tr><tr class="valign-top"><td class="align-left"><strong>Ours</strong></td><td class="align-left"><strong>94.33</strong></td></tr><tr class="valign-top"><td class="align-left">Ours (Without LBP)</td><td class="align-left">93.91</td></tr><tr class="valign-top"><td class="align-left">Ours (Without attention module)</td><td class="align-left">92.07</td></tr><tr class="valign-top"><td class="align-left">Ours (raw&nbsp;+&nbsp;depth)</td><td class="align-left">90.35</td></tr></tbody></table></div></div></div></section></section></section><section id="s0080"><h2 id="st090" class="u-h4 u-margin-l-top u-margin-xs-bottom">5. Conclusions and future work</h2><div class="u-margin-s-bottom" id="p0195">This paper presents a novel convolutional neural network with attention mechanism for facial expression recognition. The method fuses LBP features and convolution features, and then is combined with attention mechanism to improve the performance of the network. In order to prevent overfitting and ensure the <a href="/topics/computer-science/generalization-ability" title="Learn more about generalization ability from ScienceDirect's AI-generated Topic Pages" class="topic-link">generalization ability</a> of the network, we apply data augmentation in the datasets we used in the experiments. In addition, we collected a new dataset called Nanchang University Facial Expression (NCUFE) and the NCUFE dataset was annotated with seven expressions, which are anger, disgust, fear, happy, sad, surprise, and neutral. For each image type, there are 245 image sequences, each of which contains 110 images, resulting in 26,950 images in total. The presented method is evaluated on NCUFE and four famous facial expression datasets, i.e., Oulu-CASIA, JAFFE, CK+ and FER2013. The experimental results show that our method is superior to many existing methods on these datasets.</div><div class="u-margin-s-bottom" id="p0200"><span>However, our method is only suitable for 2D images. In the future, we will improve our architecture to make it suitable for video data, 3D face datasets and our depth <a href="/topics/engineering/image-data" title="Learn more about images data from ScienceDirect's AI-generated Topic Pages" class="topic-link">images data</a>, and explore better </span><a href="/topics/engineering/machine-learning-method" title="Learn more about machine learning methods from ScienceDirect's AI-generated Topic Pages" class="topic-link">machine learning methods</a> to enhance the network.</div></section><section id="s0090"><h2 id="st100" class="u-h4 u-margin-l-top u-margin-xs-bottom">CRediT authorship contribution statement</h2><div class="u-margin-s-bottom" id="p0210"><strong>Jing Li:</strong> Conceptualization, Methodology, Writing - original draft. <strong>Kan Jin:</strong> . <strong>Dalin Zhou:</strong> . <strong>Naoyuki Kubota:</strong> Writing - review &amp; editing. <strong>Zhaojie Ju:</strong> Conceptualization, Methodology, Writing - original draft.</div></section></div><section id="coi005"><h2 id="st105" class="u-h4 u-margin-l-top u-margin-xs-bottom">Declaration of Competing Interest</h2><div class="u-margin-s-bottom" id="p0215">The authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper.</div></section><section id="ak005"><h2 id="st110" class="u-h4 u-margin-l-top u-margin-xs-bottom">Acknowledgements</h2><div class="u-margin-s-bottom" id="p0220">This work is supported by <span id="gp005">National Natural Science Foundation of China</span> under Grant <a class="anchor anchor-primary" href="#gp005"><span class="anchor-text-container"><span class="anchor-text">61963027</span></span></a>, <a class="anchor anchor-primary" href="#gp005"><span class="anchor-text-container"><span class="anchor-text">61703198</span></span></a>, and <a class="anchor anchor-primary" href="#gp005"><span class="anchor-text-container"><span class="anchor-text">51575412</span></span></a>, Natural Science Foundation for Distinguished Young Scholars of Jiangxi Province under Grant <a class="anchor anchor-primary" href="#gp005"><span class="anchor-text-container"><span class="anchor-text">2018ACB21014</span></span></a>.</div></section></div><div class="related-content-links u-display-none-from-md"><button class="button-link button-link-primary button-link-small" type="button"><span class="button-link-text-container"><span class="button-link-text">Recommended articles</span></span></button></div><div class="Tail"></div><div><section class="bibliography u-font-serif text-s" id="bi005"><h2 class="section-title u-h4 u-margin-l-top u-margin-xs-bottom">References</h2><section class="bibliography-sec" id="bs005"><ol class="references" id="reference-links-bs005"><li><span class="label u-font-sans"><a class="anchor anchor-primary" href="#bb0015" id="ref-id-b0015" data-aa-button="sd:product:journal:article:location=references:type=anchor:name=citation-name"><span class="anchor-text-container"><span class="anchor-text">[1]</span></span></a></span><span class="reference" id="h0015"><div class="other-ref"><span>Y.-H. Lai, S.-H. Lai, Emotion-preserving representation learning via generative adversarial network for multi-view facial expression recognition, in: Automatic Face &amp; Gesture Recognition (FG 2018), 2018 13th IEEE International Conference on. IEEE, 2018, pp. 263–270</span></div><div class="ReferenceLinks u-font-sans"><a class="anchor link anchor-primary" href="https://scholar.google.com/scholar?q=Y.-H.%20Lai%2C%20S.-H.%20Lai%2C%20Emotion-preserving%20representation%20learning%20via%20generative%20adversarial%20network%20for%20multi-view%20facial%20expression%20recognition%2C%20in%3A%20Automatic%20Face%20%26%20Gesture%20Recognition%20(FG%202018)%2C%202018%2013th%20IEEE%20International%20Conference%20on.%20IEEE%2C%202018%2C%20pp.%20263%E2%80%93270" target="_blank" rel="noopener noreferrer"><span class="anchor-text-container"><span class="anchor-text">Google Scholar</span><svg focusable="false" viewBox="0 0 8 8" height="20" aria-label="Opens in new window" class="icon icon-arrow-up-right-tiny arrow-external-link"><path d="M1.12949 2.1072V1H7V6.85795H5.89111V2.90281L0.784057 8L0 7.21635L5.11902 2.1072H1.12949Z"></path></svg></span></a></div></span></li><li><span class="label u-font-sans"><a class="anchor anchor-primary" href="#bb0020" id="ref-id-b0020" data-aa-button="sd:product:journal:article:location=references:type=anchor:name=citation-name"><span class="anchor-text-container"><span class="anchor-text">[2]</span></span></a></span><span class="reference" id="h0020"><div class="other-ref"><span>A. Mollahosseini, D. Chan, M.H. Mahoor, Going deeper in facial expression recognition using deep neural networks, (2016) 1–10</span></div><div class="ReferenceLinks u-font-sans"><a class="anchor link anchor-primary" href="https://scholar.google.com/scholar?q=A.%20Mollahosseini%2C%20D.%20Chan%2C%20M.H.%20Mahoor%2C%20Going%20deeper%20in%20facial%20expression%20recognition%20using%20deep%20neural%20networks%2C%20(2016)%201%E2%80%9310" target="_blank" rel="noopener noreferrer"><span class="anchor-text-container"><span class="anchor-text">Google Scholar</span><svg focusable="false" viewBox="0 0 8 8" height="20" aria-label="Opens in new window" class="icon icon-arrow-up-right-tiny arrow-external-link"><path d="M1.12949 2.1072V1H7V6.85795H5.89111V2.90281L0.784057 8L0 7.21635L5.11902 2.1072H1.12949Z"></path></svg></span></a></div></span></li><li><span class="label u-font-sans"><a class="anchor anchor-primary" href="#bb0025" id="ref-id-b0025" data-aa-button="sd:product:journal:article:location=references:type=anchor:name=citation-name"><span class="anchor-text-container"><span class="anchor-text">[3]</span></span></a></span><span class="reference" id="h0025"><div class="other-ref"><span>C. Szegedy, W. Liu, Y. Jia, et al., Going deeper with convolutions, IEEE Conference on Computer Vision and Pattern Recognition. IEEE Computer Society, 2015, pp. 1–9.</span></div><div class="ReferenceLinks u-font-sans"><a class="anchor link anchor-primary" href="https://scholar.google.com/scholar?q=C.%20Szegedy%2C%20W.%20Liu%2C%20Y.%20Jia%2C%20et%20al.%2C%20Going%20deeper%20with%20convolutions%2C%20IEEE%20Conference%20on%20Computer%20Vision%20and%20Pattern%20Recognition.%20IEEE%20Computer%20Society%2C%202015%2C%20pp.%201%E2%80%939." target="_blank" rel="noopener noreferrer"><span class="anchor-text-container"><span class="anchor-text">Google Scholar</span><svg focusable="false" viewBox="0 0 8 8" height="20" aria-label="Opens in new window" class="icon icon-arrow-up-right-tiny arrow-external-link"><path d="M1.12949 2.1072V1H7V6.85795H5.89111V2.90281L0.784057 8L0 7.21635L5.11902 2.1072H1.12949Z"></path></svg></span></a></div></span></li><li><span class="label u-font-sans"><a class="anchor anchor-primary" href="#bb0030" id="ref-id-b0030" data-aa-button="sd:product:journal:article:location=references:type=anchor:name=citation-name"><span class="anchor-text-container"><span class="anchor-text">[4]</span></span></a></span><span class="reference" id="h0030"><div class="other-ref"><span>K. He, X. Zhang, S. Ren, et al., Deep residual learning for image recognition, (2015) 770–778</span></div><div class="ReferenceLinks u-font-sans"><a class="anchor link anchor-primary" href="https://scholar.google.com/scholar?q=K.%20He%2C%20X.%20Zhang%2C%20S.%20Ren%2C%20et%20al.%2C%20Deep%20residual%20learning%20for%20image%20recognition%2C%20(2015)%20770%E2%80%93778" target="_blank" rel="noopener noreferrer"><span class="anchor-text-container"><span class="anchor-text">Google Scholar</span><svg focusable="false" viewBox="0 0 8 8" height="20" aria-label="Opens in new window" class="icon icon-arrow-up-right-tiny arrow-external-link"><path d="M1.12949 2.1072V1H7V6.85795H5.89111V2.90281L0.784057 8L0 7.21635L5.11902 2.1072H1.12949Z"></path></svg></span></a></div></span></li><li><span class="label u-font-sans"><a class="anchor anchor-primary" href="#bb0035" id="ref-id-b0035" data-aa-button="sd:product:journal:article:location=references:type=anchor:name=citation-name"><span class="anchor-text-container"><span class="anchor-text">[5]</span></span></a></span><span class="reference" id="h0035"><div class="contribution"><div class="authors u-font-sans">Sun, H. Jin, Z. Zhao</div><div id="ref-id-h0035" class="title text-m">An efficient unconstrained facial expression recognition algorithm based on stack binarized auto-encoders and binarized neural networks</div></div><div class="host u-font-sans">Neurocomputing, 267 (2017), pp. 385-395</div><div class="ReferenceLinks u-font-sans"><a class="anchor pdf link anchor-primary anchor-icon-left anchor-with-icon" href="/science/article/pii/S0925231217311785/pdfft?md5=7fbe0b1c4dc1cca0c398830dccaaac06&amp;pid=1-s2.0-S0925231217311785-main.pdf" target="_blank" rel="nofollow" aria-describedby="ref-id-h0035"><svg focusable="false" viewBox="0 0 35 32" height="20" class="icon icon-pdf-multicolor"><path d="M7 .362h17.875l6.763 6.1V31.64H6.948V16z" stroke="#000" stroke-width=".703" fill="#fff"></path><path d="M.167 2.592H22.39V9.72H.166z" fill="#da0000"></path><path fill="#fff9f9" d="M5.97 3.638h1.62c1.053 0 1.483.677 1.488 1.564.008.96-.6 1.564-1.492 1.564h-.644v1.66h-.977V3.64m.977.897v1.34h.542c.27 0 .596-.068.596-.673-.002-.6-.32-.667-.596-.667h-.542m3.8.036v2.92h.35c.933 0 1.223-.448 1.228-1.462.008-1.06-.316-1.45-1.23-1.45h-.347m-.977-.94h1.03c1.68 0 2.523.586 2.534 2.39.01 1.688-.607 2.4-2.534 2.4h-1.03V3.64m4.305 0h2.63v.934h-1.657v.894H16.6V6.4h-1.56v2.026h-.97V3.638"></path><path d="M19.462 13.46c.348 4.274-6.59 16.72-8.508 15.792-1.82-.85 1.53-3.317 2.92-4.366-2.864.894-5.394 3.252-3.837 3.93 2.113.895 7.048-9.25 9.41-15.394zM14.32 24.874c4.767-1.526 14.735-2.974 15.152-1.407.824-3.157-13.72-.37-15.153 1.407zm5.28-5.043c2.31 3.237 9.816 7.498 9.788 3.82-.306 2.046-6.66-1.097-8.925-4.164-4.087-5.534-2.39-8.772-1.682-8.732.917.047 1.074 1.307.67 2.442-.173-1.406-.58-2.44-1.224-2.415-1.835.067-1.905 4.46 1.37 9.065z" fill="#f91d0a"></path></svg><span class="anchor-text-container"><span class="anchor-text">View PDF</span></span></a><a class="anchor link anchor-primary" href="/science/article/pii/S0925231217311785" aria-describedby="ref-id-h0035"><span class="anchor-text-container"><span class="anchor-text">View article</span></span></a><a class="anchor link anchor-primary" href="https://www.scopus.com/inward/record.url?eid=2-s2.0-85021789014&amp;partnerID=10&amp;rel=R3.0.0" target="_blank" rel="noopener noreferrer" aria-describedby="ref-id-h0035"><span class="anchor-text-container"><span class="anchor-text">View in Scopus</span><svg focusable="false" viewBox="0 0 8 8" height="20" aria-label="Opens in new window" class="icon icon-arrow-up-right-tiny arrow-external-link"><path d="M1.12949 2.1072V1H7V6.85795H5.89111V2.90281L0.784057 8L0 7.21635L5.11902 2.1072H1.12949Z"></path></svg></span></a><a class="anchor link anchor-primary" href="https://scholar.google.com/scholar_lookup?title=An%20efficient%20unconstrained%20facial%20expression%20recognition%20algorithm%20based%20on%20stack%20binarized%20auto-encoders%20and%20binarized%20neural%20networks&amp;publication_year=2017&amp;author=Sun&amp;author=H.%20Jin&amp;author=Z.%20Zhao" target="_blank" rel="noopener noreferrer" aria-describedby="ref-id-h0035"><span class="anchor-text-container"><span class="anchor-text">Google Scholar</span><svg focusable="false" viewBox="0 0 8 8" height="20" aria-label="Opens in new window" class="icon icon-arrow-up-right-tiny arrow-external-link"><path d="M1.12949 2.1072V1H7V6.85795H5.89111V2.90281L0.784057 8L0 7.21635L5.11902 2.1072H1.12949Z"></path></svg></span></a></div></span></li><li><span class="label u-font-sans"><a class="anchor anchor-primary" href="#bb0040" id="ref-id-b0040" data-aa-button="sd:product:journal:article:location=references:type=anchor:name=citation-name"><span class="anchor-text-container"><span class="anchor-text">[6]</span></span></a></span><span class="reference" id="h0040"><div class="other-ref"><span>C. Szegedy, S. Ioffe, V. Vanhoucke, et al., Inception-v4, Inception-ResNet and the Impact of Residual Connections on Learning, 2016</span></div><div class="ReferenceLinks u-font-sans"><a class="anchor link anchor-primary" href="https://scholar.google.com/scholar?q=C.%20Szegedy%2C%20S.%20Ioffe%2C%20V.%20Vanhoucke%2C%20et%20al.%2C%20Inception-v4%2C%20Inception-ResNet%20and%20the%20Impact%20of%20Residual%20Connections%20on%20Learning%2C%202016" target="_blank" rel="noopener noreferrer"><span class="anchor-text-container"><span class="anchor-text">Google Scholar</span><svg focusable="false" viewBox="0 0 8 8" height="20" aria-label="Opens in new window" class="icon icon-arrow-up-right-tiny arrow-external-link"><path d="M1.12949 2.1072V1H7V6.85795H5.89111V2.90281L0.784057 8L0 7.21635L5.11902 2.1072H1.12949Z"></path></svg></span></a></div></span></li><li><span class="label u-font-sans"><a class="anchor anchor-primary" href="#bb0045" id="ref-id-b0045" data-aa-button="sd:product:journal:article:location=references:type=anchor:name=citation-name"><span class="anchor-text-container"><span class="anchor-text">[7]</span></span></a></span><span class="reference" id="h0045"><div class="other-ref"><span>B. Hasani, M.H. Mahoor, Spatio-temporal facial expression recognition using convolutional neural networks and conditional random fields, (2017) 790–795</span></div><div class="ReferenceLinks u-font-sans"><a class="anchor link anchor-primary" href="https://scholar.google.com/scholar?q=B.%20Hasani%2C%20M.H.%20Mahoor%2C%20Spatio-temporal%20facial%20expression%20recognition%20using%20convolutional%20neural%20networks%20and%20conditional%20random%20fields%2C%20(2017)%20790%E2%80%93795" target="_blank" rel="noopener noreferrer"><span class="anchor-text-container"><span class="anchor-text">Google Scholar</span><svg focusable="false" viewBox="0 0 8 8" height="20" aria-label="Opens in new window" class="icon icon-arrow-up-right-tiny arrow-external-link"><path d="M1.12949 2.1072V1H7V6.85795H5.89111V2.90281L0.784057 8L0 7.21635L5.11902 2.1072H1.12949Z"></path></svg></span></a></div></span></li><li><span class="label u-font-sans"><a class="anchor anchor-primary" href="#bb0050" id="ref-id-b0050" data-aa-button="sd:product:journal:article:location=references:type=anchor:name=citation-name"><span class="anchor-text-container"><span class="anchor-text">[8]</span></span></a></span><span class="reference" id="h0050"><div class="contribution"><div class="authors u-font-sans">Z. Yu, G. Liu, Q. Liu, <em> et al.</em></div><div id="ref-id-h0050" class="title text-m">Spatio-temporal convolutional features with nested LSTM for facial expression recognition[J]</div></div><div class="host u-font-sans">Neurocomputing, 317 (2018), pp. 50-57</div><div class="ReferenceLinks u-font-sans"><a class="anchor pdf link anchor-primary anchor-icon-left anchor-with-icon" href="/science/article/pii/S0925231218308634/pdfft?md5=41149ff1659402937f3542b188491f6c&amp;pid=1-s2.0-S0925231218308634-main.pdf" target="_blank" rel="nofollow" aria-describedby="ref-id-h0050"><svg focusable="false" viewBox="0 0 35 32" height="20" class="icon icon-pdf-multicolor"><path d="M7 .362h17.875l6.763 6.1V31.64H6.948V16z" stroke="#000" stroke-width=".703" fill="#fff"></path><path d="M.167 2.592H22.39V9.72H.166z" fill="#da0000"></path><path fill="#fff9f9" d="M5.97 3.638h1.62c1.053 0 1.483.677 1.488 1.564.008.96-.6 1.564-1.492 1.564h-.644v1.66h-.977V3.64m.977.897v1.34h.542c.27 0 .596-.068.596-.673-.002-.6-.32-.667-.596-.667h-.542m3.8.036v2.92h.35c.933 0 1.223-.448 1.228-1.462.008-1.06-.316-1.45-1.23-1.45h-.347m-.977-.94h1.03c1.68 0 2.523.586 2.534 2.39.01 1.688-.607 2.4-2.534 2.4h-1.03V3.64m4.305 0h2.63v.934h-1.657v.894H16.6V6.4h-1.56v2.026h-.97V3.638"></path><path d="M19.462 13.46c.348 4.274-6.59 16.72-8.508 15.792-1.82-.85 1.53-3.317 2.92-4.366-2.864.894-5.394 3.252-3.837 3.93 2.113.895 7.048-9.25 9.41-15.394zM14.32 24.874c4.767-1.526 14.735-2.974 15.152-1.407.824-3.157-13.72-.37-15.153 1.407zm5.28-5.043c2.31 3.237 9.816 7.498 9.788 3.82-.306 2.046-6.66-1.097-8.925-4.164-4.087-5.534-2.39-8.772-1.682-8.732.917.047 1.074 1.307.67 2.442-.173-1.406-.58-2.44-1.224-2.415-1.835.067-1.905 4.46 1.37 9.065z" fill="#f91d0a"></path></svg><span class="anchor-text-container"><span class="anchor-text">View PDF</span></span></a><a class="anchor link anchor-primary" href="/science/article/pii/S0925231218308634" aria-describedby="ref-id-h0050"><span class="anchor-text-container"><span class="anchor-text">View article</span></span></a><a class="anchor link anchor-primary" href="https://www.scopus.com/inward/record.url?eid=2-s2.0-85052749914&amp;partnerID=10&amp;rel=R3.0.0" target="_blank" rel="noopener noreferrer" aria-describedby="ref-id-h0050"><span class="anchor-text-container"><span class="anchor-text">View in Scopus</span><svg focusable="false" viewBox="0 0 8 8" height="20" aria-label="Opens in new window" class="icon icon-arrow-up-right-tiny arrow-external-link"><path d="M1.12949 2.1072V1H7V6.85795H5.89111V2.90281L0.784057 8L0 7.21635L5.11902 2.1072H1.12949Z"></path></svg></span></a><a class="anchor link anchor-primary" href="https://scholar.google.com/scholar_lookup?title=Spatio-temporal%20convolutional%20features%20with%20nested%20LSTM%20for%20facial%20expression%20recognitionJ&amp;publication_year=2018&amp;author=Z.%20Yu&amp;author=G.%20Liu&amp;author=Q.%20Liu" target="_blank" rel="noopener noreferrer" aria-describedby="ref-id-h0050"><span class="anchor-text-container"><span class="anchor-text">Google Scholar</span><svg focusable="false" viewBox="0 0 8 8" height="20" aria-label="Opens in new window" class="icon icon-arrow-up-right-tiny arrow-external-link"><path d="M1.12949 2.1072V1H7V6.85795H5.89111V2.90281L0.784057 8L0 7.21635L5.11902 2.1072H1.12949Z"></path></svg></span></a></div></span></li><li><span class="label u-font-sans"><a class="anchor anchor-primary" href="#bb0060" id="ref-id-b0060" data-aa-button="sd:product:journal:article:location=references:type=anchor:name=citation-name"><span class="anchor-text-container"><span class="anchor-text">[9]</span></span></a></span><span class="reference" id="h0060"><div class="contribution"><div class="authors u-font-sans">T. Ojala, I. Harwood</div><div id="ref-id-h0060" class="title text-m">A comparative study of texture measures with classification based on feature distributions</div></div><div class="host u-font-sans">Pattern Recogn., 29 (1) (1996), pp. 51-59</div><div class="ReferenceLinks u-font-sans"><a class="anchor pdf link anchor-primary anchor-icon-left anchor-with-icon" href="/science/article/pii/0031320395000674/pdf?md5=5c75587242849348976ac5833537e301&amp;pid=1-s2.0-0031320395000674-main.pdf" target="_blank" rel="nofollow" aria-describedby="ref-id-h0060"><svg focusable="false" viewBox="0 0 35 32" height="20" class="icon icon-pdf-multicolor"><path d="M7 .362h17.875l6.763 6.1V31.64H6.948V16z" stroke="#000" stroke-width=".703" fill="#fff"></path><path d="M.167 2.592H22.39V9.72H.166z" fill="#da0000"></path><path fill="#fff9f9" d="M5.97 3.638h1.62c1.053 0 1.483.677 1.488 1.564.008.96-.6 1.564-1.492 1.564h-.644v1.66h-.977V3.64m.977.897v1.34h.542c.27 0 .596-.068.596-.673-.002-.6-.32-.667-.596-.667h-.542m3.8.036v2.92h.35c.933 0 1.223-.448 1.228-1.462.008-1.06-.316-1.45-1.23-1.45h-.347m-.977-.94h1.03c1.68 0 2.523.586 2.534 2.39.01 1.688-.607 2.4-2.534 2.4h-1.03V3.64m4.305 0h2.63v.934h-1.657v.894H16.6V6.4h-1.56v2.026h-.97V3.638"></path><path d="M19.462 13.46c.348 4.274-6.59 16.72-8.508 15.792-1.82-.85 1.53-3.317 2.92-4.366-2.864.894-5.394 3.252-3.837 3.93 2.113.895 7.048-9.25 9.41-15.394zM14.32 24.874c4.767-1.526 14.735-2.974 15.152-1.407.824-3.157-13.72-.37-15.153 1.407zm5.28-5.043c2.31 3.237 9.816 7.498 9.788 3.82-.306 2.046-6.66-1.097-8.925-4.164-4.087-5.534-2.39-8.772-1.682-8.732.917.047 1.074 1.307.67 2.442-.173-1.406-.58-2.44-1.224-2.415-1.835.067-1.905 4.46 1.37 9.065z" fill="#f91d0a"></path></svg><span class="anchor-text-container"><span class="anchor-text">View PDF</span></span></a><a class="anchor link anchor-primary" href="/science/article/pii/0031320395000674" aria-describedby="ref-id-h0060"><span class="anchor-text-container"><span class="anchor-text">View article</span></span></a><a class="anchor link anchor-primary" href="https://scholar.google.com/scholar_lookup?title=A%20comparative%20study%20of%20texture%20measures%20with%20classification%20based%20on%20feature%20distributions&amp;publication_year=1996&amp;author=T.%20Ojala&amp;author=I.%20Harwood" target="_blank" rel="noopener noreferrer" aria-describedby="ref-id-h0060"><span class="anchor-text-container"><span class="anchor-text">Google Scholar</span><svg focusable="false" viewBox="0 0 8 8" height="20" aria-label="Opens in new window" class="icon icon-arrow-up-right-tiny arrow-external-link"><path d="M1.12949 2.1072V1H7V6.85795H5.89111V2.90281L0.784057 8L0 7.21635L5.11902 2.1072H1.12949Z"></path></svg></span></a></div></span></li><li><span class="label u-font-sans"><a class="anchor anchor-primary" href="#bb0070" id="ref-id-b0070" data-aa-button="sd:product:journal:article:location=references:type=anchor:name=citation-name"><span class="anchor-text-container"><span class="anchor-text">[10]</span></span></a></span><span class="reference" id="h0070"><div class="other-ref"><span>T. Ojala, M. Pietikinen, T. Menp, Multiresolution grayscale and rotation invariant texture classification with local binary patterns, IEEE PAMI, vol. 24, no. 7, 2002</span></div><div class="ReferenceLinks u-font-sans"><a class="anchor link anchor-primary" href="https://scholar.google.com/scholar?q=T.%20Ojala%2C%20M.%20Pietikinen%2C%20T.%20Menp%2C%20Multiresolution%20grayscale%20and%20rotation%20invariant%20texture%20classification%20with%20local%20binary%20patterns%2C%20IEEE%20PAMI%2C%20vol.%2024%2C%20no.%207%2C%202002" target="_blank" rel="noopener noreferrer"><span class="anchor-text-container"><span class="anchor-text">Google Scholar</span><svg focusable="false" viewBox="0 0 8 8" height="20" aria-label="Opens in new window" class="icon icon-arrow-up-right-tiny arrow-external-link"><path d="M1.12949 2.1072V1H7V6.85795H5.89111V2.90281L0.784057 8L0 7.21635L5.11902 2.1072H1.12949Z"></path></svg></span></a></div></span></li><li><span class="label u-font-sans"><a class="anchor anchor-primary" href="#bb0075" id="ref-id-b0075" data-aa-button="sd:product:journal:article:location=references:type=anchor:name=citation-name"><span class="anchor-text-container"><span class="anchor-text">[11]</span></span></a></span><span class="reference" id="h0075"><div class="other-ref"><span>P. Lucey, J.F. Cohn, T. Kanade, J. Saragih, Z. Ambadar, I. Matthews, The extended cohn-kanade dataset (ck+): a complete dataset for action unit and emotion-specified expression, in: Computer Vision and Pattern Recognition Workshops (CVPRW), 2010 IEEE Computer Society Conference on, IEEE, 2010, pp. 94–101.</span></div><div class="ReferenceLinks u-font-sans"><a class="anchor link anchor-primary" href="https://scholar.google.com/scholar?q=P.%20Lucey%2C%20J.F.%20Cohn%2C%20T.%20Kanade%2C%20J.%20Saragih%2C%20Z.%20Ambadar%2C%20I.%20Matthews%2C%20The%20extended%20cohn-kanade%20dataset%20(ck%2B)%3A%20a%20complete%20dataset%20for%20action%20unit%20and%20emotion-specified%20expression%2C%20in%3A%20Computer%20Vision%20and%20Pattern%20Recognition%20Workshops%20(CVPRW)%2C%202010%20IEEE%20Computer%20Society%20Conference%20on%2C%20IEEE%2C%202010%2C%20pp.%2094%E2%80%93101." target="_blank" rel="noopener noreferrer"><span class="anchor-text-container"><span class="anchor-text">Google Scholar</span><svg focusable="false" viewBox="0 0 8 8" height="20" aria-label="Opens in new window" class="icon icon-arrow-up-right-tiny arrow-external-link"><path d="M1.12949 2.1072V1H7V6.85795H5.89111V2.90281L0.784057 8L0 7.21635L5.11902 2.1072H1.12949Z"></path></svg></span></a></div></span></li><li><span class="label u-font-sans"><a class="anchor anchor-primary" href="#bb0080" id="ref-id-b0080" data-aa-button="sd:product:journal:article:location=references:type=anchor:name=citation-name"><span class="anchor-text-container"><span class="anchor-text">[12]</span></span></a></span><span class="reference" id="h0080"><div class="contribution"><div class="authors u-font-sans">W. Sun, H. Zhao, Z. Jin</div><div id="ref-id-h0080" class="title text-m">A visual attention based ROI detection method for facial expression recognition</div></div><div class="host u-font-sans">Neurocomputing, 296 (2018), pp. 12-22</div><div class="ReferenceLinks u-font-sans"><a class="anchor pdf link anchor-primary anchor-icon-left anchor-with-icon" href="/science/article/pii/S0925231218303266/pdfft?md5=7ded741b2ce5b7c49cfbee8eecffca81&amp;pid=1-s2.0-S0925231218303266-main.pdf" target="_blank" rel="nofollow" aria-describedby="ref-id-h0080"><svg focusable="false" viewBox="0 0 35 32" height="20" class="icon icon-pdf-multicolor"><path d="M7 .362h17.875l6.763 6.1V31.64H6.948V16z" stroke="#000" stroke-width=".703" fill="#fff"></path><path d="M.167 2.592H22.39V9.72H.166z" fill="#da0000"></path><path fill="#fff9f9" d="M5.97 3.638h1.62c1.053 0 1.483.677 1.488 1.564.008.96-.6 1.564-1.492 1.564h-.644v1.66h-.977V3.64m.977.897v1.34h.542c.27 0 .596-.068.596-.673-.002-.6-.32-.667-.596-.667h-.542m3.8.036v2.92h.35c.933 0 1.223-.448 1.228-1.462.008-1.06-.316-1.45-1.23-1.45h-.347m-.977-.94h1.03c1.68 0 2.523.586 2.534 2.39.01 1.688-.607 2.4-2.534 2.4h-1.03V3.64m4.305 0h2.63v.934h-1.657v.894H16.6V6.4h-1.56v2.026h-.97V3.638"></path><path d="M19.462 13.46c.348 4.274-6.59 16.72-8.508 15.792-1.82-.85 1.53-3.317 2.92-4.366-2.864.894-5.394 3.252-3.837 3.93 2.113.895 7.048-9.25 9.41-15.394zM14.32 24.874c4.767-1.526 14.735-2.974 15.152-1.407.824-3.157-13.72-.37-15.153 1.407zm5.28-5.043c2.31 3.237 9.816 7.498 9.788 3.82-.306 2.046-6.66-1.097-8.925-4.164-4.087-5.534-2.39-8.772-1.682-8.732.917.047 1.074 1.307.67 2.442-.173-1.406-.58-2.44-1.224-2.415-1.835.067-1.905 4.46 1.37 9.065z" fill="#f91d0a"></path></svg><span class="anchor-text-container"><span class="anchor-text">View PDF</span></span></a><a class="anchor link anchor-primary" href="/science/article/pii/S0925231218303266" aria-describedby="ref-id-h0080"><span class="anchor-text-container"><span class="anchor-text">View article</span></span></a><a class="anchor link anchor-primary" href="https://www.scopus.com/inward/record.url?eid=2-s2.0-85044515478&amp;partnerID=10&amp;rel=R3.0.0" target="_blank" rel="noopener noreferrer" aria-describedby="ref-id-h0080"><span class="anchor-text-container"><span class="anchor-text">View in Scopus</span><svg focusable="false" viewBox="0 0 8 8" height="20" aria-label="Opens in new window" class="icon icon-arrow-up-right-tiny arrow-external-link"><path d="M1.12949 2.1072V1H7V6.85795H5.89111V2.90281L0.784057 8L0 7.21635L5.11902 2.1072H1.12949Z"></path></svg></span></a><a class="anchor link anchor-primary" href="https://scholar.google.com/scholar_lookup?title=A%20visual%20attention%20based%20ROI%20detection%20method%20for%20facial%20expression%20recognition&amp;publication_year=2018&amp;author=W.%20Sun&amp;author=H.%20Zhao&amp;author=Z.%20Jin" target="_blank" rel="noopener noreferrer" aria-describedby="ref-id-h0080"><span class="anchor-text-container"><span class="anchor-text">Google Scholar</span><svg focusable="false" viewBox="0 0 8 8" height="20" aria-label="Opens in new window" class="icon icon-arrow-up-right-tiny arrow-external-link"><path d="M1.12949 2.1072V1H7V6.85795H5.89111V2.90281L0.784057 8L0 7.21635L5.11902 2.1072H1.12949Z"></path></svg></span></a></div></span></li><li><span class="label u-font-sans"><a class="anchor anchor-primary" href="#bb0085" id="ref-id-b0085" data-aa-button="sd:product:journal:article:location=references:type=anchor:name=citation-name"><span class="anchor-text-container"><span class="anchor-text">[13]</span></span></a></span><span class="reference" id="h0085"><div class="other-ref"><span>M. Lyons, S. Akamatsu, M. Kamachi, J. Gyoba, Coding facial expressions with Gabor wavelets, in: Proceedings Third IEEE International Conference on Automatic Face and Gesture Recognition, 1998, pp. 200–205</span></div><div class="ReferenceLinks u-font-sans"><a class="anchor link anchor-primary" href="https://scholar.google.com/scholar?q=M.%20Lyons%2C%20S.%20Akamatsu%2C%20M.%20Kamachi%2C%20J.%20Gyoba%2C%20Coding%20facial%20expressions%20with%20Gabor%20wavelets%2C%20in%3A%20Proceedings%20Third%20IEEE%20International%20Conference%20on%20Automatic%20Face%20and%20Gesture%20Recognition%2C%201998%2C%20pp.%20200%E2%80%93205" target="_blank" rel="noopener noreferrer"><span class="anchor-text-container"><span class="anchor-text">Google Scholar</span><svg focusable="false" viewBox="0 0 8 8" height="20" aria-label="Opens in new window" class="icon icon-arrow-up-right-tiny arrow-external-link"><path d="M1.12949 2.1072V1H7V6.85795H5.89111V2.90281L0.784057 8L0 7.21635L5.11902 2.1072H1.12949Z"></path></svg></span></a></div></span></li><li><span class="label u-font-sans"><a class="anchor anchor-primary" href="#bb0090" id="ref-id-b0090" data-aa-button="sd:product:journal:article:location=references:type=anchor:name=citation-name"><span class="anchor-text-container"><span class="anchor-text">[14]</span></span></a></span><span class="reference" id="h0090"><div class="other-ref"><span>G. Huang, Z. Liu, K. Q. Weinberger, L. van der Maaten, Densely connected convolutional networks. arXiv preprint arXiv:1608.06993, 2016</span></div><div class="ReferenceLinks u-font-sans"><a class="anchor link anchor-primary" href="https://scholar.google.com/scholar?q=G.%20Huang%2C%20Z.%20Liu%2C%20K.%20Q.%20Weinberger%2C%20L.%20van%20der%20Maaten%2C%20Densely%20connected%20convolutional%20networks.%20arXiv%20preprint%20arXiv%3A1608.06993%2C%202016" target="_blank" rel="noopener noreferrer"><span class="anchor-text-container"><span class="anchor-text">Google Scholar</span><svg focusable="false" viewBox="0 0 8 8" height="20" aria-label="Opens in new window" class="icon icon-arrow-up-right-tiny arrow-external-link"><path d="M1.12949 2.1072V1H7V6.85795H5.89111V2.90281L0.784057 8L0 7.21635L5.11902 2.1072H1.12949Z"></path></svg></span></a></div></span></li><li><span class="label u-font-sans"><a class="anchor anchor-primary" href="#bb0095" id="ref-id-b0095" data-aa-button="sd:product:journal:article:location=references:type=anchor:name=citation-name"><span class="anchor-text-container"><span class="anchor-text">[15]</span></span></a></span><span class="reference" id="h0095"><div class="other-ref"><span>T. Zhao, X. Wu, Pyramid feature attention network for saliency detection, Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, 2019, 3085–3094</span></div><div class="ReferenceLinks u-font-sans"><a class="anchor link anchor-primary" href="https://scholar.google.com/scholar?q=T.%20Zhao%2C%20X.%20Wu%2C%20Pyramid%20feature%20attention%20network%20for%20saliency%20detection%2C%20Proceedings%20of%20the%20IEEE%20Conference%20on%20Computer%20Vision%20and%20Pattern%20Recognition%2C%202019%2C%203085%E2%80%933094" target="_blank" rel="noopener noreferrer"><span class="anchor-text-container"><span class="anchor-text">Google Scholar</span><svg focusable="false" viewBox="0 0 8 8" height="20" aria-label="Opens in new window" class="icon icon-arrow-up-right-tiny arrow-external-link"><path d="M1.12949 2.1072V1H7V6.85795H5.89111V2.90281L0.784057 8L0 7.21635L5.11902 2.1072H1.12949Z"></path></svg></span></a></div></span></li><li><span class="label u-font-sans"><a class="anchor anchor-primary" href="#bb0100" id="ref-id-b0100" data-aa-button="sd:product:journal:article:location=references:type=anchor:name=citation-name"><span class="anchor-text-container"><span class="anchor-text">[16]</span></span></a></span><span class="reference" id="h0100"><div class="other-ref"><span>R.R. Varior, B. Shuai, J. Tighe, et al., Scale-Aware Attention Network for Crowd Counting. arXiv preprint arXiv:1901.06026, 2019.</span></div><div class="ReferenceLinks u-font-sans"><a class="anchor link anchor-primary" href="https://scholar.google.com/scholar?q=R.R.%20Varior%2C%20B.%20Shuai%2C%20J.%20Tighe%2C%20et%20al.%2C%20Scale-Aware%20Attention%20Network%20for%20Crowd%20Counting.%20arXiv%20preprint%20arXiv%3A1901.06026%2C%202019." target="_blank" rel="noopener noreferrer"><span class="anchor-text-container"><span class="anchor-text">Google Scholar</span><svg focusable="false" viewBox="0 0 8 8" height="20" aria-label="Opens in new window" class="icon icon-arrow-up-right-tiny arrow-external-link"><path d="M1.12949 2.1072V1H7V6.85795H5.89111V2.90281L0.784057 8L0 7.21635L5.11902 2.1072H1.12949Z"></path></svg></span></a></div></span></li><li><span class="label u-font-sans"><a class="anchor anchor-primary" href="#bb0105" id="ref-id-b0105" data-aa-button="sd:product:journal:article:location=references:type=anchor:name=citation-name"><span class="anchor-text-container"><span class="anchor-text">[17]</span></span></a></span><span class="reference" id="h0105"><div class="other-ref"><span>T.F. Cootes, G.J. Edwards, C.J. Taylor, Active appearance models, IEEE Trans. Pattern Anal. Mach. Intell. 23 (6) (2011) 6815</span></div><div class="ReferenceLinks u-font-sans"><a class="anchor link anchor-primary" href="https://scholar.google.com/scholar?q=T.F.%20Cootes%2C%20G.J.%20Edwards%2C%20C.J.%20Taylor%2C%20Active%20appearance%20models%2C%20IEEE%20Trans.%20Pattern%20Anal.%20Mach.%20Intell.%2023%20(6)%20(2011)%206815" target="_blank" rel="noopener noreferrer"><span class="anchor-text-container"><span class="anchor-text">Google Scholar</span><svg focusable="false" viewBox="0 0 8 8" height="20" aria-label="Opens in new window" class="icon icon-arrow-up-right-tiny arrow-external-link"><path d="M1.12949 2.1072V1H7V6.85795H5.89111V2.90281L0.784057 8L0 7.21635L5.11902 2.1072H1.12949Z"></path></svg></span></a></div></span></li><li><span class="label u-font-sans"><a class="anchor anchor-primary" href="#bb0110" id="ref-id-b0110" data-aa-button="sd:product:journal:article:location=references:type=anchor:name=citation-name"><span class="anchor-text-container"><span class="anchor-text">[18]</span></span></a></span><span class="reference" id="h0110"><div class="other-ref"><span>W. Wang, Q. Sun, T. Chen, et al., A Fine-Grained Facial Expression Database for End-to-End Multi-Pose Facial Expression Recognition, arXiv preprint arXiv:1907.10838, 2019.</span></div><div class="ReferenceLinks u-font-sans"><a class="anchor link anchor-primary" href="https://scholar.google.com/scholar?q=W.%20Wang%2C%20Q.%20Sun%2C%20T.%20Chen%2C%20et%20al.%2C%20A%20Fine-Grained%20Facial%20Expression%20Database%20for%20End-to-End%20Multi-Pose%20Facial%20Expression%20Recognition%2C%20arXiv%20preprint%20arXiv%3A1907.10838%2C%202019." target="_blank" rel="noopener noreferrer"><span class="anchor-text-container"><span class="anchor-text">Google Scholar</span><svg focusable="false" viewBox="0 0 8 8" height="20" aria-label="Opens in new window" class="icon icon-arrow-up-right-tiny arrow-external-link"><path d="M1.12949 2.1072V1H7V6.85795H5.89111V2.90281L0.784057 8L0 7.21635L5.11902 2.1072H1.12949Z"></path></svg></span></a></div></span></li><li><span class="label u-font-sans"><a class="anchor anchor-primary" href="#bb0115" id="ref-id-b0115" data-aa-button="sd:product:journal:article:location=references:type=anchor:name=citation-name"><span class="anchor-text-container"><span class="anchor-text">[19]</span></span></a></span><span class="reference" id="h0115"><div class="other-ref"><span>C.M. Kuo, S.H. Lai, M. Sarkis, A compact deep learning model for robust facial expression recognition, Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition Workshops, 2018, pp. 2121–2129</span></div><div class="ReferenceLinks u-font-sans"><a class="anchor link anchor-primary" href="https://scholar.google.com/scholar?q=C.M.%20Kuo%2C%20S.H.%20Lai%2C%20M.%20Sarkis%2C%20A%20compact%20deep%20learning%20model%20for%20robust%20facial%20expression%20recognition%2C%20Proceedings%20of%20the%20IEEE%20Conference%20on%20Computer%20Vision%20and%20Pattern%20Recognition%20Workshops%2C%202018%2C%20pp.%202121%E2%80%932129" target="_blank" rel="noopener noreferrer"><span class="anchor-text-container"><span class="anchor-text">Google Scholar</span><svg focusable="false" viewBox="0 0 8 8" height="20" aria-label="Opens in new window" class="icon icon-arrow-up-right-tiny arrow-external-link"><path d="M1.12949 2.1072V1H7V6.85795H5.89111V2.90281L0.784057 8L0 7.21635L5.11902 2.1072H1.12949Z"></path></svg></span></a></div></span></li><li><span class="label u-font-sans"><a class="anchor anchor-primary" href="#bb0120" id="ref-id-b0120" data-aa-button="sd:product:journal:article:location=references:type=anchor:name=citation-name"><span class="anchor-text-container"><span class="anchor-text">[20]</span></span></a></span><span class="reference" id="h0120"><div class="other-ref"><span>C. Turan, K.M. Lam, X. He, Soft Locality Preserving Map (SLPM) for Facial Expression Recognition. arXiv preprint arXiv:1801.03754, 2018.</span></div><div class="ReferenceLinks u-font-sans"><a class="anchor link anchor-primary" href="https://scholar.google.com/scholar?q=C.%20Turan%2C%20K.M.%20Lam%2C%20X.%20He%2C%20Soft%20Locality%20Preserving%20Map%20(SLPM)%20for%20Facial%20Expression%20Recognition.%20arXiv%20preprint%20arXiv%3A1801.03754%2C%202018." target="_blank" rel="noopener noreferrer"><span class="anchor-text-container"><span class="anchor-text">Google Scholar</span><svg focusable="false" viewBox="0 0 8 8" height="20" aria-label="Opens in new window" class="icon icon-arrow-up-right-tiny arrow-external-link"><path d="M1.12949 2.1072V1H7V6.85795H5.89111V2.90281L0.784057 8L0 7.21635L5.11902 2.1072H1.12949Z"></path></svg></span></a></div></span></li><li><span class="label u-font-sans"><a class="anchor anchor-primary" href="#bb0125" id="ref-id-b0125" data-aa-button="sd:product:journal:article:location=references:type=anchor:name=citation-name"><span class="anchor-text-container"><span class="anchor-text">[21]</span></span></a></span><span class="reference" id="h0125"><div class="other-ref"><span>Z. Zhang, M. Lyons, M. Schuster, S. Akamatsu, Comparison between geometry-based and Gabor-wavelets-based facial expression recognition using multi-layer perceptron, in Third IEEE International Conference on Automatic Face and Gesture Recognition, 1998. Proceedings, Nara 1998, pp. 454_9.</span></div><div class="ReferenceLinks u-font-sans"><a class="anchor link anchor-primary" href="https://scholar.google.com/scholar?q=Z.%20Zhang%2C%20M.%20Lyons%2C%20M.%20Schuster%2C%20S.%20Akamatsu%2C%20Comparison%20between%20geometry-based%20and%20Gabor-wavelets-based%20facial%20expression%20recognition%20using%20multi-layer%20perceptron%2C%20in%20Third%20IEEE%20International%20Conference%20on%20Automatic%20Face%20and%20Gesture%20Recognition%2C%201998.%20Proceedings%2C%20Nara%201998%2C%20pp.%20454_9." target="_blank" rel="noopener noreferrer"><span class="anchor-text-container"><span class="anchor-text">Google Scholar</span><svg focusable="false" viewBox="0 0 8 8" height="20" aria-label="Opens in new window" class="icon icon-arrow-up-right-tiny arrow-external-link"><path d="M1.12949 2.1072V1H7V6.85795H5.89111V2.90281L0.784057 8L0 7.21635L5.11902 2.1072H1.12949Z"></path></svg></span></a></div></span></li><li><span class="label u-font-sans"><a class="anchor anchor-primary" href="#bb0130" id="ref-id-b0130" data-aa-button="sd:product:journal:article:location=references:type=anchor:name=citation-name"><span class="anchor-text-container"><span class="anchor-text">[22]</span></span></a></span><span class="reference" id="h0130"><div class="contribution"><div class="authors u-font-sans">C. Cortes, V.N. Vapnik</div><div id="ref-id-h0130" class="title text-m">Support vector networks</div></div><div class="host u-font-sans">Mach. Learn., 20 (1995), pp. 273-297</div><div class="ReferenceLinks u-font-sans"><a class="anchor link anchor-primary" href="https://www.scopus.com/inward/record.url?eid=2-s2.0-34249753618&amp;partnerID=10&amp;rel=R3.0.0" target="_blank" rel="noopener noreferrer" aria-describedby="ref-id-h0130"><span class="anchor-text-container"><span class="anchor-text">View in Scopus</span><svg focusable="false" viewBox="0 0 8 8" height="20" aria-label="Opens in new window" class="icon icon-arrow-up-right-tiny arrow-external-link"><path d="M1.12949 2.1072V1H7V6.85795H5.89111V2.90281L0.784057 8L0 7.21635L5.11902 2.1072H1.12949Z"></path></svg></span></a><a class="anchor link anchor-primary" href="https://scholar.google.com/scholar_lookup?title=Support%20vector%20networks&amp;publication_year=1995&amp;author=C.%20Cortes&amp;author=V.N.%20Vapnik" target="_blank" rel="noopener noreferrer" aria-describedby="ref-id-h0130"><span class="anchor-text-container"><span class="anchor-text">Google Scholar</span><svg focusable="false" viewBox="0 0 8 8" height="20" aria-label="Opens in new window" class="icon icon-arrow-up-right-tiny arrow-external-link"><path d="M1.12949 2.1072V1H7V6.85795H5.89111V2.90281L0.784057 8L0 7.21635L5.11902 2.1072H1.12949Z"></path></svg></span></a></div></span></li><li><span class="label u-font-sans"><a class="anchor anchor-primary" href="#bb0135" id="ref-id-b0135" data-aa-button="sd:product:journal:article:location=references:type=anchor:name=citation-name"><span class="anchor-text-container"><span class="anchor-text">[23]</span></span></a></span><span class="reference" id="h0135"><div class="contribution"><div class="authors u-font-sans">K. Zhang, Y. Huang, Y. Du, <em> et al.</em></div><div id="ref-id-h0135" class="title text-m">Facial expression recognition based on deep evolutional spatial-temporal networks</div></div><div class="host u-font-sans">IEEE Trans. Image Process., 26 (9) (2017), pp. 4193-4203</div><div class="ReferenceLinks u-font-sans"><a class="anchor link anchor-primary" href="https://www.scopus.com/inward/record.url?eid=2-s2.0-85027517303&amp;partnerID=10&amp;rel=R3.0.0" target="_blank" rel="noopener noreferrer" aria-describedby="ref-id-h0135"><span class="anchor-text-container"><span class="anchor-text">View in Scopus</span><svg focusable="false" viewBox="0 0 8 8" height="20" aria-label="Opens in new window" class="icon icon-arrow-up-right-tiny arrow-external-link"><path d="M1.12949 2.1072V1H7V6.85795H5.89111V2.90281L0.784057 8L0 7.21635L5.11902 2.1072H1.12949Z"></path></svg></span></a><a class="anchor link anchor-primary" href="https://scholar.google.com/scholar_lookup?title=Facial%20expression%20recognition%20based%20on%20deep%20evolutional%20spatial-temporal%20networks&amp;publication_year=2017&amp;author=K.%20Zhang&amp;author=Y.%20Huang&amp;author=Y.%20Du" target="_blank" rel="noopener noreferrer" aria-describedby="ref-id-h0135"><span class="anchor-text-container"><span class="anchor-text">Google Scholar</span><svg focusable="false" viewBox="0 0 8 8" height="20" aria-label="Opens in new window" class="icon icon-arrow-up-right-tiny arrow-external-link"><path d="M1.12949 2.1072V1H7V6.85795H5.89111V2.90281L0.784057 8L0 7.21635L5.11902 2.1072H1.12949Z"></path></svg></span></a></div></span></li><li><span class="label u-font-sans"><a class="anchor anchor-primary" href="#bb0140" id="ref-id-b0140" data-aa-button="sd:product:journal:article:location=references:type=anchor:name=citation-name"><span class="anchor-text-container"><span class="anchor-text">[24]</span></span></a></span><span class="reference" id="h0140"><div class="other-ref"><span>T. Cover, P. Hart, Nearest neighbor pattern classification, IEEE Trans. Inform. Theor. 13 (1) (1967) pp. 21_7</span></div><div class="ReferenceLinks u-font-sans"><a class="anchor link anchor-primary" href="https://scholar.google.com/scholar?q=T.%20Cover%2C%20P.%20Hart%2C%20Nearest%20neighbor%20pattern%20classification%2C%20IEEE%20Trans.%20Inform.%20Theor.%2013%20(1)%20(1967)%20pp.%2021_7" target="_blank" rel="noopener noreferrer"><span class="anchor-text-container"><span class="anchor-text">Google Scholar</span><svg focusable="false" viewBox="0 0 8 8" height="20" aria-label="Opens in new window" class="icon icon-arrow-up-right-tiny arrow-external-link"><path d="M1.12949 2.1072V1H7V6.85795H5.89111V2.90281L0.784057 8L0 7.21635L5.11902 2.1072H1.12949Z"></path></svg></span></a></div></span></li><li><span class="label u-font-sans"><a class="anchor anchor-primary" href="#bb0145" id="ref-id-b0145" data-aa-button="sd:product:journal:article:location=references:type=anchor:name=citation-name"><span class="anchor-text-container"><span class="anchor-text">[25]</span></span></a></span><span class="reference" id="h0145"><div class="contribution"><div class="authors u-font-sans">G. Zhao, X. Huang, M. Taini, <em> et al.</em></div><div id="ref-id-h0145" class="title text-m">Facial expression recognition from near-infrared videos</div></div><div class="host u-font-sans">Image Vision Comput., 29 (9) (2011), pp. 607-619</div><div class="ReferenceLinks u-font-sans"><a class="anchor pdf link anchor-primary anchor-icon-left anchor-with-icon" href="/science/article/pii/S0262885611000515/pdfft?md5=9117a88e2958ec35b47c9caa69169926&amp;pid=1-s2.0-S0262885611000515-main.pdf" target="_blank" rel="nofollow" aria-describedby="ref-id-h0145"><svg focusable="false" viewBox="0 0 35 32" height="20" class="icon icon-pdf-multicolor"><path d="M7 .362h17.875l6.763 6.1V31.64H6.948V16z" stroke="#000" stroke-width=".703" fill="#fff"></path><path d="M.167 2.592H22.39V9.72H.166z" fill="#da0000"></path><path fill="#fff9f9" d="M5.97 3.638h1.62c1.053 0 1.483.677 1.488 1.564.008.96-.6 1.564-1.492 1.564h-.644v1.66h-.977V3.64m.977.897v1.34h.542c.27 0 .596-.068.596-.673-.002-.6-.32-.667-.596-.667h-.542m3.8.036v2.92h.35c.933 0 1.223-.448 1.228-1.462.008-1.06-.316-1.45-1.23-1.45h-.347m-.977-.94h1.03c1.68 0 2.523.586 2.534 2.39.01 1.688-.607 2.4-2.534 2.4h-1.03V3.64m4.305 0h2.63v.934h-1.657v.894H16.6V6.4h-1.56v2.026h-.97V3.638"></path><path d="M19.462 13.46c.348 4.274-6.59 16.72-8.508 15.792-1.82-.85 1.53-3.317 2.92-4.366-2.864.894-5.394 3.252-3.837 3.93 2.113.895 7.048-9.25 9.41-15.394zM14.32 24.874c4.767-1.526 14.735-2.974 15.152-1.407.824-3.157-13.72-.37-15.153 1.407zm5.28-5.043c2.31 3.237 9.816 7.498 9.788 3.82-.306 2.046-6.66-1.097-8.925-4.164-4.087-5.534-2.39-8.772-1.682-8.732.917.047 1.074 1.307.67 2.442-.173-1.406-.58-2.44-1.224-2.415-1.835.067-1.905 4.46 1.37 9.065z" fill="#f91d0a"></path></svg><span class="anchor-text-container"><span class="anchor-text">View PDF</span></span></a><a class="anchor link anchor-primary" href="/science/article/pii/S0262885611000515" aria-describedby="ref-id-h0145"><span class="anchor-text-container"><span class="anchor-text">View article</span></span></a><a class="anchor link anchor-primary" href="https://www.scopus.com/inward/record.url?eid=2-s2.0-80052725518&amp;partnerID=10&amp;rel=R3.0.0" target="_blank" rel="noopener noreferrer" aria-describedby="ref-id-h0145"><span class="anchor-text-container"><span class="anchor-text">View in Scopus</span><svg focusable="false" viewBox="0 0 8 8" height="20" aria-label="Opens in new window" class="icon icon-arrow-up-right-tiny arrow-external-link"><path d="M1.12949 2.1072V1H7V6.85795H5.89111V2.90281L0.784057 8L0 7.21635L5.11902 2.1072H1.12949Z"></path></svg></span></a><a class="anchor link anchor-primary" href="https://scholar.google.com/scholar_lookup?title=Facial%20expression%20recognition%20from%20near-infrared%20videos&amp;publication_year=2011&amp;author=G.%20Zhao&amp;author=X.%20Huang&amp;author=M.%20Taini" target="_blank" rel="noopener noreferrer" aria-describedby="ref-id-h0145"><span class="anchor-text-container"><span class="anchor-text">Google Scholar</span><svg focusable="false" viewBox="0 0 8 8" height="20" aria-label="Opens in new window" class="icon icon-arrow-up-right-tiny arrow-external-link"><path d="M1.12949 2.1072V1H7V6.85795H5.89111V2.90281L0.784057 8L0 7.21635L5.11902 2.1072H1.12949Z"></path></svg></span></a></div></span></li><li><span class="label u-font-sans"><a class="anchor anchor-primary" href="#bb0150" id="ref-id-b0150" data-aa-button="sd:product:journal:article:location=references:type=anchor:name=citation-name"><span class="anchor-text-container"><span class="anchor-text">[26]</span></span></a></span><span class="reference" id="h0150"><div class="other-ref"><span>Huiyuan Yang, Umur Ciftci, Lijun Yin, Facial expression recognition by de-expression residue learning, Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, 2018</span></div><div class="ReferenceLinks u-font-sans"><a class="anchor link anchor-primary" href="https://scholar.google.com/scholar?q=Huiyuan%20Yang%2C%20Umur%20Ciftci%2C%20Lijun%20Yin%2C%20Facial%20expression%20recognition%20by%20de-expression%20residue%20learning%2C%20Proceedings%20of%20the%20IEEE%20Conference%20on%20Computer%20Vision%20and%20Pattern%20Recognition%2C%202018" target="_blank" rel="noopener noreferrer"><span class="anchor-text-container"><span class="anchor-text">Google Scholar</span><svg focusable="false" viewBox="0 0 8 8" height="20" aria-label="Opens in new window" class="icon icon-arrow-up-right-tiny arrow-external-link"><path d="M1.12949 2.1072V1H7V6.85795H5.89111V2.90281L0.784057 8L0 7.21635L5.11902 2.1072H1.12949Z"></path></svg></span></a></div></span></li><li><span class="label u-font-sans"><a class="anchor anchor-primary" href="#bb0155" id="ref-id-b0155" data-aa-button="sd:product:journal:article:location=references:type=anchor:name=citation-name"><span class="anchor-text-container"><span class="anchor-text">[27]</span></span></a></span><span class="reference" id="h0155"><div class="other-ref"><span>P. Liu, S. Han, Z. Meng Y. Tong, Facial expression recognition via a boosted deep belief network, in: Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, 2014, pp. 1805–1812</span></div><div class="ReferenceLinks u-font-sans"><a class="anchor link anchor-primary" href="https://scholar.google.com/scholar?q=P.%20Liu%2C%20S.%20Han%2C%20Z.%20Meng%20Y.%20Tong%2C%20Facial%20expression%20recognition%20via%20a%20boosted%20deep%20belief%20network%2C%20in%3A%20Proceedings%20of%20the%20IEEE%20Conference%20on%20Computer%20Vision%20and%20Pattern%20Recognition%2C%202014%2C%20pp.%201805%E2%80%931812" target="_blank" rel="noopener noreferrer"><span class="anchor-text-container"><span class="anchor-text">Google Scholar</span><svg focusable="false" viewBox="0 0 8 8" height="20" aria-label="Opens in new window" class="icon icon-arrow-up-right-tiny arrow-external-link"><path d="M1.12949 2.1072V1H7V6.85795H5.89111V2.90281L0.784057 8L0 7.21635L5.11902 2.1072H1.12949Z"></path></svg></span></a></div></span></li><li><span class="label u-font-sans"><a class="anchor anchor-primary" href="#bb0160" id="ref-id-b0160" data-aa-button="sd:product:journal:article:location=references:type=anchor:name=citation-name"><span class="anchor-text-container"><span class="anchor-text">[28]</span></span></a></span><span class="reference" id="h0160"><div class="other-ref"><span>Zhong, Lei, et al., A graph-structured representation with BRNN for static-based facial expression recognition, 2019 14th IEEE International Conference on Automatic Face &amp; Gesture Recognition (FG 2019), IEEE, 2019.</span></div><div class="ReferenceLinks u-font-sans"><a class="anchor link anchor-primary" href="https://scholar.google.com/scholar?q=Zhong%2C%20Lei%2C%20et%20al.%2C%20A%20graph-structured%20representation%20with%20BRNN%20for%20static-based%20facial%20expression%20recognition%2C%202019%2014th%20IEEE%20International%20Conference%20on%20Automatic%20Face%20%26%20Gesture%20Recognition%20(FG%202019)%2C%20IEEE%2C%202019." target="_blank" rel="noopener noreferrer"><span class="anchor-text-container"><span class="anchor-text">Google Scholar</span><svg focusable="false" viewBox="0 0 8 8" height="20" aria-label="Opens in new window" class="icon icon-arrow-up-right-tiny arrow-external-link"><path d="M1.12949 2.1072V1H7V6.85795H5.89111V2.90281L0.784057 8L0 7.21635L5.11902 2.1072H1.12949Z"></path></svg></span></a></div></span></li><li><span class="label u-font-sans"><a class="anchor anchor-primary" href="#bb0165" id="ref-id-b0165" data-aa-button="sd:product:journal:article:location=references:type=anchor:name=citation-name"><span class="anchor-text-container"><span class="anchor-text">[29]</span></span></a></span><span class="reference" id="h0165"><div class="other-ref"><span>Arriaga, Octavio, Matias Valdenegro-Toro, Paul Plöger, Real-time convolutional neural networks for emotion and gender classification. arXiv preprint arXiv:1710.07557 (2017).</span></div><div class="ReferenceLinks u-font-sans"><a class="anchor link anchor-primary" href="https://scholar.google.com/scholar?q=Arriaga%2C%20Octavio%2C%20Matias%20Valdenegro-Toro%2C%20Paul%20Pl%C3%B6ger%2C%20Real-time%20convolutional%20neural%20networks%20for%20emotion%20and%20gender%20classification.%20arXiv%20preprint%20arXiv%3A1710.07557%20(2017)." target="_blank" rel="noopener noreferrer"><span class="anchor-text-container"><span class="anchor-text">Google Scholar</span><svg focusable="false" viewBox="0 0 8 8" height="20" aria-label="Opens in new window" class="icon icon-arrow-up-right-tiny arrow-external-link"><path d="M1.12949 2.1072V1H7V6.85795H5.89111V2.90281L0.784057 8L0 7.21635L5.11902 2.1072H1.12949Z"></path></svg></span></a></div></span></li><li><span class="label u-font-sans"><a class="anchor anchor-primary" href="#bb0170" id="ref-id-b0170" data-aa-button="sd:product:journal:article:location=references:type=anchor:name=citation-name"><span class="anchor-text-container"><span class="anchor-text">[30]</span></span></a></span><span class="reference" id="h0170"><div class="contribution"><div class="authors u-font-sans">J. Shao, Y. Qian</div><div id="ref-id-h0170" class="title text-m">Three convolutional neural network models for facial expression recognition in the wild</div></div><div class="host u-font-sans">Neurocomputing, 355 (2019), pp. 82-92</div><div class="ReferenceLinks u-font-sans"><a class="anchor pdf link anchor-primary anchor-icon-left anchor-with-icon" href="/science/article/pii/S0925231219306137/pdfft?md5=b31bdcbb1e65c9378c37c8bc3bd861d0&amp;pid=1-s2.0-S0925231219306137-main.pdf" target="_blank" rel="nofollow" aria-describedby="ref-id-h0170"><svg focusable="false" viewBox="0 0 35 32" height="20" class="icon icon-pdf-multicolor"><path d="M7 .362h17.875l6.763 6.1V31.64H6.948V16z" stroke="#000" stroke-width=".703" fill="#fff"></path><path d="M.167 2.592H22.39V9.72H.166z" fill="#da0000"></path><path fill="#fff9f9" d="M5.97 3.638h1.62c1.053 0 1.483.677 1.488 1.564.008.96-.6 1.564-1.492 1.564h-.644v1.66h-.977V3.64m.977.897v1.34h.542c.27 0 .596-.068.596-.673-.002-.6-.32-.667-.596-.667h-.542m3.8.036v2.92h.35c.933 0 1.223-.448 1.228-1.462.008-1.06-.316-1.45-1.23-1.45h-.347m-.977-.94h1.03c1.68 0 2.523.586 2.534 2.39.01 1.688-.607 2.4-2.534 2.4h-1.03V3.64m4.305 0h2.63v.934h-1.657v.894H16.6V6.4h-1.56v2.026h-.97V3.638"></path><path d="M19.462 13.46c.348 4.274-6.59 16.72-8.508 15.792-1.82-.85 1.53-3.317 2.92-4.366-2.864.894-5.394 3.252-3.837 3.93 2.113.895 7.048-9.25 9.41-15.394zM14.32 24.874c4.767-1.526 14.735-2.974 15.152-1.407.824-3.157-13.72-.37-15.153 1.407zm5.28-5.043c2.31 3.237 9.816 7.498 9.788 3.82-.306 2.046-6.66-1.097-8.925-4.164-4.087-5.534-2.39-8.772-1.682-8.732.917.047 1.074 1.307.67 2.442-.173-1.406-.58-2.44-1.224-2.415-1.835.067-1.905 4.46 1.37 9.065z" fill="#f91d0a"></path></svg><span class="anchor-text-container"><span class="anchor-text">View PDF</span></span></a><a class="anchor link anchor-primary" href="/science/article/pii/S0925231219306137" aria-describedby="ref-id-h0170"><span class="anchor-text-container"><span class="anchor-text">View article</span></span></a><a class="anchor link anchor-primary" href="https://www.scopus.com/inward/record.url?eid=2-s2.0-85065595874&amp;partnerID=10&amp;rel=R3.0.0" target="_blank" rel="noopener noreferrer" aria-describedby="ref-id-h0170"><span class="anchor-text-container"><span class="anchor-text">View in Scopus</span><svg focusable="false" viewBox="0 0 8 8" height="20" aria-label="Opens in new window" class="icon icon-arrow-up-right-tiny arrow-external-link"><path d="M1.12949 2.1072V1H7V6.85795H5.89111V2.90281L0.784057 8L0 7.21635L5.11902 2.1072H1.12949Z"></path></svg></span></a><a class="anchor link anchor-primary" href="https://scholar.google.com/scholar_lookup?title=Three%20convolutional%20neural%20network%20models%20for%20facial%20expression%20recognition%20in%20the%20wild&amp;publication_year=2019&amp;author=J.%20Shao&amp;author=Y.%20Qian" target="_blank" rel="noopener noreferrer" aria-describedby="ref-id-h0170"><span class="anchor-text-container"><span class="anchor-text">Google Scholar</span><svg focusable="false" viewBox="0 0 8 8" height="20" aria-label="Opens in new window" class="icon icon-arrow-up-right-tiny arrow-external-link"><path d="M1.12949 2.1072V1H7V6.85795H5.89111V2.90281L0.784057 8L0 7.21635L5.11902 2.1072H1.12949Z"></path></svg></span></a></div></span></li><li><span class="label u-font-sans"><a class="anchor anchor-primary" href="#bb0175" id="ref-id-b0175" data-aa-button="sd:product:journal:article:location=references:type=anchor:name=citation-name"><span class="anchor-text-container"><span class="anchor-text">[31]</span></span></a></span><span class="reference" id="h0175"><div class="other-ref"><span>D. Hamester, P. Barros, S. Wermter, Face expression recognition with a 2-channel convolutional neural network, in: Neural Networks (IJCNN), 2015 International Joint Conference on, IEEE, 2015, pp. 1–8</span></div><div class="ReferenceLinks u-font-sans"><a class="anchor link anchor-primary" href="https://scholar.google.com/scholar?q=D.%20Hamester%2C%20P.%20Barros%2C%20S.%20Wermter%2C%20Face%20expression%20recognition%20with%20a%202-channel%20convolutional%20neural%20network%2C%20in%3A%20Neural%20Networks%20(IJCNN)%2C%202015%20International%20Joint%20Conference%20on%2C%20IEEE%2C%202015%2C%20pp.%201%E2%80%938" target="_blank" rel="noopener noreferrer"><span class="anchor-text-container"><span class="anchor-text">Google Scholar</span><svg focusable="false" viewBox="0 0 8 8" height="20" aria-label="Opens in new window" class="icon icon-arrow-up-right-tiny arrow-external-link"><path d="M1.12949 2.1072V1H7V6.85795H5.89111V2.90281L0.784057 8L0 7.21635L5.11902 2.1072H1.12949Z"></path></svg></span></a></div></span></li><li><span class="label u-font-sans"><a class="anchor anchor-primary" href="#bb0180" id="ref-id-b0180" data-aa-button="sd:product:journal:article:location=references:type=anchor:name=citation-name"><span class="anchor-text-container"><span class="anchor-text">[32]</span></span></a></span><span class="reference" id="h0180"><div class="contribution"><div class="authors u-font-sans">K. Simonyan, A. Zisserman</div><div id="ref-id-h0180" class="title text-m">Very deep convolutional networks for large-scale image recognition</div></div><div class="host u-font-sans">Comput. Sci. (2014)</div><div class="ReferenceLinks u-font-sans"><a class="anchor link anchor-primary" href="https://scholar.google.com/scholar_lookup?title=Very%20deep%20convolutional%20networks%20for%20large-scale%20image%20recognition&amp;publication_year=2014&amp;author=K.%20Simonyan&amp;author=A.%20Zisserman" target="_blank" rel="noopener noreferrer" aria-describedby="ref-id-h0180"><span class="anchor-text-container"><span class="anchor-text">Google Scholar</span><svg focusable="false" viewBox="0 0 8 8" height="20" aria-label="Opens in new window" class="icon icon-arrow-up-right-tiny arrow-external-link"><path d="M1.12949 2.1072V1H7V6.85795H5.89111V2.90281L0.784057 8L0 7.21635L5.11902 2.1072H1.12949Z"></path></svg></span></a></div></span></li><li><span class="label u-font-sans"><a class="anchor anchor-primary" href="#bb0185" id="ref-id-b0185" data-aa-button="sd:product:journal:article:location=references:type=anchor:name=citation-name"><span class="anchor-text-container"><span class="anchor-text">[33]</span></span></a></span><span class="reference" id="h0185"><div class="other-ref"><span>P. Rodriguez, G. Cucurull, J. Gonalez, et al., Deep pain: exploiting long short-term memory networks for facial expression classification, IEEE Trans. Cybern. PP (99) (2017) 1–11</span></div><div class="ReferenceLinks u-font-sans"><a class="anchor link anchor-primary" href="https://scholar.google.com/scholar?q=P.%20Rodriguez%2C%20G.%20Cucurull%2C%20J.%20Gonalez%2C%20et%20al.%2C%20Deep%20pain%3A%20exploiting%20long%20short-term%20memory%20networks%20for%20facial%20expression%20classification%2C%20IEEE%20Trans.%20Cybern.%20PP%20(99)%20(2017)%201%E2%80%9311" target="_blank" rel="noopener noreferrer"><span class="anchor-text-container"><span class="anchor-text">Google Scholar</span><svg focusable="false" viewBox="0 0 8 8" height="20" aria-label="Opens in new window" class="icon icon-arrow-up-right-tiny arrow-external-link"><path d="M1.12949 2.1072V1H7V6.85795H5.89111V2.90281L0.784057 8L0 7.21635L5.11902 2.1072H1.12949Z"></path></svg></span></a></div></span></li><li><span class="label u-font-sans"><a class="anchor anchor-primary" href="#bb0190" id="ref-id-b0190" data-aa-button="sd:product:journal:article:location=references:type=anchor:name=citation-name"><span class="anchor-text-container"><span class="anchor-text">[34]</span></span></a></span><span class="reference" id="h0190"><div class="other-ref"><span>J. Li, Y. Mi, J. Yu, et al., A novel convolutional neural network for facial expression recognition, International Conference on Cognitive Systems and Signal Processing. Springer, Singapore, 2018, pp. 310–320</span></div><div class="ReferenceLinks u-font-sans"><a class="anchor link anchor-primary" href="https://scholar.google.com/scholar?q=J.%20Li%2C%20Y.%20Mi%2C%20J.%20Yu%2C%20et%20al.%2C%20A%20novel%20convolutional%20neural%20network%20for%20facial%20expression%20recognition%2C%20International%20Conference%20on%20Cognitive%20Systems%20and%20Signal%20Processing.%20Springer%2C%20Singapore%2C%202018%2C%20pp.%20310%E2%80%93320" target="_blank" rel="noopener noreferrer"><span class="anchor-text-container"><span class="anchor-text">Google Scholar</span><svg focusable="false" viewBox="0 0 8 8" height="20" aria-label="Opens in new window" class="icon icon-arrow-up-right-tiny arrow-external-link"><path d="M1.12949 2.1072V1H7V6.85795H5.89111V2.90281L0.784057 8L0 7.21635L5.11902 2.1072H1.12949Z"></path></svg></span></a></div></span></li><li><span class="label u-font-sans"><a class="anchor anchor-primary" href="#bb0195" id="ref-id-b0195" data-aa-button="sd:product:journal:article:location=references:type=anchor:name=citation-name"><span class="anchor-text-container"><span class="anchor-text">[35]</span></span></a></span><span class="reference" id="h0195"><div class="other-ref"><span>H. Yang, U. Ciftci, L. Yin, Facial expression recognition by de-expression residue learning, in: Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, 2018, pp. 2168–2177</span></div><div class="ReferenceLinks u-font-sans"><a class="anchor link anchor-primary" href="https://scholar.google.com/scholar?q=H.%20Yang%2C%20U.%20Ciftci%2C%20L.%20Yin%2C%20Facial%20expression%20recognition%20by%20de-expression%20residue%20learning%2C%20in%3A%20Proceedings%20of%20the%20IEEE%20Conference%20on%20Computer%20Vision%20and%20Pattern%20Recognition%2C%202018%2C%20pp.%202168%E2%80%932177" target="_blank" rel="noopener noreferrer"><span class="anchor-text-container"><span class="anchor-text">Google Scholar</span><svg focusable="false" viewBox="0 0 8 8" height="20" aria-label="Opens in new window" class="icon icon-arrow-up-right-tiny arrow-external-link"><path d="M1.12949 2.1072V1H7V6.85795H5.89111V2.90281L0.784057 8L0 7.21635L5.11902 2.1072H1.12949Z"></path></svg></span></a></div></span></li><li><span class="label u-font-sans"><a class="anchor anchor-primary" href="#bb0200" id="ref-id-b0200" data-aa-button="sd:product:journal:article:location=references:type=anchor:name=citation-name"><span class="anchor-text-container"><span class="anchor-text">[36]</span></span></a></span><span class="reference" id="h0200"><div class="other-ref"><span>Y. Lecun, L. Bottou, Y. Bengio, et al., Gradient-based learning applied to document recognition, Proc. IEEE 86 (11) (1998) 2278–2324</span></div><div class="ReferenceLinks u-font-sans"><a class="anchor link anchor-primary" href="https://scholar.google.com/scholar?q=Y.%20Lecun%2C%20L.%20Bottou%2C%20Y.%20Bengio%2C%20et%20al.%2C%20Gradient-based%20learning%20applied%20to%20document%20recognition%2C%20Proc.%20IEEE%2086%20(11)%20(1998)%202278%E2%80%932324" target="_blank" rel="noopener noreferrer"><span class="anchor-text-container"><span class="anchor-text">Google Scholar</span><svg focusable="false" viewBox="0 0 8 8" height="20" aria-label="Opens in new window" class="icon icon-arrow-up-right-tiny arrow-external-link"><path d="M1.12949 2.1072V1H7V6.85795H5.89111V2.90281L0.784057 8L0 7.21635L5.11902 2.1072H1.12949Z"></path></svg></span></a></div></span></li><li><span class="label u-font-sans"><a class="anchor anchor-primary" href="#bb0205" id="ref-id-b0205" data-aa-button="sd:product:journal:article:location=references:type=anchor:name=citation-name"><span class="anchor-text-container"><span class="anchor-text">[37]</span></span></a></span><span class="reference" id="h0205"><div class="contribution"><div class="authors u-font-sans">Z. Zhang, P. Luo, C.L. Chen, X. Tang</div><div id="ref-id-h0205" class="title text-m">From facial expression recognition to interpersonal relation prediction</div></div><div class="host u-font-sans">Int. J. Comput. Vis., 126 (5) (2018), pp. 1-20</div><div class="ReferenceLinks u-font-sans"><a class="anchor pdf link anchor-primary anchor-icon-left anchor-with-icon" href="/science/article/pii/S0022509616308845/pdfft?md5=9a1ea4149cd6c5664d8820f505a6b262&amp;pid=1-s2.0-S0022509616308845-main.pdf" target="_blank" rel="nofollow" aria-describedby="ref-id-h0205"><svg focusable="false" viewBox="0 0 35 32" height="20" class="icon icon-pdf-multicolor"><path d="M7 .362h17.875l6.763 6.1V31.64H6.948V16z" stroke="#000" stroke-width=".703" fill="#fff"></path><path d="M.167 2.592H22.39V9.72H.166z" fill="#da0000"></path><path fill="#fff9f9" d="M5.97 3.638h1.62c1.053 0 1.483.677 1.488 1.564.008.96-.6 1.564-1.492 1.564h-.644v1.66h-.977V3.64m.977.897v1.34h.542c.27 0 .596-.068.596-.673-.002-.6-.32-.667-.596-.667h-.542m3.8.036v2.92h.35c.933 0 1.223-.448 1.228-1.462.008-1.06-.316-1.45-1.23-1.45h-.347m-.977-.94h1.03c1.68 0 2.523.586 2.534 2.39.01 1.688-.607 2.4-2.534 2.4h-1.03V3.64m4.305 0h2.63v.934h-1.657v.894H16.6V6.4h-1.56v2.026h-.97V3.638"></path><path d="M19.462 13.46c.348 4.274-6.59 16.72-8.508 15.792-1.82-.85 1.53-3.317 2.92-4.366-2.864.894-5.394 3.252-3.837 3.93 2.113.895 7.048-9.25 9.41-15.394zM14.32 24.874c4.767-1.526 14.735-2.974 15.152-1.407.824-3.157-13.72-.37-15.153 1.407zm5.28-5.043c2.31 3.237 9.816 7.498 9.788 3.82-.306 2.046-6.66-1.097-8.925-4.164-4.087-5.534-2.39-8.772-1.682-8.732.917.047 1.074 1.307.67 2.442-.173-1.406-.58-2.44-1.224-2.415-1.835.067-1.905 4.46 1.37 9.065z" fill="#f91d0a"></path></svg><span class="anchor-text-container"><span class="anchor-text">View PDF</span></span></a><a class="anchor link anchor-primary" href="/science/article/pii/S0022509616308845" aria-describedby="ref-id-h0205"><span class="anchor-text-container"><span class="anchor-text">View article</span></span></a><a class="anchor link anchor-primary" href="https://scholar.google.com/scholar_lookup?title=From%20facial%20expression%20recognition%20to%20interpersonal%20relation%20prediction&amp;publication_year=2018&amp;author=Z.%20Zhang&amp;author=P.%20Luo&amp;author=C.L.%20Chen&amp;author=X.%20Tang" target="_blank" rel="noopener noreferrer" aria-describedby="ref-id-h0205"><span class="anchor-text-container"><span class="anchor-text">Google Scholar</span><svg focusable="false" viewBox="0 0 8 8" height="20" aria-label="Opens in new window" class="icon icon-arrow-up-right-tiny arrow-external-link"><path d="M1.12949 2.1072V1H7V6.85795H5.89111V2.90281L0.784057 8L0 7.21635L5.11902 2.1072H1.12949Z"></path></svg></span></a></div></span></li><li><span class="label u-font-sans"><a class="anchor anchor-primary" href="#bb0210" id="ref-id-b0210" data-aa-button="sd:product:journal:article:location=references:type=anchor:name=citation-name"><span class="anchor-text-container"><span class="anchor-text">[38]</span></span></a></span><span class="reference" id="h0210"><div class="other-ref"><span>P.D.M. Fernandez, F.A.G. Peña, T.I. Ren, et al., FERAtt: facial expression recognition with attention net. arXiv preprint arXiv:1902.03284, 2019.</span></div><div class="ReferenceLinks u-font-sans"><a class="anchor link anchor-primary" href="https://scholar.google.com/scholar?q=P.D.M.%20Fernandez%2C%20F.A.G.%20Pe%C3%B1a%2C%20T.I.%20Ren%2C%20et%20al.%2C%20FERAtt%3A%20facial%20expression%20recognition%20with%20attention%20net.%20arXiv%20preprint%20arXiv%3A1902.03284%2C%202019." target="_blank" rel="noopener noreferrer"><span class="anchor-text-container"><span class="anchor-text">Google Scholar</span><svg focusable="false" viewBox="0 0 8 8" height="20" aria-label="Opens in new window" class="icon icon-arrow-up-right-tiny arrow-external-link"><path d="M1.12949 2.1072V1H7V6.85795H5.89111V2.90281L0.784057 8L0 7.21635L5.11902 2.1072H1.12949Z"></path></svg></span></a></div></span></li><li><span class="label u-font-sans"><a class="anchor anchor-primary" href="#bb0215" id="ref-id-b0215" data-aa-button="sd:product:journal:article:location=references:type=anchor:name=citation-name"><span class="anchor-text-container"><span class="anchor-text">[39]</span></span></a></span><span class="reference" id="h0215"><div class="other-ref"><span>https://www.kaggle.com/c/challenges-in-representation-learning-facial-expression-recognition-challenge/data</span></div><div class="ReferenceLinks u-font-sans"><a class="anchor link anchor-primary" href="https://scholar.google.com/scholar?q=https%3A%2F%2Fwww.kaggle.com%2Fc%2Fchallenges-in-representation-learning-facial-expression-recognition-challenge%2Fdata" target="_blank" rel="noopener noreferrer"><span class="anchor-text-container"><span class="anchor-text">Google Scholar</span><svg focusable="false" viewBox="0 0 8 8" height="20" aria-label="Opens in new window" class="icon icon-arrow-up-right-tiny arrow-external-link"><path d="M1.12949 2.1072V1H7V6.85795H5.89111V2.90281L0.784057 8L0 7.21635L5.11902 2.1072H1.12949Z"></path></svg></span></a></div></span></li><li><span class="label u-font-sans"><a class="anchor anchor-primary" href="#bb0220" id="ref-id-b0220" data-aa-button="sd:product:journal:article:location=references:type=anchor:name=citation-name"><span class="anchor-text-container"><span class="anchor-text">[40]</span></span></a></span><span class="reference" id="h0220"><div class="other-ref"><span>Y. Guo, D. Tao, J. Yu, H. Xiong, Y. Li, D. Tao, Deep neural networks with relativity learning for facial expression recognition, in: Multimedia &amp; Expo Workshops (ICMEW), 2016 IEEE International Conference on, IEEE, 2016, pp. 1–6.</span></div><div class="ReferenceLinks u-font-sans"><a class="anchor link anchor-primary" href="https://scholar.google.com/scholar?q=Y.%20Guo%2C%20D.%20Tao%2C%20J.%20Yu%2C%20H.%20Xiong%2C%20Y.%20Li%2C%20D.%20Tao%2C%20Deep%20neural%20networks%20with%20relativity%20learning%20for%20facial%20expression%20recognition%2C%20in%3A%20Multimedia%20%26%20Expo%20Workshops%20(ICMEW)%2C%202016%20IEEE%20International%20Conference%20on%2C%20IEEE%2C%202016%2C%20pp.%201%E2%80%936." target="_blank" rel="noopener noreferrer"><span class="anchor-text-container"><span class="anchor-text">Google Scholar</span><svg focusable="false" viewBox="0 0 8 8" height="20" aria-label="Opens in new window" class="icon icon-arrow-up-right-tiny arrow-external-link"><path d="M1.12949 2.1072V1H7V6.85795H5.89111V2.90281L0.784057 8L0 7.21635L5.11902 2.1072H1.12949Z"></path></svg></span></a></div></span></li><li><span class="label u-font-sans"><a class="anchor anchor-primary" href="#bb0225" id="ref-id-b0225" data-aa-button="sd:product:journal:article:location=references:type=anchor:name=citation-name"><span class="anchor-text-container"><span class="anchor-text">[41]</span></span></a></span><span class="reference" id="h0225"><div class="other-ref"><span>B.-K. Kim, S.-Y. Dong, J. Roh, G. Kim, S.-Y. Lee, Fusing aligned and non-aligned face information for automatic affect recognition in the wild: A deep learning approach, in: Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition Workshops, 2016, pp. 48–57</span></div><div class="ReferenceLinks u-font-sans"><a class="anchor link anchor-primary" href="https://scholar.google.com/scholar?q=B.-K.%20Kim%2C%20S.-Y.%20Dong%2C%20J.%20Roh%2C%20G.%20Kim%2C%20S.-Y.%20Lee%2C%20Fusing%20aligned%20and%20non-aligned%20face%20information%20for%20automatic%20affect%20recognition%20in%20the%20wild%3A%20A%20deep%20learning%20approach%2C%20in%3A%20Proceedings%20of%20the%20IEEE%20Conference%20on%20Computer%20Vision%20and%20Pattern%20Recognition%20Workshops%2C%202016%2C%20pp.%2048%E2%80%9357" target="_blank" rel="noopener noreferrer"><span class="anchor-text-container"><span class="anchor-text">Google Scholar</span><svg focusable="false" viewBox="0 0 8 8" height="20" aria-label="Opens in new window" class="icon icon-arrow-up-right-tiny arrow-external-link"><path d="M1.12949 2.1072V1H7V6.85795H5.89111V2.90281L0.784057 8L0 7.21635L5.11902 2.1072H1.12949Z"></path></svg></span></a></div></span></li><li><span class="label u-font-sans"><a class="anchor anchor-primary" href="#bb0230" id="ref-id-b0230" data-aa-button="sd:product:journal:article:location=references:type=anchor:name=citation-name"><span class="anchor-text-container"><span class="anchor-text">[42]</span></span></a></span><span class="reference" id="h0230"><div class="other-ref"><span>C. Pramerdorfer, M. Kampel, Facial expression recognition using convolutional neural networks: State of the art, arXiv preprint arXiv:1612.02903, 2016.</span></div><div class="ReferenceLinks u-font-sans"><a class="anchor link anchor-primary" href="https://scholar.google.com/scholar?q=C.%20Pramerdorfer%2C%20M.%20Kampel%2C%20Facial%20expression%20recognition%20using%20convolutional%20neural%20networks%3A%20State%20of%20the%20art%2C%20arXiv%20preprint%20arXiv%3A1612.02903%2C%202016." target="_blank" rel="noopener noreferrer"><span class="anchor-text-container"><span class="anchor-text">Google Scholar</span><svg focusable="false" viewBox="0 0 8 8" height="20" aria-label="Opens in new window" class="icon icon-arrow-up-right-tiny arrow-external-link"><path d="M1.12949 2.1072V1H7V6.85795H5.89111V2.90281L0.784057 8L0 7.21635L5.11902 2.1072H1.12949Z"></path></svg></span></a></div></span></li><li><span class="label u-font-sans"><a class="anchor anchor-primary" href="#bb0235" id="ref-id-b0235" data-aa-button="sd:product:journal:article:location=references:type=anchor:name=citation-name"><span class="anchor-text-container"><span class="anchor-text">[43]</span></span></a></span><span class="reference" id="h0235"><div class="other-ref"><span>Dhwani Mehta, Mohammad Faridul Haque Siddiqui, Ahmad Y. Javaid, Recognition of emotion intensities using machine learning algorithms: a comparative study, Sensors 19 (8) (2019) 1897</span></div><div class="ReferenceLinks u-font-sans"><a class="anchor link anchor-primary" href="https://scholar.google.com/scholar?q=Dhwani%20Mehta%2C%20Mohammad%20Faridul%20Haque%20Siddiqui%2C%20Ahmad%20Y.%20Javaid%2C%20Recognition%20of%20emotion%20intensities%20using%20machine%20learning%20algorithms%3A%20a%20comparative%20study%2C%20Sensors%2019%20(8)%20(2019)%201897" target="_blank" rel="noopener noreferrer"><span class="anchor-text-container"><span class="anchor-text">Google Scholar</span><svg focusable="false" viewBox="0 0 8 8" height="20" aria-label="Opens in new window" class="icon icon-arrow-up-right-tiny arrow-external-link"><path d="M1.12949 2.1072V1H7V6.85795H5.89111V2.90281L0.784057 8L0 7.21635L5.11902 2.1072H1.12949Z"></path></svg></span></a></div></span></li><li><span class="label u-font-sans"><a class="anchor anchor-primary" href="#bb0240" id="ref-id-b0240" data-aa-button="sd:product:journal:article:location=references:type=anchor:name=citation-name"><span class="anchor-text-container"><span class="anchor-text">[44]</span></span></a></span><span class="reference" id="h0240"><div class="other-ref"><span>T. Connie, M. Al-Shabi, W.P. Cheah, et al., Facial expression recognition using a hybrid CNN–SIFT aggregator, International Workshop on Multi-disciplinary Trends in Artificial Intelligence, Springer, Cham, 2017, pp. 139–149</span></div><div class="ReferenceLinks u-font-sans"><a class="anchor link anchor-primary" href="https://scholar.google.com/scholar?q=T.%20Connie%2C%20M.%20Al-Shabi%2C%20W.P.%20Cheah%2C%20et%20al.%2C%20Facial%20expression%20recognition%20using%20a%20hybrid%20CNN%E2%80%93SIFT%20aggregator%2C%20International%20Workshop%20on%20Multi-disciplinary%20Trends%20in%20Artificial%20Intelligence%2C%20Springer%2C%20Cham%2C%202017%2C%20pp.%20139%E2%80%93149" target="_blank" rel="noopener noreferrer"><span class="anchor-text-container"><span class="anchor-text">Google Scholar</span><svg focusable="false" viewBox="0 0 8 8" height="20" aria-label="Opens in new window" class="icon icon-arrow-up-right-tiny arrow-external-link"><path d="M1.12949 2.1072V1H7V6.85795H5.89111V2.90281L0.784057 8L0 7.21635L5.11902 2.1072H1.12949Z"></path></svg></span></a></div></span></li></ol></section></section></div><div id="section-cited-by"><section aria-label="Cited by" class="ListArticles preview"><div class="PageDivider"></div><header id="citing-articles-header"><h2 class="u-h4 u-margin-l-ver u-font-serif">Cited by (242)</h2></header><div aria-describedby="citing-articles-header"><div class="citing-articles u-margin-l-bottom"><ul><li class="ListArticleItem u-margin-l-bottom"><div class="sub-heading u-margin-xs-bottom"><h3 class="u-font-serif" id="citing-articles-article-0-title"><a class="anchor anchor-primary" href="/science/article/pii/S1566253523003354"><span class="anchor-text-container"><span class="anchor-text">Emotion recognition and artificial intelligence: A systematic review (2014–2023) and research recommendations</span></span></a></h3><div>2024, Information Fusion</div></div><div class="buttons"><button class="button-link button-link-primary button-link-icon-right" data-aa-button="sd:product:journal:article:location=citing-articles:type=view-details" aria-describedby="citing-articles-article-0-title" aria-controls="citing-articles-article-0" aria-expanded="false" type="button"><span class="button-link-text-container"><span class="button-link-text">Show abstract</span></span><svg focusable="false" viewBox="0 0 92 128" height="20" class="icon icon-navigate-down"><path d="M1 51l7-7 38 38 38-38 7 7-45 45z"></path></svg></button></div><div class="u-display-none" aria-hidden="true"><div class="abstract u-margin-xs-top u-margin-m-bottom u-font-serif" id="reference-abstract"><div class="u-margin-ver-m"><div class="u-margin-s-bottom" id="d1e11286">Emotion recognition is the ability to precisely infer human emotions from numerous sources and modalities using questionnaires, physical signals, and physiological signals. Recently, emotion recognition has gained attention because of its diverse application areas, like affective computing, healthcare, human–robot interactions, and market research. This paper provides a comprehensive and systematic review of emotion recognition techniques of the current decade. The paper includes emotion recognition using physical and physiological signals. Physical signals involve speech and facial expression, while physiological signals include electroencephalogram, electrocardiogram, galvanic skin response, and eye tracking. The paper provides an introduction to various emotion models, stimuli used for emotion elicitation, and the background of existing automated emotion recognition systems. This paper covers comprehensive searching and scanning of well-known datasets followed by design criteria for review. After a thorough analysis and discussion, we selected 142 journal articles using PRISMA guidelines. The review provides a detailed analysis of existing studies and available datasets of emotion recognition. Our review analysis also presented potential challenges in the existing literature and directions for future research.</div></div></div></div></li><li class="ListArticleItem u-margin-l-bottom"><div class="sub-heading u-margin-xs-bottom"><h3 class="u-font-serif" id="citing-articles-article-1-title"><a class="anchor anchor-primary" href="/science/article/pii/S1568494621009832"><span class="anchor-text-container"><span class="anchor-text">A hybrid approach for forecasting ship motion using CNN–GRU–AM and GCWOA</span></span></a></h3><div>2022, Applied Soft Computing</div></div><div class="buttons"><button class="button-link button-link-primary button-link-icon-right" data-aa-button="sd:product:journal:article:location=citing-articles:type=view-details" aria-describedby="citing-articles-article-1-title" aria-controls="citing-articles-article-1" aria-expanded="false" type="button"><span class="button-link-text-container"><span class="button-link-text">Show abstract</span></span><svg focusable="false" viewBox="0 0 92 128" height="20" class="icon icon-navigate-down"><path d="M1 51l7-7 38 38 38-38 7 7-45 45z"></path></svg></button></div><div class="u-display-none" aria-hidden="true"><div class="abstract u-margin-xs-top u-margin-m-bottom u-font-serif" id="reference-abstract"><div class="u-margin-ver-m"><div class="u-margin-s-bottom" id="d1e1277">The motion of a ship, which has six degrees of freedom, is a complex nonlinear dynamic process with variable periodicity and chaotic characteristics. With the development of smart ships, modern high-precision equipment needs the help from high accuracy of ship motion (SHM) forecasting. Existing models will not easily be able to satisfy future accuracy requirements. Therefore, to improve the accuracy of SHM forecasts, by firstly determining the sequence features of SHM time series, a convolutional neural network (CNN) was used herein to extract automatically spatial feature vectors. Considering the variable-period characteristics of SHM time series, a gated recurrent unit (GRU) was used to learn the inherent time characteristics and to extract temporal feature vectors. The attention mechanism (AM) was developed to control the effect of feature vectors on the output to solve the problem of the contribution of feature vectors. Integrating the above methods, an SHM hybrid forecasting model, the SHM CNN–GRU–AM (SHM-C&amp;G&amp;A) model, was established. Secondly, in view of the difficulty of selecting the hyperparameters of a hybrid model, on account of the defects of the whale optimization algorithm (WOA), a normal cloud local search (NCLS) algorithm was developed. Exploiting the advantages of the normal cloud search (NCS) and the genetic algorithm (GA), a genetic random global search (GRGS) algorithm was developed. Then, a hybrid genetic cloud whale optimization algorithm (GCWOA) was developed and used to optimize the hyperparameters of the SHM-C&amp;G&amp;A model. Accordingly, a hybrid forecasting approach that integrates SHM-C&amp;G&amp;A and GCWOA was proposed; it is referred to as GCWOA-SHM-C&amp;G&amp;A. Finally, ship heave and pitch time series data are used to analyze an example to test the forecasting effectiveness of SHM-C&amp;G&amp;A and the optimization performance of GCWOA. The experimental results reveal that the proposed SHM-C&amp;G&amp;A model is more robust that the other models that are considered in this paper, and exhibits better nonlinear characteristics. The proposed GCWOA yields a better combination of hyperparameters than contrast algorithms in the forecasting process.</div></div></div></div></li><li class="ListArticleItem u-margin-l-bottom"><div class="sub-heading u-margin-xs-bottom"><h3 class="u-font-serif" id="citing-articles-article-2-title"><a class="anchor anchor-primary" href="https://doi.org/10.3390/biomimetics8020199" target="_blank"><span class="anchor-text-container"><span class="anchor-text">Distract Your Attention: Multi-Head Cross Attention Network for Facial Expression Recognition</span><svg focusable="false" viewBox="0 0 8 8" height="20" aria-label="Opens in new window" class="icon icon-arrow-up-right-tiny arrow-external-link"><path d="M1.12949 2.1072V1H7V6.85795H5.89111V2.90281L0.784057 8L0 7.21635L5.11902 2.1072H1.12949Z"></path></svg></span></a></h3><div>2023, Biomimetics</div></div><div class="buttons"></div><div class="u-display-none" aria-hidden="true"><div class="abstract u-margin-xs-top u-margin-m-bottom u-font-serif" id="reference-abstract"></div></div></li><li class="ListArticleItem u-margin-l-bottom"><div class="sub-heading u-margin-xs-bottom"><h3 class="u-font-serif" id="citing-articles-article-3-title"><a class="anchor anchor-primary" href="https://doi.org/10.1109/TAFFC.2021.3122146" target="_blank"><span class="anchor-text-container"><span class="anchor-text">Facial Expression Recognition With Visual Transformers and Attentional Selective Fusion</span><svg focusable="false" viewBox="0 0 8 8" height="20" aria-label="Opens in new window" class="icon icon-arrow-up-right-tiny arrow-external-link"><path d="M1.12949 2.1072V1H7V6.85795H5.89111V2.90281L0.784057 8L0 7.21635L5.11902 2.1072H1.12949Z"></path></svg></span></a></h3><div>2023, IEEE Transactions on Affective Computing</div></div><div class="buttons"></div><div class="u-display-none" aria-hidden="true"><div class="abstract u-margin-xs-top u-margin-m-bottom u-font-serif" id="reference-abstract"></div></div></li><li class="ListArticleItem u-margin-l-bottom"><div class="sub-heading u-margin-xs-bottom"><h3 class="u-font-serif" id="citing-articles-article-4-title"><a class="anchor anchor-primary" href="https://doi.org/10.30880/jscdm.2021.02.01.006" target="_blank"><span class="anchor-text-container"><span class="anchor-text">Facial Expression Recognition Based on Deep Learning Convolution Neural Network: A Review</span><svg focusable="false" viewBox="0 0 8 8" height="20" aria-label="Opens in new window" class="icon icon-arrow-up-right-tiny arrow-external-link"><path d="M1.12949 2.1072V1H7V6.85795H5.89111V2.90281L0.784057 8L0 7.21635L5.11902 2.1072H1.12949Z"></path></svg></span></a></h3><div>2021, Journal of Soft Computing and Data Mining</div></div><div class="buttons"></div><div class="u-display-none" aria-hidden="true"><div class="abstract u-margin-xs-top u-margin-m-bottom u-font-serif" id="reference-abstract"></div></div></li><li class="ListArticleItem u-margin-l-bottom"><div class="sub-heading u-margin-xs-bottom"><h3 class="u-font-serif" id="citing-articles-article-5-title"><a class="anchor anchor-primary" href="https://doi.org/10.1155/2020/4065207" target="_blank"><span class="anchor-text-container"><span class="anchor-text">Emotion Recognition of Students Based on Facial Expressions in Online Education Based on the Perspective of Computer Simulation</span><svg focusable="false" viewBox="0 0 8 8" height="20" aria-label="Opens in new window" class="icon icon-arrow-up-right-tiny arrow-external-link"><path d="M1.12949 2.1072V1H7V6.85795H5.89111V2.90281L0.784057 8L0 7.21635L5.11902 2.1072H1.12949Z"></path></svg></span></a></h3><div>2020, Complexity</div></div><div class="buttons"></div><div class="u-display-none" aria-hidden="true"><div class="abstract u-margin-xs-top u-margin-m-bottom u-font-serif" id="reference-abstract"></div></div></li></ul><a class="button-alternative button-alternative-secondary large-alternative button-alternative-icon-left" href="http://www.scopus.com/scopus/inward/citedby.url?partnerID=10&amp;rel=3.0.0&amp;eid=2-s2.0-85087331607&amp;md5=ba6a1756cbf7d149f11ac631079ec6a" target="_blank" id="citing-articles-view-all-btn"><svg focusable="false" viewBox="0 0 54 128" height="20" class="icon icon-navigate-right"><path d="M1 99l38-38L1 23l7-7 45 45-45 45z"></path></svg><span class="button-alternative-text-container"><span class="button-alternative-text">View all citing articles on Scopus</span></span><svg focusable="false" viewBox="0 0 8 8" height="20" aria-label="Opens in new window" class="icon icon-arrow-up-right-tiny arrow-external-link"><path d="M1.12949 2.1072V1H7V6.85795H5.89111V2.90281L0.784057 8L0 7.21635L5.11902 2.1072H1.12949Z"></path></svg></a></div></div></section></div><div class="article-biography article-biography-has-image" id="bg005"><div class="article-biography-image"><img src="https://ars.els-cdn.com/content/image/1-s2.0-S0925231220309838-fx1.jpg" height="155" alt=""></div><div class="article-biography-text"><div class="u-margin-s-bottom" id="sp0010">Jing Li received the B.E. degree in Electronic Information Engineering from Nanchang University, China, in 2005, and obtained her PhD degree in Electronic and Electrical Engineering from the University of Sheffield, UK, in 2011. From 2011 to 2012, she was a Research Associate with the Department of Computer Science at the University of Sheffield. Currently, she is an Associate Professor with the School of Information Engineering at Nanchang University. Her research interests include visual tracking, behavior recognition, and crowd scene analysis. She has authored or coauthored in various journals, such as IEEE Transactions on Industrial Informatics, IEEE Transactions on Image Processing, Information Sciences (Elsevier), etc.</div></div></div><div class="article-biography article-biography-has-image" id="bg010"><div class="article-biography-image"><img src="https://ars.els-cdn.com/content/image/1-s2.0-S0925231220309838-fx2.jpg" height="155" alt=""></div><div class="article-biography-text"><div class="u-margin-s-bottom" id="sp0015">Kan Jin received the B.E. degree in Mechatronic Engineering from Hubei Polytechnic University, China, in 2017. He is currently pursuing the M.S. degree in the School of Information Engineering at Nanchang University, China. His research interests include facial expression recognition and crowd counting.</div></div></div><div class="article-biography article-biography-has-image" id="bg015"><div class="article-biography-image"><img src="https://ars.els-cdn.com/content/image/1-s2.0-S0925231220309838-fx3.jpg" height="155" alt=""></div><div class="article-biography-text"><div class="u-margin-s-bottom" id="sp0020">Dalin Zhou received the B.S. degree in automation from the University of Science and Technology of China, Hefei, China, in 2012, the Ph.D. degree in computing from the University of Portsmouth, UK, in 2018 and is currently a Lecturer in Computer Science with the School of Computing, the University of Portsmouth, UK. His current research interests include signal processing, machine learning, computational intelligence, biomedical robotics and multimodal sensor fusion. His current research contributes to the monitoring and rehabilitation of limb motor function improving the daily life activity and working capability for both the disadvantaged group of limb-impaired patients and the aging community.</div></div></div><div class="article-biography article-biography-has-image" id="bg020"><div class="article-biography-image"><img src="https://ars.els-cdn.com/content/image/1-s2.0-S0925231220309838-fx4.jpg" height="155" alt=""></div><div class="article-biography-text"><div class="u-margin-s-bottom" id="sp0025">Naoyuki Kubota,<!-- -->&nbsp;<!-- -->Faculty of Systems Design, Tokyo Metropolitan University, Tokyo, Japan Naoyuki Kubota received the B.Sc. degree from Osaka Kyoiku University, Kashiwara, Japan, in 1992, the M.Eng. degree from Hokkaido University, Hokkaido, Japan, in 1994, and the D.E. degree from Nagoya University, Nagoya, Japan, in 1997. He joined the Osaka Institute of Technology, Osaka, Japan, in 1997. He joined the Department of Human and Artificial Intelligence Systems, University of Fukui, Fukui, Japan, as an Associate Professor in 2000. He joined the Department of Mechanical Engineering, Tokyo Metropolitan University, Tokyo, Japan, in 2004. He was an Associate Professor from 2005 to 2012, and has been a Professor since 2012 at the Department of System Design, Tokyo Metropolitan University.</div></div></div><div class="article-biography article-biography-has-image" id="bg025"><div class="article-biography-image"><img src="https://ars.els-cdn.com/content/image/1-s2.0-S0925231220309838-fx5.jpg" height="155" alt=""></div><div class="article-biography-text"><div class="u-margin-s-bottom" id="sp0030">Zhaojie Ju received the B.S. in automatic control and the M.S. in intelligent robotics both from Huazhong University of Science and Technology, China, and the Ph.D. degree in intelligent robotics at the University of Portsmouth, UK. He held a research appointment at the University College London, London, U.K., before he started his independent academic position at the University of Portsmouth, U.K., in 2012. His research interests include machine intelligence, pattern recognition, and their applications on human motion analysis, multi-fingered robotic hand control, human–robot interaction and collaboration, and robot skill learning. He has authored or co-authored over 180 publications in journals, book chapters, and conference proceedings and received four best paper awards and one Best AE Award in ICRA2018.</div></div></div><a class="anchor abstract-link anchor-primary" href="/science/article/abs/pii/S0925231220309838"><span class="anchor-text-container"><span class="anchor-text">View Abstract</span></span></a><div class="Copyright"><span class="copyright-line">© 2020 Elsevier B.V. All rights reserved.</span></div></article><div class="u-display-block-from-md col-lg-6 col-md-8 pad-right u-padding-s-top"><aside class="RelatedContent u-clr-grey8" aria-label="Related content"><section class="RelatedContentPanel u-margin-s-bottom"><header id="recommended-articles-header" class="related-content-panel-header u-margin-s-bottom"><button class="button-link button-link-secondary related-content-panel-toggle is-up button-link-icon-right button-link-has-colored-icon" aria-expanded="true" data-aa-button="sd:product:journal:article:location=recommended-articles:type=close" type="button"><span class="button-link-text-container"><span class="button-link-text"><h2 class="section-title u-h4"><span class="related-content-panel-title-text">Recommended articles</span></h2></span></span><svg focusable="false" viewBox="0 0 92 128" height="20" class="icon icon-navigate-down"><path d="M1 51l7-7 38 38 38-38 7 7-45 45z"></path></svg></button></header><div class="" aria-hidden="false" aria-describedby="recommended-articles-header"><div id="recommended-articles" class="text-xs"><ul><li class="RelatedContentPanelItem u-display-block"><div class="sub-heading u-padding-xs-bottom"><h3 class="related-content-panel-list-entry-outline-padding text-s u-font-serif" id="recommended-articles-article0-title"><a class="anchor u-clamp-2-lines anchor-primary" href="/science/article/pii/S0031320319301268" title="Deep multi-path convolutional neural network joint with salient region attention for facial expression recognition"><span class="anchor-text-container"><span class="anchor-text"><span>Deep multi-path convolutional neural network joint with salient region attention for facial expression recognition</span></span></span></a></h3><div class="article-source u-clr-grey6"><div class="source">Pattern Recognition, Volume 92, 2019, pp. 177-191</div></div><div class="authors"><span>Siyue</span> <span>Xie</span>, …, <span>Yongbo</span> <span>Wu</span></div></div><div class="buttons"><a class="anchor anchor-primary anchor-icon-left anchor-with-icon" href="/science/article/pii/S0031320319301268/pdfft?md5=08c0a5960ed9eb448d57b616913411eb&amp;pid=1-s2.0-S0031320319301268-main.pdf" target="_blank" rel="nofollow" aria-describedby="recommended-articles-article0-title"><svg focusable="false" viewBox="0 0 35 32" height="20" class="icon icon-pdf-multicolor"><path d="M7 .362h17.875l6.763 6.1V31.64H6.948V16z" stroke="#000" stroke-width=".703" fill="#fff"></path><path d="M.167 2.592H22.39V9.72H.166z" fill="#da0000"></path><path fill="#fff9f9" d="M5.97 3.638h1.62c1.053 0 1.483.677 1.488 1.564.008.96-.6 1.564-1.492 1.564h-.644v1.66h-.977V3.64m.977.897v1.34h.542c.27 0 .596-.068.596-.673-.002-.6-.32-.667-.596-.667h-.542m3.8.036v2.92h.35c.933 0 1.223-.448 1.228-1.462.008-1.06-.316-1.45-1.23-1.45h-.347m-.977-.94h1.03c1.68 0 2.523.586 2.534 2.39.01 1.688-.607 2.4-2.534 2.4h-1.03V3.64m4.305 0h2.63v.934h-1.657v.894H16.6V6.4h-1.56v2.026h-.97V3.638"></path><path d="M19.462 13.46c.348 4.274-6.59 16.72-8.508 15.792-1.82-.85 1.53-3.317 2.92-4.366-2.864.894-5.394 3.252-3.837 3.93 2.113.895 7.048-9.25 9.41-15.394zM14.32 24.874c4.767-1.526 14.735-2.974 15.152-1.407.824-3.157-13.72-.37-15.153 1.407zm5.28-5.043c2.31 3.237 9.816 7.498 9.788 3.82-.306 2.046-6.66-1.097-8.925-4.164-4.087-5.534-2.39-8.772-1.682-8.732.917.047 1.074 1.307.67 2.442-.173-1.406-.58-2.44-1.224-2.415-1.835.067-1.905 4.46 1.37 9.065z" fill="#f91d0a"></path></svg><span class="anchor-text-container"><span class="anchor-text">View PDF</span></span></a></div></li><li class="RelatedContentPanelItem u-display-block"><div class="sub-heading u-padding-xs-bottom"><h3 class="related-content-panel-list-entry-outline-padding text-s u-font-serif" id="recommended-articles-article1-title"><a class="anchor u-clamp-2-lines anchor-primary" href="/science/article/pii/S187705092031142X" title="Deep self-attention network for facial emotion recognition"><span class="anchor-text-container"><span class="anchor-text"><span>Deep self-attention network for facial emotion recognition</span></span></span></a></h3><div class="article-source u-clr-grey6"><div class="source">Procedia Computer Science, Volume 171, 2020, pp. 1527-1534</div></div><div class="authors"><span>Arpita</span> <span>Gupta</span>, …, <span>Ramadoss</span> <span>Balakrishnan</span></div></div><div class="buttons"><a class="anchor anchor-primary anchor-icon-left anchor-with-icon" href="/science/article/pii/S187705092031142X/pdf?md5=88d113e5c11f24f68d2b7b65bb08cc66&amp;pid=1-s2.0-S187705092031142X-main.pdf" target="_blank" rel="nofollow" aria-describedby="recommended-articles-article1-title"><svg focusable="false" viewBox="0 0 35 32" height="20" class="icon icon-pdf-multicolor"><path d="M7 .362h17.875l6.763 6.1V31.64H6.948V16z" stroke="#000" stroke-width=".703" fill="#fff"></path><path d="M.167 2.592H22.39V9.72H.166z" fill="#da0000"></path><path fill="#fff9f9" d="M5.97 3.638h1.62c1.053 0 1.483.677 1.488 1.564.008.96-.6 1.564-1.492 1.564h-.644v1.66h-.977V3.64m.977.897v1.34h.542c.27 0 .596-.068.596-.673-.002-.6-.32-.667-.596-.667h-.542m3.8.036v2.92h.35c.933 0 1.223-.448 1.228-1.462.008-1.06-.316-1.45-1.23-1.45h-.347m-.977-.94h1.03c1.68 0 2.523.586 2.534 2.39.01 1.688-.607 2.4-2.534 2.4h-1.03V3.64m4.305 0h2.63v.934h-1.657v.894H16.6V6.4h-1.56v2.026h-.97V3.638"></path><path d="M19.462 13.46c.348 4.274-6.59 16.72-8.508 15.792-1.82-.85 1.53-3.317 2.92-4.366-2.864.894-5.394 3.252-3.837 3.93 2.113.895 7.048-9.25 9.41-15.394zM14.32 24.874c4.767-1.526 14.735-2.974 15.152-1.407.824-3.157-13.72-.37-15.153 1.407zm5.28-5.043c2.31 3.237 9.816 7.498 9.788 3.82-.306 2.046-6.66-1.097-8.925-4.164-4.087-5.534-2.39-8.772-1.682-8.732.917.047 1.074 1.307.67 2.442-.173-1.406-.58-2.44-1.224-2.415-1.835.067-1.905 4.46 1.37 9.065z" fill="#f91d0a"></path></svg><span class="anchor-text-container"><span class="anchor-text">View PDF</span></span></a></div></li><li class="RelatedContentPanelItem u-display-block"><div class="sub-heading u-padding-xs-bottom"><h3 class="related-content-panel-list-entry-outline-padding text-s u-font-serif" id="recommended-articles-article2-title"><a class="anchor u-clamp-2-lines anchor-primary" href="/science/article/pii/S0167865517303902" title="Deep spatial-temporal feature fusion for facial expression recognition in static images"><span class="anchor-text-container"><span class="anchor-text"><span>Deep spatial-temporal feature fusion for facial expression recognition in static images</span></span></span></a></h3><div class="article-source u-clr-grey6"><div class="source">Pattern Recognition Letters, Volume 119, 2019, pp. 49-61</div></div><div class="authors"><span>Ning</span> <span>Sun</span>, …, <span>Guang</span> <span>Han</span></div></div><div class="buttons"><a class="anchor anchor-primary anchor-icon-left anchor-with-icon" href="/science/article/pii/S0167865517303902/pdfft?md5=7d06ffd4ab371ac33b9e8cd3a5e7d5b3&amp;pid=1-s2.0-S0167865517303902-main.pdf" target="_blank" rel="nofollow" aria-describedby="recommended-articles-article2-title"><svg focusable="false" viewBox="0 0 35 32" height="20" class="icon icon-pdf-multicolor"><path d="M7 .362h17.875l6.763 6.1V31.64H6.948V16z" stroke="#000" stroke-width=".703" fill="#fff"></path><path d="M.167 2.592H22.39V9.72H.166z" fill="#da0000"></path><path fill="#fff9f9" d="M5.97 3.638h1.62c1.053 0 1.483.677 1.488 1.564.008.96-.6 1.564-1.492 1.564h-.644v1.66h-.977V3.64m.977.897v1.34h.542c.27 0 .596-.068.596-.673-.002-.6-.32-.667-.596-.667h-.542m3.8.036v2.92h.35c.933 0 1.223-.448 1.228-1.462.008-1.06-.316-1.45-1.23-1.45h-.347m-.977-.94h1.03c1.68 0 2.523.586 2.534 2.39.01 1.688-.607 2.4-2.534 2.4h-1.03V3.64m4.305 0h2.63v.934h-1.657v.894H16.6V6.4h-1.56v2.026h-.97V3.638"></path><path d="M19.462 13.46c.348 4.274-6.59 16.72-8.508 15.792-1.82-.85 1.53-3.317 2.92-4.366-2.864.894-5.394 3.252-3.837 3.93 2.113.895 7.048-9.25 9.41-15.394zM14.32 24.874c4.767-1.526 14.735-2.974 15.152-1.407.824-3.157-13.72-.37-15.153 1.407zm5.28-5.043c2.31 3.237 9.816 7.498 9.788 3.82-.306 2.046-6.66-1.097-8.925-4.164-4.087-5.534-2.39-8.772-1.682-8.732.917.047 1.074 1.307.67 2.442-.173-1.406-.58-2.44-1.224-2.415-1.835.067-1.905 4.46 1.37 9.065z" fill="#f91d0a"></path></svg><span class="anchor-text-container"><span class="anchor-text">View PDF</span></span></a></div></li><li class="RelatedContentPanelItem u-display-none"><div class="sub-heading u-padding-xs-bottom"><h3 class="related-content-panel-list-entry-outline-padding text-s u-font-serif" id="recommended-articles-article3-title"><a class="anchor u-clamp-2-lines anchor-primary" href="/science/article/pii/S2214785320363835" title="A CNN based facial expression recognizer"><span class="anchor-text-container"><span class="anchor-text"><span>A CNN based facial expression recognizer</span></span></span></a></h3><div class="article-source u-clr-grey6"><div class="source">Materials Today: Proceedings, Volume 37, Part 2, 2021, pp. 2578-2581</div></div><div class="authors"><span>B. Sai Mani</span> <span>Teja</span>, …, <span>M.A.</span> <span>Berlin</span></div></div><div class="buttons"><a class="anchor anchor-primary anchor-icon-left anchor-with-icon" href="/science/article/pii/S2214785320363835/pdfft?md5=e1a550d6db8eeb2009f5f3d95f54d1e1&amp;pid=1-s2.0-S2214785320363835-main.pdf" target="_blank" rel="nofollow" aria-describedby="recommended-articles-article3-title"><svg focusable="false" viewBox="0 0 35 32" height="20" class="icon icon-pdf-multicolor"><path d="M7 .362h17.875l6.763 6.1V31.64H6.948V16z" stroke="#000" stroke-width=".703" fill="#fff"></path><path d="M.167 2.592H22.39V9.72H.166z" fill="#da0000"></path><path fill="#fff9f9" d="M5.97 3.638h1.62c1.053 0 1.483.677 1.488 1.564.008.96-.6 1.564-1.492 1.564h-.644v1.66h-.977V3.64m.977.897v1.34h.542c.27 0 .596-.068.596-.673-.002-.6-.32-.667-.596-.667h-.542m3.8.036v2.92h.35c.933 0 1.223-.448 1.228-1.462.008-1.06-.316-1.45-1.23-1.45h-.347m-.977-.94h1.03c1.68 0 2.523.586 2.534 2.39.01 1.688-.607 2.4-2.534 2.4h-1.03V3.64m4.305 0h2.63v.934h-1.657v.894H16.6V6.4h-1.56v2.026h-.97V3.638"></path><path d="M19.462 13.46c.348 4.274-6.59 16.72-8.508 15.792-1.82-.85 1.53-3.317 2.92-4.366-2.864.894-5.394 3.252-3.837 3.93 2.113.895 7.048-9.25 9.41-15.394zM14.32 24.874c4.767-1.526 14.735-2.974 15.152-1.407.824-3.157-13.72-.37-15.153 1.407zm5.28-5.043c2.31 3.237 9.816 7.498 9.788 3.82-.306 2.046-6.66-1.097-8.925-4.164-4.087-5.534-2.39-8.772-1.682-8.732.917.047 1.074 1.307.67 2.442-.173-1.406-.58-2.44-1.224-2.415-1.835.067-1.905 4.46 1.37 9.065z" fill="#f91d0a"></path></svg><span class="anchor-text-container"><span class="anchor-text">View PDF</span></span></a></div></li><li class="RelatedContentPanelItem u-display-none"><div class="sub-heading u-padding-xs-bottom"><h3 class="related-content-panel-list-entry-outline-padding text-s u-font-serif" id="recommended-articles-article4-title"><a class="anchor u-clamp-2-lines anchor-primary" href="/science/article/pii/S0167865521000489" title="Landmark guidance independent spatio-channel attention and complementary context information based facial expression recognition"><span class="anchor-text-container"><span class="anchor-text"><span>Landmark guidance independent spatio-channel attention and complementary context information based facial expression recognition</span></span></span></a></h3><div class="article-source u-clr-grey6"><div class="source">Pattern Recognition Letters, Volume 145, 2021, pp. 58-66</div></div><div class="authors"><span>Darshan</span> <span>Gera</span>, <span>S</span> <span>Balasubramanian</span></div></div><div class="buttons"><a class="anchor anchor-primary anchor-icon-left anchor-with-icon" href="/science/article/pii/S0167865521000489/pdfft?md5=4744a0def560a5dd8ab3d07f57599987&amp;pid=1-s2.0-S0167865521000489-main.pdf" target="_blank" rel="nofollow" aria-describedby="recommended-articles-article4-title"><svg focusable="false" viewBox="0 0 35 32" height="20" class="icon icon-pdf-multicolor"><path d="M7 .362h17.875l6.763 6.1V31.64H6.948V16z" stroke="#000" stroke-width=".703" fill="#fff"></path><path d="M.167 2.592H22.39V9.72H.166z" fill="#da0000"></path><path fill="#fff9f9" d="M5.97 3.638h1.62c1.053 0 1.483.677 1.488 1.564.008.96-.6 1.564-1.492 1.564h-.644v1.66h-.977V3.64m.977.897v1.34h.542c.27 0 .596-.068.596-.673-.002-.6-.32-.667-.596-.667h-.542m3.8.036v2.92h.35c.933 0 1.223-.448 1.228-1.462.008-1.06-.316-1.45-1.23-1.45h-.347m-.977-.94h1.03c1.68 0 2.523.586 2.534 2.39.01 1.688-.607 2.4-2.534 2.4h-1.03V3.64m4.305 0h2.63v.934h-1.657v.894H16.6V6.4h-1.56v2.026h-.97V3.638"></path><path d="M19.462 13.46c.348 4.274-6.59 16.72-8.508 15.792-1.82-.85 1.53-3.317 2.92-4.366-2.864.894-5.394 3.252-3.837 3.93 2.113.895 7.048-9.25 9.41-15.394zM14.32 24.874c4.767-1.526 14.735-2.974 15.152-1.407.824-3.157-13.72-.37-15.153 1.407zm5.28-5.043c2.31 3.237 9.816 7.498 9.788 3.82-.306 2.046-6.66-1.097-8.925-4.164-4.087-5.534-2.39-8.772-1.682-8.732.917.047 1.074 1.307.67 2.442-.173-1.406-.58-2.44-1.224-2.415-1.835.067-1.905 4.46 1.37 9.065z" fill="#f91d0a"></path></svg><span class="anchor-text-container"><span class="anchor-text">View PDF</span></span></a></div></li><li class="RelatedContentPanelItem u-display-none"><div class="sub-heading u-padding-xs-bottom"><h3 class="related-content-panel-list-entry-outline-padding text-s u-font-serif" id="recommended-articles-article5-title"><a class="anchor u-clamp-2-lines anchor-primary" href="/science/article/pii/S0167865519303769" title="Facial expression recognition based on deep convolution long short-term memory networks of double-channel weighted mixture"><span class="anchor-text-container"><span class="anchor-text"><span>Facial expression recognition based on deep convolution long short-term memory networks of double-channel weighted mixture</span></span></span></a></h3><div class="article-source u-clr-grey6"><div class="source">Pattern Recognition Letters, Volume 131, 2020, pp. 128-134</div></div><div class="authors"><span>Hepeng</span> <span>Zhang</span>, …, <span>Guohui</span> <span>Tian</span></div></div><div class="buttons"><a class="anchor anchor-primary anchor-icon-left anchor-with-icon" href="/science/article/pii/S0167865519303769/pdfft?md5=dfbd1ff583d9a9384418367512e35b57&amp;pid=1-s2.0-S0167865519303769-main.pdf" target="_blank" rel="nofollow" aria-describedby="recommended-articles-article5-title"><svg focusable="false" viewBox="0 0 35 32" height="20" class="icon icon-pdf-multicolor"><path d="M7 .362h17.875l6.763 6.1V31.64H6.948V16z" stroke="#000" stroke-width=".703" fill="#fff"></path><path d="M.167 2.592H22.39V9.72H.166z" fill="#da0000"></path><path fill="#fff9f9" d="M5.97 3.638h1.62c1.053 0 1.483.677 1.488 1.564.008.96-.6 1.564-1.492 1.564h-.644v1.66h-.977V3.64m.977.897v1.34h.542c.27 0 .596-.068.596-.673-.002-.6-.32-.667-.596-.667h-.542m3.8.036v2.92h.35c.933 0 1.223-.448 1.228-1.462.008-1.06-.316-1.45-1.23-1.45h-.347m-.977-.94h1.03c1.68 0 2.523.586 2.534 2.39.01 1.688-.607 2.4-2.534 2.4h-1.03V3.64m4.305 0h2.63v.934h-1.657v.894H16.6V6.4h-1.56v2.026h-.97V3.638"></path><path d="M19.462 13.46c.348 4.274-6.59 16.72-8.508 15.792-1.82-.85 1.53-3.317 2.92-4.366-2.864.894-5.394 3.252-3.837 3.93 2.113.895 7.048-9.25 9.41-15.394zM14.32 24.874c4.767-1.526 14.735-2.974 15.152-1.407.824-3.157-13.72-.37-15.153 1.407zm5.28-5.043c2.31 3.237 9.816 7.498 9.788 3.82-.306 2.046-6.66-1.097-8.925-4.164-4.087-5.534-2.39-8.772-1.682-8.732.917.047 1.074 1.307.67 2.442-.173-1.406-.58-2.44-1.224-2.415-1.835.067-1.905 4.46 1.37 9.065z" fill="#f91d0a"></path></svg><span class="anchor-text-container"><span class="anchor-text">View PDF</span></span></a></div></li></ul></div><button class="button-link more-recommendations-button u-margin-s-bottom button-link-primary button-link-icon-right" type="button"><span class="button-link-text-container"><span class="button-link-text">Show 3 more articles</span></span><svg focusable="false" viewBox="0 0 92 128" height="20" class="icon icon-navigate-down"><path d="M1 51l7-7 38 38 38-38 7 7-45 45z"></path></svg></button></div></section><section class="RelatedContentPanel u-margin-s-bottom"><header id="metrics-header" class="related-content-panel-header u-margin-s-bottom"><button class="button-link button-link-secondary related-content-panel-toggle is-up button-link-icon-right button-link-has-colored-icon" aria-expanded="true" type="button"><span class="button-link-text-container"><span class="button-link-text"><h2 class="section-title u-h4"><span class="related-content-panel-title-text">Article Metrics</span></h2></span></span><svg focusable="false" viewBox="0 0 92 128" height="20" class="icon icon-navigate-down"><path d="M1 51l7-7 38 38 38-38 7 7-45 45z"></path></svg></button></header><div class="" aria-hidden="false" aria-describedby="metrics-header"><div class="plum-sciencedirect-theme"><div class="PlumX-Summary"><div class="pps-container pps-container-vertical plx-no-print"><div class="pps-branding pps-branding-top"><img alt="plumX logo" src="//cdn.plu.mx/3ba727faf225e19d2c759f6ebffc511d/plumx-inverse-logo.png" class="plx-logo"></div><div class="pps-cols"><div class="pps-col plx-citation"><div class="plx-citation"><div class="pps-title">Citations</div><ul><li class="plx-citation"><span class="pps-label">Citation Indexes: </span><span class="pps-count">239</span></li></ul></div></div><div class="pps-col plx-capture"><div class="plx-capture"><div class="pps-title">Captures</div><ul><li class="plx-capture"><span class="pps-label">Readers: </span><span class="pps-count">198</span></li></ul></div></div></div><div><div class="pps-branding pps-branding-bottom"><img alt="plumX logo" src="//cdn.plu.mx/3ba727faf225e19d2c759f6ebffc511d/plumx-logo.png" class="plx-logo"></div><a target="_blank" href="https://plu.mx/plum/a/?doi=10.1016/j.neucom.2020.06.014&amp;theme=plum-sciencedirect-theme&amp;hideUsage=true" class="pps-seemore" title="PlumX Metrics Detail Page">View details<svg fill="currentColor" tabindex="-1" focusable="false" width="16" height="16" viewBox="0 0 16 16" class="svg-arrow"><path d="M16 4.452l-1.26-1.26L8 9.932l-6.74-6.74L0 4.452l8 8 8-8z"></path></svg></a></div></div></div></div></div></section></aside></div></div></div></div><footer role="contentinfo" class="els-footer u-bg-white text-xs u-padding-s-hor u-padding-m-hor-from-sm u-padding-l-hor-from-md u-padding-l-ver u-margin-l-top u-margin-xl-top-from-sm u-margin-l-top-from-md"><div class="els-footer-elsevier u-margin-m-bottom u-margin-0-bottom-from-md u-margin-s-right u-margin-m-right-from-md u-margin-l-right-from-lg"><a class="anchor anchor-primary anchor-icon-left anchor-with-icon" href="https://www.elsevier.com/" target="_blank" aria-label="Elsevier home page (opens in a new tab)" rel="nofollow"><img class="footer-logo" src="https://sdfestaticassets-eu-west-1.sciencedirectassets.com/shared-assets/47/images/elsevier-non-solus-new-with-wordmark.svg" alt="Elsevier logo with wordmark" height="64" width="58" loading="lazy"></a></div><div class="els-footer-content"><div class="u-remove-if-print"><ul class="els-footer-links u-margin-xs-bottom" style="list-style:none"><li><a class="anchor u-display-flex u-clr-grey8 u-margin-s-bottom u-margin-0-bottom-from-sm u-margin-m-right-from-sm u-margin-l-right-from-md anchor-primary anchor-small" href="https://www.elsevier.com/solutions/sciencedirect" target="_blank" id="els-footer-about-science-direct" rel="nofollow"><span class="anchor-text-container"><span class="anchor-text">About ScienceDirect</span><svg focusable="false" viewBox="0 0 8 8" height="20" aria-label="Opens in new window" class="icon icon-arrow-up-right-tiny arrow-external-link"><path d="M1.12949 2.1072V1H7V6.85795H5.89111V2.90281L0.784057 8L0 7.21635L5.11902 2.1072H1.12949Z"></path></svg></span></a></li><li><a class="anchor u-display-flex u-clr-grey8 u-margin-s-bottom u-margin-0-bottom-from-sm u-margin-m-right-from-sm u-margin-l-right-from-md anchor-primary anchor-small" href="/user/institution/login?targetURL=%2Fscience%2Farticle%2Fpii%2FS0925231220309838" id="els-footer-remote-access" rel="nofollow"><span class="anchor-text-container"><span class="anchor-text">Remote access</span></span></a></li><li><a class="anchor u-display-flex u-clr-grey8 u-margin-s-bottom u-margin-0-bottom-from-sm u-margin-m-right-from-sm u-margin-l-right-from-md anchor-primary anchor-small" href="https://sd-cart.elsevier.com/?" target="_blank" id="els-footer-shopping-cart" rel="nofollow"><span class="anchor-text-container"><span class="anchor-text">Shopping cart</span><svg focusable="false" viewBox="0 0 8 8" height="20" aria-label="Opens in new window" class="icon icon-arrow-up-right-tiny arrow-external-link"><path d="M1.12949 2.1072V1H7V6.85795H5.89111V2.90281L0.784057 8L0 7.21635L5.11902 2.1072H1.12949Z"></path></svg></span></a></li><li><a class="anchor u-display-flex u-clr-grey8 u-margin-s-bottom u-margin-0-bottom-from-sm u-margin-m-right-from-sm u-margin-l-right-from-md anchor-primary anchor-small" href="https://www.elsmediakits.com" target="_blank" id="els-footer-advertise" rel="nofollow"><span class="anchor-text-container"><span class="anchor-text">Advertise</span><svg focusable="false" viewBox="0 0 8 8" height="20" aria-label="Opens in new window" class="icon icon-arrow-up-right-tiny arrow-external-link"><path d="M1.12949 2.1072V1H7V6.85795H5.89111V2.90281L0.784057 8L0 7.21635L5.11902 2.1072H1.12949Z"></path></svg></span></a></li><li><a class="anchor u-display-flex u-clr-grey8 u-margin-s-bottom u-margin-0-bottom-from-sm u-margin-m-right-from-sm u-margin-l-right-from-md anchor-primary anchor-small" href="https://service.elsevier.com/ci/pta/login/redirect/contact/supporthub/sciencedirect/p_li/xyhJEXWoHAMsz8VQOu3h2LHHIekBL3hT38urfpOCxeAty3TF61ibE7vsQPaZh4C6srqm9MNOxus2v65ykDkikA4MoWWax9xsxmy7qS6Jhq1MDk8fC~ZGE1crT~IU0fB88KgH29YS658ka3vhWTqW3QsF38M7JrWC3EPvnlMgTGg39gl1xRqh4DNloSU9hGNUBWmK_Teu~5LuRZ6Al86jUzFxO7CiLa3WIvaVAP5f3g900Gfh5TZfq33GuKqA9hfimBRbW0fFzY3a21RwOu4PLrz0ZSWIczBuiylb5NC3rWc*" target="_blank" id="els-footer-contact-support" rel="nofollow"><span class="anchor-text-container"><span class="anchor-text">Contact and support</span><svg focusable="false" viewBox="0 0 8 8" height="20" aria-label="Opens in new window" class="icon icon-arrow-up-right-tiny arrow-external-link"><path d="M1.12949 2.1072V1H7V6.85795H5.89111V2.90281L0.784057 8L0 7.21635L5.11902 2.1072H1.12949Z"></path></svg></span></a></li><li><a class="anchor u-display-flex u-clr-grey8 u-margin-s-bottom u-margin-0-bottom-from-sm u-margin-m-right-from-sm u-margin-l-right-from-md anchor-primary anchor-small" href="https://www.elsevier.com/legal/elsevier-website-terms-and-conditions" target="_blank" id="els-footer-terms-condition" rel="nofollow"><span class="anchor-text-container"><span class="anchor-text">Terms and conditions</span><svg focusable="false" viewBox="0 0 8 8" height="20" aria-label="Opens in new window" class="icon icon-arrow-up-right-tiny arrow-external-link"><path d="M1.12949 2.1072V1H7V6.85795H5.89111V2.90281L0.784057 8L0 7.21635L5.11902 2.1072H1.12949Z"></path></svg></span></a></li><li><a class="anchor u-display-flex u-clr-grey8 u-margin-s-bottom u-margin-0-bottom-from-sm u-margin-m-right-from-sm u-margin-l-right-from-md anchor-primary anchor-small" href="https://www.elsevier.com/legal/privacy-policy" target="_blank" id="els-footer-privacy-policy" rel="nofollow"><span class="anchor-text-container"><span class="anchor-text">Privacy policy</span><svg focusable="false" viewBox="0 0 8 8" height="20" aria-label="Opens in new window" class="icon icon-arrow-up-right-tiny arrow-external-link"><path d="M1.12949 2.1072V1H7V6.85795H5.89111V2.90281L0.784057 8L0 7.21635L5.11902 2.1072H1.12949Z"></path></svg></span></a></li></ul></div><p id="els-footer-cookie-message" class="u-remove-if-print">Cookies are used by this site. <!-- --> <button class="button-link ot-sdk-show-settings cookie-btn button-link-primary button-link-small" id="ot-sdk-btn" type="button">Cookie Settings</button></p><p id="els-footer-copyright">All content on this site: Copyright © <!-- -->2024<!-- --> Elsevier B.V., its licensors, and contributors. All rights are reserved, including those for text and data mining, AI training, and similar technologies. For all open access content, the Creative Commons licensing terms apply.</p></div><div class="els-footer-relx u-margin-0-top u-margin-m-top-from-xs u-margin-0-top-from-md"><a class="anchor anchor-primary anchor-icon-left anchor-with-icon" href="https://www.relx.com/" target="_blank" aria-label="RELX home page (opens in a new tab)" id="els-footer-relx" rel="nofollow"><img loading="lazy" src="https://sdfestaticassets-eu-west-1.sciencedirectassets.com/shared-assets/60/images/logo-relx-tm.svg" width="93" height="20" alt="RELX group home page"></a></div></footer></div></div></div></div>
<div id="floating-ui-node" class="floating-ui-node" data-sd-ui-floating-ui="true"></div>
<script async="" src="https://assets.adobedtm.com/4a848ae9611a/032db4f73473/launch-a6263b31083f.min.js" type="text/javascript"></script>
<script type="text/javascript">
    window.pageData = {"content":[{"contentType":"JL","format":"MIME-XHTML","id":"sd:article:pii:S0925231220309838","type":"sd:article:JL:scope-full","detail":"sd:article:subtype:fla","publicationType":"journal","issn":"0925-2312","volumeNumber":"411","suppl":"C","provider":"elsevier","entitlementType":"package"}],"page":{"businessUnit":"ELS:RP:ST","language":"en","name":"product:journal:article","noTracking":"false","productAppVersion":"full-direct","productName":"SD","type":"CP-CA","environment":"prod","loadTimestamp":1728990728907,"loadTime":"","testId":"sd:qna-article-page:beta-test"},"visitor":{"accessType":"ae:REG_SHIBBOLETH","accountId":"ae:50401","accountName":"ae:IT University of Copenhagen","loginStatus":"logged in","userId":"ae:71970787","ipAddress":"77.165.246.201","appSessionId":"6465a12a-1939-4136-ac19-1d08b328e0a8"}};
    window.pageData.page.loadTime = performance ? Math.round(performance.now()).toString() : '';

    try {
      appData.push({
      event: 'pageLoad',
      page: pageData.page,
      visitor: pageData.visitor,
      content: pageData.content
      })
    } catch(e) {
        console.warn("There was an error loading or running Adobe DTM: ", e);
    }
</script>
<script nomodule="" src="https://sdfestaticassets-eu-west-1.sciencedirectassets.com/shared-assets/73/js/core-js/3.20.2/core-js.es.minified.js" type="text/javascript"></script>
<script src="https://sdfestaticassets-eu-west-1.sciencedirectassets.com/shared-assets/108/js/react/18.3.1/react.production.min.js" type="text/javascript"></script>
<script src="https://sdfestaticassets-eu-west-1.sciencedirectassets.com/shared-assets/108/js/react-dom/18.3.1/react-dom.production.min.js" type="text/javascript"></script>
<script async="" src="https://sdfestaticassets-eu-west-1.sciencedirectassets.com/prod/fe5f1a9a67d6a2bd1341815211e4a5a7e50a5117/arp.js" type="text/javascript"></script>
<script type="text/javascript">
    const pendoData = {"visitor":{"pageName":"SD:product:journal:article","pageType":"CP-CA","pageProduct":"SD","pageLanguage":"en","pageEnvironment":"prod","accessType":"ae:REG_SHIBBOLETH","countryCode":"NL"},"account":{"id":"ae:50401","name":"ae:IT University of Copenhagen"},"events":{}};;
    pendoData.events = {
      ready: function () {
        pendo.addAltText();
      },
    };
    function runPendo(data, options) {
  const {
    firstDelay,
    maxRetries,
    urlPrefix,
    urlSuffix,
    apiKey
  } = options;
  (function (apiKey) {
    (function (p, e, n, d, o) {
      var v, w, x, y, z;
      o = p[d] = p[d] || {};
      o._q = [];
      v = ['initialize', 'identify', 'updateOptions', 'pageLoad'];
      for (w = 0, x = v.length; w < x; ++w) (function (m) {
        o[m] = o[m] || function () {
          o._q[m === v[0] ? 'unshift' : 'push']([m].concat([].slice.call(arguments, 0)));
        };
      })(v[w]);
      y = e.createElement(n);
      y.async = !0;
      y.src = urlPrefix + apiKey + urlSuffix;
      z = e.getElementsByTagName(n)[0];
      z.parentNode.insertBefore(y, z);
    })(window, document, 'script', 'pendo');
    pendo.addAltText = function () {
      var target = document.querySelector('body');
      var observer = new MutationObserver(function (mutations) {
        mutations.forEach(function (mutation) {
          if (mutation?.addedNodes?.length) {
            if (mutation.addedNodes[0]?.className?.includes("_pendo-badge")) {
              const badge = mutation.addedNodes[0];
              const altText = badge?.attributes['aria-label'].value ? badge?.attributes['aria-label'].value : 'Feedback';
              const pendoBadgeImage = pendo.dom(`#${badge?.attributes?.id.value} img`);
              if (pendoBadgeImage.length) {
                pendoBadgeImage[0]?.setAttribute('alt', altText);
              }
            }
          }
        });
      });
      var config = {
        attributeFilter: ['data-layout'],
        attributes: true,
        childList: true,
        characterData: true,
        subtree: false
      };
      observer.observe(target, config);
    };
  })(apiKey);
  (function watchAndSetPendo(nextDelay, retryAttempt) {
    if (typeof pageDataTracker === 'object' && typeof pageDataTracker.getVisitorId === 'function' && pageDataTracker.getVisitorId()) {
      data.visitor.id = pageDataTracker.getVisitorId();
      console.debug(`initializing pendo`);
      pendo.initialize(data);
    } else {
      if (retryAttempt > 0) {
        return setTimeout(function () {
          watchAndSetPendo(nextDelay * 2, retryAttempt - 1);
        }, nextDelay);
      }
      pendo.initialize(data);
      console.debug(`gave up ... pendo initialized`);
    }
  })(firstDelay, maxRetries);
}
    runPendo(pendoData, {
      firstDelay: 100,
      maxRetries: 5,
      urlPrefix: 'https://cdn.pendo.io/agent/static/',
      urlSuffix: '/pendo.js',
      apiKey: 'd6c1d995-bc7e-4e53-77f1-2ea4ecbb9565',
    });
  </script>
<span id="pendo-answer-rating"></span>
<script type="text/x-mathjax-config;executed=true">
        MathJax.Hub.Config({
          displayAlign: 'left',
          "fast-preview": {
            disabled: true
          },
          CommonHTML: { linebreaks: { automatic: true } },
          PreviewHTML: { linebreaks: { automatic: true } },
          'HTML-CSS': { linebreaks: { automatic: true } },
          SVG: {
            scale: 90,
            linebreaks: { automatic: true }
          }
        });
      </script>
<script async="" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=MML_SVG" type="text/javascript"></script>
<script async="" src="https://www.googletagservices.com/tag/js/gpt.js" type="text/javascript"></script>
<script async="" src="https://scholar.google.com/scholar_js/casa.js" type="text/javascript"></script>
<script data-cfasync="false">
      (function initOneTrust()  {
        const monitor = {
  init: () => {},
  loaded: () => {},
};
        function enableGroup(group) {
  document.querySelectorAll(`script[type*="ot-${group}"]`).forEach(script => {
    script.type = 'text/javascript';
    document.head.appendChild(script);
  });
}
        function runOneTrustCookies(doClear, monitor) {
  const oneTrustConsentSdkId = 'onetrust-consent-sdk';
  const emptyNodeSelectors = 'h3.ot-host-name, h4.ot-host-desc, button.ot-host-box';
  const ariaLabelledByButtonNodes = 'div.ot-accordion-layout > button';
  const ariaAttribute = 'aria-labelledby';
  function adjustOneTrustDOM() {
    const oneTrustRoot = document.getElementById('onetrust-consent-sdk');

    /* remove empty nodes */
    [...(oneTrustRoot?.querySelectorAll(emptyNodeSelectors) ?? [])].filter(e => e.textContent === '').forEach(e => e.remove());

    /* remove invalid aria-labelledby values */
    oneTrustRoot?.querySelectorAll(ariaLabelledByButtonNodes).forEach(e => {
      const presentIdValue = e.getAttribute(ariaAttribute)?.split(' ').filter(label => document.getElementById(label)).join(' ');
      if (presentIdValue) {
        e.setAttribute(ariaAttribute, presentIdValue);
      }
    });
  }
  function observeOneTrustLoaded(shouldSetOTDefaults, isConsentPresent) {
    const cb = (mutationList, observer) => {
      const oneTrustRoot = mutationList.filter(mutationRecord => mutationRecord.type === 'childList' && mutationRecord.addedNodes.length).map(mutationRecord => [...mutationRecord.addedNodes]).flat().find(e => e.id === oneTrustConsentSdkId);
      if (oneTrustRoot && typeof OneTrust !== 'undefined') {
        monitor.loaded(true);
        OneTrust.OnConsentChanged(() => {
          const perfAllowed = decodeURIComponent(document.cookie.match('(^| )OptanonConsent=([^;]+)')?.[2])?.match('groups=([0-9:0|1,?]+)&?')?.[1]?.match('2:([0|1])')[1] === '1';
          if (perfAllowed) {
            enableGroup('performance');
          }
        });
        if (!isConsentPresent && (shouldSetOTDefaults || OneTrust.GetDomainData().ConsentModel.Name === 'implied consent')) {
          OneTrust.AllowAll();
        }
        document.dispatchEvent(new CustomEvent('@sdtech/onetrust/loaded', {}));
        observer.disconnect();
        adjustOneTrustDOM();
      }
    };
    const observer = new MutationObserver(cb);
    observer.observe(document.querySelector('body'), {
      childList: true
    });
  }
  if (doClear) {
    document.cookie = 'OptanonAlertBoxClosed=; expires=Thu, 01 Jan 1970 00:00:00 UTC; samesite=lax; path=/';
  }
  const isConsentPresent = !!decodeURIComponent(document.cookie.match('(^| )OptanonConsent=([^;]+)')?.[2])?.match('groups=([0-9:0|1,?]+)&?')?.[1];
  const shouldSetOTDefaults = 'false' === 'false' && !document.cookie?.match('OptanonAlertBoxClosed=');
  if (shouldSetOTDefaults) {
    const date = new Date();
    date.setFullYear(date.getFullYear() + 1);
    document.cookie = `OptanonAlertBoxClosed=${new Date().toISOString()}; expires=${date.toUTCString()}; samesite=lax; path=/; domain=sciencedirect.com`;
  }
  observeOneTrustLoaded(shouldSetOTDefaults, isConsentPresent, monitor);
  window.addOTScript = () => {
    const otSDK = document.createElement('script');
    otSDK.setAttribute('data-cfasync', 'false');
    otSDK.setAttribute('src', 'https://cdn.cookielaw.org/scripttemplates/otSDKStub.js');
    otSDK.setAttribute('data-document-language', 'true');
    otSDK.setAttribute('data-domain-script', '865ea198-88cc-4e41-8952-1df75d554d02');
    window.addOTScript = () => {};
    document.head.appendChild(otSDK);
    monitor.init();
  };
  window.addEventListener('load', () => window.addOTScript());
}
        if (document.location.host.match(/.sciencedirect.com$/)) {
          runOneTrustCookies(true, monitor);
        }
        else {
          window.addEventListener('load', (event) => {
            enableGroup('performance');
          });
        }
      }());
    </script>

<script>
var pageDataTracker = {
    eventCookieName: 'eventTrack',
    debugCookie: 'els-aa-debugmode',
    debugCounter: 1,
    warnings: [],
    measures: {},
    timeoffset: 0

    ,trackPageLoad: function(data) {
        if (window.pageData && ((pageData.page && pageData.page.noTracking == 'true') || window.pageData_isLoaded)) {
            return false;
        }

        this.updatePageData(data);

        this.initWarnings();
        if(!(window.pageData && pageData.page && pageData.page.name)) {
            console.error('pageDataTracker.trackPageLoad() called without pageData.page.name being defined!');
            return;
        }

        this.processIdPlusData(window.pageData);

        if(window.pageData && pageData.page && !pageData.page.loadTime) {
          pageData.page.loadTime = performance ? Math.round((performance.now())).toString() : '';
        }

        if(window.pageData && pageData.page) {
            var localTime = new Date().getTime();
            if(pageData.page.loadTimestamp) {
                // calculate timeoffset
                var serverTime = parseInt(pageData.page.loadTimestamp);
                if(!isNaN(serverTime)) {
                    this.timeoffset = pageData.page.loadTimestamp - localTime;
                }
            } else {
                pageData.page.loadTimestamp = localTime;
            }
        }

        this.validateData(window.pageData);

        try {
            var cookieTest = 'aa-cookie-test';
            this.setCookie(cookieTest, cookieTest);
            if(this.getCookie(cookieTest) != cookieTest) {
                this.warnings.push('dtm5');
            }
            this.deleteCookie(cookieTest);
        } catch(e){
            this.warnings.push('dtm5');
        }

        this.registerCallbacks();
        this.setAnalyticsData();

        // handle any cookied event data
        this.getEvents();

        window.pageData_isLoaded = true;

        this.debugMessage('Init - trackPageLoad()', window.pageData);

        _satellite.track('eventDispatcher', JSON.stringify({
          eventName: 'newPage',
          eventData: {eventName: 'newPage'},
          pageData: window.pageData
        }));
    }

    ,trackEvent: function(event, data, callback) {
        if (window.pageData && pageData.page && pageData.page.noTracking == 'true') {
            return false;
        }
        
        if(!window.pageData_isLoaded) {
            if(this.isDebugEnabled()) {
                console.log('[AA] pageDataTracker.trackEvent() called without calling trackPageLoad() first.');
            }
            return false;
        }

        if (event) {
            this.initWarnings();
            if(event === 'newPage') {
                // auto fillings
                if(data && data.page && !data.page.loadTimestamp) {
                    data.page.loadTimestamp = ''+(new Date().getTime() + this.timeoffset);
                }
                this.processIdPlusData(data);
            }

            window.eventData = data ? data : {};
            window.eventData.eventName = event;
            if(!_satellite.getVar('blacklisted')) {
                this.handleEventData(event, data);
    
                if(event === 'newPage') {
                    this.validateData(window.pageData);
                }
                this.debugMessage('Event: ' + event, data);
    
                _satellite.track('eventDispatcher', JSON.stringify({
                  eventName: event,
                  eventData: window.eventData,
                  pageData: window.pageData
                }));
            } else {
                this.debugMessage('!! Blocked Event: ' + event, data);
            }
        }

        if (typeof(callback) == 'function') {
            callback.call();
        }
    }

    ,processIdPlusData: function(data) {
        if(data && data.visitor && data.visitor.idPlusData) {
            var idPlusFields = ['userId', 'accessType', 'accountId', 'accountName'];
            for(var i=0; i < idPlusFields.length; i++) {
                if(typeof data.visitor.idPlusData[idPlusFields[i]] !== 'undefined') {
                    data.visitor[idPlusFields[i]] = data.visitor.idPlusData[idPlusFields[i]];
                }
            }
            data.visitor.idPlusData = undefined;
        }
    }

    ,validateData: function(data) {
        if(!data) {
            this.warnings.push('dv0');
            return;
        }

        // top 5
        if(!(data.visitor && data.visitor.accessType)) {
            this.warnings.push('dv1');
        }
        if(data.visitor && (data.visitor.accountId || data.visitor.accountName)) {
            if(!data.visitor.accountName) {
                this.warnings.push('dv2');
            }
            if(!data.visitor.accountId) {
                this.warnings.push('dv3');
            }
        }
        if(!(data.page && data.page.productName)) {
            this.warnings.push('dv4');
        }
        if(!(data.page && data.page.businessUnit)) {
            this.warnings.push('dv5');
        }
        if(!(data.page && data.page.name)) {
            this.warnings.push('dv6');
        }

        // rp mandatory
        if(data.page && data.page.businessUnit && (data.page.businessUnit.toLowerCase().indexOf('els:rp:') !== -1 || data.page.businessUnit.toLowerCase().indexOf('els:rap:') !== -1)) {
            if(!(data.page && data.page.loadTimestamp)) {
                this.warnings.push('dv7');
            }
            if(!(data.page && data.page.loadTime)) {
                this.warnings.push('dv8');
            }
            if(!(data.visitor && data.visitor.ipAddress)) {
                this.warnings.push('dv9');
            }
            if(!(data.page && data.page.type)) {
                this.warnings.push('dv10');
            }
            if(!(data.page && data.page.language)) {
                this.warnings.push('dv11');
            }
        }

        // other
        if(data.page && data.page.environment) {
            var env = data.page.environment.toLowerCase();
            if(!(env === 'dev' || env === 'cert' || env === 'prod')) {
                this.warnings.push('dv12');
            }
        }
        if(data.content && data.content.constructor !== Array) {
            this.warnings.push('dv13');
        }

        if(data.visitor && data.visitor.accountId && data.visitor.accountId.indexOf(':') == -1) {
            this.warnings.push('dv14');
            data.visitor.accountId = "data violation"
        }
    }

    ,initWarnings: function() {
        this.warnings = [];
        try {
            var hdn = document.head.childNodes;
            var libf = false;
            for(var i=0; i<hdn.length; i++) {
                if(hdn[i].src && (hdn[i].src.indexOf('satelliteLib') !== -1 || hdn[i].src.indexOf('launch') !== -1)) {
                    libf = true;
                    break;
                }
            }
            if(!libf) {
                this.warnings.push('dtm1');
            }
        } catch(e) {}

        try {
            for (let element of document.querySelectorAll('*')) {
                // Check if the element has a src attribute and if it meets the criteria
                if (element.src && element.src.includes('assets.adobedtm.com') && element.src.includes('launch')) {
                    if (element.tagName.toLowerCase() !== 'script') {
                        this.warnings.push('dtm5');
                    }
                    if (!element.hasAttribute('async')) {
                        this.warnings.push('dtm4');
                    }
                }
            }
        } catch (e) { }
    }

    ,getMessages: function() {
        return ['v1'].concat(this.warnings).join('|');
    }
    ,addMessage: function(message) {
        this.warnings.push(message);
    }

    ,getPerformance: function() {
        var copy = {};
        for (var attr in this.measures) {
            if(this.measures.hasOwnProperty(attr)) {
                copy[attr] = this.measures[attr];
            }
        }

        this.measures = {};
        return copy;
    }

    ,dtmCodeDesc: {
        dtm1: 'satellite-lib must be placed in the <head> section',
        dtm2: 'trackPageLoad() must be placed and called before the closing </body> tag',
        dtm3: 'trackEvent() must be called at a stage where Document.readyState=complete (e.g. on the load event or a user event)',
        dtm4: 'Embed codes need to be loaded in async mode',
        dtm5: 'Embed codes not in type script',
        dv1: 'visitor.accessType not set but mandatory',
        dv2: 'visitor.accountName not set but mandatory',
        dv3: 'visitor.accountId not set but mandatory',
        dv4: 'page.productName not set but mandatory',
        dv5: 'page.businessUnit not set but mandatory',
        dv6: 'page.name not set but mandatory',
        dv7: 'page.loadTimestamp not set but mandatory',
        dv8: 'page.loadTime not set but mandatory',
        dv9: 'visitor.ipAddress not set but mandatory',
        dv10: 'page.type not set but mandatory',
        dv11: 'page.language not set but mandatory',
        dv12: 'page.environment must be set to \'prod\', \'cert\' or \'dev\'',
        dv13: 'content must be of type array of objects',
        dv14: 'account number must contain at least one \':\', e.g. \'ae:12345\''
    }

    ,debugMessage: function(event, data) {
        if(this.isDebugEnabled()) {
            console.log('[AA] --------- [' + (this.debugCounter++) + '] Web Analytics Data ---------');
            console.log('[AA] ' + event);
            console.groupCollapsed("[AA] AA Data: ");
            if(window.eventData) {
                console.log("[AA] eventData:\n" + JSON.stringify(window.eventData, true, 2));
            }
            if(window.pageData) {
                console.log("[AA] pageData:\n" + JSON.stringify(window.pageData, true, 2));
            }
            console.groupEnd();
            if(this.warnings.length > 0) {
                console.groupCollapsed("[AA] Warnings ("+this.warnings.length+"): ");
                for(var i=0; i<this.warnings.length; i++) {
                    var error = this.dtmCodeDesc[this.warnings[i]] ? this.dtmCodeDesc[this.warnings[i]] : 'Error Code: ' + this.warnings[i];
                    console.log('[AA] ' + error);
                }
                console.log('[AA] More can be found here: https://confluence.cbsels.com/display/AA/AA+Error+Catalog');
                console.groupEnd();
            }
            console.log("This mode can be disabled by calling 'pageDataTracker.disableDebug()'");
        }
    }

    ,getTrackingCode: function() {
      var campaign = _satellite.getVar('Campaign - ID');
      if(!campaign) {
        campaign = window.sessionStorage ? sessionStorage.getItem('dgcid') : '';
      }
      return campaign;
    }

    ,isDebugEnabled: function() {
        if(typeof this.debug === 'undefined') {
            this.debug = (document.cookie.indexOf(this.debugCookie) !== -1) || (window.pageData && pageData.page && pageData.page.environment && pageData.page.environment.toLowerCase() === 'dev');
            //this.debug = (document.cookie.indexOf(this.debugCookie) !== -1);
        }
        return this.debug;
    }

    ,enableDebug: function(expire) {
        if (typeof expire === 'undefined') {
            expire = 86400;
        }
        console.log('You just enabled debug mode for Adobe Analytics tracking. This mode will persist for 24h.');
        console.log("This mode can be disabled by calling 'pageDataTracker.disableDebug()'");
        this.setCookie(this.debugCookie, 'true', expire, document.location.hostname);
        this.debug = true;
    }

    ,disableDebug: function() {
        console.log('Debug mode is now disabled.');
        this.deleteCookie(this.debugCookie);
        this.debug = false;
    }

    ,setAnalyticsData: function() {
        if(!(window.pageData && pageData.page && pageData.page.productName && pageData.page.name)) {
            return;
        }
        pageData.page.analyticsPagename = pageData.page.productName + ':' + pageData.page.name;

        var pageEls = pageData.page.name.indexOf(':') > -1 ? pageData.page.name.split(':') : [pageData.page.name];
        pageData.page.sectionName = pageData.page.productName + ':' + pageEls[0];
    }

    ,getEvents: function() {
        pageData.savedEvents = {};
        pageData.eventList = [];

        var val = this.getCookie(this.eventCookieName);
        if (val) {
            pageData.savedEvents = val;
        }

        this.deleteCookie(this.eventCookieName);
    }

    ,updatePageData(data) {
        window.pageData = window.pageData || {};
        if (data && typeof(data) === 'object') {
            for (var x in data) {
                if(data.hasOwnProperty(x) && data[x] instanceof Array) {
                    pageData[x] = data[x];
                } else if(data.hasOwnProperty(x) && typeof(data[x]) === 'object') {
                    if(!pageData[x]) {
                        pageData[x] = {};
                    }
                    for (var y in data[x]) {
                        if(data[x].hasOwnProperty(y)) {
                            pageData[x][y] = data[x][y];
                        }
                    }
                }
            }
        }
    }

    ,handleEventData: function(event, data) {
        var val;
        switch(event) {
            case 'newPage':
                this.updatePageData(data);
                this.setAnalyticsData();
            case 'saveSearch':
            case 'searchResultsUpdated':
                if (data) {
                    // overwrite page-load object
                    if (data.search && typeof(data.search) == 'object') {
                        window.eventData.search.resultsPosition = '';
                        pageData.search = pageData.search || {};
                        var fields = ['advancedCriteria', 'criteria', 'currentPage', 'dataFormCriteria', 'facets', 'resultsByType', 'resultsPerPage', 'sortType', 'totalResults', 'type', 'database',
                        'suggestedClickPosition','suggestedLetterCount','suggestedResultCount', 'autoSuggestCategory', 'autoSuggestDetails','typedTerm','selectedTerm', 'channel',
                        'facetOperation', 'details'];
                        for (var i=0; i<fields.length; i++) {
                            if (data.search[fields[i]]) {
                                pageData.search[fields[i]] = data.search[fields[i]];
                            }
                        }
                    }
                }
                this.setAnalyticsData();
                break;
            case 'navigationClick':
                if (data && data.link) {
                    window.eventData.navigationLink = {
                        name: ((data.link.location || 'no location') + ':' + (data.link.name || 'no name'))
                    };
                }
                break;
            case 'autoSuggestClick':
                if (data && data.search) {
                    val = {
                        autoSuggestSearchData: (
                            'letterct:' + (data.search.suggestedLetterCount || 'none') +
                            '|resultct:' + (data.search.suggestedResultCount || 'none') +
                            '|clickpos:' + (data.search.suggestedClickPosition || 'none')
                        ).toLowerCase(),
                        autoSuggestSearchTerm: (data.search.typedTerm || ''),
                        autoSuggestTypedTerm: (data.search.typedTerm || ''),
                        autoSuggestSelectedTerm: (data.search.selectedTerm || ''),
                        autoSuggestCategory: (data.search.autoSuggestCategory || ''),
                        autoSuggestDetails: (data.search.autoSuggestDetails || '')
                    };
                }
                break;
            case 'linkOut':
                if (data && data.content && data.content.length > 0) {
                    window.eventData.linkOut = data.content[0].linkOut;
                    window.eventData.referringProduct = _satellite.getVar('Page - Product Name') + ':' + data.content[0].id;
                }
                break;
            case 'socialShare':
                if (data && data.social) {
                    window.eventData.sharePlatform = data.social.sharePlatform || '';
                }
                break;
            case 'contentInteraction':
                if (data && data.action) {
                    window.eventData.action.name = pageData.page.productName + ':' + data.action.name;
                }
                break;
            case 'searchWithinContent':
                if (data && data.search) {
                    window.pageData.search = window.pageData.search || {};
                    pageData.search.withinContentCriteria = data.search.withinContentCriteria;
                }
                break;
            case 'contentShare':
                if (data && data.content) {
                    window.eventData.sharePlatform = data.content[0].sharePlatform;
                }
                break;
            case 'contentLinkClick':
                if (data && data.link) {
                    window.eventData.action = { name: pageData.page.productName + ':' + (data.link.type || 'no link type') + ':' + (data.link.name || 'no link name') };
                }
                break;
            case 'contentWindowLoad':
            case 'contentTabClick':
                if (data && data.content) {
                    window.eventData.tabName = data.content[0].tabName || '';
                    window.eventData.windowName = data.content[0].windowName || '';
                }
                break;
            case 'userProfileUpdate':
                if (data && data.user) {
                    if (Object.prototype.toString.call(data.user) === "[object Array]") {
                        window.eventData.user = data.user[0];
                    }
                }
                break;
            case 'videoStart':
                if (data.video) {
                    data.video.length = parseFloat(data.video.length || '0');
                    data.video.position = parseFloat(data.video.position || '0');
                    s.Media.open(data.video.id, data.video.length, s.Media.playerName);
                    s.Media.play(data.video.id, data.video.position);
                }
                break;
            case 'videoPlay':
                if (data.video) {
                    data.video.position = parseFloat(data.video.position || '0');
                    s.Media.play(data.video.id, data.video.position);
                }
                break;
            case 'videoStop':
                if (data.video) {
                    data.video.position = parseFloat(data.video.position || '0');
                    s.Media.stop(data.video.id, data.video.position);
                }
                break;
            case 'videoComplete':
                if (data.video) {
                    data.video.position = parseFloat(data.video.position || '0');
                    s.Media.stop(data.video.id, data.video.position);
                    s.Media.close(data.video.id);
                }
                break;
            case 'addWebsiteExtension':
                if(data && data.page) {
                    val = {
                        wx: data.page.websiteExtension
                    }
                }
                break;
        }

        if (val) {
            this.setCookie(this.eventCookieName, val);
        }
    }

    ,registerCallbacks: function() {
        var self = this;
        if(window.usabilla_live) {
            window.usabilla_live('setEventCallback', function(category, action, label, value) {
                if(action == 'Campaign:Open') {
                    self.trackEvent('ctaImpression', {
                        cta: {
                            ids: ['usabillaid:' + label]
                        }
                    });
                } else if(action == 'Campaign:Success') {
                    self.trackEvent('ctaClick', {
                        cta: {
                            ids: ['usabillaid:' + label]
                        }
                    });
                }
            });
        }
    }

    ,getConsortiumAccountId: function() {
        var id = '';
        if (window.pageData && pageData.visitor && (pageData.visitor.consortiumId || pageData.visitor.accountId)) {
            id = (pageData.visitor.consortiumId || 'no consortium ID') + '|' + (pageData.visitor.accountId || 'no account ID');
        }

        return id;
    }

    ,getSearchClickPosition: function() {
        if (window.eventData && eventData.search && eventData.search.resultsPosition) {
            var pos = parseInt(eventData.search.resultsPosition), clickPos;
            if (!isNaN(pos)) {
                var page = pageData.search.currentPage ? parseInt(pageData.search.currentPage) : '', perPage = pageData.search.resultsPerPage ? parseInt(pageData.search.resultsPerPage) : '';
                if (!isNaN(page) && !isNaN(perPage)) {
                    clickPos = pos + ((page - 1) * perPage);
                }
            }
            return clickPos ? clickPos.toString() : eventData.search.resultsPosition;
        }
        return '';
    }

    ,getSearchFacets: function() {
        var facetList = '';
        if (window.pageData && pageData.search && pageData.search.facets) {
            if (typeof(pageData.search.facets) == 'object') {
                for (var i=0; i<pageData.search.facets.length; i++) {
                    var f = pageData.search.facets[i];
                    facetList += (facetList ? '|' : '') + f.name + '=' + f.values.join('^');
                }
            }
        }
        return facetList;
    }

    ,getSearchResultsByType: function() {
        var resultTypes = '';
        if (window.pageData && pageData.search && pageData.search.resultsByType) {
            for (var i=0; i<pageData.search.resultsByType.length; i++) {
                var r = pageData.search.resultsByType[i];
                resultTypes += (resultTypes ? '|' : '') + r.name + (r.results || r.values ? '=' + (r.results || r.values) : '');
            }
        }
        return resultTypes;
    }

    ,getJournalInfo: function() {
        var info = '';
        if (window.pageData && pageData.journal && (pageData.journal.name || pageData.journal.specialty || pageData.journal.section || pageData.journal.issn || pageData.journal.issueNumber || pageData.journal.volumeNumber || pageData.journal.family || pageData.journal.publisher)) {
            var journal = pageData.journal;
            info = (journal.name || 'no name') 
            + '|' + (journal.specialty || 'no specialty') 
            + '|' + (journal.section || 'no section') 
            + '|' + (journal.issn || 'no issn') 
            + '|' + (journal.issueNumber || 'no issue #') 
            + '|' + (journal.volumeNumber || 'no volume #')
            + '|' + (journal.family || 'no family')
            + '|' + (journal.publisher || 'no publisher');

        }
        return info;
    }

    ,getBibliographicInfo: function(doc) {
        if (!doc || !(doc.publisher || doc.indexTerms || doc.publicationType || doc.publicationRights || doc.volumeNumber || doc.issueNumber || doc.subjectAreas || doc.isbn)) {
            return '';
        }

        var terms = doc.indexTerms ? doc.indexTerms.split('+') : '';
        if (terms) {
            terms = terms.slice(0, 5).join('+');
            terms = terms.length > 100 ? terms.substring(0, 100) : terms;
        }

        var areas = doc.subjectAreas ? doc.subjectAreas.split('>') : '';
        if (areas) {
            areas = areas.slice(0, 5).join('>');
            areas = areas.length > 100 ? areas.substring(0, 100) : areas;
        }

        var biblio	= (doc.publisher || 'none')
            + '^' + (doc.publicationType || 'none')
            + '^' + (doc.publicationRights || 'none')
            + '^' + (terms || 'none')
            + '^' + (doc.volumeNumber || 'none')
            + '^' + (doc.issueNumber || 'none')
            + '^' + (areas || 'none')
            + '^' + (doc.isbn || 'none');

        return this.stripProductDelimiters(biblio).toLowerCase();
    }

    ,getContentItem: function() {
        var docs = window.eventData && eventData.content ? eventData.content : pageData.content;
        if (docs && docs.length > 0) {
            return docs[0];
        }
    }

    ,getFormattedDate: function(ts) {
        if (!ts) {
            return '';
        }

        var d = new Date(parseInt(ts) * 1000);

        // now do formatting
        var year = d.getFullYear()
            ,month = ((d.getMonth() + 1) < 10 ? '0' : '') + (d.getMonth() + 1)
            ,date = (d.getDate() < 10 ? '0' : '') + d.getDate()
            ,hours = d.getHours() > 12 ? d.getHours() - 12 : d.getHours()
            ,mins = (d.getMinutes() < 10 ? '0' : '') + d.getMinutes()
            ,ampm = d.getHours() > 12 ? 'pm' : 'am';

        hours = (hours < 10 ? '0' : '') + hours;
        return year + '-' + month + '-' + date;
    }

    ,getVisitorId: function() {
        var orgId = '4D6368F454EC41940A4C98A6@AdobeOrg';
        if(Visitor && Visitor.getInstance(orgId)) {
            return Visitor.getInstance(orgId).getMarketingCloudVisitorID();
        } else {
            return ''
        }
    }

    ,setProductsVariable: function() {
        var prodList = window.eventData && eventData.content ? eventData.content : pageData.content
            ,prods = [];
        if (prodList) {
            for (var i=0; i<prodList.length; i++) {
                if (prodList[i].id || prodList[i].type || prodList[i].publishDate || prodList[i].onlineDate) {
                    if (!prodList[i].id) {
                        prodList[i].id = 'no id';
                    }
                    var prodName = (pageData.page.productName || 'xx').toLowerCase();
                    if (prodList[i].id.indexOf(prodName + ':') != 0) {
                        prodList[i].id = prodName + ':' + prodList[i].id;
                    }
                    prodList[i].id = this.stripProductDelimiters(prodList[i].id);
                    var merch = [];
                    if (prodList[i].format) {
                        merch.push('evar17=' + this.stripProductDelimiters(prodList[i].format.toLowerCase()));
                    }
                    if (prodList[i].type) {
                        var type = prodList[i].type;
                        if (prodList[i].accessType) {
                            type += ':' + prodList[i].accessType;
                        }
                        merch.push('evar20=' + this.stripProductDelimiters(type.toLowerCase()));

                        if(type.indexOf(':manuscript') > 0) {
                            /*
                            var regex = /[a-z]+:manuscript:id:([a-z]+-[a-z]-[0-9]+-[0-9]+)/gmi;
                            var m = regex.exec(prodList[i].id);
                            if(m) {
                                merch.push('evar200=' + m[1]);
                            }
                            merch.push('evar200=' + prodList[i].id);
                            */
                            a = prodList[i].id.lastIndexOf(':');
                            if(a>0) {
                                merch.push('evar200=' + prodList[i].id.substring(a+1).toUpperCase());
                            }
                        } else if(type.indexOf(':submission') > 0) {
                            merch.push('evar200=' + prodList[i].id);
                        }
                    }
                    if(!prodList[i].title) {
                        prodList[i].title = prodList[i].name;
                    }
                    if (prodList[i].title) {
                        merch.push('evar75=' + this.stripProductDelimiters(prodList[i].title.toLowerCase()));
                    }
                    if (prodList[i].breadcrumb) {
                        merch.push('evar63=' + this.stripProductDelimiters(prodList[i].breadcrumb).toLowerCase());
                    }
                    var nowTs = new Date().getTime()/1000;
                    if (prodList[i].onlineDate && !isNaN(prodList[i].onlineDate)) {
                        if(prodList[i].onlineDate > 32503680000) {
                            prodList[i].onlineDate = prodList[i].onlineDate/1000;
                        }
                        merch.push('evar122=' + this.stripProductDelimiters(pageDataTracker.getFormattedDate(prodList[i].onlineDate)));
                        var onlineAge = Math.floor((nowTs - prodList[i].onlineDate) / 86400);
                        onlineAge = (onlineAge === 0) ? 'zero' : onlineAge;
                        merch.push('evar128=' + onlineAge);
                    }
                    if (prodList[i].publishDate && !isNaN(prodList[i].publishDate)) {
                        if(prodList[i].publishDate > 32503680000) {
                            prodList[i].publishDate = prodList[i].publishDate/1000;
                        }
                        merch.push('evar123=' + this.stripProductDelimiters(pageDataTracker.getFormattedDate(prodList[i].publishDate)));
                        var publishAge = Math.floor((nowTs - prodList[i].publishDate) / 86400);
                        publishAge = (publishAge === 0) ? 'zero' : publishAge;
                        merch.push('evar127=' + publishAge);
                    }
                    if (prodList[i].onlineDate && prodList[i].publishDate) {
                        merch.push('evar38=' + this.stripProductDelimiters(pageDataTracker.getFormattedDate(prodList[i].onlineDate) + '^' + pageDataTracker.getFormattedDate(prodList[i].publishDate)));
                    }
                    if (prodList[i].mapId) {
                        merch.push('evar70=' + this.stripProductDelimiters(prodList[i].mapId));
                    }
					if (prodList[i].relevancyScore) {
						merch.push('evar71=' + this.stripProductDelimiters(prodList[i].relevancyScore));
					}
                    if (prodList[i].status) {
                        merch.push('evar73=' + this.stripProductDelimiters(prodList[i].status));
                    }
                    if (prodList[i].previousStatus) {
                        merch.push('evar111=' + this.stripProductDelimiters(prodList[i].previousStatus));
                    }
                    if (prodList[i].entitlementType) {
                        merch.push('evar80=' + this.stripProductDelimiters(prodList[i].entitlementType));
                    }
                    if (prodList[i].recordType) {
                        merch.push('evar93=' + this.stripProductDelimiters(prodList[i].recordType));
                    }
                    if (prodList[i].exportType) {
                        merch.push('evar99=' + this.stripProductDelimiters(prodList[i].exportType));
                    }
                    if (prodList[i].importType) {
                        merch.push('evar142=' + this.stripProductDelimiters(prodList[i].importType));
                    }
                    if (prodList[i].section) {
                        merch.push('evar100=' + this.stripProductDelimiters(prodList[i].section));
                    }
                    if (prodList[i].detail) {
                        merch.push('evar104=' + this.stripProductDelimiters(prodList[i].detail.toLowerCase()));
                    } else if(prodList[i].details) {
                        merch.push('evar104=' + this.stripProductDelimiters(prodList[i].details.toLowerCase()));
                    }
                    if (prodList[i].position) {
                        merch.push('evar116=' + this.stripProductDelimiters(prodList[i].position));
                    }
                    if (prodList[i].publicationTitle) {
                        merch.push('evar129=' + this.stripProductDelimiters(prodList[i].publicationTitle));
                    }
                    if (prodList[i].specialIssueTitle) {
                        merch.push('evar130=' + this.stripProductDelimiters(prodList[i].specialIssueTitle));
                    }
                    if (prodList[i].specialIssueNumber) {
                        merch.push('evar131=' + this.stripProductDelimiters(prodList[i].specialIssueNumber));
                    }
                    if (prodList[i].referenceModuleTitle) {
                        merch.push('evar139=' + this.stripProductDelimiters(prodList[i].referenceModuleTitle));
                    }
                    if (prodList[i].referenceModuleISBN) {
                        merch.push('evar140=' + this.stripProductDelimiters(prodList[i].referenceModuleISBN));
                    }
                    if (prodList[i].volumeTitle) {
                        merch.push('evar132=' + this.stripProductDelimiters(prodList[i].volumeTitle));
                    }
                    if (prodList[i].publicationSection) {
                        merch.push('evar133=' + this.stripProductDelimiters(prodList[i].publicationSection));
                    }
                    if (prodList[i].publicationSpecialty) {
                        merch.push('evar134=' + this.stripProductDelimiters(prodList[i].publicationSpecialty));
                    }
                    if (prodList[i].issn) {
                        merch.push('evar135=' + this.stripProductDelimiters(prodList[i].issn));
                    }
                    if (prodList[i].id2) {
                        merch.push('evar159=' + this.stripProductDelimiters(prodList[i].id2));
                    }
                    if (prodList[i].id3) {
                        merch.push('evar160=' + this.stripProductDelimiters(prodList[i].id3));
                    }
                    if (prodList[i].provider) {
                        merch.push('evar164=' + this.stripProductDelimiters(prodList[i].provider));
                    }
                    if (prodList[i].citationStyle) {
                        merch.push('evar170=' + this.stripProductDelimiters(prodList[i].citationStyle));
                    }

                    var biblio = this.getBibliographicInfo(prodList[i]);
                    if (biblio) {
                        merch.push('evar28=' + biblio);
                    }

                    if (prodList[i].turnawayId) {
                        pageData.eventList.push('product turnaway');
                    }

                    var price = prodList[i].price || '', qty = prodList[i].quantity || '', evts = [];
                    if (price && qty) {
                        qty = parseInt(qty || '1');
                        price = parseFloat(price || '0');
                        price = (price * qty).toFixed(2);

                        if (window.eventData && eventData.eventName && eventData.eventName == 'cartAdd') {
                            evts.push('event20=' + price);
                        }
                    }

                    var type = window.pageData && pageData.page && pageData.page.type ? pageData.page.type : '', evt = window.eventData && eventData.eventName ? eventData.eventName : '';
                    if (type.match(/^CP\-/gi) !== null && (!evt || evt == 'newPage' || evt == 'contentView')) {
                        evts.push('event181=1');
                    }
                    if (evt == 'contentDownload' || type.match(/^CP\-DL/gi) !== null) {
                        evts.push('event182=1');
                    }
                    if (evt == 'contentDownloadRequest') {
                        evts.push('event319=1');
                    }
                    if (evt == 'contentExport') {
                        evts.push('event184=1');
                    }
                    if (this.eventFires('recommendationViews')) {
                        evts.push('event264=1');
                    }

                    if(prodList[i].datapoints) {
                        evts.push('event239=' + prodList[i].datapoints);
                    }
                    if(prodList[i].documents) {
                        evts.push('event240=' + prodList[i].documents);
                    }
                    if(prodList[i].size) {
                        evts.push('event335=' + prodList[i].size);
                        evts.push('event336=1')
                    }

                    prods.push([
                        ''					// empty category
                        ,prodList[i].id		// id
                        ,qty				// qty
                        ,price				// price
                        ,evts.join('|')		// events
                        ,merch.join('|')	// merchandising eVars
                    ].join(';'));
                }
            }
        }

        return prods.join(',');
    }
    ,eventFires: function(eventName) {
      var evt = window.eventData && eventData.eventName ? eventData.eventName : '';
      if(evt == eventName) {
        return true;
      }
      // initial pageload and new pages
      if((!window.eventData || evt == 'newPage') && window.pageData && window.pageData.trackEvents) {
        var tEvents = window.pageData.trackEvents;
        for(var i=0; i<tEvents.length; i++) {
          if(tEvents[i] == eventName) {
            return true;
          }
        }
      }
      return false;
    }

    ,md5: function(s){function L(k,d){return(k<<d)|(k>>>(32-d))}function K(G,k){var I,d,F,H,x;F=(G&2147483648);H=(k&2147483648);I=(G&1073741824);d=(k&1073741824);x=(G&1073741823)+(k&1073741823);if(I&d){return(x^2147483648^F^H)}if(I|d){if(x&1073741824){return(x^3221225472^F^H)}else{return(x^1073741824^F^H)}}else{return(x^F^H)}}function r(d,F,k){return(d&F)|((~d)&k)}function q(d,F,k){return(d&k)|(F&(~k))}function p(d,F,k){return(d^F^k)}function n(d,F,k){return(F^(d|(~k)))}function u(G,F,aa,Z,k,H,I){G=K(G,K(K(r(F,aa,Z),k),I));return K(L(G,H),F)}function f(G,F,aa,Z,k,H,I){G=K(G,K(K(q(F,aa,Z),k),I));return K(L(G,H),F)}function D(G,F,aa,Z,k,H,I){G=K(G,K(K(p(F,aa,Z),k),I));return K(L(G,H),F)}function t(G,F,aa,Z,k,H,I){G=K(G,K(K(n(F,aa,Z),k),I));return K(L(G,H),F)}function e(G){var Z;var F=G.length;var x=F+8;var k=(x-(x%64))/64;var I=(k+1)*16;var aa=Array(I-1);var d=0;var H=0;while(H<F){Z=(H-(H%4))/4;d=(H%4)*8;aa[Z]=(aa[Z]| (G.charCodeAt(H)<<d));H++}Z=(H-(H%4))/4;d=(H%4)*8;aa[Z]=aa[Z]|(128<<d);aa[I-2]=F<<3;aa[I-1]=F>>>29;return aa}function B(x){var k="",F="",G,d;for(d=0;d<=3;d++){G=(x>>>(d*8))&255;F="0"+G.toString(16);k=k+F.substr(F.length-2,2)}return k}function J(k){k=k.replace(/rn/g,"n");var d="";for(var F=0;F<k.length;F++){var x=k.charCodeAt(F);if(x<128){d+=String.fromCharCode(x)}else{if((x>127)&&(x<2048)){d+=String.fromCharCode((x>>6)|192);d+=String.fromCharCode((x&63)|128)}else{d+=String.fromCharCode((x>>12)|224);d+=String.fromCharCode(((x>>6)&63)|128);d+=String.fromCharCode((x&63)|128)}}}return d}var C=Array();var P,h,E,v,g,Y,X,W,V;var S=7,Q=12,N=17,M=22;var A=5,z=9,y=14,w=20;var o=4,m=11,l=16,j=23;var U=6,T=10,R=15,O=21;s=J(s);C=e(s);Y=1732584193;X=4023233417;W=2562383102;V=271733878;for(P=0;P<C.length;P+=16){h=Y;E=X;v=W;g=V;Y=u(Y,X,W,V,C[P+0],S,3614090360);V=u(V,Y,X,W,C[P+1],Q,3905402710);W=u(W,V,Y,X,C[P+2],N,606105819);X=u(X,W,V,Y,C[P+3],M,3250441966);Y=u(Y,X,W,V,C[P+4],S,4118548399);V=u(V,Y,X,W,C[P+5],Q,1200080426);W=u(W,V,Y,X,C[P+6],N,2821735955);X=u(X,W,V,Y,C[P+7],M,4249261313);Y=u(Y,X,W,V,C[P+8],S,1770035416);V=u(V,Y,X,W,C[P+9],Q,2336552879);W=u(W,V,Y,X,C[P+10],N,4294925233);X=u(X,W,V,Y,C[P+11],M,2304563134);Y=u(Y,X,W,V,C[P+12],S,1804603682);V=u(V,Y,X,W,C[P+13],Q,4254626195);W=u(W,V,Y,X,C[P+14],N,2792965006);X=u(X,W,V,Y,C[P+15],M,1236535329);Y=f(Y,X,W,V,C[P+1],A,4129170786);V=f(V,Y,X,W,C[P+6],z,3225465664);W=f(W,V,Y,X,C[P+11],y,643717713);X=f(X,W,V,Y,C[P+0],w,3921069994);Y=f(Y,X,W,V,C[P+5],A,3593408605);V=f(V,Y,X,W,C[P+10],z,38016083);W=f(W,V,Y,X,C[P+15],y,3634488961);X=f(X,W,V,Y,C[P+4],w,3889429448);Y=f(Y,X,W,V,C[P+9],A,568446438);V=f(V,Y,X,W,C[P+14],z,3275163606);W=f(W,V,Y,X,C[P+3],y,4107603335);X=f(X,W,V,Y,C[P+8],w,1163531501);Y=f(Y,X,W,V,C[P+13],A,2850285829);V=f(V,Y,X,W,C[P+2],z,4243563512);W=f(W,V,Y,X,C[P+7],y,1735328473);X=f(X,W,V,Y,C[P+12],w,2368359562);Y=D(Y,X,W,V,C[P+5],o,4294588738);V=D(V,Y,X,W,C[P+8],m,2272392833);W=D(W,V,Y,X,C[P+11],l,1839030562);X=D(X,W,V,Y,C[P+14],j,4259657740);Y=D(Y,X,W,V,C[P+1],o,2763975236);V=D(V,Y,X,W,C[P+4],m,1272893353);W=D(W,V,Y,X,C[P+7],l,4139469664);X=D(X,W,V,Y,C[P+10],j,3200236656);Y=D(Y,X,W,V,C[P+13],o,681279174);V=D(V,Y,X,W,C[P+0],m,3936430074);W=D(W,V,Y,X,C[P+3],l,3572445317);X=D(X,W,V,Y,C[P+6],j,76029189);Y=D(Y,X,W,V,C[P+9],o,3654602809);V=D(V,Y,X,W,C[P+12],m,3873151461);W=D(W,V,Y,X,C[P+15],l,530742520);X=D(X,W,V,Y,C[P+2],j,3299628645);Y=t(Y,X,W,V,C[P+0],U,4096336452);V=t(V,Y,X,W,C[P+7],T,1126891415);W=t(W,V,Y,X,C[P+14],R,2878612391);X=t(X,W,V,Y,C[P+5],O,4237533241);Y=t(Y,X,W,V,C[P+12],U,1700485571);V=t(V,Y,X,W,C[P+3],T,2399980690);W=t(W,V,Y,X,C[P+10],R,4293915773);X=t(X,W,V,Y,C[P+1],O,2240044497);Y=t(Y,X,W,V,C[P+8],U,1873313359);V=t(V,Y,X,W,C[P+15],T,4264355552);W=t(W,V,Y,X,C[P+6],R,2734768916);X=t(X,W,V,Y,C[P+13],O,1309151649);Y=t(Y,X,W,V,C[P+4],U,4149444226);V=t(V,Y,X,W,C[P+11],T,3174756917);W=t(W,V,Y,X,C[P+2],R,718787259);X=t(X,W,V,Y,C[P+9],O,3951481745);Y=K(Y,h);X=K(X,E);W=K(W,v);V=K(V,g)}var i=B(Y)+B(X)+B(W)+B(V);return i.toLowerCase()}
    ,stripProductDelimiters: function(val) {
        if (val) {
            return val.replace(/\;|\||\,/gi, '-');
        }
    }

    ,setCookie: function(name, value, seconds, domain) {
        domain = document.location.hostname;
        var expires = '';
        var expiresNow = '';
        var date = new Date();
        date.setTime(date.getTime() + (-1 * 1000));
        expiresNow = "; expires=" + date.toGMTString();

        if (typeof(seconds) != 'undefined') {
            date.setTime(date.getTime() + (seconds * 1000));
            expires = '; expires=' + date.toGMTString();
        }

        var type = typeof(value);
        type = type.toLowerCase();
        if (type != 'undefined' && type != 'string') {
            value = JSON.stringify(value);
        }

        // fix scoping issues
        // keep writing the old cookie, but make it expire
        document.cookie = name + '=' + value + expiresNow + '; path=/';

        // now just set the right one
        document.cookie = name + '=' + value + expires + '; path=/; domain=' + domain;
    }

    ,getCookie: function(name) {
        name = name + '=';
        var carray = document.cookie.split(';'), value;

        for (var i=0; i<carray.length; i++) {
            var c = carray[i];
            while (c.charAt(0) == ' ') {
                c = c.substring(1, c.length);
            }
            if (c.indexOf(name) == 0) {
                value = c.substring(name.length, c.length);
                try {
                    value = JSON.parse(value);
                } catch(ex) {}

                return value;
            }
        }

        return null;
    }

    ,deleteCookie: function(name) {
        this.setCookie(name, '', -1);
        this.setCookie(name, '', -1, document.location.hostname);
    }

    ,mapAdobeVars: function(s) {
        var vars = {
            pageName		: 'Page - Analytics Pagename'
            ,channel		: 'Page - Section Name'
            ,campaign		: 'Campaign - ID'
            ,currencyCode	: 'Page - Currency Code'
            ,purchaseID		: 'Order - ID'
            ,prop1			: 'Visitor - Account ID'
            ,prop2			: 'Page - Product Name'
            ,prop4			: 'Page - Type'
            ,prop6			: 'Search - Type'
            ,prop7			: 'Search - Facet List'
            ,prop8			: 'Search - Feature Used'
            ,prop12			: 'Visitor - User ID'
            ,prop13			: 'Search - Sort Type'
            ,prop14			: 'Page - Load Time'
            ,prop15         : 'Support - Topic Name'
            ,prop16			: 'Page - Business Unit'
            ,prop21			: 'Search - Criteria'
            ,prop24			: 'Page - Language'
            ,prop25			: 'Page - Product Feature'
            ,prop28         : 'Support - Search Criteria'
            ,prop30			: 'Visitor - IP Address'
            ,prop33         : 'Page - Product Application Version'
            ,prop34         : 'Page - Website Extensions'
            ,prop60			: 'Search - Data Form Criteria'
            ,prop63			: 'Page - Extended Page Name'
            ,prop65         : 'Page - Online State'
            ,prop67         : 'Research Networks'
            ,prop40: 'Page - UX Properties'

            ,eVar3			: 'Search - Total Results'
            ,eVar7			: 'Visitor - Account Name'
            ,eVar15			: 'Event - Search Results Click Position'
            ,eVar19			: 'Search - Advanced Criteria'
            ,eVar21			: 'Promo - Clicked ID'
            ,eVar22			: 'Page - Test ID'
            ,eVar27			: 'Event - AutoSuggest Search Data'
            ,eVar157		: 'Event - AutoSuggest Search Typed Term'
            ,eVar156		: 'Event - AutoSuggest Search Selected Term'
            ,eVar162		: 'Event - AutoSuggest Search Category'
            ,eVar163		: 'Event - AutoSuggest Search Details'
            ,eVar33			: 'Visitor - Access Type'
            ,eVar34			: 'Order - Promo Code'
            ,eVar39			: 'Order - Payment Method'
            ,eVar41			: 'Visitor - Industry'
            ,eVar42			: 'Visitor - SIS ID'
            ,eVar43			: 'Page - Error Type'
            ,eVar44			: 'Event - Updated User Fields'
            ,eVar48			: 'Email - Recipient ID'
            ,eVar51			: 'Email - Message ID'
            ,eVar52			: 'Visitor - Department ID'
            ,eVar53			: 'Visitor - Department Name'
            ,eVar60			: 'Search - Within Content Criteria'
            ,eVar61			: 'Search - Within Results Criteria'
            ,eVar62			: 'Search - Result Types'
            ,eVar74			: 'Page - Journal Info'
            ,eVar59			: 'Page - Journal Publisher'
            ,eVar76			: 'Email - Broadlog ID'
            ,eVar78			: 'Visitor - Details'
            ,eVar80         : 'Visitor - Usage Path Info'
            ,eVar102		: 'Form - Name'
            ,eVar103        : 'Event - Conversion Driver'
            ,eVar105        : 'Search - Current Page'
            ,eVar106        : 'Visitor - App Session ID'
            ,eVar107        : 'Page - Secondary Product Name'
            ,eVar117        : 'Search - Database'
            ,eVar126        : 'Page - Environment'
            ,eVar141        : 'Search - Criteria Original'
            ,eVar143        : 'Page - Tabs'
            ,eVar161        : 'Search - Channel'
            ,eVar169        : 'Search - Facet Operation'
            ,eVar173        : 'Search - Details'
            ,eVar174        : 'Campaign - Spredfast ID'
            ,eVar175        : 'Visitor - TMX Device ID'
            ,eVar176        : 'Visitor - TMX Request ID'
            ,eVar148        : 'Visitor - Platform Name'
            ,eVar149        : 'Visitor - Platform ID'
            ,eVar152        : 'Visitor - Product ID'
            ,eVar153        : 'Visitor - Superaccount ID'
            ,eVar154        : 'Visitor - Superaccount Name'
            ,eVar177        : 'Page - Context Domain'
            ,eVar189    : 'Page - Experimentation User Id'
            ,eVar190    : 'Page - Identity User'
            ,eVar199    : 'Page - ID+ Parameters'

            ,list2			: 'Page - Widget Names'
            ,list3			: 'Promo - IDs'
        };

        for (var i in vars) {
            s[i] = s[i] ? s[i] : _satellite.getVar(vars[i]);
        }
    }
};

// async support fallback
(function(w) {
	var eventBuffer = [];
	if(w.appData) {
		if(Array.isArray(w.appData)) {
			eventBuffer = w.appData;
		} else {
			console.error('Elsevier DataLayer "window.appData" must be specified as array');
			return;
		}
    }

	w.appData = [];

	var oldPush = w.appData.push;

	var appDataPush = function() {
        oldPush.apply(w.appData, arguments);
        for(var i=0; i<arguments.length; i++) {
            var data = arguments[i];
            if(data.event) {
                if(data.event == 'pageLoad') {
                    w.pageDataTracker.trackPageLoad(data);
                } else {
                    w.pageDataTracker.trackEvent(data.event, data);
                }
            }
        }
	};

	w.appData.push = appDataPush;
	for(var i=0; i<eventBuffer.length; i++) {
	    var data = eventBuffer[i];
	    w.appData.push(data);
	}
})(window);

</script><script>_satellite["_runScript1"](function(event, target, Promise) {
_satellite.logger.log("eventDispatcher: clearing tracking state");try{s.events="",s.linkTrackVars="",s.linkTrackEvents=""}catch(e){_satellite.logger.log("eventDispatcher: s object - could not reset state.")}try{dispatcherData=JSON.parse(event.detail),window.ddqueue=window.ddqueue||[],window.ddqueue.push(dispatcherData),window.eventData=dispatcherData.eventData,window.pageData=dispatcherData.pageData,_satellite.track(dispatcherData.eventName)}catch(e){_satellite.logger.log("eventDispatcher: exception"),_satellite.logger.log(e)}
});</script><script src="https://cdn.plu.mx/widget-summary.js" async=""></script><script>_satellite["_runScript2"](function(event, target, Promise) {
_satellite.logger.log("eventDispatcher: clearing tracking state");try{s.events="",s.linkTrackVars="",s.linkTrackEvents=""}catch(e){_satellite.logger.log("eventDispatcher: s object - could not reset state.")}try{dispatcherData=JSON.parse(event.detail),window.ddqueue=window.ddqueue||[],window.ddqueue.push(dispatcherData),window.eventData=dispatcherData.eventData,window.pageData=dispatcherData.pageData,_satellite.track(dispatcherData.eventName)}catch(e){_satellite.logger.log("eventDispatcher: exception"),_satellite.logger.log(e)}
});</script><div class="js-react-modal"></div><div class="js-react-modal"></div><div class="js-react-modal"></div><div class="js-react-modal"></div><div class="js-react-modal"></div><div class="js-react-modal"></div><div class="js-react-modal"></div><div id="onetrust-consent-sdk"><div class="onetrust-pc-dark-filter ot-hide ot-fade-in"></div><div id="onetrust-pc-sdk" class="otPcCenter ot-hide ot-fade-in" lang="en" aria-label="Preference center" role="region"><div role="alertdialog" aria-modal="true" aria-describedby="ot-pc-desc" style="height: 100%;" aria-label="Cookie Preference Center"><!-- Close Button --><div class="ot-pc-header"><!-- Logo Tag --><div class="ot-pc-logo" role="img" aria-label="Company Logo"><img alt="Company Logo" src="https://cdn.cookielaw.org/logos/static/ot_company_logo.png"></div></div><!-- Close Button --><div id="ot-pc-content" class="ot-pc-scrollbar"><div class="ot-optout-signal ot-hide"><div class="ot-optout-icon"><svg xmlns="http://www.w3.org/2000/svg"><path class="ot-floating-button__svg-fill" d="M14.588 0l.445.328c1.807 1.303 3.961 2.533 6.461 3.688 2.015.93 4.576 1.746 7.682 2.446 0 14.178-4.73 24.133-14.19 29.864l-.398.236C4.863 30.87 0 20.837 0 6.462c3.107-.7 5.668-1.516 7.682-2.446 2.709-1.251 5.01-2.59 6.906-4.016zm5.87 13.88a.75.75 0 00-.974.159l-5.475 6.625-3.005-2.997-.077-.067a.75.75 0 00-.983 1.13l4.172 4.16 6.525-7.895.06-.083a.75.75 0 00-.16-.973z" fill="#FFF" fill-rule="evenodd"></path></svg></div><span></span></div><h2 id="ot-pc-title">Cookie Preference Center</h2><div id="ot-pc-desc">We use cookies which are necessary to make our site work. We may also use additional cookies to analyse, improve and personalise our content and your digital experience. For more information, see our <a href="https://www.elsevier.com/legal/cookienotice/_nocache" target="_blank">Cookie Policy</a> and the list of <a href="https://support.google.com/admanager/answer/9012903" target="_blank">Google Ad-Tech Vendors</a>.
<br>
<br>
You may choose not to allow some types of cookies. However, blocking some types may impact your experience of our site and the services we are able to offer. See the different category headings below to find out more or change your settings.
<br>
</div><button id="accept-recommended-btn-handler">Allow all</button><section class="ot-sdk-row ot-cat-grp"><h3 id="ot-category-title"> Manage Consent Preferences</h3><div class="ot-accordion-layout ot-cat-item ot-vs-config" data-optanongroupid="1"><button aria-expanded="false" ot-accordion="true" aria-controls="ot-desc-id-1" aria-labelledby="ot-header-id-1 ot-status-id-1"></button><!-- Accordion header --><div class="ot-acc-hdr ot-always-active-group"><div class="ot-plus-minus"><span></span><span></span></div><h4 class="ot-cat-header" id="ot-header-id-1">Strictly Necessary Cookies</h4><div id="ot-status-id-1" class="ot-always-active">Always active</div></div><!-- accordion detail --><div class="ot-acc-grpcntr ot-acc-txt"><p class="ot-acc-grpdesc ot-category-desc" id="ot-desc-id-1">These cookies are necessary for the website to function and cannot be switched off in our systems. They are usually only set in response to actions made by you which amount to a request for services, such as setting your privacy preferences, logging in or filling in forms. You can set your browser to block or alert you about these cookies, but some parts of the site will not then work. These cookies do not store any personally identifiable information.
<br><br></p><div class="ot-hlst-cntr"><button class="ot-link-btn category-host-list-handler" aria-label="Cookie Details List" data-parent-id="1">Cookie Details List‎</button></div></div></div><div class="ot-accordion-layout ot-cat-item ot-vs-config" data-optanongroupid="3"><button aria-expanded="false" ot-accordion="true" aria-controls="ot-desc-id-3" aria-labelledby="ot-header-id-3"></button><!-- Accordion header --><div class="ot-acc-hdr"><div class="ot-plus-minus"><span></span><span></span></div><h4 class="ot-cat-header" id="ot-header-id-3">Functional Cookies</h4><div class="ot-tgl"><input type="checkbox" name="ot-group-id-3" id="ot-group-id-3" role="switch" class="category-switch-handler" data-optanongroupid="3" checked="" aria-labelledby="ot-header-id-3"> <label class="ot-switch" for="ot-group-id-3"><span class="ot-switch-nob" aria-checked="true" role="switch" aria-label="Functional Cookies"></span> <span class="ot-label-txt">Functional Cookies</span></label> </div></div><!-- accordion detail --><div class="ot-acc-grpcntr ot-acc-txt"><p class="ot-acc-grpdesc ot-category-desc" id="ot-desc-id-3">These cookies enable the website to provide enhanced functionality and personalisation. They may be set by us or by third party providers whose services we have added to our pages. If you do not allow these cookies then some or all of these services may not function properly.</p><div class="ot-hlst-cntr"><button class="ot-link-btn category-host-list-handler" aria-label="Cookie Details List" data-parent-id="3">Cookie Details List‎</button></div></div></div><div class="ot-accordion-layout ot-cat-item ot-vs-config" data-optanongroupid="2"><button aria-expanded="false" ot-accordion="true" aria-controls="ot-desc-id-2" aria-labelledby="ot-header-id-2"></button><!-- Accordion header --><div class="ot-acc-hdr"><div class="ot-plus-minus"><span></span><span></span></div><h4 class="ot-cat-header" id="ot-header-id-2">Performance Cookies</h4><div class="ot-tgl"><input type="checkbox" name="ot-group-id-2" id="ot-group-id-2" role="switch" class="category-switch-handler" data-optanongroupid="2" checked="" aria-labelledby="ot-header-id-2"> <label class="ot-switch" for="ot-group-id-2"><span class="ot-switch-nob" aria-checked="true" role="switch" aria-label="Performance Cookies"></span> <span class="ot-label-txt">Performance Cookies</span></label> </div></div><!-- accordion detail --><div class="ot-acc-grpcntr ot-acc-txt"><p class="ot-acc-grpdesc ot-category-desc" id="ot-desc-id-2">These cookies allow us to count visits and traffic sources so we can measure and improve the performance of our site. They help us to know which pages are the most and least popular and see how visitors move around the site.</p><div class="ot-hlst-cntr"><button class="ot-link-btn category-host-list-handler" aria-label="Cookie Details List" data-parent-id="2">Cookie Details List‎</button></div></div></div><div class="ot-accordion-layout ot-cat-item ot-vs-config" data-optanongroupid="4"><button aria-expanded="false" ot-accordion="true" aria-controls="ot-desc-id-4" aria-labelledby="ot-header-id-4"></button><!-- Accordion header --><div class="ot-acc-hdr"><div class="ot-plus-minus"><span></span><span></span></div><h4 class="ot-cat-header" id="ot-header-id-4">Targeting Cookies</h4><div class="ot-tgl"><input type="checkbox" name="ot-group-id-4" id="ot-group-id-4" role="switch" class="category-switch-handler" data-optanongroupid="4" checked="" aria-labelledby="ot-header-id-4"> <label class="ot-switch" for="ot-group-id-4"><span class="ot-switch-nob" aria-checked="true" role="switch" aria-label="Targeting Cookies"></span> <span class="ot-label-txt">Targeting Cookies</span></label> </div></div><!-- accordion detail --><div class="ot-acc-grpcntr ot-acc-txt"><p class="ot-acc-grpdesc ot-category-desc" id="ot-desc-id-4">These cookies may be set through our site by our advertising partners. They may be used by those companies to build a profile of your interests and show you relevant adverts on other sites. If you do not allow these cookies, you will experience less targeted advertising.</p><div class="ot-hlst-cntr"><button class="ot-link-btn category-host-list-handler" aria-label="Cookie Details List" data-parent-id="4">Cookie Details List‎</button></div></div></div><!-- Groups sections starts --><!-- Group section ends --><!-- Accordion Group section starts --><!-- Accordion Group section ends --></section></div><section id="ot-pc-lst" class="ot-hide ot-hosts-ui ot-pc-scrollbar"><div id="ot-pc-hdr"><div id="ot-lst-title"><button class="ot-link-btn back-btn-handler" aria-label="Back"><svg id="ot-back-arw" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" x="0px" y="0px" viewBox="0 0 444.531 444.531" xml:space="preserve"><title>Back Button</title><g><path fill="#656565" d="M213.13,222.409L351.88,83.653c7.05-7.043,10.567-15.657,10.567-25.841c0-10.183-3.518-18.793-10.567-25.835
                    l-21.409-21.416C323.432,3.521,314.817,0,304.637,0s-18.791,3.521-25.841,10.561L92.649,196.425
                    c-7.044,7.043-10.566,15.656-10.566,25.841s3.521,18.791,10.566,25.837l186.146,185.864c7.05,7.043,15.66,10.564,25.841,10.564
                    s18.795-3.521,25.834-10.564l21.409-21.412c7.05-7.039,10.567-15.604,10.567-25.697c0-10.085-3.518-18.746-10.567-25.978
                    L213.13,222.409z"></path></g></svg></button><h3>Cookie List</h3></div><div class="ot-lst-subhdr"><div class="ot-search-cntr"><p role="status" class="ot-scrn-rdr"></p><input id="vendor-search-handler" type="text" name="vendor-search-handler" placeholder="Search…" aria-label="Cookie list search"> <svg xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" x="0px" y="0px" viewBox="0 -30 110 110" aria-hidden="true"><title>Search Icon</title><path fill="#2e3644" d="M55.146,51.887L41.588,37.786c3.486-4.144,5.396-9.358,5.396-14.786c0-12.682-10.318-23-23-23s-23,10.318-23,23
            s10.318,23,23,23c4.761,0,9.298-1.436,13.177-4.162l13.661,14.208c0.571,0.593,1.339,0.92,2.162,0.92
            c0.779,0,1.518-0.297,2.079-0.837C56.255,54.982,56.293,53.08,55.146,51.887z M23.984,6c9.374,0,17,7.626,17,17s-7.626,17-17,17
            s-17-7.626-17-17S14.61,6,23.984,6z"></path></svg></div><div class="ot-fltr-cntr"><button id="filter-btn-handler" aria-label="Filter" aria-haspopup="true"><svg role="presentation" aria-hidden="true" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" x="0px" y="0px" viewBox="0 0 402.577 402.577" xml:space="preserve"><title>Filter Icon</title><g><path fill="#fff" d="M400.858,11.427c-3.241-7.421-8.85-11.132-16.854-11.136H18.564c-7.993,0-13.61,3.715-16.846,11.136
      c-3.234,7.801-1.903,14.467,3.999,19.985l140.757,140.753v138.755c0,4.955,1.809,9.232,5.424,12.854l73.085,73.083
      c3.429,3.614,7.71,5.428,12.851,5.428c2.282,0,4.66-0.479,7.135-1.43c7.426-3.238,11.14-8.851,11.14-16.845V172.166L396.861,31.413
      C402.765,25.895,404.093,19.231,400.858,11.427z"></path></g></svg></button></div><div id="ot-anchor"></div><section id="ot-fltr-modal"><div id="ot-fltr-cnt"><button id="clear-filters-handler">Clear</button><div class="ot-fltr-scrlcnt ot-pc-scrollbar"><div class="ot-fltr-opts"><div class="ot-fltr-opt"><div class="ot-chkbox"><input id="chkbox-id" type="checkbox" class="category-filter-handler"> <label for="chkbox-id"><span class="ot-label-txt">checkbox label</span></label> <span class="ot-label-status">label</span></div></div></div><div class="ot-fltr-btns"><button id="filter-apply-handler">Apply</button> <button id="filter-cancel-handler">Cancel</button></div></div></div></section></div></div><section id="ot-lst-cnt" class="ot-host-cnt ot-pc-scrollbar"><div id="ot-sel-blk"><div class="ot-sel-all"><div class="ot-sel-all-hdr"><span class="ot-consent-hdr">Consent</span> <span class="ot-li-hdr">Leg.Interest</span></div><div class="ot-sel-all-chkbox"><div class="ot-chkbox" id="ot-selall-hostcntr"><input id="select-all-hosts-groups-handler" type="checkbox"> <label for="select-all-hosts-groups-handler"><span class="ot-label-txt">checkbox label</span></label> <span class="ot-label-status">label</span></div><div class="ot-chkbox" id="ot-selall-vencntr"><input id="select-all-vendor-groups-handler" type="checkbox"> <label for="select-all-vendor-groups-handler"><span class="ot-label-txt">checkbox label</span></label> <span class="ot-label-status">label</span></div><div class="ot-chkbox" id="ot-selall-licntr"><input id="select-all-vendor-leg-handler" type="checkbox"> <label for="select-all-vendor-leg-handler"><span class="ot-label-txt">checkbox label</span></label> <span class="ot-label-status">label</span></div></div></div></div><div class="ot-sdk-row"><div class="ot-sdk-column"><ul id="ot-host-lst"></ul></div></div></section></section><div class="ot-pc-footer ot-pc-scrollbar"><div class="ot-btn-container"> <button class="save-preference-btn-handler onetrust-close-btn-handler">Confirm my choices</button></div><!-- Footer logo --><div class="ot-pc-footer-logo"><a href="https://www.onetrust.com/products/cookie-consent/" target="_blank" rel="noopener noreferrer" aria-label="Powered by OneTrust Opens in a new Tab"><img alt="Powered by Onetrust" src="https://cdn.cookielaw.org/logos/static/powered_by_logo.svg" title="Powered by OneTrust Opens in a new Tab"></a></div></div><!-- Cookie subgroup container --><!-- Vendor list link --><!-- Cookie lost link --><!-- Toggle HTML element --><!-- Checkbox HTML --><!-- plus minus--><!-- Arrow SVG element --><!-- Accordion basic element --><span class="ot-scrn-rdr" aria-atomic="true" aria-live="polite"></span><!-- Vendor Service container and item template --></div><iframe class="ot-text-resize" sandbox="allow-same-origin" title="onetrust-text-resize" style="position: absolute; top: -50000px; width: 100em;" aria-hidden="true"></iframe></div></div><button aria-label="Feedback" type="button" id="_pendo-badge_9BcFvkCLLiElWp6hocDK3ZG6Z4E" data-layout="badgeBlank" class="_pendo-badge _pendo-badge_" style="z-index: 19000; margin: 0px; height: 32px; width: 128px; font-size: 0px; background: rgba(255, 255, 255, 0); padding: 0px; line-height: 1; min-width: auto; box-shadow: rgb(136, 136, 136) 0px 0px 0px 0px; border: 0px; float: none; vertical-align: baseline; cursor: pointer; position: absolute; top: 31848px; left: 912px;"><img id="pendo-image-badge-19b66351" src="https://pendo-static-5661679399600128.storage.googleapis.com/D_T2uHq_M1r-XQq8htU6Z3GjHfE/guide-media-75af8ddc-3c43-49fd-8836-cfc7e2c3ea60" alt="Feedback" data-_pendo-image-1="" class="_pendo-image _pendo-badge-image" style="display: block; height: 32px; width: 128px; box-shadow: rgb(136, 136, 136) 0px 0px 0px 0px; float: none; vertical-align: baseline;"></button></body></html>