Title,Authors,Year,Cited By,Dataset,Abstract,URL,Mentions_F1,Mentions_Accuracy,Mentions_Bias
The extended cohn-kanade dataset (ck+): A complete dataset for action unit and emotion-specified expression,"['P Lucey', 'JF Cohn', 'T Kanade', 'J Saragih']",2010,5134,CK+,"In 2000, the Cohn-Kanade (CK) database was released for the purpose of promoting research  into automatically detecting individual facial expressions. Since then, the CK database",https://ieeexplore.ieee.org/document/5543262,False,False,False
A Novel Platform for Detection of CK+ and CK− CTCs,"['CV Pecot', 'FZ Bischoff', 'JA Mayer', 'KL Wong', 'T Pham']",2011,225,CK+,"Metastasis is a complex, multistep process that begins with the epithelial–mesenchymal  transition (EMT). Circulating tumor cells (CTC) are believed to have undergone EMT and thus",https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3237635/,False,False,False
All circulating EpCAM+ CK+ CD45-objects predict overall survival in castration-resistant prostate cancer,"['FAW Coumans', 'CJM Doggen', 'G Attard', 'JS De Bono']",2010,241,CK+,Background Presence of five or more circulating tumor cells (CTC) in patients with metastatic  carcinomas is associated with poor survival. Although many objects positive for epithelial,https://pubmed.ncbi.nlm.nih.gov/20147742/,False,False,False
"Patterns of circulating tumor cells identified by CEP8, CK and CD45 in pancreatic cancer","['Y Zhang', 'F Wang', 'N Ning', 'Q Chen']",2015,102,CK+,"To improve the identification for CTCs with weak or negative CK and diploid CTCs in  pancreatic cancer, we combined immune‐staining of CK, CD45, DAPI and fluorescence in situ",https://pubmed.ncbi.nlm.nih.gov/25042121/,False,False,False
Detection of breast cancer cells in the peripheral blood is positively correlated with estrogen‐receptor status and predicts for poor prognosis,"['JJ Gaforio', 'MJ Serrano']",2003,181,CK+,We investigated whether detection of cytokeratin‐positive (CK+) cells in the peripheral blood  (PB) of breast cancer patients before chemotherapy could be a prognostic factor. Blood,https://pubmed.ncbi.nlm.nih.gov/14601059/,False,False,False
Optimal policies for the inventory problem with negotiable leadtime,['Y Fukuda'],1964,327,CK+,"In this paper we study the dynamic inventory problem in which amounts of stock ordered at  unit prices c k and c k+1 (c k > c k+1 ) are delivered, respectively, k and k + 1 periods later. It",https://www.jstor.org/stable/2627513,False,False,False
CD133 expression in circulating tumor cells from breast cancer patients: potential role in resistance to chemotherapy,"['R Nadal', 'FG Ortega', 'M Salido']",2013,122,CK+,"CD133 has been associated with cell properties such as self renewal, migration and  vasculogenic mimicry, potentially involved in generation of circulating tumor cells (CTCs). We",https://pubmed.ncbi.nlm.nih.gov/23661576/,False,False,False
Heterogeneous atypical cell populations are present in blood of metastatic breast cancer patients,"['MB Lustberg', 'P Balasubramanian', 'B Miller']",2014,126,CK+,"Introduction Circulating tumor cells (CTCs) are commonly isolated from the blood by  targeting the epithelial cell adhesion molecule (EpCAM) through positive selection. However,",https://breast-cancer-research.biomedcentral.com/articles/10.1186/bcr3622,False,False,False
Epithelial to mesenchymal transition markers expressed in circulating tumour cells of early and metastatic breast cancer patients,"['G Kallergi', 'MA Papadaki', 'E Politaki', 'D Mavroudis']",2011,452,CK+,"Introduction Epithelial to mesenchymal transition (EMT) is considered an essential process  in the metastatic cascade. EMT is characterised by upregulation of vimentin, Twist, Snail,",https://breast-cancer-research.biomedcentral.com/articles/10.1186/bcr2896,False,False,False
Detection of circulating cytokeratin-positive cells in the blood of breast cancer patients using immunomagnetic enrichment and digital microscopy,"['TE Witzig', 'B Bossy', 'T Kimlinger', 'PC Roche', 'JN Ingle']",2002,221,CK+,Purpose: To examine the feasibility for identifying and enumerating cytokeratin positive (CK+)  cells in the peripheral blood of breast cancer patients. Experimental Design: Blood,https://pubmed.ncbi.nlm.nih.gov/12006523/,False,False,False
The multiple mini-interview (MMI) for student selection in health professions training–a systematic review,"['A Pau', 'K Jeevaratnam', 'YS Chen', 'AA Fall', 'C Khoo']",2013,244,MMI,Background: The Multiple Mini-Interview (MMI) has been used increasingly for selection of  students to health professions programmes. Objectives: This paper reports on the evidence,https://pubmed.ncbi.nlm.nih.gov/24050709/,False,False,False
Advances in optical fiber sensors based on multimode interference (MMI): a review,"['K Wang', 'X Dong', 'MH Köhler', 'P Kienle']",2020,111,MMI,"This review presents MMI-based fiber sensors with a specific  The fundamentals of MMI-based  fiber sensors are briefly  sensors, MMI-based sensors with no-core fiber (NCF), MMI-based",https://ieeexplore.ieee.org/document/9162065,False,False,False
Low loss MMI couplers for high performance MZI modulators,"['DJ Thomson', 'Y Hu', 'GT Reed']",2010,171,MMI,"to below 1 dB/MMI without affecting the static extinction  ) MMI-based crossing structure  [10], and in MMI couplers in other material systems [11]. Other approaches are possible for MMI",https://ieeexplore.ieee.org/iel5/68/5577591/05540271.pdf,False,False,False
General matrix theory of self-imaging in multimode interference (MMI) couplers,"['JM Heaton', 'RM Jenkins']",1999,115,MMI,We present a simple and very general matrix method for predicting the properties of integrated  optical multimode interference (MMI) couplers with single-mode input and output guides.,http://ieeexplore.ieee.org/document/740707/,False,False,False
A compact and low-loss MMI coupler fabricated with CMOS technology,"['Z Sheng', 'Z Wang', 'C Qiu', 'L Li', 'A Pang']",2012,125,MMI,"of the MMI coupler was reduced to 0.2dB [13]. In this paper, a compact and low loss MMI  coupler  The footprint of the optimal MMI coupler is only ~3.6×11.5μm2 for the multimode region.",https://ieeexplore.ieee.org/document/6363508,False,False,False
Evidence regarding the utility of multiple mini-interview (MMI) for selection to undergraduate health programs: A BEME systematic review: BEME Guide No. 37,"['EL Rees', 'AW Hawarden', 'G Dent', 'R Hays', 'J Bates']",2016,155,MMI,"Background: In the 11 years since its development at McMaster University Medical School,  the multiple mini-interview (MMI) has become a popular selection tool. We aimed to",https://pubmed.ncbi.nlm.nih.gov/27050026/,False,False,False
Boosted MMI for model and feature-space discriminative training,"['D Povey', 'D Kanevsky', 'B Kingsbury']",2008,498,MMI,the MMI objective function (we use “fBMMI” if boosted MMI is  for the lower range of the MMI  objective function; this leads to  fixed value such as 7 for both MPE and MMI-based training.,https://www.danielpovey.com/files/icassp08_mmi.pdf,False,False,False
Design of an ultracompact MMI wavelength demultiplexer in slot waveguide structures,"['J Xiao', 'X Liu', 'X Sun']",2007,130,MMI,"connect the input/output channels and the MMI section for reducing excess loss. The modal   a MMI section of 119.8μm in length, which is only 27.5% length of that of the MMI coupler by",https://opg.optica.org/oe/fulltext.cfm?uri=oe-15-13-8300,False,False,False
MMI training for continuous phoneme recognition on the TIMIT database,"['S Kapadia', 'V Valtchev', 'SJ Young']",1993,155,MMI,"using MMI. A comprehensive set of results are presented comparing the ML and MMI training   HMMs show clear performance gains achieved by MMI training, and are comparable to the",https://ieeexplore.ieee.org/document/319349/,False,False,False
End-to-end Speech Recognition Using Lattice-free MMI.,"['H Hadian', 'H Sameti', 'D Povey', 'S Khudanpur']",2018,209,MMI,"LF-MMI setup outperforms other end-to-end approaches under similar conditions.  -MMI  and CTC will be briefly described, and then in Section 4 we will describe the end-to-end LF-MMI",https://www.danielpovey.com/files/2018_interspeech_end2end.pdf,False,False,False
Performance comparisons of facial expression recognition in JAFFE database,"['FY Shih', 'CF Chuang', 'PSP Wang']",2008,201,JAFFE,"Facial expression provides an important behavioral measure for studies of emotion, cognitive  processes, and social interaction. Facial expression recognition has recently become a",https://www.cin.ufpe.br/~rps/Artigos/Performance%20Comparisons%20of%20Facial%20Expression%20Recognition%20in%20Jaffe%20Database.pdf,False,False,False
Estimation of creatinine by the Jaffe reaction: a comparison of three methods,"['H Husdan', 'A Rapoport']",1968,588,JAFFE,"Total chromogen, true, and AutoAnalyzer methods of measuring serum and urine creatinine  by the Jaffe reaction were investigated. Some factors influencing this reaction were",https://pubmed.ncbi.nlm.nih.gov/5637963/,False,False,False
Exotica,['RL Jaffe'],2005,689,JAFFE,"The first evidence for quantum chromodynamics (QCD), the theory of the strong interactions,  came from the systematics of baryon and meson spectroscopy. An important early",,False,False,False
A Study of the Mechanism of the Jaffé Reaction,"['KG Blass', 'RJ Thibert', 'LK Lam']",1974,190,JAFFE,"A reaction structure for the Jaffe chromogen is proposed.  Jaffe reaction proposals have  been summarized in Table 1. A  account for the formation of the red Jaffe color were varied, and",https://d-nb.info/1207639168/34,False,False,False
Geographic localization of knowledge spillovers as evidenced by patent citations,"['AB Jaffe', 'M Trajtenberg']",1993,11517,JAFFE,"We compare the geographic location of patent citations with that of the cited patents, as  evidence of the extent to which knowledge spillovers are geographically localized. We find that",https://www.jstor.org/stable/2118401,False,False,False
Creatinine determination according to Jaffe—what does it stand for?,"['JR Delanghe', 'MM Speeckaert']",2011,317,JAFFE,", the Jaffe method is still popular due to its simplicity and low cost. However, few people are  aware that, in fact, Max Jaffe  The following paper highlights the discovery of Jaffe and its",https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4421578/,False,False,False
Plasma creatinine determination a new and specific Jaffe reaction method,['C Slot'],1965,738,JAFFE,All the methods devised to improve the specificity of Jaffe’s  out by measuring the total Jaffe  chromogen and calling it creatin The purpose of the present paper is to present a new Jaffe,https://pubmed.ncbi.nlm.nih.gov/5838275/,False,False,False
Rho GTPases: biochemistry and biology,"['AB Jaffe', 'A Hall']",2005,3868,JAFFE,Approximately one percent of the human genome encodes proteins that either regulate or are  regulated by direct interaction with members of the Rho family of small GTPases. Through,https://pubmed.ncbi.nlm.nih.gov/16212495/,False,False,False
"Technological opportunity and spillovers of R&D: evidence from firms' patents, profits and market value",['AB Jaffe'],1986,6097,JAFFE,"This paper presents evidence that firms' patents, profits and market value are systematically  related to the""technological position"" of firms' research programs. Further, firms are seen to """,https://www.jstor.org/stable/1816464,False,False,False
"Measures of response: RECIST, WHO, and new alternatives",['CC Jaffe'],2006,370,JAFFE,RECIST (Response Evaluation Criteria in Solid Tumors) is a widely employed method  introduced in 2000 to assess change in tumor size in response to therapy. The simplicity of the,https://pubmed.ncbi.nlm.nih.gov/16829648/,False,False,False
Time-frequency processing of nonstationary signals: Advanced TFD design to aid diagnosis with highlights from medical applications,"['B Boashash', 'G Azemi']",2013,118,TFD,", the TFD of the signal is calculated using a reduced interference TFD (RI-TFD) and is then  transformed into a 2-D binary image [1], [6], [7]. The maximum peaks in the TFD are found",https://ieeexplore.ieee.org/document/6633066,False,False,False
Characterization of a Second tfd Gene Cluster for Chlorophenol and Chlorocatechol Metabolism on Plasmid pJP4 in Ralstonia eutropha JMP134(pJP4),"['CM Laemmli', 'JHJ Leveau', 'AJB Zehnder']",2000,146,TFD,"Thus, the functions encoded by the tfd II genes seem to be redundant with respect to those  of the tfd I cluster. One reason why the tfd II genes do not disappear from plasmid pJP4 might",https://pubmed.ncbi.nlm.nih.gov/10894723/,False,False,False
Atomic scattering factors calculated from the TFD atomic model,"['LH Thomas', 'K Umeda']",1957,396,TFD,"Using the TFD electron density, recently published by one of us  TFD curve of the atomic  scattering factor per electron fo versus the Bethe variable~, from the TF universal curve. The TFD",https://pubs.aip.org/aip/jcp/article/26/2/293/203640/Atomic-Scattering-Factors-Calculated-from-the-TFD,False,False,False
ICDAR 2019 CROHME+ TFD: Competition on recognition of handwritten mathematical expressions and typeset formula detection,"['M Mahdavi', 'R Zanibbi', 'H Mouchere']",2019,155,TFD,"We summarize the tasks, protocol, and outcome for the 6th Competition on Recognition of  Handwritten Mathematical Expressions (CROHME), which includes a new formula detection in",https://ieeexplore.ieee.org/document/8978036,False,False,False
"… acid degradation by the 2, 4-dichlorophenoxyacetic acid (TFD) pathway of plasmid pJP4: mapping and characterization of the TFD regulatory gene, tfdR","['AR Harker', 'RH Olsen', 'RJ Seidler']",1989,124,TFD,"in the presence of an inducer of the TFD pathway, namely, TFD or 3-chlorobenzoate. A mutant   TFD pathway, and this allowed the metabolism of PAA in the absence of the inducer, TFD.",https://pubmed.ncbi.nlm.nih.gov/2914848/,False,False,False
"The Completely Sequenced Plasmid pEST4011 Contains a Novel IncP1 Backbone and a Catabolic Transposon Harboring tfd Genes for 2,4-Dichlorophenoxyacetic …","['E Vedler', 'M Vahter', 'A Heinaru']",2004,112,TFD,"The tfd genes of these two elements are homologous to the pJP4 tfd genes but are  gene  products except TfdD and TfdF are very similar to pJP4 tfd gene products, including TfdA (84%",https://www.ncbi.nlm.nih.gov/pmc/articles/PMC523222/,False,False,False
Deep learning approaches for facial emotion recognition: A case study on FER-2013,"['P Giannopoulos', 'I Perikos', 'I Hatzilygeroudis']",2018,207,FER-2013,"To that end, we experiment with GoogLeNet and Alexnet, two popular and wide used deep  learning methods, and we examine their performance on FER-2013 dataset. The results",https://link.springer.com/chapter/10.1007/978-3-319-66790-4_1,False,False,False
The facial emotion recognition (FER-2013) dataset for prediction system of micro-expressions face using the convolutional neural network (CNN) algorithm based …,"['L Zahara', 'P Musa', 'EP Wibowo', 'I Karim']",2020,134,FER-2013,Training process using dataset FER-2013 The data training process in this study utilizing  the FER2013 dataset has been preprocessed and called the dataset with the file name fer2013.,https://ieeexplore.ieee.org/abstract/document/9288560,False,False,False
Facial emotion recognition: State of the art performance on FER2013,"['Y Khaireddin', 'Z Chen']",2021,205,FER-2013,Facial emotion recognition (FER) is significant for human-computer interaction such as  clinical practice and behavioral description. Accurate and robust FER by computer models,https://arxiv.org/abs/2105.03588,False,False,False
Using CNN for facial expression recognition: a study of the effects of kernel size and number of filters on accuracy,"['A Agrawal', 'N Mittal']",2020,289,FER-2013,"This work tries to overcome this limitation by using FER-2013  accuracy is investigated using  FER-2013 dataset. Our major  –124, 2013) on FER-2013 dataset. These architectures can",https://link.springer.com/article/10.1007/s00371-019-01630-9,False,True,False
Deep neural networks with relativity learning for facial expression recognition,"['Y Guo', 'D Tao', 'J Yu', 'H Xiong', 'Y Li']",2016,127,FER-2013,"FER-2013 training set and fine tuned on the SFEW 2.0 and FER-2013 training sets; the test  samples are FER-2013  , which is the same as FER-2013 data. Figure 4 shows examples of",https://ieeexplore.ieee.org/document/7574736,False,False,False
Facial expression recognition using a hybrid CNN–SIFT aggregator,"['T Connie', 'M Al-Shabi', 'WP Cheah', 'M Goh']",2017,183,FER-2013,Table 1 shows the distributions of the expressions along the FER-2013 and CK+ datasets.  The FER-2013 has more samples than CK+ in all categories. Happiness is the most frequent,https://arxiv.org/abs/1608.02833,False,False,False
Facial expression recognition with CNN ensemble,"['K Liu', 'M Zhang', 'Z Pan']",2016,208,FER-2013,"newly released Facial Expression Recognition 2013 (FER2013) dataset. The dataset was   The overall accuracy of our model on the FER-2013 dataset is 65.03%, which is considered",https://ieeexplore.ieee.org/document/7756145,False,True,False
Facial emotion recognition of students using convolutional neural network,"['I Lasri', 'AR Solh', 'M El Belkacemi']",2019,112,FER-2013,"We trained our Convolutional Neural Network model using FER 2013 database which  includes seven emotions (happiness, anger, sadness, disgust, neutral, fear and surprise) The",https://ieeexplore.ieee.org/document/8942386,False,False,False
Dfew: A large-scale database for recognizing dynamic facial expressions in the wild,"['X Jiang', 'Y Zong', 'W Zheng', 'C Tang', 'W Xia']",2020,126,AFEW7.0,"Recently, facial expression recognition (FER) in the wild has gained a lot of researchers'  attention because it is a valuable topic to enable the FER techniques to move from the",https://arxiv.org/abs/2008.05924,False,False,False
Hierarchical committee of deep cnns with exponentially-weighted decision fusion for static facial expression recognition,"['BK Kim', 'H Lee', 'J Roh', 'SY Lee']",2015,167,SFEW2.0,We present a pattern recognition framework to improve committee machines of deep  convolutional neural networks (deep CNNs) and its application to static facial expression,https://dl.acm.org/doi/10.1145/2818346.2830590,False,False,False
Hierarchical committee of deep convolutional neural networks for robust facial expression recognition,"['BK Kim', 'J Roh', 'SY Dong', 'SY Lee']",2016,307,SFEW2.0,This paper describes our approach towards robust facial expression recognition (FER) for  the third Emotion Recognition in the Wild (EmotiW2015) challenge. We train multiple deep,https://link.springer.com/article/10.1007/s12193-015-0209-0,False,False,False
Multi-pie,"['R Gross', 'I Matthews', 'J Cohn', 'T Kanade']",2010,2679,Multi-PIE,In the experiments comparing performance on PIE and Multi-PIE we show results for matched   well as results using the full set of subjects available in Multi-PIE (labeled as “M-PIE Full”).,https://www.cs.cmu.edu/afs/cs/project/PIE/MultiPie/Multi-Pie/Home.html,False,False,False
Multi-task pose-invariant face recognition,"['C Ding', 'C Xu', 'D Tao']",2015,302,Multi-PIE,"The Multi-PIE [50] database contains images of 337 subjects,  for the pose problem on  Multi-PIE, we adopt the three most  its single-task baselines on MultiPIE to justify the significance of",https://ieeexplore.ieee.org/document/7006757,False,False,False
Multi-task convolutional neural network for pose-invariant face recognition,"['X Yin', 'X Liu']",2017,381,Multi-PIE,"This work utilizes all data in the Multi-PIE dataset [16], ie,  the full range of variations on  Multi-PIE. We also apply our method  tion study on the entire Multi-PIE. We achieve comparable or",https://ieeexplore.ieee.org/document/8080244,False,False,False
A deep neural network-driven feature learning method for multi-view facial expression recognition,"['T Zhang', 'W Zheng', 'Z Cui', 'Y Zong']",2016,381,Multi-PIE,"To evaluate the effectiveness of the proposed method, two nonfrontal facial expression  databases, namely BU-3DFE and Multi-PIE, are respectively used to testify our method and the",https://ieeexplore.ieee.org/abstract/document/7530823/,False,False,False
An efficient multimodal 2D+ 3D feature-based approach to automatic facial expression recognition,"['H Li', 'H Ding', 'D Huang', 'Y Wang', 'X Zhao']",2015,118,BU-3DFE,"We evaluate iPar–CLR on the whole BU–3DFE database and the expressive samples in  Bosphorus, and find that it can precisely localize all the pre-defined 49 facial landmarks for all",https://www.sciencedirect.com/science/article/pii/S1077314215001587,False,False,False
Morphable face models-an open framework,"['T Gerig', 'A Morel-Forster', 'C Blumer']",2018,310,BU-3DFE,"the BU-3DFE database, we compare our registrations to the landmarks, which are provided  with the BU-3DFE  to the positions that are provided with the BU-3DFE dataset. In Table I, the",https://arxiv.org/abs/1709.08398,False,False,False
Learning expressionlets on spatio-temporal manifold for dynamic facial expression recognition,"['M Liu', 'S Shan', 'R Wang', 'X Chen']",2014,455,Oulu-CASIA,"Oulu-CASIA VIS Database. The Oulu-CASIA VIS database [33] is a subset of the Oulu-CASIA  NIR-VIS database, in which all the videos were taken under the visible (VIS) light condition.",https://openaccess.thecvf.com/content_cvpr_2014/papers/Liu_Learning_Expressionlets_on_2014_CVPR_paper.pdf,False,False,False
Joint fine-tuning in deep neural networks for facial expression recognition,"['H Jung', 'S Lee', 'J Yim', 'S Park', 'J Kim']",2015,933,Oulu-CASIA,"For further experiments, we used Oulu-CASIA, which includes 480 image sequences taken  under normal illumination conditions. Each image sequence has one of six emotion labels:",http://ieeexplore.ieee.org/document/7410698/,False,False,False
Facenet2expnet: Regularizing a deep face recognition net for expression recognition,"['H Ding', 'SK Zhou', 'R Chellappa']",2017,489,Oulu-CASIA,"Evaluations on four public expression databases, CK+, OuluCASIA, TFD, and SFEW   experiments on both constrained (CK+, Oulu-CASIA, TFD) and unconstrained datasets (SFEW). For",https://arxiv.org/abs/1609.06591,False,False,False
A compact deep learning model for robust facial expression recognition,"['CM Kuo', 'SH Lai', 'M Sarkis']",2018,194,Oulu-CASIA,CK+ and Oulu-CASIA databases. We can see that the improvement on Oulu-CASIA database  is  are more weakexpression samples in Oulu-CASIA database which is hard to distinguish,https://openaccess.thecvf.com/content_cvpr_2018_workshops/papers/w41/Kuo_A_Compact_Deep_CVPR_2018_paper.pdf,False,False,False
Facial expression recognition by de-expression residue learning,"['H Yang', 'U Ciftci', 'L Yin']",2018,512,Oulu-CASIA,The Oulu-CASIA database [33] contains data captured under  The Oulu-CASIA VIS has 480  video sequences taken from  on recognizing six expressions on Oulu-CASIA over 10 runs is,https://ieeexplore.ieee.org/document/8578329,False,False,False
Identity-adaptive facial expression recognition through expression regeneration using conditional generative adversarial networks,"['H Yang', 'Z Zhang', 'L Yin']",2018,132,Oulu-CASIA,"+, Oulu-CASIA, BU- Oulu-CASIA database [16] contains two subsets: VIS and NIR. Here,  we only use the VIS subset, in which all videos were captured by VIS camera. The Oulu-CASIA",https://ieeexplore.ieee.org/document/8373843,False,False,False
Peak-piloted deep network for facial expression recognition,"['X Zhao', 'X Liang', 'L Liu', 'T Li', 'Y Han']",2016,369,Oulu-CASIA,"Extensive comparisons on two popular FER datasets, Oulu-CASIA and CK+, demonstrate  the superiority of the PPDN over state-of-the-art FER methods, as well as the advantages of",https://arxiv.org/abs/1607.06997,False,False,False
Facial expression recognition based on deep evolutional spatial-temporal networks,"['K Zhang', 'Y Huang', 'Y Du', 'L Wang']",2017,454,Oulu-CASIA,"On three widely used facial expression databases (CK+, Oulu-CASIA, and MMI), our method  reduces the error rates of the previous best ones by 45.5%, 25.8%, and 24.4%, respectively.",https://ieeexplore.ieee.org/document/7890464/,False,False,False
Deep spatial-temporal feature fusion for facial expression recognition in static images,"['N Sun', 'Q Li', 'R Huan', 'J Liu', 'G Han']",2019,116,RaFD,Traditional methods of performing facial expression recognition commonly use hand-crafted  spatial features. This paper proposes a multi-channel deep neural network that learns and,https://www.sciencedirect.com/science/article/pii/S0167865517303902,False,False,False
Facial expressions of emotion (KDEF): Identification under different display-duration conditions,"['MG Calvo', 'D Lundqvist']",2008,671,KDEF,"Out of the large KDEF database (70 models x 7  valid KDEF stimuli can be significantly  increased far beyond the current 40-model sample. For the present study, the original KDEF",https://link.springer.com/article/10.3758/BRM.40.1.109,False,False,False
The Karolinska directed emotional faces: a validation study,"['E Goeleven', 'R De Raedt', 'L Leyman']",2008,962,KDEF,"from the Karolinska Directed Emotional Faces database (KDEF). Pictures were evaluated  on  Hit rates, intensity, and arousal of the 20 best KDEF pictures for each basic emotion are",https://www.tandfonline.com/doi/abs/10.1080/02699930701626582,False,False,False
Karolinska directed emotional faces,"['D Lundqvist', 'A Flykt', 'A Öhman']",1998,3807,KDEF,The original KDEF database consists of a total of 490 JPEG pictures (72x72 dots per inch)  showing 70 individuals (35 women and 35 men) displaying 7 different emotional expressions (,https://kdef.se/,False,False,False
Facial emotion recognition using transfer learning in the deep CNN,"['MAH Akhand', 'S Roy', 'N Siddique', 'MAS Kamal']",2021,252,KDEF,") and well-known KDEF and JAFFE facial image datasets. FER on the KDEF dataset is more   Moreover, the achieved performance on the KDEF dataset with profile views is promising as",https://www.mdpi.com/2079-9292/10/9/1036,False,False,False
"Emotionet: An accurate, real-time algorithm for the automatic annotation of a million facial expressions in the wild","['C Fabian Benitez-Quiroz', 'R Srinivasan']",2016,685,EmotioNet,Research in face perception and emotion theory requires very large annotated databases of  images of facial expressions of emotion. Annotations should include Action Units (AUs) and,https://ieeexplore.ieee.org/document/7780969,False,False,False
Emotionet challenge: Recognition of facial expressions of emotion in the wild,"['CF Benitez-Quiroz', 'R Srinivasan', 'Q Feng']",2017,107,EmotioNet,This paper details the methodology and results of the EmotioNet challenge. This challenge  is the first to test the ability of computer vision algorithms in the automatic analysis of a large,https://arxiv.org/abs/1703.01210,False,False,False
Moel: Mixture of empathetic listeners,"['Z Lin', 'A Madotto', 'J Shin', 'P Xu', 'P Fung']",2019,238,EmotioNet,"acle emotion et information using a certain probability ϵoracle, and we gradually anneal it  during the training. We set an annealing rate γ = 1 × 10−3, and a threshold tthd equal to 1 ×",https://aclanthology.org/D19-1012,False,False,False
"Emotion recognition in conversation: Research challenges, datasets, and recent advances","['S Poria', 'N Majumder', 'R Mihalcea', 'E Hovy']",2019,447,EmotioNet,"Emotion is intrinsic to humans and consequently, emotion understanding is a key part of  human-like artificial intelligence (AI). Emotion recognition in conversation (ERC) is becoming",https://arxiv.org/abs/1905.02947,False,False,False
"Face behavior a la carte: Expressions, affect and action units in a single network","['D Kollias', 'V Sharmanska', 'S Zafeiriou']",2019,206,EmotioNet,"EmotioNet database Next, we performed zero-shot experiments on the EmotioNet basic and  compound set that was released for the related Challenge. This set includes 6 basic plus 10",https://arxiv.org/abs/1910.11111,False,False,False
Reliable crowdsourcing and deep locality-preserving learning for expression recognition in the wild,"['S Li', 'W Deng', 'JP Du']",2017,1683,RAF-DB,"database, RAF-DB,  , RAF-DB is the first database that contains compound expressions  in the wild. Our cross-database study shows that the action units of basic emotions in RAF-DB",https://ieeexplore.ieee.org/document/8099760,False,False,False
Region attention networks for pose and occlusion robust facial expression recognition,"['K Wang', 'X Peng', 'J Yang', 'D Meng']",2020,772,RAF-DB,"RAF-DB. Images with at least one type of occlusion are selected as the occlusion test sets.   Among all the occlusion types on FERPluse, AffectNet, and RAF-DB, the upper occlusion has",https://ieeexplore.ieee.org/document/8974606,False,False,False
Suppressing uncertainties for large-scale facial expression recognition,"['K Wang', 'X Peng', 'J Yang', 'S Lu']",2020,686,RAF-DB,"We evaluate δ2 from 0 to 0.5 on original RAF-DB, and show the results in Figure 5 (middle).   We study different ratios from 0.9 to 0.5 in both synthetic noisy and original RAF-DB dataset.",https://arxiv.org/abs/2002.10392,False,False,False
Robust lightweight facial expression recognition network with label distribution training,"['Z Zhao', 'Q Liu', 'F Zhou']",2021,219,RAF-DB,"RAF-DB The RAF-DB dataset contains 30,000 facial images annotated with basic or  compound expressions by 40 trained human coders. Consistent with the most previous work, only",https://ojs.aaai.org/index.php/AAAI/article/view/16465/16272,False,False,False
Facial expression recognition with visual transformers and attentional selective fusion,"['F Ma', 'B Sun', 'S Li']",2021,196,RAF-DB,"We also compare the effects of the MTE on RAF-DB, FERPlus and AffectNet. It is worth to  explain that we set the number of layers Nl ¼ 4 and the number of heads Nh ¼ 8 in Table 6 to",https://ieeexplore.ieee.org/document/9585378,False,False,False
Multi-region ensemble convolutional neural network for facial expression recognition,"['Y Fan', 'JCK Lam', 'VOK Li']",2018,168,RAF-DB,"To extract and align faces both from original images in RAF-DB and frames of videos in  AFEW 7.0, we use a C++ library, Dlib Footnote 3 face detector to locate the 68 facial landmarks.",https://arxiv.org/abs/1807.10575,False,False,False
"Affectnet: A database for facial expression, valence, and arousal computing in the wild","['A Mollahosseini', 'B Hasani']",2017,1958,AffectNet,"new database of facial emotions in the wild (called AffectNet). AffectNet contains more than  1,000,000 facial images from the  AffectNet is by far the largest database of facial expression,",https://arxiv.org/abs/1708.03985,False,False,False
"Face behavior a la carte: Expressions, affect and action units in a single network","['D Kollias', 'V Sharmanska', 'S Zafeiriou']",2019,206,AffectNet,multi-task learning framework was constructed for emotion recognition and valence-arousal  estimation; this work was based on a database (AffectNet [30]) annotated for both tasks. In,https://arxiv.org/abs/1910.11111,False,False,False
Robust lightweight facial expression recognition network with label distribution training,"['Z Zhao', 'Q Liu', 'F Zhou']",2021,219,AffectNet,"AffectNet-7 and AffectNet-8, in which the AffectNet-8 added expression of contempt based  on AffectNet-7.  of the eighth expression categories in the AffectNet test data (see Figure 4).",https://ojs.aaai.org/index.php/AAAI/article/view/16465/16272,False,False,False
Learning deep global multi-scale and local attention features for facial expression recognition in the wild,"['Z Zhao', 'Q Liu', 'S Wang']",2021,222,AffectNet,"Due to the AffectNet dataset has an imbalanced training set but a balanced validation set,  we  VI, we obtain 64.53% in term of FER accuracy on AffectNet with 7 expression categories,",https://ieeexplore.ieee.org/document/9474949,False,True,False
Deep neural network augmentation: Generating faces for affect analysis,"['D Kollias', 'S Cheng', 'E Ververas', 'I Kotsia']",2020,135,AffectNet,Let us note that for AffectNet no test set is released and thus we use the released validation  set to test on and randomly divide the training set into a training and a validation subset (with,https://arxiv.org/abs/1811.05027,False,False,False
Exponentially fitted symplectic integrator,"['TE Simos', 'J Vigo-Aguiar']",2003,117,ExpW,In this paper a procedure for constructing efficient symplectic integrators for Hamiltonian  problems is introduced. This procedure is based on the combination of the exponential fitting,https://www.sciencedirect.com/science/article/pii/S0010465505005795,False,False,False
Highly efficient temporal cleaner for femtosecond pulses based on cross-polarized wave generation in a dual crystal scheme,"['A Jullien', 'S Kourtev', 'O Albert', 'G Cheriaux', 'J Etchepare']",2006,108,ExpW,"rectly oriented second crystal, another field EXPW = αEXPW,  As EXPW and EXPW result  from the same process in the  on the two samples, EXPW and EXPW are then spatially identical",https://link.springer.com/article/10.1007/s00340-006-2334-7,False,False,False
Construction of trigonometrically and exponentially fitted Runge–Kutta–Nyström methods for the numerical solution of the schrödinger equation and related problems …,"['Z Kalogiratou', 'TE Simos']",2002,115,ExpW,General conditions are presented for an m-stage Runge–Kutta–Nyström fitting to exponential  and trigonometric functions. As an example an 8th order Runge–Kutta–Nyström method is,https://link.springer.com/article/10.1023/A:1016231100377,False,False,False
